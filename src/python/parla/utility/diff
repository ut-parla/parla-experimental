diff --git a/src/python/parla/utility/execute.py b/src/python/parla/utility/execute.py
index 1937985..b76d675 100644
--- a/src/python/parla/utility/execute.py
+++ b/src/python/parla/utility/execute.py
@@ -102,7 +102,7 @@ def get_placement_set_from(ps_str_set, num_gpus):
             ps_set.append(gpu(3)[{"vcus":1000}])
         elif dev_type >= DeviceType.USER_CHOSEN_DEVICE:
             gpu_idx = (dev_type - DeviceType.USER_CHOSEN_DEVICE) % num_gpus
-            ps_set.append(gpu(gpu_idx)[{"vcus":1000}])
+            ps_set.append(gpu[{"vcus:":1000}](gpu_idx))
         else:
             raise ValueError("Does not support this placement:", dev_type)
     return tuple(ps_set)
@@ -253,8 +253,8 @@ def create_task_no_data(task, taskspaces, config, data_list=None):
         if config.gil_fraction is not None:
             gil_fraction = config.gil_fraction
 
-        #print("task idx:", task_idx, " dependencies:", dependencies, " vcu:", device_fraction,
-        #      " placement:", placement_set)
+        print("task idx:", task_idx, " dependencies:", dependencies, " vcu:", device_fraction,
+              " placement:", placement_set, " placement key:", placement_set_str)
 
         @spawn(taskspace[task_idx], dependencies=dependencies, vcus=device_fraction, placement=[placement_set])
         async def task_func():
@@ -423,10 +423,8 @@ def create_task_lazy_data(task, taskspaces, config=None, data_list=None):
 
         if config.gil_fraction is not None:
             gil_fraction = config.gil_fraction
-        '''
         print("task idx:", task_idx, " dependencies:", dependencies, " vcu:", device_fraction,
             " placement:", placement_set)
-        '''
         @spawn(taskspace[task_idx], dependencies=dependencies, vcus=device_fraction, placement=[placement_set])
         async def task_func():
             if config.verbose:
@@ -716,7 +714,7 @@ class GraphContext(object):
 
         with open(self.tmpfilepath, 'w') as tmpfile:
             graph = self.graph_function(self.config)
-            #print(graph)
+            print(graph)
             tmpfile.write(graph)
 
         self.data_config, self.graph = read_pgraph(self.tmpfilepath)
diff --git a/src/python/parla/utility/graphs.py b/src/python/parla/utility/graphs.py
index b7c0ee7..0b3879d 100644
--- a/src/python/parla/utility/graphs.py
+++ b/src/python/parla/utility/graphs.py
@@ -627,6 +627,7 @@ def generate_serial_graph(config: SerialConfig) -> str:
 
 def generate_reduction_graph(config: ReductionConfig) -> str:
     task_config = config.task_config
+    num_gpus = config.num_gpus
     configurations = task_config.configurations
 
     graph = ""
@@ -654,11 +655,15 @@ def generate_reduction_graph(config: ReductionConfig) -> str:
     #           but for now, we only consider a single device placement and so,  
     #           follow the old generator's graph generation rule.
 
-    for device_id, task_config in configurations.items():
-        last_flag = 1 if device_id == list(
+    device_id = DeviceType.ANY_GPU_DEVICE
+    for config_device_id, task_config in configurations.items():
+        last_flag = 1 if config_device_id == list(
             configurations.keys())[-1] else 0
 
         post_configuration_string += f"{task_config.task_time}, {task_config.device_fraction}, {task_config.gil_accesses}, {task_config.gil_fraction}, {task_config.memory} }}"
+        # TODO(hc): This should be refined.
+        #           If users did not set "fixed", then it should be any cpu or gpu.
+        device_id = config_device_id
 
         if last_flag == 0:
             post_configuration_string += ", "
@@ -667,7 +672,7 @@ def generate_reduction_graph(config: ReductionConfig) -> str:
     global_idx = 0
     for i in range(config.levels, -1, -1):
         total_tasks_in_level = config.branch_factor ** i
-        segment = total_tasks_in_level / 4
+        segment = total_tasks_in_level / num_gpus
         for j in range(total_tasks_in_level):
             if reverse_level > 0:
                 dependency_string  = " "
@@ -694,6 +699,7 @@ def generate_reduction_graph(config: ReductionConfig) -> str:
                 write_dependency = f"{global_idx}"
             device_id = 1
             if config.fixed_placement:
+                # USER_CHOSEN_DEVICE acts as an offset.
                 device_id = int(DeviceType.USER_CHOSEN_DEVICE + j // segment)
             pre_configuration_string = f"{{ {device_id} : "
             configuration_string = pre_configuration_string + post_configuration_string
