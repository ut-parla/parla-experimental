{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Parla","text":"<p>The classical C++ Doxygen Style documentation cane be found [here]](doxygen/html/index.html). This includes callgraph and inheritance diagrams.</p>"},{"location":"runtime/","title":"Runtime","text":"<p>This is a sample runtime comment.</p>"},{"location":"tutorial/","title":"Parla Tutorial","text":"<p>This tutorial serves as a quick start guide to working with Parla.  Before starting the tutorial, be sure to install Parla using the instructions in the top-level README.  Each lesson in this tutorial has its own README which introduces a new feature of Parla.  Accompanying source code demonstrates that feature.</p>"},{"location":"tutorial/#setup","title":"Setup","text":"<p>For this tutorial, we provide a Parla container that could be used out of the box. To get a shell inside the provided docker container run</p> <pre><code>docker run --gpus all --rm -it utpecos/parla\n</code></pre> <p>In this container, a Parla repo with tutorial branch is put at the root of HOME directory.</p> <p>Depending on your Docker configuration, you may need to run this command as root using sudo or some other method. Since CUDA is required for all the demos, you must provide some GPUs for the docker container to use. For this to work using the command shown, you need to use Docker 19.03 or later.</p>"},{"location":"tutorial/#lessons","title":"Lessons","text":"<ol> <li>Hello World!  </li> <li>Run your first Parla program.  </li> <li>Intro to Tasks  </li> <li>Create TaskSpaces and Task IDs.  </li> <li>Express dependencies and order between tasks.  </li> <li>Wait on task completion.  </li> <li>More on Tasks  </li> <li>Run tasks in loops.  </li> <li>Call external libraries.  </li> <li>Capture external variables in tasks.  </li> <li>Devices and Architectures  </li> <li>Place tasks on specific devices and architectures.  </li> <li>Create specialized function variants.  </li> <li>Data Movement  </li> <li>Easily move data between devices.  </li> <li>Automatically partition and move data.  </li> <li>Task Constraints  </li> <li>Limit resource usage of tasks.  </li> </ol>"},{"location":"tutorial/#completion","title":"Completion","text":"<p>After completing the tutorial, check out Parla.py/examples to see Parla features used in real applications. </p>"},{"location":"tutorial/0_hello_world/","title":"Lesson 0: Hello, World!","text":"<p>We create our first Parla program and print to the console from a Parla task.</p> <p>There is only one source code file for this lesson: <code>hello.py</code></p> <p>If Parla is installed properly, you can run this example as you would any other Python script:</p> <pre><code>$ python hello.py\n</code></pre> <p>Parla's parallel programming model is centered around tasks. Tasks are a basic unit of work. Specifically in Parla, tasks are annotated code blocks that run asynchronously with respect to their enclosing block.</p> <p>Although syntactically tasks often look like Python functions, they are semantically different. Parla tasks are not functions in the usual sense: the Parla runtime can launch tasks as soon as they are spawned; they capture local variables in the closure by value; they cannot be called by user-code, and, typically, they do not return values.</p> <p>Tasks: - can be defined with dependencies. This creates an online &amp; dynamic workflow DAG that begins execution as it is spawned. - may run asynchronously and concurrently with other tasks. - may have various constraints (device, memory, data, threads) on where and when they can execute. - can launch on different hardware contexts. - can specify input and output data objects to prefetch required data into device memory.</p> <p>We will discuss more advantaged usage and features of tasks later. For now, we define a single, simple task.</p> <p>We break down this program line by line:</p> <p>First, lines 13 - 19:</p> <pre><code>13  from parla import Parla, spawn\n...\n15  from parla.cpu import cpu\n</code></pre> <p>Line 13 imports the context manager for the Parla runtime and the <code>@spawn</code> decorator for instantiating tasks.</p> <p>Line 15 loads and configures the <code>cpu</code> device type which is needed to have a valid target for task execution.</p> <p>We'll temporarily skip ahead to lines 28 - 30:</p> <pre><code>28  if __name__ == \"__main__\":\n29      with Parla():\n30          main()\n</code></pre> <p>Line 29 enters and starts the Parla runtime. This creates a threadpool and begins running a scheduler that will listen for spawned tasks. The scheduler can dispatch tasks to all configured device types (defined at import time) before it is initialized.</p> <p>All Parla code must execute within the Parla context manager.</p> <p>Notice that we do not directly create Parla tasks in the global scope. Instead, we define a <code>main</code> function and create our tasks there. To ensure correct capture of local variables, Parla tasks should not be defined in the global scope.</p> <p>And finally, our <code>main</code> function defined on lines 20 - 25:</p> <pre><code>20 def main():\n21\n22     # ...\n23     @spawn()\n24     def hello_world():\n25        print(\"Hello, World!\", flush=True)\n</code></pre> <p>On line 25, the <code>@spawn</code> decorator creates a task that executes the function it decorates. As soon as the task is spawned, it is visible to the runtime and may begin asynchronous execution.</p> <p>In this example, the task is not guaranteed to complete until the Parla context is exited on line 31 (which waits for all unfinished tasks).</p> <p>Once run, you should see \"Hello, World!\" the console output. Congratulations! You've run your first Parla program!</p>"},{"location":"tutorial/1_control_flow/","title":"Lesson 1: Control Flow","text":""},{"location":"tutorial/1_control_flow/#how-to-manage-parla-tasks","title":"How to manage Parla tasks","text":"<p>Parla supports flexible task management. Here we introduce features to organize tasks and control their order of execution.</p>"},{"location":"tutorial/1_control_flow/#taskspaces","title":"TaskSpaces","text":"<p>Tasks are organized through TaskSpaces, an indexible collection of tasks. You can think of these as a kind of namespace for task ids.</p> <p>A TaskSpace can be indexed by any hashable value. Although, for ease of use and interpretability, we highly recommend sticking to sets of integers. TaskSpaces can be indexed in arbitrary dimension.</p> <p>In Parla 0.2, please only use strings of length 1 for TaskSpace keys.</p> <p>The use of TaskSpaces can be seen in <code>0_taskspaces.py</code>:</p> <pre><code>    task_space = TaskSpace(\"Your First TaskSpace\")\n\n    @spawn(taskid=task_space[0])\n    async def task_0():\n        print('I am task 0', flush=True)\n</code></pre> <p>The 'taskid' argument to <code>@spawn</code> is the name of the task. This name as a (TaskSpace + Index) combination must be unique during the lifetime of the Parla runtime. If a taskid is not specified, the task will be placed into a default global TaskSpace.</p> <p><code>0_taskspaces.py</code> shows different ways to add a task to a TaskSpace.</p>"},{"location":"tutorial/1_control_flow/#task-dependencies","title":"Task Dependencies","text":"<p>Tasks can be ordered by specifying dependencies between them. If TaskB depends on TaskA then TaskB will be guaranteed to execute only after TaskA has completed.</p> <p>Dependencies can be specified by passing a list of taskids to the <code>dependencies</code> argument of <code>@spawn</code>. This is the second argument and may be specified without a keyword.</p> <pre><code>    space_A = TaskSpace(\"TaskSpace A\")\n    @spawn(space_A[0])\n    async def task_A():\n        print('I am taskA', flush=True)\n\n    @spawn(space_A[1], dependencies=[space_A[0]])\n    async def task_B():\n        print('I am taskB', flush=True)\n</code></pre> <p>Dependencies can be specified across any number of TaskSpaces. Tasks do not need to be within the same TaskSpace to depend on each other.</p> <p>TaskSpaces can be sliced with standard Python syntax.</p> <pre><code>    @spawn(space_B[0], dependencies=[space_A[0:2]])\n    async def task_C():\n        print('I am taskC', flush=True)\n</code></pre> <p>For example, the above task_C will depend on the first 2 entries of TaskSpace <code>space_A</code>.</p> <p>Tasks can be spawned out of order. A tasks dependencies do not need to have been before being listed through the TaskSpace.</p> <p>Examples of different ways to specify task dependencies can be seen in <code>1_dependencies.py</code>.</p>"},{"location":"tutorial/1_control_flow/#barriers","title":"Barriers","text":"<p>Barriers are used to synchronize execution of tasks. They block a task's execution until all tasks listed in the barrier have completed.</p> <p>Parla uses Python's asyncio <code>async/await</code> semantics to wait on task execution. This means any task that contains a barrier must be declared <code>async def</code> and spawned normally with <code>@spawn</code>.</p> <pre><code>    @spawn(taskid=task_space[0])\n    async def task_0():\n        print('I am task 0', flush=True)\n        await tasks\n        print('I am task 0 again', flush=True)\n</code></pre> <p>Although it looks like an <code>async def</code> task has an asynchronous body, the task will still wait for its body to fully complete before the task is marked as completed. Tasks can wait on tasks that are not marked <code>async def</code>.</p> <p>Barriers are a special (implicit) type of dependency. When a task encounters a barrier, it will release control of its worker thread and spawn a new continuation of itself as a separate task. As a consequence, Barriers can only be used within tasks and cannot be used in the outermost non-task scope.</p> <p>This new task will have the targets of the barrier added to its dependency list. The continuation will only execute after all tasks listed in the barrier have completed.</p> <p>The use of barriers can be seen in <code>2_barriers.py</code>. One can wait on individual taskid, on a TaskSpace, or on a task handle.</p>"},{"location":"tutorial/2_variable_capture_and_return/","title":"Lesson 2: Scoping and Returns","text":"<p>This section introduces further detail on how to use tasks. Specifically, we discuss how tasks are different than normal python functions, how one could return variables created within a task, and some general advice for writing performant Parla applications.</p>"},{"location":"tutorial/2_variable_capture_and_return/#semantics-of-variable-capture","title":"Semantics of Variable Capture","text":"<p>As mentioned in Lesson 0, Parla tasks are NOT python functions. Here we highlight that they modify the usual Pythonic scoping and variable-capture semantics.</p> <p>When spawned Parla tasks capture variables from the enclosing scope by value. If a variable is reassigned in the outer scope after spawning a task, it will not affect the value observed within the task.</p> <p>This capture makes it possible to spawn tasks in a loop where each task holds values from the iteration that spawned it. This preserves sequential semantics when writing parallel code.</p> <p>We've actually been using this all along in the tutorial, but to make it explicit consider the following chain of tasks:</p> <pre><code>   for i in range(3):\n       # Define a dependency chain\n       dep = [T[i - 1]] if i &gt; 0 else []\n\n       #Spawn a chain of tasks\n       @spawn(T[i], dependencies=dep)\n       def task():\n           # Reference a nonlocal variable 'i' (copied by value)\n           nonlocal i\n           # Add 4 to the now-local variable 'i'\n           i = i + 4\n           # Output to the console the value of the local 'i'\n           print(\"Check Task State [\", i, \"]\", flush=True)\n</code></pre> <p>Parla ensures that the output is <code>4 5 6</code> not <code>4, 8, 12</code>, <code>6, 7, 8</code>, or undefined behavior.</p> <p>The capture-by-value is a shallow copy. For non-primitive types any underlying data buffers will be shared.</p> <pre><code>   import numpy as np\n\n   shared_array = np.zeros(3)\n   for i in range(3):\n       @spawn(T[i])\n       def task():\n           shared_array[i] = i\n\n    await T\n    print(shared_array, flush=True)\n</code></pre> <p>All tasks have a local shallow-copy of the <code>shared_array</code> NumPy ndarray. The tasks all share the same data buffer and can update it concurrently. These changes are reflected in the outer-scope.</p> <p>As tasks can write to a shared buffer, the user must be careful of race conditions when defining task dependencies!</p> <p>Note: Parla can only capture local variables. Any variables in the global namespace will be captured by reference and are vulnerable to race conditions and undefined behavior. For most use-cases, we recommend only defining Parla tasks in a local scope.</p>"},{"location":"tutorial/2_variable_capture_and_return/#returning-values-from-tasks","title":"Returning values from Tasks","text":"<p>The most common way to return data from a task is to write back to a shared buffer, like the NumPy example above. For passing back general objects, you can write back to lists or dictionaries from the outer scope.</p> <pre><code>   shared_dictionary = {}\n\n   for i in range(3):\n       @spawn(T[i])\n       def task():\n           local_array = np.random.rand(3)\n           shared_dictionary[i] = local_array\n\n    await T\n    print(shared_dictionary, flush=True)\n</code></pre> <p>Tasks can also return values through a synchronization point. Individual tasks (either through the handle or the task-id) can be awaited to get the return value of the task.</p> <pre><code>    for i in range(3):\n         @spawn(T[i])\n         def task():\n              local_array = np.random.rand(3)\n              return local_array\n\n    array1 = await T[0]\n    array2 = await T[1]\n    array3 = await T[2]\n</code></pre> <p>At the moment, there are no data futures in Parla.</p>"},{"location":"tutorial/2_variable_capture_and_return/#general-advice-for-writing-tasks","title":"General Advice for Writing Tasks","text":"<p>Unlike many Python tasking systems, Parla tasks are run within a thread-based environment. All tasks execute within the same process and, unfortunately, share the same Python interpreter (if run with CPython). All tasks need to acquire the Python Global Interpreter Lock (GIL) to execute any lines of native Python code. This means any pure Python will execute serially and not show parallel speedup.</p> <p>Tasks only achieve true parallelism when they call out to compiled libraries and external code that releases the GIL, such as Numpy, Cupy, or jit-compiled Numba kernels. Parla is well-suited for parallelism in compute-heavy domains, but less-suited to workloads that need to execute many routines with native-Python-implemented libraries (like SymPy).</p> <p>To write code that performs well in Parla, tasks should avoid holding and accessing the GIL as much as possible. For a 50ms task, the GIL should be held for less than 5\\% of the total task-time to avoid noticeable overheads.</p> <p>Launching tasks with threads, however, does give us some advantages. Tasks share the same address space, allowing copyless operations on any memory buffers. We do not need to worry about managing or importing separate module lists in different persistent-Python processes, and any <code>jit</code> compilation by Numba or other external libraries will be automatically reused between subsequent tasks.</p>"},{"location":"tutorial/3_devices_and_architectures/","title":"Lesson 3: Devices and Architectures","text":"<p>Parla provides features to organize execution on heterogeneous architectures. We currently only support Nvidia GPUs, but have active development on AMD GPU support and plan to extend to other device types and accelerators in the future.</p> <p>When launching a task, the user can list a <code>placement</code> constraint to specify a specific device or type of device that the task can launch on.</p> <p>This lesson introduces task placements in Parla through the following simple examples: <code>cpu.py</code>, <code>gpu.py</code>, and <code>hetero_devices.py</code></p> <p>To run these examples, you need at least 2 GPU devices, a CUDA driver &amp; runtime, and CuPy.</p> <p>We use an element-wise vector addition operation as the main computation of a task.</p>"},{"location":"tutorial/3_devices_and_architectures/#device-initialization","title":"Device Initialization","text":"<p>In the first three lessons you've already been running tasks on the CPU. By default, Parla schedules an unlabeled task on any of the initialized device. So far the lessons have only initialized CPU devices through the following import:</p> <pre><code>from parla.cpu import cpu\n</code></pre> <p>This configures and adds a \"CPU\" device to the runtime using your system's information. The <code>cpu</code> object is the general class of \"CPU\" type devices.</p> <p>If you want to activate all CUDA devices on the machine, you can import the <code>cuda</code> module. Note that this requires a CUDA runtime and CuPy.</p> <pre><code>from parla.cuda import gpu\n</code></pre> <p>This will initialize all devices seen by the <code>CUDA_VISIBLE_DEVICES</code> environment variable. The <code>gpu</code> object represents the general class of \"CUDA GPU\" type devices. Querying <code>gpu(i)</code> returns the specific <code>i</code>th device.</p> <p>All devices your application uses must be initialized before the Parla runtime context manager is entered.</p>"},{"location":"tutorial/3_devices_and_architectures/#task-placement","title":"Task Placement","text":"<p>The spawn decorator takes a <code>placement</code> argument. Placement takes a device type, device, ndarray, or task.</p> <p>If the argument is a device type, then the task may be scheduled on any available device of the specified type. If it is a specific device, the task will only be scheduled on that device. If it is an ndarray (cupy or numpy), the task will be scheduled on the device that holds that data at spawn time. If the placement argument is a task, then the spawning task will be scheduled on the same device as the argument task.</p> <p>For example, the following will constrain a task to only execute on a gpu.</p> <pre><code>@spawn(placement=gpu)\n</code></pre> <p>And the following will constrain a task to only execute on the <code>0</code>th gpu.</p> <pre><code>@spawn(placement=gpu(0))\n</code></pre> <p>Placement can also take a list of objects. In this case, the task could be scheduled on any of the specified devices.</p> <p>Specify task placements through <code>ndarray</code> objects. This task will be launched to either of devices where <code>x</code> or <code>y</code> was defined when this task was spawned.</p> <pre><code>x = np.ones(10)\nwith cp.cuda.Device(1):\n    y = cp.ones(10)\n@spawn(placement=[x, y])\ndef task():\n    //do work\n</code></pre> <p>The below is an output of <code>cpu.py</code>.</p> <pre><code>Spawns a CPU architecture task.\nCPU kernel is called..\nOutput&gt;&gt; 6 8 10 12\n\nSpecifies a placement through data location\nThis should be running on CPU\nSpawns a single task on CPU\nCPU kernel is called..\nOutput&gt;&gt; 6 8 10 12\n</code></pre>"},{"location":"tutorial/3_devices_and_architectures/#relative-data-movement","title":"Relative Data Movement","text":"<p>In <code>gpu.py</code>, all data is initialized on the host. Each task must first should copy their corresponding slice to device memory. To simplify data movements between devices at runtime, Parla provides the following APIs: <code>clone_here()</code> and <code>copy()</code>. <code>clone_here()</code> copies a data to the current device memory regardless of the data's location. <code>copy()</code> copies data between arrays regardless of their current locations.</p> <pre><code>53  tmp_x = clone_here(x_c[gpu_id:(gpu_id+1)])\n54  tmp_y = clone_here(y_c[gpu_id:(gpu_id+1)])\n55  z_chunk = elemwise_add(tmp_x, tmp_y)\n56  copy(z_c[gpu_id:(gpu_id+1)], z_chunk)\n</code></pre> <p>The below is an output of <code>gpu.py</code>.</p> <pre><code>This should be running on GPU\nGPU kernel is called..\nOutput&gt;&gt; [ 6  8 10 12]\n\nGPU[0] calculates z[0]\nGPU kernel is called..\nGPU[1] calculates z[1]\nGPU kernel is called..\nGPU[2] calculates z[2]\nGPU kernel is called..\nGPU[3] calculates z[3]\nGPU kernel is called..\nOutput&gt;&gt; 6 8 10 12\n</code></pre>"},{"location":"tutorial/3_devices_and_architectures/#heterogeneous-function-variants","title":"Heterogeneous Function Variants","text":"<p>Some tasks can be scheduled on either CPU or GPU architectures. You can find an example in <code>hetero_devices.py</code>.</p> <p>Line 35 sets the placement to a CPU or GPU architecture.</p> <pre><code>35  @spawn(placement=[cpu, gpu])\n</code></pre> <p>Different types of devices should call different kernel codes. To handle this case, Parla supports <code>@specialized</code> and <code>@[ORIGINAL FUNCTION].variant([ARCHITECTURE TYPE])</code> decorators. If <code>@specialized</code> is prepended to a function declaration, it implies that that function is for a CPU execution and its variants for different computing devices may exist in the program. Line 11 declares a CPU element-wise vector addition, and sets that its variant may exist.</p> <pre><code>11  @specialized\n12  def elemwise_add():\n</code></pre> <p>Line 20 declares a variant of the <code>elemewise_add()</code> that exploits cupy kernels for a GPU execution.</p> <pre><code>20  @elemwise_add.variant(gpu)\n21  def elemwise_add_gpu():\n</code></pre> <p>When the <code>elemwise_add()</code> is called at line 38, the Parla runtime automatically finds the placement of <code>single_task_on_both</code> task, finds a compatible function variant, and calls it.</p> <p>Parla defines variants of functions instead of tasks. This allows the construction of larger tasks with bodies is composed of multiple function variants. The modularity allows parts of a task to be ported to the device slowly.</p> <p>The below is an output of <code>hetero_devices.py</code>.</p> <pre><code>Spawns a single task on either CPU or GPU\nGPU kernel is called..\nOutput&gt;&gt; 6 8 10 12\n</code></pre> <p>Congratulations! You've learned about how to utilize heterogeneous architectures/tasks in Parla.</p>"},{"location":"tutorial/4_data_partitioning_and_automatic_movement/","title":"Lesson 4: Data Partitioning and Automatic Movement","text":"<p>Parla provides partitioners to partition 1-D or 2-D arrays into <code>logical devices</code>. These partitions can be moved around different (physical) devices automatically on demand by the Parla runtime.</p> <p>This section introduces how to use the Parla partitioners and the automatic data movement.</p> <p>The provided script starts from an 1-D random array of length 4 for demonstration.</p> <pre><code>data = np.random.rand(4)\n</code></pre> <p>This section presents the following three examples:</p> <ol> <li>Evenly partition the initial array into two disjointed arrays, placing each to CPU and GPU0, respectively.</li> <li>Add up the two partitions on GPU0 without explicit data movement.</li> <li>Same as the step 2 on CPU.</li> </ol> <p>For step 1, we first create a Parla partitioner (aka mapper), <code>LDeviceSequenceBlocked</code>. (For 2-D partitioning, Parla provides partitioners of two schemes, namely <code>LDeviceGridBlocked</code> and <code>LDeviceGridRaveled</code>.) <pre><code>mapper = LDeviceSequenceBlocked(2, placement=[cpu[0], gpu[0]])\npartitioned_view = mapper.partition_tensor(data)\n</code></pre></p> <p>We print out the details (value, type, and residence device) of the partitions.</p> <p>Next, we perform the addition on GPU0. <pre><code>@spawn(task[0], placement=gpu[0])\ndef t1():\n    sum_on_gpu = partitioned_view[0] + partitioned_view[1]\n</code></pre> Although we don't explicitly do any data movement operation like <code>clone_here</code>, the input partitions are automatically moved to GPU0 as a cupy array. The output is also the cupy array allocated on the same device. The subsequent print statements show the processes explained above. Similarly, without any explicit data movement, we could perform the addition on CPU. <pre><code>@spawn(task[1], dependencies=[task[0]], placement=cpu[0])\ndef t2():\n    sum_on_cpu = partitioned_view[0] + partitioned_view[1]\n</code></pre> All the inputs and the output are numpy arrays on CPU.</p> <p>Example output (values may vary due to random generation): <pre><code>Initial array:  [0.0603186  0.11194458 0.99213128 0.20585806]\n=======\nPartitions:\n[0.0603186  0.11194458] of type &lt;class 'numpy.ndarray'&gt; on device &lt;CPU 0&gt;\n[0.99213128 0.20585806] of type &lt;class 'cupy._core.core.ndarray'&gt; on device &lt;CUDA 0&gt;\n=======\nOn GPU, inputs are automatically cloned here\ninput types: [&lt;class 'cupy._core.core.ndarray'&gt;, &lt;class 'cupy._core.core.ndarray'&gt;]\noutput type: &lt;class 'cupy._core.core.ndarray'&gt;\noutput: [1.05244989 0.31780264]\n=======\nOn CPU, inputs are automatically cloned here\ninput types: [&lt;class 'numpy.ndarray'&gt;, &lt;class 'numpy.ndarray'&gt;]\noutput type: &lt;class 'numpy.ndarray'&gt;\noutput: [1.05244989 0.31780264]\n</code></pre></p>"},{"location":"tutorial/5_task_constraints/","title":"Lesson 5: Task Constraints","text":"<p>In this lesson we limit the resource usage of tasks and explore the benefits of doing so.  There is only one source code file for this lesson: <code>task_constraints.py</code> </p> <p>The Parla <code>@spawn</code> decorator can take optional parameters limiting the resource usage of tasks.  Two resource constraints are currently supported: <code>memory</code> and <code>vcus</code>.  <code>vcus</code> specifies how much computing units should be allocated for a task. It is currently an experimental feature and we are not going to explain it in this lesson.  In this lesson, we will explore usage of the <code>memory</code> constraint.  </p> <p>In the current implementation of Parla, task constraints can best be thought of as hints to the Parla scheduler rather than as true restrictions. The <code>memory</code> constraint informs the Parla scheduler of the peak memory usage of a task in bytes, enabling it to make better scheduling decisions;  however, Parla does not currently enforce the task to operate within its set constraints, and it is the programmer's duty to ensure that tasks do not exceed the constraints passed to the scheduler.  </p> <p>Let's take a look at how the <code>memory</code> constraint can be used to improve the scheduling of GPU-based tasks.  When running GPU tasks, Parla creates a new CUDA stream in which to run each task.  By default, though, it can only place one task on a GPU at a time.  By expressing <code>memory</code> constraints, the programmer informs the Parla scheduler of the peak memory usage of a task,  thereby enabling the scheduler to calculate how many tasks may be colocated on a single GPU.  Thus, multiple tasks may run in separate streams on a single GPU.  This technique has the advantage of overlapping communication and computation of different tasks,  improving performance without the programmer having to work directly with CUDA.  </p> <p>We now examine lines of interest for the code example provided in this lesson.  In lines 10-16 we define a function which copies an array to the GPU, takes the square root of all elements, and then copies data back to the CPU.  The <code>clone_here</code> function ensures that data is copied on the proper device and stream.  </p> <pre><code>10  def gpu_sqrt(data, i):\n11      gpu_data = clone_here(data[i])\n12      print(f\"{cp.cuda.get_current_stream()}: data[{i}] host to device transfer complete\")\n13      cp.sqrt(gpu_data)\n14      print(f\"{cp.cuda.get_current_stream()}: data[{i}] computation complete\")\n15      data[i] = cp.asnumpy(gpu_data)\n16      print(f\"{cp.cuda.get_current_stream()}: data[{i}] device to host transfer complete\")\n</code></pre> <p>In lines 27-31, we spawn two tasks, each performing <code>gpu_sqrt</code> on a large array of data on GPU 0.  In these first two tasks, no memory constraints are set.  </p> <pre><code>27          print(\"\\nStarting GPU tasks with no memory constraints\")\n28          for i in range(2):\n29              @spawn(placement=gpu(0))\n30              async def t1():\n31                  gpu_sqrt(data, i)\n</code></pre> <p>After awaiting these two tasks, we spawn two more identical tasks, but this time with memory constraints set (in bytes).  </p> <pre><code>35          print(\"\\nStarting GPU tasks with memory constraints\")\n36          for i in range(2):\n37              @spawn(placement=gpu(0), memory=2**32)\n38              async def t2():\n39                  gpu_sqrt(data, i)\n</code></pre> <p>Here is an example output from running this script:</p> <pre><code>Initializing data on host\n\nStarting GPU tasks with no memory constraints\n&lt;Stream 47606900461072&gt;: data[0] host to device transfer complete\n&lt;Stream 47606900461072&gt;: data[0] computation complete\n&lt;Stream 47606900461072&gt;: data[0] device to host transfer complete\n&lt;Stream 47600451457104&gt;: data[1] host to device transfer complete\n&lt;Stream 47600451457104&gt;: data[1] computation complete\n&lt;Stream 47600451457104&gt;: data[1] device to host transfer complete\n\nStarting GPU tasks with memory constraints\n&lt;Stream 47606903095984&gt;: data[0] host to device transfer complete\n&lt;Stream 47606903095984&gt;: data[0] computation complete\n&lt;Stream 47600481891744&gt;: data[1] host to device transfer complete\n&lt;Stream 47606903095984&gt;: data[0] device to host transfer complete\n&lt;Stream 47600481891744&gt;: data[1] computation complete\n&lt;Stream 47600481891744&gt;: data[1] device to host transfer complete\n</code></pre> <p>Some observations: - All four tasks ran on a unique CUDA stream. - The tasks without memory constraints ran in order on the GPU since Parla could only schedule one at a time. - The tasks with memory constraints overlap computation and communication for the two arrays. - You may not see this exact order when running code on your system,  but importantly, you will never see interleaving of the tasks running in the first stage since only one can run at a time.  </p> <p>As a final note, it is important to properly express the peak memory usage of your task if the scheduler is to properly colocate tasks on a single GPU.  Take particular care to include extra memory used by out-of-place algorithms.  If the <code>memory</code> constraint is lower than the actual peak memory usage, Parla may colocate too many tasks on a single GPU and run out of memory to allocate.  </p> <p>Congratulations! You've learned to improve the performance of Parla applications by expressing task constraints!  </p>"},{"location":"tutorial/6_automatic_data_movement/","title":"Lesson 6: Automatic Data Movement","text":"<p>Instead of explicitly writing code to move data between devices, user could use Parla to manage data movement automatically. </p> <p>This section introduces PArray, a NumPy/CuPy-compatible array data structure provided by Parla. </p> <p>PArray is designed as a intelligent lightweight wrapper for NumPy and CuPy <code>ndarray</code>. Data wrapped by PArray will be automatically moved to the device where an access will happen.</p> <p>The provided script show how to use PArray in a Parla program. At least two GPU devices are required to run this script.</p>"},{"location":"tutorial/6_automatic_data_movement/#create-a-parray-obejct","title":"Create a PArray Obejct","text":"<p>To create a PArray, we need to initialize it with data.</p> <p>This could be done by call <code>array</code> method with array like object (e.g. <code>list</code>, <code>ndarray</code>).</p> <pre><code>11    A = parray.array([[1, 2], [3, 4]])\n</code></pre> <p>We could also convert existing NumPy/CuPy array to PArray.</p> <pre><code>12    data = np.random.rand(2,2)\n13    B = parray.asarray(data)\n</code></pre> <p>Now we have a PArray object that contains data in host memory.</p>"},{"location":"tutorial/6_automatic_data_movement/#manipulate-with-numpycupy-api","title":"Manipulate with NumPy/CuPy API","text":"<p>PArray's support the same member methods as NumPy/CuPy <code>ndarray</code> does.</p> <pre><code>&gt;&gt; A = parray.array([[1, 2], [3, 4]])\n&gt;&gt; A.argmax(axis=1)\n[1 1]\n</code></pre> <p>Static methods of NumPy/CuPy could also be used with the help of two addition methods <code>.array</code> and <code>.update</code>.</p> <p><code>.array</code> returns a view of PArray, which has type <code>numpy.ndarray</code> (or <code>cupy.ndarray</code> for GPU tasks).</p> <p><code>.update</code> takes an ndarray as input and replaces the PArray's underlying buffer.</p> <p>Examples:</p> <pre><code>B.update(cp.sqrt(B.array))\n</code></pre> <p>When only a portion of the PArray is assigned (slicing or indexing),  <code>.update</code>  could be omitted.</p> <pre><code>B[0][1] = np.sum((B + A).array)\n</code></pre>"},{"location":"tutorial/6_automatic_data_movement/#task-with-parray","title":"Task with PArray","text":"<p>To use a PArray object in a Parla Task, we need to put it in fields of <code>spawn</code>, so the scheduler will be able to know which array is used in the task and schedule a data movement in background.</p> <p>There are three different access pattern:</p>"},{"location":"tutorial/6_automatic_data_movement/#read-only","title":"Read Only","text":"<p><pre><code>19        @spawn(ts[0], placement=gpu(0), input=[A])\n20        async def read_only_task():\n21            print(A)\n</code></pre> If a task only does modify a PArray, it should be put in <code>input</code> field. And all read only operations are allowed here, (e.g <code>print</code>, copy).</p> <p><code>print</code> a PArray will give a dictionary, where key is the device index (<code>-1</code> for CPU device and <code>0, 1 ...</code> for GPU devices)</p> <p><pre><code>{0: array([[1, 2], [3, 4]]), \n1: None, 2: None, 3: None, \n-1: array([[1, 2], [3, 4]])}\n</code></pre> Result of <code>print A</code> indicates that the array has been copied to GPU 0 automatically when this task starts.</p>"},{"location":"tutorial/6_automatic_data_movement/#write-only","title":"Write Only","text":"<pre><code>23      @spawn(ts[1], placement=gpu(1), output=[B])\n24      async def write_only_task():\n25          B.update(cp.sqrt(cp.random.rand(2, 2)))\n</code></pre> <p>If a task write to but didn't read from a PArray, it should be put in <code>output</code> field. And the PArray could be modified in this task.</p>"},{"location":"tutorial/6_automatic_data_movement/#read-and-write","title":"Read and Write","text":"<p><pre><code>27      @spawn(ts[2], [ts[0:2]], placement=cpu, input=[A], inout=[B])\n28      async def write_and_write_task():\n29          B[0][1] = np.sum((B + A).array)\n</code></pre> PArray should be put in <code>inout</code> field if it is read and written by the same task.</p> <p>In the above example, a task read from B's value and write to new value to B, while A is not modified. So A is put in <code>input</code> and B is put in <code>inout</code>.</p>"},{"location":"tutorial/6_automatic_data_movement/#fine-grained-data-movement","title":"Fine-Grained Data Movement","text":"<p>Previous examples only show how PArray is moved as a whole. It is also useful to be able to move only a portion of it.</p> <p><pre><code>31      @spawn(ts[3], [ts[2]], placement=gpu(1), inout=[A[0]])\n32      async def write_and_write_task():\n33          A[0] = cp.sqrt(A[0].array)\n</code></pre> Here only <code>A[0]</code> is moved.</p> <p>Note: currently, fine-grained data movement on two overlapping portions is not supported.</p>"},{"location":"tutorial/6_automatic_data_movement/#memory-coherence","title":"Memory Coherence","text":"<p>Since PArray will generate multiple copies of the same data in multiple devices, it needs to maintain the correct memory coherence in the system. <code>input</code>, <code>output</code> and <code>inout</code> not only are used by scheduler determine data dependence between tasks, but also used by PArray to update its coherence protocol. Therefore, it is necessary for programmer to correctly identify PArray in <code>input</code>, <code>output</code> and <code>inout</code>.</p> <p>What's more, this memory model requires the application to be data race free in task granularity. That is, reads and writes on the same PArray between any two parallel tasks should be serilized.</p> <p>For example, if there is no dependence between task A and task B, they may be scheduled to run in parallel. If A write on a PArray and B read from it, a data race will happen between two tasks and the behavior is undefined.</p> <p>For fine grained data movement, read and write on two different portion of a PArray is not considered to be a race and could run correctly with parallel tasks. However, read and write on a portion and a complete copy will be considered as a race.</p>"},{"location":"tutorial/6_automatic_data_movement/#writeback-of-subarray","title":"Writeback of Subarray","text":"<p>Since we assume subarray are not overlapped, PArray runtime will not writeback changes of subarray in other deivces unless a writeback is triggered.</p> <p>That means the following example won't work since task_B will not see changes in task_A. <pre><code>@spawn(t[0], output=[arr[0]],placement=gpu[0])\ndef task_a():\n    arr[0] = 1\n\n@spawn(t[1], dependencies=[t[0]], input=[arr[0]],placement=gpu[1])\ndef task_b():\n    assert arr[0] == 1 # will fail since task_a's change has not been writeback to other devices\n</code></pre></p> <p>Therefore, whenever you want to access overlapping subarray (including the same subarray in different devices), you need to insert a writeback task between them to sync the data, which should be</p> <pre><code>@spawn(t[0], output=[arr[0]],placement=gpu[0])\ndef task_a():\n    arr[0] = 1\n\n@spawn(a[0], dependencies=[t[0]], inout=[arr],placement=cpu)  # try to access array with `inout` will trigger writeback to that device\ndef write_back():\n    pass # do nothing is okay\n\n@spawn(t[1], dependencies=[t[0], a[0]], input=[arr[0]],placement=gpu[1])\ndef task_b():\n    assert arr[0] == 1 # success now\n</code></pre>"},{"location":"runtime/annotated/","title":"Class List","text":"<p>Here are the classes, structs, unions and interfaces with brief descriptions:</p> <ul> <li>class ArchitectureRequirement </li> <li>class CPUDevice </li> <li>class CUDADevice </li> <li>class CopyableAtomic A copyable atomic class inherited from std::atomic. </li> <li>class Device Devices can be distinguished from other devices by a class type and its index. </li> <li>class DeviceManager <code>DeviceManager</code> registers/provides devices and their information on the current system to the Parla runtime. </li> <li>class DeviceQueue Per-device container for tasks that are waiting to be dequeued. </li> <li>class DeviceRequirement </li> <li>class InnerDataTask </li> <li>class InnerScheduler The C++ \"Mirror\" of Parla's Python Scheduler This class is used to create a C++ representation of a Parla Scheduler All scheduling logic should be handled by these after creation until launched by the Python callback. </li> <li>class InnerTask The C++ \"Mirror\" of Parla's Python Tasks This class is used to create a C++ representation of a Parla Task All scheduling logic should be handled by these after creation until launched by the Python callback. </li> <li>class InnerTaskSpace </li> <li>class InnerWorker The C++ \"Mirror\" of Parla's Python Workers This class is used to create a C++ representation of a Parla Worker All scheduling logic should be handled by these after creation until launched by the Python callback. </li> <li>class Launcher </li> <li>class LauncherStatus </li> <li>class LocalityLoadBalancingMappingPolicy </li> <li>class Mapper Mapper phase of the scheduler. </li> <li>class MapperStatus </li> <li>class MappingPolicy </li> <li>class MemoryReserver MemoryReserver phase of the scheduler. </li> <li>class MemoryReserverStatus </li> <li>class MultiDeviceRequirements </li> <li>class PArrayTracker </li> <li>class PhaseManager Manages a group of DeviceQueues. </li> <li>class PhaseStatus Records metrics that track phase execution (e.g. success, failure, etc.) </li> <li>class PlacementRequirementBase Base classes. </li> <li>class PlacementRequirementCollections Resource contains device types (architectures), specific devices, their memory and virtual computation units. </li> <li>class ProtectedQueue </li> <li>class ProtectedVector </li> <li>class ResourcePool A pool of resources, allows for comparisons and updates of current values. </li> <li>class RuntimeReserver RuntimeReserver phase of the scheduler. </li> <li>class RuntimeReserverStatus </li> <li>namespace Scheduler </li> <li>class Status </li> <li>class SchedulerPhase Abstract Interface for general scheduler runtime phase. </li> <li>class SinglePlacementRequirementBase </li> <li>namespace Task </li> <li>class StatusFlags </li> <li>class TaskBarrier The C++ \"Mirror\" of Parla's Python TaskSets &amp; Spaces They are used as barriers for the calling thread for the completion of their members. </li> <li>class WorkerPool </li> <li>namespace chrono </li> <li>namespace parla </li> <li>namespace cython <ul> <li>namespace containers </li> <li>namespace core </li> <li>class CyDataMovementTaskAttributes </li> <li>class CyTaskList </li> <li>class DataMovementTaskAttributes </li> <li>class PyInnerScheduler </li> <li>class PyInnerTask </li> <li>class PyInnerWorker </li> <li>class PyTaskBarrier </li> <li>class PyTaskSpace </li> <li>class Resources </li> <li>namespace cyparray </li> <li>class CyPArray </li> <li>namespace cyparray_state </li> <li>class CyPArrayState </li> <li>namespace device </li> <li>class CupyStream </li> <li>class CyCPUDevice </li> <li>class CyCUDADevice </li> <li>class CyDevice </li> <li>class DeviceResource </li> <li>class DeviceResourceRequirement </li> <li>class PyArchitecture </li> <li>class PyCPUArchitecture </li> <li>class PyCPUDevice </li> <li>class PyCUDAArchitecture </li> <li>class PyCUDADevice </li> <li>class PyDevice </li> <li>class Stream </li> <li>namespace device_manager </li> <li>class CyDeviceManager </li> <li>class PrintableFrozenSet </li> <li>class PyDeviceManager </li> <li>class StreamPool </li> <li>namespace scheduler </li> <li>class ControllableThread </li> <li>class Scheduler </li> <li>class SchedulerContext </li> <li>class SchedulerException </li> <li>class TaskBodyException </li> <li>class WorkerThread </li> <li>class WorkerThreadException </li> <li>class _SchedulerLocals </li> <li>namespace tasks </li> <li>class AtomicTaskList </li> <li>class AtomicTaskSpace </li> <li>class BackendTaskList </li> <li>class BackendTaskSpace </li> <li>class CPUEnvironment </li> <li>class ComputeTask A compute task is a task that executes a user defined Python function on a device. </li> <li>class DataMovementTask A data movement task is a task that moves data between devices. </li> <li>class GPUEnvironment </li> <li>class Task Python Task interface. </li> <li>class TaskCollection </li> <li>class TaskCompleted This state specifies that a task has completed execution. </li> <li>class TaskCreated This state specifies that a task has been created but not yet spawned. </li> <li>class TaskEnvironment A TaskEnvironment is a collection of devices or other TaskEnvironments used to coordinate and synchronize kernels in theTask body. </li> <li>class TaskException This state specifies that a task has completed execution with an exception. </li> <li>class TaskList </li> <li>class TaskMapped This state specifies that a task has been mapped to a device set, but not yet resered its resources there. </li> <li>class TaskReady This state specifies that a task is \"ready\" to be launched. </li> <li>class TaskReserved This state specifies that a task has reserved its persistent resources (e.g. </li> <li>class TaskRunahead State: A task is executing in a stream but the body has completed. </li> <li>class TaskRunning This state specifies that a task is executing in a stream. </li> <li>class TaskSpace </li> <li>class TaskSpawned This state specifies that a task is ready to be mapped to a specific device set. </li> <li>class TaskState Abstract base class for Task State. </li> <li>class TerminalEnvironment An endpoint TaskEnvironment representing a single device. </li> <li>class _TaskLocals </li> <li>namespace variants </li> <li>class VariantDefinitionError Error for an invalid function variant definition. </li> <li>class _VariantFunction Function wrapper that dispatches to different architecture targets. </li> </ul> </li> <li>namespace parray </li> <li>class InnerPArray </li> <li>class PArrayState </li> <li>namespace std </li> <li>namespace chrono_literals </li> <li>namespace string_view_literals </li> <li>namespace threading </li> </ul>"},{"location":"runtime/files/","title":"File List","text":"<p>Here is a list of all files with brief descriptions:</p> <ul> <li>dir src </li> <li>dir c <ul> <li>dir backend </li> <li>file device.cpp </li> <li>file device_manager.cpp </li> <li>file parray.cpp </li> <li>file parray_state.cpp </li> <li>file parray_tracker.cpp </li> <li>file phases.cpp </li> <li>file policy.cpp </li> <li>file resource_requirements.cpp </li> <li>file resources.cpp </li> <li>file scheduler.cpp </li> <li>dir impl_none <ul> <li>file utility.cpp </li> </ul> </li> <li>dir include <ul> <li>file atomic_wrapper.hpp Provides a copyable atomic class for use in STL containers. </li> <li>file containers.hpp Provides interface for thread-safe containers. </li> <li>file device.hpp Provides interface for abstract device object. </li> <li>file device_manager.hpp Provides interface for device initialization and management. </li> <li>file device_queues.hpp Provides interface for task queues and collections of task queues for multidevice tasks. </li> <li>file gpu_utility.hpp Provides architecture independent interface to event and stream creation &amp; synchronization. </li> <li>file parray.hpp Provides C++ interface to PArray State and ID. </li> <li>file parray_state.hpp Provides C++ interface to parray coherency. </li> <li>file parray_tracker.hpp Provides interface to scheduler tracking of parray data objects. </li> <li>file phases.hpp Interface for scheduler runtime phases. </li> <li>file policy.hpp Interface for mapping policies. </li> <li>file profiling.hpp Provides macros for NVTX profiling and BINLOG tracing. </li> <li>file resource_requirements.hpp Provides task constraint classes to hold potential placement locations and architectures. </li> <li>file resources.hpp Provides a resource pool for tracking resource usage. </li> <li>file runtime.hpp The core C++ runtime for Parla. Includes the main scheduler and task classes. </li> </ul> </li> <li>file task.cpp </li> </ul> </li> <li>dir python <ul> <li>dir parla </li> <li>dir cython <ul> <li>file containers.pyx </li> <li>file core.pyx Contains the core intermediate cython wrapper classes for Task, Workers, and Scheduler. </li> <li>file cyparray.pyx </li> <li>file cyparray_state.pyx </li> <li>file device.pyx </li> <li>file device_manager.pyx Contains the cython wrapper and python layer DeviceManager and StreamPool classes. </li> <li>file scheduler.pyx Contains the core Python logic to manage workers and launch tasks. </li> <li>file tasks.pyx Contains the Task and TaskEnvironment classes, which are used to represent tasks and their execution environments. </li> <li>file variants.pyx Provides decorators for dispatching functions based on the active TaskEnvironment. </li> </ul> </li> </ul> </li> </ul>"},{"location":"runtime/classArchitectureRequirement/","title":"Class ArchitectureRequirement","text":"<p>ClassList &gt; ArchitectureRequirement</p> <p>Inherits the following classes: SinglePlacementRequirementBase</p>"},{"location":"runtime/classArchitectureRequirement/#public-functions","title":"Public Functions","text":"Type Name const std::vector&lt; std::shared_ptr&lt; DeviceRequirement &gt; &gt; &amp; GetDeviceRequirementOptions ()  void append_placement_req_opt (std::shared_ptr&lt; DeviceRequirement &gt; req)  virtual bool is_arch_req () override virtual bool is_dev_req () override virtual bool is_multidev_req () override"},{"location":"runtime/classArchitectureRequirement/#public-functions-inherited-from-placementrequirementbase","title":"Public Functions inherited from PlacementRequirementBase","text":"<p>See PlacementRequirementBase</p> Type Name virtual bool is_arch_req () = 0 virtual bool is_dev_req () = 0 virtual bool is_multidev_req () = 0"},{"location":"runtime/classArchitectureRequirement/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classArchitectureRequirement/#function-getdevicerequirementoptions","title":"function GetDeviceRequirementOptions","text":"<pre><code>const std::vector&lt; std::shared_ptr&lt; DeviceRequirement &gt; &gt; &amp; ArchitectureRequirement::GetDeviceRequirementOptions () </code></pre>"},{"location":"runtime/classArchitectureRequirement/#function-append_placement_req_opt","title":"function append_placement_req_opt","text":"<pre><code>void ArchitectureRequirement::append_placement_req_opt (\nstd::shared_ptr&lt; DeviceRequirement &gt; req\n) </code></pre>"},{"location":"runtime/classArchitectureRequirement/#function-is_arch_req","title":"function is_arch_req","text":"<pre><code>inline virtual bool ArchitectureRequirement::is_arch_req () override\n</code></pre> <p>Implements PlacementRequirementBase::is_arch_req</p>"},{"location":"runtime/classArchitectureRequirement/#function-is_dev_req","title":"function is_dev_req","text":"<pre><code>inline virtual bool ArchitectureRequirement::is_dev_req () override\n</code></pre> <p>Implements PlacementRequirementBase::is_dev_req</p>"},{"location":"runtime/classArchitectureRequirement/#function-is_multidev_req","title":"function is_multidev_req","text":"<pre><code>inline virtual bool ArchitectureRequirement::is_multidev_req () override\n</code></pre> <p>Implements PlacementRequirementBase::is_multidev_req</p> <p>The documentation for this class was generated from the following file <code>src/c/backend/include/resource_requirements.hpp</code></p>"},{"location":"runtime/classCPUDevice/","title":"Class CPUDevice","text":"<p>ClassList &gt; CPUDevice</p> <p>Inherits the following classes: Device</p>"},{"location":"runtime/classCPUDevice/#public-functions","title":"Public Functions","text":"Type Name CPUDevice (DevID_t dev_id, size_t mem_sz, size_t num_vcus, void * py_dev)"},{"location":"runtime/classCPUDevice/#public-functions-inherited-from-device","title":"Public Functions inherited from Device","text":"<p>See Device</p> Type Name Device () = delete Device (DeviceType arch, DevID_t dev_id, MemorySz_t mem_sz, VCU_t num_vcus, void * py_dev, int copy_engines=2)  const bool check_resource_availability (DeviceRequirement * dev_req) const const DevID_t get_global_id () const const DevID_t get_id () constReturn a device id. ResourcePool_t &amp; get_mapped_pool () Returns the currently mapped resources on the device. const Resource_t get_mapped_resource (Resource type) const const Resource_t get_max_resource (Resource type) const const MemorySz_t get_memory_size () const const std::string get_name () const const VCU_t get_num_vcus () const void * get_py_device () Returns the pointer to the python device object. ResourcePool_t &amp; get_reserved_pool () Returns the currently reserved resources on the device. const Resource_t get_reserved_resource (Resource type) const const ResourcePool_t &amp; get_resource_pool () constReturns the device details (maximum resources available) This is assumed to be constant after device creation. const DeviceType get_type () const const Resource_t query_mapped_resource (Resource type) const const Resource_t query_reserved_resource (Resource type) const const Resource_t query_resource (Resource type) const void set_global_id (DevID_t global_id)"},{"location":"runtime/classCPUDevice/#protected-attributes-inherited-from-device","title":"Protected Attributes inherited from Device","text":"<p>See Device</p> Type Name DevID_t dev_global_id_ DevID_t dev_id_ DeviceType dev_type_ ResourcePool_t mapped_res_ void * py_dev_ ResourcePool_t res_ ResourcePool_t reserved_res_ std::unordered_map&lt; std::string, size_t &gt; resource_map_"},{"location":"runtime/classCPUDevice/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classCPUDevice/#function-cpudevice","title":"function CPUDevice","text":"<pre><code>inline CPUDevice::CPUDevice (\nDevID_t dev_id,\nsize_t mem_sz,\nsize_t num_vcus,\nvoid * py_dev\n) </code></pre> <p>The documentation for this class was generated from the following file <code>src/c/backend/include/device.hpp</code></p>"},{"location":"runtime/classCUDADevice/","title":"Class CUDADevice","text":"<p>ClassList &gt; CUDADevice</p> <p>Inherits the following classes: Device</p>"},{"location":"runtime/classCUDADevice/#public-functions","title":"Public Functions","text":"Type Name CUDADevice (DevID_t dev_id, size_t mem_sz, size_t num_vcus, void * py_dev)"},{"location":"runtime/classCUDADevice/#public-functions-inherited-from-device","title":"Public Functions inherited from Device","text":"<p>See Device</p> Type Name Device () = delete Device (DeviceType arch, DevID_t dev_id, MemorySz_t mem_sz, VCU_t num_vcus, void * py_dev, int copy_engines=2)  const bool check_resource_availability (DeviceRequirement * dev_req) const const DevID_t get_global_id () const const DevID_t get_id () constReturn a device id. ResourcePool_t &amp; get_mapped_pool () Returns the currently mapped resources on the device. const Resource_t get_mapped_resource (Resource type) const const Resource_t get_max_resource (Resource type) const const MemorySz_t get_memory_size () const const std::string get_name () const const VCU_t get_num_vcus () const void * get_py_device () Returns the pointer to the python device object. ResourcePool_t &amp; get_reserved_pool () Returns the currently reserved resources on the device. const Resource_t get_reserved_resource (Resource type) const const ResourcePool_t &amp; get_resource_pool () constReturns the device details (maximum resources available) This is assumed to be constant after device creation. const DeviceType get_type () const const Resource_t query_mapped_resource (Resource type) const const Resource_t query_reserved_resource (Resource type) const const Resource_t query_resource (Resource type) const void set_global_id (DevID_t global_id)"},{"location":"runtime/classCUDADevice/#protected-attributes-inherited-from-device","title":"Protected Attributes inherited from Device","text":"<p>See Device</p> Type Name DevID_t dev_global_id_ DevID_t dev_id_ DeviceType dev_type_ ResourcePool_t mapped_res_ void * py_dev_ ResourcePool_t res_ ResourcePool_t reserved_res_ std::unordered_map&lt; std::string, size_t &gt; resource_map_"},{"location":"runtime/classCUDADevice/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classCUDADevice/#function-cudadevice","title":"function CUDADevice","text":"<pre><code>inline CUDADevice::CUDADevice (\nDevID_t dev_id,\nsize_t mem_sz,\nsize_t num_vcus,\nvoid * py_dev\n) </code></pre> <p>The documentation for this class was generated from the following file <code>src/c/backend/include/device.hpp</code></p>"},{"location":"runtime/classCopyableAtomic/","title":"Class CopyableAtomic","text":"<p>template &lt;typename T typename T&gt;</p> <p>ClassList &gt; CopyableAtomic</p> <p>A copyable atomic class inherited from std::atomic. </p> <ul> <li><code>#include &lt;atomic_wrapper.hpp&gt;</code></li> </ul> <p>Inherits the following classes: std::atomic&lt; T &gt;</p>"},{"location":"runtime/classCopyableAtomic/#public-functions","title":"Public Functions","text":"Type Name CopyableAtomic ()  constexpr CopyableAtomic (T base)  constexpr CopyableAtomic (const CopyableAtomic&lt; T &gt; &amp; other) Copy constructor. CopyableAtomic &amp; operator= (const CopyableAtomic&lt; T &gt; &amp; other) Copy assignment operator."},{"location":"runtime/classCopyableAtomic/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classCopyableAtomic/#function-copyableatomic-13","title":"function CopyableAtomic [1/3]","text":"<pre><code>inline CopyableAtomic::CopyableAtomic () </code></pre>"},{"location":"runtime/classCopyableAtomic/#function-copyableatomic-23","title":"function CopyableAtomic [2/3]","text":"<pre><code>inline constexpr CopyableAtomic::CopyableAtomic (\nT base\n) </code></pre>"},{"location":"runtime/classCopyableAtomic/#function-copyableatomic-33","title":"function CopyableAtomic [3/3]","text":"<pre><code>inline constexpr CopyableAtomic::CopyableAtomic (\nconst CopyableAtomic &lt; T &gt; &amp; other\n) </code></pre>"},{"location":"runtime/classCopyableAtomic/#function-operator","title":"function operator=","text":"<pre><code>inline CopyableAtomic &amp; CopyableAtomic::operator= (\nconst CopyableAtomic &lt; T &gt; &amp; other\n) </code></pre> <p>The documentation for this class was generated from the following file <code>src/c/backend/include/atomic_wrapper.hpp</code></p>"},{"location":"runtime/classDevice/","title":"Class Device","text":"<p>ClassList &gt; Device</p> <p>Devices can be distinguished from other devices by a class type and its index. </p> <ul> <li><code>#include &lt;device.hpp&gt;</code></li> </ul> <p>Inherited by the following classes: CPUDevice,  CUDADevice</p>"},{"location":"runtime/classDevice/#public-functions","title":"Public Functions","text":"Type Name Device () = delete Device (DeviceType arch, DevID_t dev_id, MemorySz_t mem_sz, VCU_t num_vcus, void * py_dev, int copy_engines=2)  const bool check_resource_availability (DeviceRequirement * dev_req) const const DevID_t get_global_id () const const DevID_t get_id () constReturn a device id. ResourcePool_t &amp; get_mapped_pool () Returns the currently mapped resources on the device. const Resource_t get_mapped_resource (Resource type) const const Resource_t get_max_resource (Resource type) const const MemorySz_t get_memory_size () const const std::string get_name () const const VCU_t get_num_vcus () const void * get_py_device () Returns the pointer to the python device object. ResourcePool_t &amp; get_reserved_pool () Returns the currently reserved resources on the device. const Resource_t get_reserved_resource (Resource type) const const ResourcePool_t &amp; get_resource_pool () constReturns the device details (maximum resources available) This is assumed to be constant after device creation. const DeviceType get_type () const const Resource_t query_mapped_resource (Resource type) const const Resource_t query_reserved_resource (Resource type) const const Resource_t query_resource (Resource type) const void set_global_id (DevID_t global_id)"},{"location":"runtime/classDevice/#protected-attributes","title":"Protected Attributes","text":"Type Name DevID_t dev_global_id_ DevID_t dev_id_ DeviceType dev_type_ ResourcePool_t mapped_res_ void * py_dev_ ResourcePool_t res_ ResourcePool_t reserved_res_ std::unordered_map&lt; std::string, size_t &gt; resource_map_"},{"location":"runtime/classDevice/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classDevice/#function-device-12","title":"function Device [1/2]","text":"<pre><code>Device::Device () = delete\n</code></pre>"},{"location":"runtime/classDevice/#function-device-22","title":"function Device [2/2]","text":"<pre><code>inline Device::Device (\nDeviceType arch,\nDevID_t dev_id,\nMemorySz_t mem_sz,\nVCU_t num_vcus,\nvoid * py_dev,\nint copy_engines=2\n) </code></pre>"},{"location":"runtime/classDevice/#function-check_resource_availability","title":"function check_resource_availability","text":"<pre><code>const bool Device::check_resource_availability (\nDeviceRequirement * dev_req\n) const\n</code></pre>"},{"location":"runtime/classDevice/#function-get_global_id","title":"function get_global_id","text":"<pre><code>inline const DevID_t Device::get_global_id () const\n</code></pre>"},{"location":"runtime/classDevice/#function-get_id","title":"function get_id","text":"<pre><code>inline const DevID_t Device::get_id () const\n</code></pre>"},{"location":"runtime/classDevice/#function-get_mapped_pool","title":"function get_mapped_pool","text":"<p>Returns the currently mapped resources on the device. <pre><code>inline ResourcePool_t &amp; Device::get_mapped_pool () </code></pre></p> <p>This starts at 0 and increases as resources are mapped. Decreased when resources are released at the end of a task. This is not runtime necessary, but useful to mapping policy. </p>"},{"location":"runtime/classDevice/#function-get_mapped_resource","title":"function get_mapped_resource","text":"<pre><code>inline const Resource_t Device::get_mapped_resource (\nResource type\n) const\n</code></pre>"},{"location":"runtime/classDevice/#function-get_max_resource","title":"function get_max_resource","text":"<pre><code>inline const Resource_t Device::get_max_resource (\nResource type\n) const\n</code></pre>"},{"location":"runtime/classDevice/#function-get_memory_size","title":"function get_memory_size","text":"<pre><code>inline const MemorySz_t Device::get_memory_size () const\n</code></pre>"},{"location":"runtime/classDevice/#function-get_name","title":"function get_name","text":"<pre><code>inline const std::string Device::get_name () const\n</code></pre>"},{"location":"runtime/classDevice/#function-get_num_vcus","title":"function get_num_vcus","text":"<pre><code>inline const VCU_t Device::get_num_vcus () const\n</code></pre>"},{"location":"runtime/classDevice/#function-get_py_device","title":"function get_py_device","text":"<pre><code>inline void * Device::get_py_device () </code></pre>"},{"location":"runtime/classDevice/#function-get_reserved_pool","title":"function get_reserved_pool","text":"<p>Returns the currently reserved resources on the device. <pre><code>inline ResourcePool_t &amp; Device::get_reserved_pool () </code></pre></p> <p>This starts at max and decreases as resources are reserved. This represents the resources currently in use by the tasks. This is necessary to determine if tasks can be scheduled without oversubscription or OOM errors. </p>"},{"location":"runtime/classDevice/#function-get_reserved_resource","title":"function get_reserved_resource","text":"<pre><code>inline const Resource_t Device::get_reserved_resource (\nResource type\n) const\n</code></pre>"},{"location":"runtime/classDevice/#function-get_resource_pool","title":"function get_resource_pool","text":"<pre><code>inline const ResourcePool_t &amp; Device::get_resource_pool () const\n</code></pre>"},{"location":"runtime/classDevice/#function-get_type","title":"function get_type","text":"<pre><code>inline const DeviceType Device::get_type () const\n</code></pre>"},{"location":"runtime/classDevice/#function-query_mapped_resource","title":"function query_mapped_resource","text":"<pre><code>inline const Resource_t Device::query_mapped_resource (\nResource type\n) const\n</code></pre>"},{"location":"runtime/classDevice/#function-query_reserved_resource","title":"function query_reserved_resource","text":"<pre><code>inline const Resource_t Device::query_reserved_resource (\nResource type\n) const\n</code></pre>"},{"location":"runtime/classDevice/#function-query_resource","title":"function query_resource","text":"<pre><code>inline const Resource_t Device::query_resource (\nResource type\n) const\n</code></pre>"},{"location":"runtime/classDevice/#function-set_global_id","title":"function set_global_id","text":"<pre><code>inline void Device::set_global_id (\nDevID_t global_id\n) </code></pre>"},{"location":"runtime/classDevice/#protected-attributes-documentation","title":"Protected Attributes Documentation","text":""},{"location":"runtime/classDevice/#variable-dev_global_id_","title":"variable dev_global_id_","text":"<pre><code>DevID_t Device::dev_global_id_;\n</code></pre>"},{"location":"runtime/classDevice/#variable-dev_id_","title":"variable dev_id_","text":"<pre><code>DevID_t Device::dev_id_;\n</code></pre>"},{"location":"runtime/classDevice/#variable-dev_type_","title":"variable dev_type_","text":"<pre><code>DeviceType Device::dev_type_;\n</code></pre>"},{"location":"runtime/classDevice/#variable-mapped_res_","title":"variable mapped_res_","text":"<pre><code>ResourcePool_t Device::mapped_res_;\n</code></pre>"},{"location":"runtime/classDevice/#variable-py_dev_","title":"variable py_dev_","text":"<pre><code>void* Device::py_dev_;\n</code></pre>"},{"location":"runtime/classDevice/#variable-res_","title":"variable res_","text":"<pre><code>ResourcePool_t Device::res_;\n</code></pre>"},{"location":"runtime/classDevice/#variable-reserved_res_","title":"variable reserved_res_","text":"<pre><code>ResourcePool_t Device::reserved_res_;\n</code></pre>"},{"location":"runtime/classDevice/#variable-resource_map_","title":"variable resource_map_","text":"<pre><code>std::unordered_map&lt;std::string, size_t&gt; Device::resource_map_;\n</code></pre> <p>The documentation for this class was generated from the following file <code>src/c/backend/include/device.hpp</code></p>"},{"location":"runtime/classDeviceManager/","title":"Class DeviceManager","text":"<p>ClassList &gt; DeviceManager</p> <p><code>DeviceManager</code> registers/provides devices and their information on the current system to the Parla runtime.</p> <ul> <li><code>#include &lt;device_manager.hpp&gt;</code></li> </ul>"},{"location":"runtime/classDeviceManager/#public-functions","title":"Public Functions","text":"Type Name DeviceManager ()  DeviceManager (const DeviceManager &amp;) = delete Device * get_device_by_global_id (DevID_t global_dev_id) const Device * get_device_by_parray_id (DevID_t parray_dev_id) const std::vector&lt; Device * &gt; &amp; get_devices ()  std::vector&lt; Device * &gt; &amp; get_devices (DeviceType dev_type)  int get_num_devices ()  int get_num_devices (DeviceType dev_type)  size_t get_num_devices ()  const DevID_t globalid_to_parrayid (DevID_t global_dev_id) const const int parrayid_to_globalid (DevID_t parray_dev_id) const void print_registered_devices ()  void register_device (Device * new_dev)"},{"location":"runtime/classDeviceManager/#protected-attributes","title":"Protected Attributes","text":"Type Name std::vector&lt; Device * &gt; all_devices_ std::array&lt; std::vector&lt; Device * &gt;, NUM_DEVICE_TYPES &gt; arch_devices_ DevID_t last_dev_id_   = = 0"},{"location":"runtime/classDeviceManager/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classDeviceManager/#function-devicemanager-12","title":"function DeviceManager [1/2]","text":"<pre><code>inline DeviceManager::DeviceManager () </code></pre>"},{"location":"runtime/classDeviceManager/#function-devicemanager-22","title":"function DeviceManager [2/2]","text":"<pre><code>DeviceManager::DeviceManager (\nconst DeviceManager &amp;\n) = delete\n</code></pre>"},{"location":"runtime/classDeviceManager/#function-get_device_by_global_id","title":"function get_device_by_global_id","text":"<pre><code>inline Device * DeviceManager::get_device_by_global_id (\nDevID_t global_dev_id\n) const\n</code></pre>"},{"location":"runtime/classDeviceManager/#function-get_device_by_parray_id","title":"function get_device_by_parray_id","text":"<pre><code>inline Device * DeviceManager::get_device_by_parray_id (\nDevID_t parray_dev_id\n) const\n</code></pre>"},{"location":"runtime/classDeviceManager/#function-get_devices-12","title":"function get_devices [1/2]","text":"<pre><code>template&lt;DeviceType T&gt;\ninline std::vector&lt; Device * &gt; &amp; DeviceManager::get_devices () </code></pre>"},{"location":"runtime/classDeviceManager/#function-get_devices-22","title":"function get_devices [2/2]","text":"<pre><code>inline std::vector&lt; Device * &gt; &amp; DeviceManager::get_devices (\nDeviceType dev_type\n) </code></pre>"},{"location":"runtime/classDeviceManager/#function-get_num_devices-13","title":"function get_num_devices [1/3]","text":"<pre><code>template&lt;DeviceType T&gt;\ninline int DeviceManager::get_num_devices () </code></pre>"},{"location":"runtime/classDeviceManager/#function-get_num_devices-23","title":"function get_num_devices [2/3]","text":"<pre><code>inline int DeviceManager::get_num_devices (\nDeviceType dev_type\n) </code></pre>"},{"location":"runtime/classDeviceManager/#function-get_num_devices-33","title":"function get_num_devices [3/3]","text":"<pre><code>inline size_t DeviceManager::get_num_devices () </code></pre>"},{"location":"runtime/classDeviceManager/#function-globalid_to_parrayid","title":"function globalid_to_parrayid","text":"<pre><code>inline const DevID_t DeviceManager::globalid_to_parrayid (\nDevID_t global_dev_id\n) const\n</code></pre>"},{"location":"runtime/classDeviceManager/#function-parrayid_to_globalid","title":"function parrayid_to_globalid","text":"<pre><code>inline const int DeviceManager::parrayid_to_globalid (\nDevID_t parray_dev_id\n) const\n</code></pre>"},{"location":"runtime/classDeviceManager/#function-print_registered_devices","title":"function print_registered_devices","text":"<pre><code>inline void DeviceManager::print_registered_devices () </code></pre>"},{"location":"runtime/classDeviceManager/#function-register_device","title":"function register_device","text":"<pre><code>inline void DeviceManager::register_device (\nDevice * new_dev\n) </code></pre>"},{"location":"runtime/classDeviceManager/#protected-attributes-documentation","title":"Protected Attributes Documentation","text":""},{"location":"runtime/classDeviceManager/#variable-all_devices_","title":"variable all_devices_","text":"<pre><code>std::vector&lt;Device *&gt; DeviceManager::all_devices_;\n</code></pre>"},{"location":"runtime/classDeviceManager/#variable-arch_devices_","title":"variable arch_devices_","text":"<pre><code>std::array&lt;std::vector&lt;Device *&gt;, NUM_DEVICE_TYPES&gt; DeviceManager::arch_devices_;\n</code></pre>"},{"location":"runtime/classDeviceManager/#variable-last_dev_id_","title":"variable last_dev_id_","text":"<pre><code>DevID_t DeviceManager::last_dev_id_;\n</code></pre> <p>The documentation for this class was generated from the following file <code>src/c/backend/include/device_manager.hpp</code></p>"},{"location":"runtime/classDeviceQueue/","title":"Class DeviceQueue","text":"<p>template &lt;ResourceCategory category&gt;</p> <p>ClassList &gt; DeviceQueue</p> <p>Per-device container for tasks that are waiting to be dequeued. More...</p> <ul> <li><code>#include &lt;device_queues.hpp&gt;</code></li> </ul>"},{"location":"runtime/classDeviceQueue/#public-functions","title":"Public Functions","text":"Type Name DeviceQueue () = default DeviceQueue (Device * device)  bool empty ()  void enqueue (InnerTask * task) Enqueues a task on this device. InnerTask * front ()  Device * get_device ()  InnerTask * pop () Grabs the next task that can be dequeued on this device. size_t size ()"},{"location":"runtime/classDeviceQueue/#protected-attributes","title":"Protected Attributes","text":"Type Name Device * device MixedQueue_t mixed_queue std::atomic&lt; int &gt; num_tasks   = {0} MDQueue_t waiting_queue"},{"location":"runtime/classDeviceQueue/#detailed-description","title":"Detailed Description","text":"<p>Supports both single and multi-device tasks. Multi-device tasks are shared between DeviceQueues. Should ONLY be used through PhaseManager.</p> <p>Template parameters:</p> <ul> <li><code>category</code> the resource category (persistent/non-persistent) that this queue supervises the phase of. </li> </ul>"},{"location":"runtime/classDeviceQueue/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classDeviceQueue/#function-devicequeue-12","title":"function DeviceQueue [1/2]","text":"<pre><code>DeviceQueue::DeviceQueue () = default\n</code></pre>"},{"location":"runtime/classDeviceQueue/#function-devicequeue-22","title":"function DeviceQueue [2/2]","text":"<pre><code>inline DeviceQueue::DeviceQueue (\nDevice * device\n) </code></pre>"},{"location":"runtime/classDeviceQueue/#function-empty","title":"function empty","text":"<pre><code>inline bool DeviceQueue::empty () </code></pre>"},{"location":"runtime/classDeviceQueue/#function-enqueue","title":"function enqueue","text":"<p>Enqueues a task on this device. <pre><code>inline void DeviceQueue::enqueue (\nInnerTask * task\n) </code></pre></p> <p>Parameters:</p> <ul> <li><code>task</code> the task to enqueue </li> </ul>"},{"location":"runtime/classDeviceQueue/#function-front","title":"function front","text":"<pre><code>inline InnerTask * DeviceQueue::front () </code></pre> <p>Returns:</p> <p>the next task that can be dequeued on this device. If there are no tasks that can dequeued, returns nullptr.</p> <p>A task is can be dequeued if: * It is a single-device task * It is a multi-device task that is no longer waiting for its other instances</p> <p>We do not block on multi-device tasks that are still waiting for their other instances. This allows progress on single-device tasks and avoids deadlock if multi-device tasks are enqueued out of order.</p> <p>This does not check resources, it only checks if the task is ready to dequeue. It does not remove the returned task from the queue. </p>"},{"location":"runtime/classDeviceQueue/#function-get_device","title":"function get_device","text":"<pre><code>inline Device * DeviceQueue::get_device () </code></pre> <p>Returns:</p> <p>the device that this queue is associated with </p>"},{"location":"runtime/classDeviceQueue/#function-pop","title":"function pop","text":"<p>Grabs the next task that can be dequeued on this device. <pre><code>inline InnerTask * DeviceQueue::pop () </code></pre></p> <p>If there are no tasks that can dequeued, returns nullptr. Removes the returned task from the queue.</p> <p>Should be called only after front() returns a non-null task. Otherwise, the internal state may be modified (may push multi-device to waiting queue).</p> <p>Returns:</p> <p>the previous task at HEAD of the queue. </p>"},{"location":"runtime/classDeviceQueue/#function-size","title":"function size","text":"<pre><code>inline size_t DeviceQueue::size () </code></pre>"},{"location":"runtime/classDeviceQueue/#protected-attributes-documentation","title":"Protected Attributes Documentation","text":""},{"location":"runtime/classDeviceQueue/#variable-device","title":"variable device","text":"<pre><code>Device* DeviceQueue&lt; category &gt;::device;\n</code></pre>"},{"location":"runtime/classDeviceQueue/#variable-mixed_queue","title":"variable mixed_queue","text":"<pre><code>MixedQueue_t DeviceQueue&lt; category &gt;::mixed_queue;\n</code></pre>"},{"location":"runtime/classDeviceQueue/#variable-num_tasks","title":"variable num_tasks","text":"<pre><code>std::atomic&lt;int&gt; DeviceQueue&lt; category &gt;::num_tasks;\n</code></pre>"},{"location":"runtime/classDeviceQueue/#variable-waiting_queue","title":"variable waiting_queue","text":"<pre><code>MDQueue_t DeviceQueue&lt; category &gt;::waiting_queue;\n</code></pre> <p>The documentation for this class was generated from the following file <code>src/c/backend/include/device_queues.hpp</code></p>"},{"location":"runtime/classDeviceRequirement/","title":"Class DeviceRequirement","text":"<p>ClassList &gt; DeviceRequirement</p> <p>Inherits the following classes: SinglePlacementRequirementBase</p>"},{"location":"runtime/classDeviceRequirement/#public-functions","title":"Public Functions","text":"Type Name DeviceRequirement (Device * dev, ResourcePool_t res_req)  Device * device ()  virtual bool is_arch_req () override virtual bool is_dev_req () override virtual bool is_multidev_req () override const ResourcePool_t &amp; res_req () const ResourcePool_t &amp; res_req ()"},{"location":"runtime/classDeviceRequirement/#public-functions-inherited-from-placementrequirementbase","title":"Public Functions inherited from PlacementRequirementBase","text":"<p>See PlacementRequirementBase</p> Type Name virtual bool is_arch_req () = 0 virtual bool is_dev_req () = 0 virtual bool is_multidev_req () = 0"},{"location":"runtime/classDeviceRequirement/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classDeviceRequirement/#function-devicerequirement","title":"function DeviceRequirement","text":"<pre><code>inline DeviceRequirement::DeviceRequirement (\nDevice * dev,\nResourcePool_t res_req\n) </code></pre>"},{"location":"runtime/classDeviceRequirement/#function-device","title":"function device","text":"<pre><code>inline Device * DeviceRequirement::device () </code></pre>"},{"location":"runtime/classDeviceRequirement/#function-is_arch_req","title":"function is_arch_req","text":"<pre><code>inline virtual bool DeviceRequirement::is_arch_req () override\n</code></pre> <p>Implements PlacementRequirementBase::is_arch_req</p>"},{"location":"runtime/classDeviceRequirement/#function-is_dev_req","title":"function is_dev_req","text":"<pre><code>inline virtual bool DeviceRequirement::is_dev_req () override\n</code></pre> <p>Implements PlacementRequirementBase::is_dev_req</p>"},{"location":"runtime/classDeviceRequirement/#function-is_multidev_req","title":"function is_multidev_req","text":"<pre><code>inline virtual bool DeviceRequirement::is_multidev_req () override\n</code></pre> <p>Implements PlacementRequirementBase::is_multidev_req</p>"},{"location":"runtime/classDeviceRequirement/#function-res_req-12","title":"function res_req [1/2]","text":"<pre><code>inline const ResourcePool_t &amp; DeviceRequirement::res_req () const\n</code></pre>"},{"location":"runtime/classDeviceRequirement/#function-res_req-22","title":"function res_req [2/2]","text":"<pre><code>inline ResourcePool_t &amp; DeviceRequirement::res_req () </code></pre> <p>The documentation for this class was generated from the following file <code>src/c/backend/include/resource_requirements.hpp</code></p>"},{"location":"runtime/classInnerDataTask/","title":"Class InnerDataTask","text":"<p>ClassList &gt; InnerDataTask</p> <p>Inherits the following classes: InnerTask</p>"},{"location":"runtime/classInnerDataTask/#public-attributes-inherited-from-innertask","title":"Public Attributes inherited from InnerTask","text":"<p>See InnerTask</p> Type Name std::vector&lt; Device * &gt; assigned_devices TaskList dependencies std::vector&lt; InnerTask * &gt; dependency_buffer   = = std::vector&lt;InnerTask *&gt;() TaskList dependents std::unordered_map&lt; int, ResourcePool_t &gt; device_constraints PointerList events long long int id   = = 0 int instance   = = 0 std::atomic&lt; bool &gt; is_data   = {false} std::mutex mtx std::string name   = = \"\" std::atomic&lt; int &gt; num_blocking_compute_dependencies   = {1} std::atomic&lt; int &gt; num_blocking_dependencies   = {1} std::atomic&lt; int &gt; num_persistant_instances   = {1} std::atomic&lt; int &gt; num_runtime_instances   = {1} std::atomic&lt; int &gt; num_unmapped_dependencies   = {1} std::atomic&lt; int &gt; num_unreserved_dependencies   = {1} std::atomic&lt; int &gt; num_unspawned_dependencies   = {1} std::vector&lt; std::vector&lt; std::pair&lt; parray::InnerPArray *, AccessMode &gt; &gt; &gt; parray_list std::atomic&lt; int &gt; priority   = {0} std::atomic&lt; bool &gt; processed_data   = {true} void * py_task   = = nullptr bool removed_reserved   = {false} bool removed_runtime   = {false} InnerScheduler * scheduler   = = nullptr SpaceList spaces std::atomic&lt; Task::State &gt; state   = {Task::CREATED} std::atomic&lt; Task::Status &gt; status   = {Task::INITIAL} PointerList streams Task::SynchronizationType sync_type   = = Task::NON_BLOCKING"},{"location":"runtime/classInnerDataTask/#public-functions","title":"Public Functions","text":"Type Name InnerDataTask () = delete InnerDataTask (std::string name, long long int id, parray::InnerPArray * parray, AccessMode access_mode, int dev_id)  AccessMode get_access_mode () Return a access mode of PArray. int get_device_id ()  void * get_py_parray () Return a python PArray pointer (as void*)."},{"location":"runtime/classInnerDataTask/#public-functions-inherited-from-innertask","title":"Public Functions inherited from InnerTask","text":"<p>See InnerTask</p> Type Name InnerTask ()  InnerTask (long long int id, void * py_task)  InnerTask (std::string name, long long int id, void * py_task)  void add_assigned_device (Device * device)  Task::StatusFlags add_dependencies (std::vector&lt; InnerTask * &gt; &amp; tasks, bool data_tasks=false)  Task::State add_dependency (InnerTask * task)  Task::State add_dependent_space (TaskBarrier * barrier)  Task::State add_dependent_task (InnerTask * task)  void add_device_req (Device * dev_ptr, MemorySz_t mem_sz, VCU_t num_vcus)  void add_event (uintptr_t event)  void add_parray (parray::InnerPArray * parray, int access_mode, int dev_id)  void add_stream (uintptr_t stream)  void begin_arch_req_addition ()  void begin_multidev_req_addition ()  bool blocked ()  void clear_dependencies ()  void copy_assigned_devices (const std::vector&lt; Device * &gt; &amp; others)  int decrement_num_instances ()  Task::Status determine_status (bool spawnable, bool mappable, bool reservable, bool ready)  void end_arch_req_addition ()  void end_multidev_req_addition ()  std::vector&lt; Device * &gt; &amp; get_assigned_devices ()  bool get_complete ()  std::vector&lt; void * &gt; get_dependencies ()  std::vector&lt; void * &gt; get_dependents ()  const std::string &amp; get_name () const std::string get_name ()  int get_num_blocking_dependencies () const int get_num_dependencies ()  int get_num_dependents ()  int get_num_instances ()  int get_num_unmapped_dependencies () const PlacementRequirementCollections &amp; get_placement_req_options ()  void * get_py_task ()  bool get_removed ()  Task::State get_state () const Task::Status get_status () const void handle_runahead_dependencies (int sync_type)  bool is_data_task ()  Task::StatusFlags notify (Task::State dependency_state, bool is_data=false)  void notify_dependents (TaskStateList &amp; tasks, Task::State new_state)  void notify_dependents_completed ()  bool notify_dependents_wrapper ()  Task::StatusFlags process_dependencies ()  void queue_dependency (InnerTask * task)  void reset ()  void reset_events_streams ()  void set_complete ()  void set_id (long long int name)  void set_name (std::string name)  void set_num_instances ()  void set_priority (int priority)  void set_py_task (void * py_task)  void set_removed (bool waiting)  void set_scheduler (InnerScheduler * scheduler)  int set_state (int state)  Task::State set_state (Task::State state)  Task::Status set_status (Task::Status status)  void synchronize_dependency_events ()  void synchronize_events ()  void wait_dependency_events ()"},{"location":"runtime/classInnerDataTask/#protected-types-inherited-from-innertask","title":"Protected Types inherited from InnerTask","text":"<p>See InnerTask</p> Type Name enum ReqAdditionState"},{"location":"runtime/classInnerDataTask/#protected-attributes-inherited-from-innertask","title":"Protected Attributes inherited from InnerTask","text":"<p>See InnerTask</p> Type Name PlacementRequirementCollections placement_req_options_ uint32_t req_addition_mode_ std::shared_ptr&lt; ArchitectureRequirement &gt; tmp_arch_req_ std::shared_ptr&lt; MultiDeviceRequirements &gt; tmp_multdev_reqs_"},{"location":"runtime/classInnerDataTask/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classInnerDataTask/#function-innerdatatask-12","title":"function InnerDataTask [1/2]","text":"<pre><code>InnerDataTask::InnerDataTask () = delete\n</code></pre>"},{"location":"runtime/classInnerDataTask/#function-innerdatatask-22","title":"function InnerDataTask [2/2]","text":"<pre><code>inline InnerDataTask::InnerDataTask (\nstd::string name,\nlong long int id,\nparray::InnerPArray * parray,\nAccessMode access_mode,\nint dev_id\n) </code></pre>"},{"location":"runtime/classInnerDataTask/#function-get_access_mode","title":"function get_access_mode","text":"<pre><code>AccessMode InnerDataTask::get_access_mode () </code></pre>"},{"location":"runtime/classInnerDataTask/#function-get_device_id","title":"function get_device_id","text":"<pre><code>inline int InnerDataTask::get_device_id () </code></pre>"},{"location":"runtime/classInnerDataTask/#function-get_py_parray","title":"function get_py_parray","text":"<pre><code>void * InnerDataTask::get_py_parray () </code></pre> <p>The documentation for this class was generated from the following file <code>src/c/backend/include/runtime.hpp</code></p>"},{"location":"runtime/classInnerScheduler/","title":"Class InnerScheduler","text":"<p>ClassList &gt; InnerScheduler</p> <p>The C++ \"Mirror\" of Parla's Python Scheduler This class is used to create a C++ representation of a Parla Scheduler All scheduling logic should be handled by these after creation until launched by the Python callback. </p> <ul> <li><code>#include &lt;runtime.hpp&gt;</code></li> </ul>"},{"location":"runtime/classInnerScheduler/#public-attributes","title":"Public Attributes","text":"Type Name Launcher * launcher Mapper * mapper MemoryReserver * memory_reserver std::atomic&lt; int &gt; num_active_tasks   = {1} void * py_scheduler RuntimeReserver * runtime_reserver std::atomic&lt; bool &gt; should_run   = = true bool sleep_flag   = = false int sleep_time   = = 20 Scheduler::Status status stopfunc_t stop_callback std::vector&lt; InnerTask * &gt; task_buffer   = = std::vector&lt;InnerTask *&gt;(10) WorkerPool_t workers"},{"location":"runtime/classInnerScheduler/#public-functions","title":"Public Functions","text":"Type Name InnerScheduler (DeviceManager * device_manager)  Scheduler::Status activate ()  void activate_wrapper ()  void add_worker (InnerWorker * worker)  void decrease_num_active_tasks ()  int decrease_num_notified_workers ()  void enqueue_task (InnerTask * task, Task::StatusFlags flags)  void enqueue_tasks (TaskStateList &amp; tasks)  void enqueue_worker (InnerWorker * worker)  DeviceManager * get_device_manager ()  int get_num_active_tasks ()  int get_num_notified_workers ()  int get_num_ready_tasks ()  int get_num_running_tasks ()  bool get_parray_state (DevID_t global_dev_idx, uint64_t parray_parent_id)  PArrayTracker * get_parray_tracker ()  void increase_num_active_tasks ()  int increase_num_notified_workers ()  void release_parray (parray::InnerPArray * parray, DevID_t global_dev_id)  void reserve_parray (parray::InnerPArray * parray, DevID_t global_dev_id)  void run ()  void set_num_workers (int nworkers)  void set_py_scheduler (void * py_scheduler)  void set_stop_callback (stopfunc_t stop_callback)  void spawn_task (InnerTask * task)  void spawn_wait ()  void stop ()  void task_cleanup (InnerWorker * worker, InnerTask * task, int state)  void task_cleanup_postsync (InnerWorker * worker, InnerTask * task, int state)  void task_cleanup_presync (InnerWorker * worker, InnerTask * task, int state)  ~InnerScheduler ()"},{"location":"runtime/classInnerScheduler/#protected-attributes","title":"Protected Attributes","text":"Type Name DeviceManager * device_manager_ It manages all device instances in C++. PArrayTracker parray_tracker_ It manages the current/planned distribution of PArrays across devices."},{"location":"runtime/classInnerScheduler/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"runtime/classInnerScheduler/#variable-launcher","title":"variable launcher","text":"<pre><code>Launcher* InnerScheduler::launcher;\n</code></pre>"},{"location":"runtime/classInnerScheduler/#variable-mapper","title":"variable mapper","text":"<pre><code>Mapper* InnerScheduler::mapper;\n</code></pre>"},{"location":"runtime/classInnerScheduler/#variable-memory_reserver","title":"variable memory_reserver","text":"<pre><code>MemoryReserver* InnerScheduler::memory_reserver;\n</code></pre>"},{"location":"runtime/classInnerScheduler/#variable-num_active_tasks","title":"variable num_active_tasks","text":"<pre><code>std::atomic&lt;int&gt; InnerScheduler::num_active_tasks;\n</code></pre>"},{"location":"runtime/classInnerScheduler/#variable-py_scheduler","title":"variable py_scheduler","text":"<pre><code>void* InnerScheduler::py_scheduler;\n</code></pre>"},{"location":"runtime/classInnerScheduler/#variable-runtime_reserver","title":"variable runtime_reserver","text":"<pre><code>RuntimeReserver* InnerScheduler::runtime_reserver;\n</code></pre>"},{"location":"runtime/classInnerScheduler/#variable-should_run","title":"variable should_run","text":"<pre><code>std::atomic&lt;bool&gt; InnerScheduler::should_run;\n</code></pre>"},{"location":"runtime/classInnerScheduler/#variable-sleep_flag","title":"variable sleep_flag","text":"<pre><code>bool InnerScheduler::sleep_flag;\n</code></pre>"},{"location":"runtime/classInnerScheduler/#variable-sleep_time","title":"variable sleep_time","text":"<pre><code>int InnerScheduler::sleep_time;\n</code></pre>"},{"location":"runtime/classInnerScheduler/#variable-status","title":"variable status","text":"<pre><code>Scheduler::Status InnerScheduler::status;\n</code></pre>"},{"location":"runtime/classInnerScheduler/#variable-stop_callback","title":"variable stop_callback","text":"<pre><code>stopfunc_t InnerScheduler::stop_callback;\n</code></pre>"},{"location":"runtime/classInnerScheduler/#variable-task_buffer","title":"variable task_buffer","text":"<pre><code>std::vector&lt;InnerTask *&gt; InnerScheduler::task_buffer;\n</code></pre>"},{"location":"runtime/classInnerScheduler/#variable-workers","title":"variable workers","text":"<pre><code>WorkerPool_t InnerScheduler::workers;\n</code></pre>"},{"location":"runtime/classInnerScheduler/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classInnerScheduler/#function-innerscheduler","title":"function InnerScheduler","text":"<pre><code>InnerScheduler::InnerScheduler (\nDeviceManager * device_manager\n) </code></pre>"},{"location":"runtime/classInnerScheduler/#function-activate","title":"function activate","text":"<pre><code>Scheduler::Status InnerScheduler::activate () </code></pre>"},{"location":"runtime/classInnerScheduler/#function-activate_wrapper","title":"function activate_wrapper","text":"<pre><code>void InnerScheduler::activate_wrapper () </code></pre>"},{"location":"runtime/classInnerScheduler/#function-add_worker","title":"function add_worker","text":"<pre><code>void InnerScheduler::add_worker (\nInnerWorker * worker\n) </code></pre>"},{"location":"runtime/classInnerScheduler/#function-decrease_num_active_tasks","title":"function decrease_num_active_tasks","text":"<pre><code>void InnerScheduler::decrease_num_active_tasks () </code></pre>"},{"location":"runtime/classInnerScheduler/#function-decrease_num_notified_workers","title":"function decrease_num_notified_workers","text":"<pre><code>int InnerScheduler::decrease_num_notified_workers () </code></pre>"},{"location":"runtime/classInnerScheduler/#function-enqueue_task","title":"function enqueue_task","text":"<pre><code>void InnerScheduler::enqueue_task (\nInnerTask * task,\nTask::StatusFlags flags\n) </code></pre>"},{"location":"runtime/classInnerScheduler/#function-enqueue_tasks","title":"function enqueue_tasks","text":"<pre><code>void InnerScheduler::enqueue_tasks (\nTaskStateList &amp; tasks\n) </code></pre>"},{"location":"runtime/classInnerScheduler/#function-enqueue_worker","title":"function enqueue_worker","text":"<pre><code>void InnerScheduler::enqueue_worker (\nInnerWorker * worker\n) </code></pre>"},{"location":"runtime/classInnerScheduler/#function-get_device_manager","title":"function get_device_manager","text":"<pre><code>inline DeviceManager * InnerScheduler::get_device_manager () </code></pre>"},{"location":"runtime/classInnerScheduler/#function-get_num_active_tasks","title":"function get_num_active_tasks","text":"<pre><code>int InnerScheduler::get_num_active_tasks () </code></pre>"},{"location":"runtime/classInnerScheduler/#function-get_num_notified_workers","title":"function get_num_notified_workers","text":"<pre><code>inline int InnerScheduler::get_num_notified_workers () </code></pre>"},{"location":"runtime/classInnerScheduler/#function-get_num_ready_tasks","title":"function get_num_ready_tasks","text":"<pre><code>int InnerScheduler::get_num_ready_tasks () </code></pre>"},{"location":"runtime/classInnerScheduler/#function-get_num_running_tasks","title":"function get_num_running_tasks","text":"<pre><code>int InnerScheduler::get_num_running_tasks () </code></pre>"},{"location":"runtime/classInnerScheduler/#function-get_parray_state","title":"function get_parray_state","text":"<pre><code>inline bool InnerScheduler::get_parray_state (\nDevID_t global_dev_idx,\nuint64_t parray_parent_id\n) </code></pre>"},{"location":"runtime/classInnerScheduler/#function-get_parray_tracker","title":"function get_parray_tracker","text":"<pre><code>inline PArrayTracker * InnerScheduler::get_parray_tracker () </code></pre>"},{"location":"runtime/classInnerScheduler/#function-increase_num_active_tasks","title":"function increase_num_active_tasks","text":"<pre><code>void InnerScheduler::increase_num_active_tasks () </code></pre>"},{"location":"runtime/classInnerScheduler/#function-increase_num_notified_workers","title":"function increase_num_notified_workers","text":"<pre><code>int InnerScheduler::increase_num_notified_workers () </code></pre>"},{"location":"runtime/classInnerScheduler/#function-release_parray","title":"function release_parray","text":"<pre><code>inline void InnerScheduler::release_parray (\nparray::InnerPArray * parray,\nDevID_t global_dev_id\n) </code></pre>"},{"location":"runtime/classInnerScheduler/#function-reserve_parray","title":"function reserve_parray","text":"<pre><code>inline void InnerScheduler::reserve_parray (\nparray::InnerPArray * parray,\nDevID_t global_dev_id\n) </code></pre>"},{"location":"runtime/classInnerScheduler/#function-run","title":"function run","text":"<pre><code>void InnerScheduler::run () </code></pre>"},{"location":"runtime/classInnerScheduler/#function-set_num_workers","title":"function set_num_workers","text":"<pre><code>void InnerScheduler::set_num_workers (\nint nworkers\n) </code></pre>"},{"location":"runtime/classInnerScheduler/#function-set_py_scheduler","title":"function set_py_scheduler","text":"<pre><code>void InnerScheduler::set_py_scheduler (\nvoid * py_scheduler\n) </code></pre>"},{"location":"runtime/classInnerScheduler/#function-set_stop_callback","title":"function set_stop_callback","text":"<pre><code>void InnerScheduler::set_stop_callback (\nstopfunc_t stop_callback\n) </code></pre>"},{"location":"runtime/classInnerScheduler/#function-spawn_task","title":"function spawn_task","text":"<pre><code>void InnerScheduler::spawn_task (\nInnerTask * task\n) </code></pre>"},{"location":"runtime/classInnerScheduler/#function-spawn_wait","title":"function spawn_wait","text":"<pre><code>void InnerScheduler::spawn_wait () </code></pre>"},{"location":"runtime/classInnerScheduler/#function-stop","title":"function stop","text":"<pre><code>void InnerScheduler::stop () </code></pre>"},{"location":"runtime/classInnerScheduler/#function-task_cleanup","title":"function task_cleanup","text":"<pre><code>void InnerScheduler::task_cleanup (\nInnerWorker * worker,\nInnerTask * task,\nint state\n) </code></pre>"},{"location":"runtime/classInnerScheduler/#function-task_cleanup_postsync","title":"function task_cleanup_postsync","text":"<pre><code>void InnerScheduler::task_cleanup_postsync (\nInnerWorker * worker,\nInnerTask * task,\nint state\n) </code></pre>"},{"location":"runtime/classInnerScheduler/#function-task_cleanup_presync","title":"function task_cleanup_presync","text":"<pre><code>void InnerScheduler::task_cleanup_presync (\nInnerWorker * worker,\nInnerTask * task,\nint state\n) </code></pre>"},{"location":"runtime/classInnerScheduler/#function-innerscheduler_1","title":"function ~InnerScheduler","text":"<pre><code>InnerScheduler::~InnerScheduler () </code></pre>"},{"location":"runtime/classInnerScheduler/#protected-attributes-documentation","title":"Protected Attributes Documentation","text":""},{"location":"runtime/classInnerScheduler/#variable-device_manager_","title":"variable device_manager_","text":"<p>It manages all device instances in C++. <pre><code>DeviceManager* InnerScheduler::device_manager_;\n</code></pre></p> <p>This is destructed by the Cython scheduler. </p>"},{"location":"runtime/classInnerScheduler/#variable-parray_tracker_","title":"variable parray_tracker_","text":"<p>It manages the current/planned distribution of PArrays across devices. <pre><code>PArrayTracker InnerScheduler::parray_tracker_;\n</code></pre></p> <p>Parla task mapping policy considers locality of PArrays through this. </p> <p>The documentation for this class was generated from the following file <code>src/c/backend/include/runtime.hpp</code></p>"},{"location":"runtime/classInnerTask/","title":"Class InnerTask","text":"<p>ClassList &gt; InnerTask</p> <p>The C++ \"Mirror\" of Parla's Python Tasks This class is used to create a C++ representation of a Parla Task All scheduling logic should be handled by these after creation until launched by the Python callback. </p> <ul> <li><code>#include &lt;runtime.hpp&gt;</code></li> </ul> <p>Inherited by the following classes: InnerDataTask</p>"},{"location":"runtime/classInnerTask/#public-attributes","title":"Public Attributes","text":"Type Name std::vector&lt; Device * &gt; assigned_devices TaskList dependencies std::vector&lt; InnerTask * &gt; dependency_buffer   = = std::vector&lt;InnerTask *&gt;() TaskList dependents std::unordered_map&lt; int, ResourcePool_t &gt; device_constraints PointerList events long long int id   = = 0 int instance   = = 0 std::atomic&lt; bool &gt; is_data   = {false} std::mutex mtx std::string name   = = \"\" std::atomic&lt; int &gt; num_blocking_compute_dependencies   = {1} std::atomic&lt; int &gt; num_blocking_dependencies   = {1} std::atomic&lt; int &gt; num_persistant_instances   = {1} std::atomic&lt; int &gt; num_runtime_instances   = {1} std::atomic&lt; int &gt; num_unmapped_dependencies   = {1} std::atomic&lt; int &gt; num_unreserved_dependencies   = {1} std::atomic&lt; int &gt; num_unspawned_dependencies   = {1} std::vector&lt; std::vector&lt; std::pair&lt; parray::InnerPArray *, AccessMode &gt; &gt; &gt; parray_list std::atomic&lt; int &gt; priority   = {0} std::atomic&lt; bool &gt; processed_data   = {true} void * py_task   = = nullptr bool removed_reserved   = {false} bool removed_runtime   = {false} InnerScheduler * scheduler   = = nullptr SpaceList spaces std::atomic&lt; Task::State &gt; state   = {Task::CREATED} std::atomic&lt; Task::Status &gt; status   = {Task::INITIAL} PointerList streams Task::SynchronizationType sync_type   = = Task::NON_BLOCKING"},{"location":"runtime/classInnerTask/#public-functions","title":"Public Functions","text":"Type Name InnerTask ()  InnerTask (long long int id, void * py_task)  InnerTask (std::string name, long long int id, void * py_task)  void add_assigned_device (Device * device)  Task::StatusFlags add_dependencies (std::vector&lt; InnerTask * &gt; &amp; tasks, bool data_tasks=false)  Task::State add_dependency (InnerTask * task)  Task::State add_dependent_space (TaskBarrier * barrier)  Task::State add_dependent_task (InnerTask * task)  void add_device_req (Device * dev_ptr, MemorySz_t mem_sz, VCU_t num_vcus)  void add_event (uintptr_t event)  void add_parray (parray::InnerPArray * parray, int access_mode, int dev_id)  void add_stream (uintptr_t stream)  void begin_arch_req_addition ()  void begin_multidev_req_addition ()  bool blocked ()  void clear_dependencies ()  void copy_assigned_devices (const std::vector&lt; Device * &gt; &amp; others)  int decrement_num_instances ()  Task::Status determine_status (bool spawnable, bool mappable, bool reservable, bool ready)  void end_arch_req_addition ()  void end_multidev_req_addition ()  std::vector&lt; Device * &gt; &amp; get_assigned_devices ()  bool get_complete ()  std::vector&lt; void * &gt; get_dependencies ()  std::vector&lt; void * &gt; get_dependents ()  const std::string &amp; get_name () const std::string get_name ()  int get_num_blocking_dependencies () const int get_num_dependencies ()  int get_num_dependents ()  int get_num_instances ()  int get_num_unmapped_dependencies () const PlacementRequirementCollections &amp; get_placement_req_options ()  void * get_py_task ()  bool get_removed ()  Task::State get_state () const Task::Status get_status () const void handle_runahead_dependencies (int sync_type)  bool is_data_task ()  Task::StatusFlags notify (Task::State dependency_state, bool is_data=false)  void notify_dependents (TaskStateList &amp; tasks, Task::State new_state)  void notify_dependents_completed ()  bool notify_dependents_wrapper ()  Task::StatusFlags process_dependencies ()  void queue_dependency (InnerTask * task)  void reset ()  void reset_events_streams ()  void set_complete ()  void set_id (long long int name)  void set_name (std::string name)  void set_num_instances ()  void set_priority (int priority)  void set_py_task (void * py_task)  void set_removed (bool waiting)  void set_scheduler (InnerScheduler * scheduler)  int set_state (int state)  Task::State set_state (Task::State state)  Task::Status set_status (Task::Status status)  void synchronize_dependency_events ()  void synchronize_events ()  void wait_dependency_events ()"},{"location":"runtime/classInnerTask/#protected-types","title":"Protected Types","text":"Type Name enum ReqAdditionState"},{"location":"runtime/classInnerTask/#protected-attributes","title":"Protected Attributes","text":"Type Name PlacementRequirementCollections placement_req_options_ uint32_t req_addition_mode_ std::shared_ptr&lt; ArchitectureRequirement &gt; tmp_arch_req_ std::shared_ptr&lt; MultiDeviceRequirements &gt; tmp_multdev_reqs_"},{"location":"runtime/classInnerTask/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"runtime/classInnerTask/#variable-assigned_devices","title":"variable assigned_devices","text":"<pre><code>std::vector&lt;Device *&gt; InnerTask::assigned_devices;\n</code></pre>"},{"location":"runtime/classInnerTask/#variable-dependencies","title":"variable dependencies","text":"<pre><code>TaskList InnerTask::dependencies;\n</code></pre>"},{"location":"runtime/classInnerTask/#variable-dependency_buffer","title":"variable dependency_buffer","text":"<pre><code>std::vector&lt;InnerTask *&gt; InnerTask::dependency_buffer;\n</code></pre>"},{"location":"runtime/classInnerTask/#variable-dependents","title":"variable dependents","text":"<pre><code>TaskList InnerTask::dependents;\n</code></pre>"},{"location":"runtime/classInnerTask/#variable-device_constraints","title":"variable device_constraints","text":"<pre><code>std::unordered_map&lt;int, ResourcePool_t&gt; InnerTask::device_constraints;\n</code></pre>"},{"location":"runtime/classInnerTask/#variable-events","title":"variable events","text":"<pre><code>PointerList InnerTask::events;\n</code></pre>"},{"location":"runtime/classInnerTask/#variable-id","title":"variable id","text":"<pre><code>long long int InnerTask::id;\n</code></pre>"},{"location":"runtime/classInnerTask/#variable-instance","title":"variable instance","text":"<pre><code>int InnerTask::instance;\n</code></pre>"},{"location":"runtime/classInnerTask/#variable-is_data","title":"variable is_data","text":"<pre><code>std::atomic&lt;bool&gt; InnerTask::is_data;\n</code></pre>"},{"location":"runtime/classInnerTask/#variable-mtx","title":"variable mtx","text":"<pre><code>std::mutex InnerTask::mtx;\n</code></pre>"},{"location":"runtime/classInnerTask/#variable-name","title":"variable name","text":"<pre><code>std::string InnerTask::name;\n</code></pre>"},{"location":"runtime/classInnerTask/#variable-num_blocking_compute_dependencies","title":"variable num_blocking_compute_dependencies","text":"<pre><code>std::atomic&lt;int&gt; InnerTask::num_blocking_compute_dependencies;\n</code></pre>"},{"location":"runtime/classInnerTask/#variable-num_blocking_dependencies","title":"variable num_blocking_dependencies","text":"<pre><code>std::atomic&lt;int&gt; InnerTask::num_blocking_dependencies;\n</code></pre>"},{"location":"runtime/classInnerTask/#variable-num_persistant_instances","title":"variable num_persistant_instances","text":"<pre><code>std::atomic&lt;int&gt; InnerTask::num_persistant_instances;\n</code></pre>"},{"location":"runtime/classInnerTask/#variable-num_runtime_instances","title":"variable num_runtime_instances","text":"<pre><code>std::atomic&lt;int&gt; InnerTask::num_runtime_instances;\n</code></pre>"},{"location":"runtime/classInnerTask/#variable-num_unmapped_dependencies","title":"variable num_unmapped_dependencies","text":"<pre><code>std::atomic&lt;int&gt; InnerTask::num_unmapped_dependencies;\n</code></pre>"},{"location":"runtime/classInnerTask/#variable-num_unreserved_dependencies","title":"variable num_unreserved_dependencies","text":"<pre><code>std::atomic&lt;int&gt; InnerTask::num_unreserved_dependencies;\n</code></pre>"},{"location":"runtime/classInnerTask/#variable-num_unspawned_dependencies","title":"variable num_unspawned_dependencies","text":"<pre><code>std::atomic&lt;int&gt; InnerTask::num_unspawned_dependencies;\n</code></pre>"},{"location":"runtime/classInnerTask/#variable-parray_list","title":"variable parray_list","text":"<pre><code>std::vector&lt;std::vector&lt;std::pair&lt;parray::InnerPArray *, AccessMode&gt; &gt; &gt; InnerTask::parray_list;\n</code></pre>"},{"location":"runtime/classInnerTask/#variable-priority","title":"variable priority","text":"<pre><code>std::atomic&lt;int&gt; InnerTask::priority;\n</code></pre>"},{"location":"runtime/classInnerTask/#variable-processed_data","title":"variable processed_data","text":"<pre><code>std::atomic&lt;bool&gt; InnerTask::processed_data;\n</code></pre>"},{"location":"runtime/classInnerTask/#variable-py_task","title":"variable py_task","text":"<pre><code>void* InnerTask::py_task;\n</code></pre>"},{"location":"runtime/classInnerTask/#variable-removed_reserved","title":"variable removed_reserved","text":"<pre><code>bool InnerTask::removed_reserved;\n</code></pre>"},{"location":"runtime/classInnerTask/#variable-removed_runtime","title":"variable removed_runtime","text":"<pre><code>bool InnerTask::removed_runtime;\n</code></pre>"},{"location":"runtime/classInnerTask/#variable-scheduler","title":"variable scheduler","text":"<pre><code>InnerScheduler* InnerTask::scheduler;\n</code></pre>"},{"location":"runtime/classInnerTask/#variable-spaces","title":"variable spaces","text":"<pre><code>SpaceList InnerTask::spaces;\n</code></pre>"},{"location":"runtime/classInnerTask/#variable-state","title":"variable state","text":"<pre><code>std::atomic&lt;Task::State&gt; InnerTask::state;\n</code></pre>"},{"location":"runtime/classInnerTask/#variable-status","title":"variable status","text":"<pre><code>std::atomic&lt;Task::Status&gt; InnerTask::status;\n</code></pre>"},{"location":"runtime/classInnerTask/#variable-streams","title":"variable streams","text":"<pre><code>PointerList InnerTask::streams;\n</code></pre>"},{"location":"runtime/classInnerTask/#variable-sync_type","title":"variable sync_type","text":"<pre><code>Task::SynchronizationType InnerTask::sync_type;\n</code></pre>"},{"location":"runtime/classInnerTask/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classInnerTask/#function-innertask-13","title":"function InnerTask [1/3]","text":"<pre><code>InnerTask::InnerTask () </code></pre>"},{"location":"runtime/classInnerTask/#function-innertask-23","title":"function InnerTask [2/3]","text":"<pre><code>InnerTask::InnerTask (\nlong long int id,\nvoid * py_task\n) </code></pre>"},{"location":"runtime/classInnerTask/#function-innertask-33","title":"function InnerTask [3/3]","text":"<pre><code>InnerTask::InnerTask (\nstd::string name,\nlong long int id,\nvoid * py_task\n) </code></pre>"},{"location":"runtime/classInnerTask/#function-add_assigned_device","title":"function add_assigned_device","text":"<pre><code>void InnerTask::add_assigned_device (\nDevice * device\n) </code></pre>"},{"location":"runtime/classInnerTask/#function-add_dependencies","title":"function add_dependencies","text":"<pre><code>Task::StatusFlags InnerTask::add_dependencies (\nstd::vector&lt; InnerTask * &gt; &amp; tasks,\nbool data_tasks=false\n) </code></pre>"},{"location":"runtime/classInnerTask/#function-add_dependency","title":"function add_dependency","text":"<pre><code>Task::State InnerTask::add_dependency (\nInnerTask * task\n) </code></pre>"},{"location":"runtime/classInnerTask/#function-add_dependent_space","title":"function add_dependent_space","text":"<pre><code>Task::State InnerTask::add_dependent_space (\nTaskBarrier * barrier\n) </code></pre>"},{"location":"runtime/classInnerTask/#function-add_dependent_task","title":"function add_dependent_task","text":"<pre><code>Task::State InnerTask::add_dependent_task (\nInnerTask * task\n) </code></pre>"},{"location":"runtime/classInnerTask/#function-add_device_req","title":"function add_device_req","text":"<pre><code>void InnerTask::add_device_req (\nDevice * dev_ptr,\nMemorySz_t mem_sz,\nVCU_t num_vcus\n) </code></pre>"},{"location":"runtime/classInnerTask/#function-add_event","title":"function add_event","text":"<pre><code>inline void InnerTask::add_event (\nuintptr_t event\n) </code></pre>"},{"location":"runtime/classInnerTask/#function-add_parray","title":"function add_parray","text":"<pre><code>void InnerTask::add_parray (\nparray::InnerPArray * parray,\nint access_mode,\nint dev_id\n) </code></pre>"},{"location":"runtime/classInnerTask/#function-add_stream","title":"function add_stream","text":"<pre><code>inline void InnerTask::add_stream (\nuintptr_t stream\n) </code></pre>"},{"location":"runtime/classInnerTask/#function-begin_arch_req_addition","title":"function begin_arch_req_addition","text":"<pre><code>void InnerTask::begin_arch_req_addition () </code></pre>"},{"location":"runtime/classInnerTask/#function-begin_multidev_req_addition","title":"function begin_multidev_req_addition","text":"<pre><code>void InnerTask::begin_multidev_req_addition () </code></pre>"},{"location":"runtime/classInnerTask/#function-blocked","title":"function blocked","text":"<pre><code>bool InnerTask::blocked () </code></pre>"},{"location":"runtime/classInnerTask/#function-clear_dependencies","title":"function clear_dependencies","text":"<pre><code>void InnerTask::clear_dependencies () </code></pre>"},{"location":"runtime/classInnerTask/#function-copy_assigned_devices","title":"function copy_assigned_devices","text":"<pre><code>void InnerTask::copy_assigned_devices (\nconst std::vector&lt; Device * &gt; &amp; others\n) </code></pre>"},{"location":"runtime/classInnerTask/#function-decrement_num_instances","title":"function decrement_num_instances","text":"<pre><code>template&lt;ResourceCategory category&gt;\ninline int InnerTask::decrement_num_instances () </code></pre>"},{"location":"runtime/classInnerTask/#function-determine_status","title":"function determine_status","text":"<pre><code>Task::Status InnerTask::determine_status (\nbool spawnable,\nbool mappable,\nbool reservable,\nbool ready\n) </code></pre>"},{"location":"runtime/classInnerTask/#function-end_arch_req_addition","title":"function end_arch_req_addition","text":"<pre><code>void InnerTask::end_arch_req_addition () </code></pre>"},{"location":"runtime/classInnerTask/#function-end_multidev_req_addition","title":"function end_multidev_req_addition","text":"<pre><code>void InnerTask::end_multidev_req_addition () </code></pre>"},{"location":"runtime/classInnerTask/#function-get_assigned_devices","title":"function get_assigned_devices","text":"<pre><code>std::vector&lt; Device * &gt; &amp; InnerTask::get_assigned_devices () </code></pre>"},{"location":"runtime/classInnerTask/#function-get_complete","title":"function get_complete","text":"<pre><code>bool InnerTask::get_complete () </code></pre>"},{"location":"runtime/classInnerTask/#function-get_dependencies","title":"function get_dependencies","text":"<pre><code>std::vector&lt; void * &gt; InnerTask::get_dependencies () </code></pre>"},{"location":"runtime/classInnerTask/#function-get_dependents","title":"function get_dependents","text":"<pre><code>std::vector&lt; void * &gt; InnerTask::get_dependents () </code></pre>"},{"location":"runtime/classInnerTask/#function-get_name-12","title":"function get_name [1/2]","text":"<pre><code>inline const std::string &amp; InnerTask::get_name () const\n</code></pre>"},{"location":"runtime/classInnerTask/#function-get_name-22","title":"function get_name [2/2]","text":"<pre><code>std::string InnerTask::get_name () </code></pre>"},{"location":"runtime/classInnerTask/#function-get_num_blocking_dependencies","title":"function get_num_blocking_dependencies","text":"<pre><code>inline int InnerTask::get_num_blocking_dependencies () const\n</code></pre>"},{"location":"runtime/classInnerTask/#function-get_num_dependencies","title":"function get_num_dependencies","text":"<pre><code>int InnerTask::get_num_dependencies () </code></pre>"},{"location":"runtime/classInnerTask/#function-get_num_dependents","title":"function get_num_dependents","text":"<pre><code>int InnerTask::get_num_dependents () </code></pre>"},{"location":"runtime/classInnerTask/#function-get_num_instances","title":"function get_num_instances","text":"<pre><code>template&lt;ResourceCategory category&gt;\ninline int InnerTask::get_num_instances () </code></pre>"},{"location":"runtime/classInnerTask/#function-get_num_unmapped_dependencies","title":"function get_num_unmapped_dependencies","text":"<pre><code>inline int InnerTask::get_num_unmapped_dependencies () const\n</code></pre>"},{"location":"runtime/classInnerTask/#function-get_placement_req_options","title":"function get_placement_req_options","text":"<pre><code>inline PlacementRequirementCollections &amp; InnerTask::get_placement_req_options () </code></pre>"},{"location":"runtime/classInnerTask/#function-get_py_task","title":"function get_py_task","text":"<pre><code>void * InnerTask::get_py_task () </code></pre>"},{"location":"runtime/classInnerTask/#function-get_removed","title":"function get_removed","text":"<pre><code>template&lt;ResourceCategory category&gt;\ninline bool InnerTask::get_removed () </code></pre>"},{"location":"runtime/classInnerTask/#function-get_state","title":"function get_state","text":"<pre><code>inline Task::State InnerTask::get_state () const\n</code></pre>"},{"location":"runtime/classInnerTask/#function-get_status","title":"function get_status","text":"<pre><code>inline Task::Status InnerTask::get_status () const\n</code></pre>"},{"location":"runtime/classInnerTask/#function-handle_runahead_dependencies","title":"function handle_runahead_dependencies","text":"<pre><code>inline void InnerTask::handle_runahead_dependencies (\nint sync_type\n) </code></pre>"},{"location":"runtime/classInnerTask/#function-is_data_task","title":"function is_data_task","text":"<pre><code>bool InnerTask::is_data_task () </code></pre>"},{"location":"runtime/classInnerTask/#function-notify","title":"function notify","text":"<pre><code>Task::StatusFlags InnerTask::notify (\nTask::State dependency_state,\nbool is_data=false\n) </code></pre>"},{"location":"runtime/classInnerTask/#function-notify_dependents","title":"function notify_dependents","text":"<pre><code>void InnerTask::notify_dependents (\nTaskStateList &amp; tasks,\nTask::State new_state\n) </code></pre>"},{"location":"runtime/classInnerTask/#function-notify_dependents_completed","title":"function notify_dependents_completed","text":"<pre><code>void InnerTask::notify_dependents_completed () </code></pre>"},{"location":"runtime/classInnerTask/#function-notify_dependents_wrapper","title":"function notify_dependents_wrapper","text":"<pre><code>bool InnerTask::notify_dependents_wrapper () </code></pre>"},{"location":"runtime/classInnerTask/#function-process_dependencies","title":"function process_dependencies","text":"<pre><code>Task::StatusFlags InnerTask::process_dependencies () </code></pre>"},{"location":"runtime/classInnerTask/#function-queue_dependency","title":"function queue_dependency","text":"<pre><code>void InnerTask::queue_dependency (\nInnerTask * task\n) </code></pre>"},{"location":"runtime/classInnerTask/#function-reset","title":"function reset","text":"<pre><code>inline void InnerTask::reset () </code></pre>"},{"location":"runtime/classInnerTask/#function-reset_events_streams","title":"function reset_events_streams","text":"<pre><code>inline void InnerTask::reset_events_streams () </code></pre>"},{"location":"runtime/classInnerTask/#function-set_complete","title":"function set_complete","text":"<pre><code>void InnerTask::set_complete () </code></pre>"},{"location":"runtime/classInnerTask/#function-set_id","title":"function set_id","text":"<pre><code>void InnerTask::set_id (\nlong long int name\n) </code></pre>"},{"location":"runtime/classInnerTask/#function-set_name","title":"function set_name","text":"<pre><code>void InnerTask::set_name (\nstd::string name\n) </code></pre>"},{"location":"runtime/classInnerTask/#function-set_num_instances","title":"function set_num_instances","text":"<pre><code>template&lt;ResourceCategory category&gt;\ninline void InnerTask::set_num_instances () </code></pre>"},{"location":"runtime/classInnerTask/#function-set_priority","title":"function set_priority","text":"<pre><code>void InnerTask::set_priority (\nint priority\n) </code></pre>"},{"location":"runtime/classInnerTask/#function-set_py_task","title":"function set_py_task","text":"<pre><code>void InnerTask::set_py_task (\nvoid * py_task\n) </code></pre>"},{"location":"runtime/classInnerTask/#function-set_removed","title":"function set_removed","text":"<pre><code>template&lt;ResourceCategory category&gt;\ninline void InnerTask::set_removed (\nbool waiting\n) </code></pre>"},{"location":"runtime/classInnerTask/#function-set_scheduler","title":"function set_scheduler","text":"<pre><code>void InnerTask::set_scheduler (\nInnerScheduler * scheduler\n) </code></pre>"},{"location":"runtime/classInnerTask/#function-set_state-12","title":"function set_state [1/2]","text":"<pre><code>int InnerTask::set_state (\nint state\n) </code></pre>"},{"location":"runtime/classInnerTask/#function-set_state-22","title":"function set_state [2/2]","text":"<pre><code>Task::State InnerTask::set_state (\nTask::State state\n) </code></pre>"},{"location":"runtime/classInnerTask/#function-set_status","title":"function set_status","text":"<pre><code>Task::Status InnerTask::set_status (\nTask::Status status\n) </code></pre>"},{"location":"runtime/classInnerTask/#function-synchronize_dependency_events","title":"function synchronize_dependency_events","text":"<pre><code>inline void InnerTask::synchronize_dependency_events () </code></pre>"},{"location":"runtime/classInnerTask/#function-synchronize_events","title":"function synchronize_events","text":"<pre><code>inline void InnerTask::synchronize_events () </code></pre>"},{"location":"runtime/classInnerTask/#function-wait_dependency_events","title":"function wait_dependency_events","text":"<pre><code>inline void InnerTask::wait_dependency_events () </code></pre>"},{"location":"runtime/classInnerTask/#protected-types-documentation","title":"Protected Types Documentation","text":""},{"location":"runtime/classInnerTask/#enum-reqadditionstate","title":"enum ReqAdditionState","text":"<pre><code>enum InnerTask::ReqAdditionState {\nSingleDevAdd = 1,\nMultiDevAdd = 3\n};\n</code></pre>"},{"location":"runtime/classInnerTask/#protected-attributes-documentation","title":"Protected Attributes Documentation","text":""},{"location":"runtime/classInnerTask/#variable-placement_req_options_","title":"variable placement_req_options_","text":"<pre><code>PlacementRequirementCollections InnerTask::placement_req_options_;\n</code></pre>"},{"location":"runtime/classInnerTask/#variable-req_addition_mode_","title":"variable req_addition_mode_","text":"<pre><code>uint32_t InnerTask::req_addition_mode_;\n</code></pre>"},{"location":"runtime/classInnerTask/#variable-tmp_arch_req_","title":"variable tmp_arch_req_","text":"<pre><code>std::shared_ptr&lt;ArchitectureRequirement&gt; InnerTask::tmp_arch_req_;\n</code></pre>"},{"location":"runtime/classInnerTask/#variable-tmp_multdev_reqs_","title":"variable tmp_multdev_reqs_","text":"<pre><code>std::shared_ptr&lt;MultiDeviceRequirements&gt; InnerTask::tmp_multdev_reqs_;\n</code></pre> <p>The documentation for this class was generated from the following file <code>src/c/backend/include/runtime.hpp</code></p>"},{"location":"runtime/classInnerTaskSpace/","title":"Class InnerTaskSpace","text":"<p>ClassList &gt; InnerTaskSpace</p> <p>Inherits the following classes: TaskBarrier</p>"},{"location":"runtime/classInnerTaskSpace/#public-attributes","title":"Public Attributes","text":"Type Name std::unordered_map&lt; int64_t, InnerTask * &gt; task_map"},{"location":"runtime/classInnerTaskSpace/#public-attributes-inherited-from-taskbarrier","title":"Public Attributes inherited from TaskBarrier","text":"<p>See TaskBarrier</p> Type Name std::condition_variable cv int64_t id std::mutex mtx std::atomic&lt; int &gt; num_incomplete_tasks   = {0}"},{"location":"runtime/classInnerTaskSpace/#public-functions","title":"Public Functions","text":"Type Name InnerTaskSpace () = default void add_task (int64_t key, InnerTask * task)  void add_tasks (std::vector&lt; int64_t &gt; &amp; keys, std::vector&lt; InnerTask * &gt; &amp; tasks)  void get_tasks (std::vector&lt; int64_t &gt; &amp; keys, std::vector&lt; InnerTask * &gt; &amp; tasks)  void notify ()  void wait ()"},{"location":"runtime/classInnerTaskSpace/#public-functions-inherited-from-taskbarrier","title":"Public Functions inherited from TaskBarrier","text":"<p>See TaskBarrier</p> Type Name TaskBarrier () = default TaskBarrier (int num_tasks)  Task::State _add_task (InnerTask * task)  void add_task (InnerTask * task)  void add_tasks (std::vector&lt; InnerTask * &gt; &amp; tasks)  void notify ()  void set_id (int64_t id)  void wait ()"},{"location":"runtime/classInnerTaskSpace/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"runtime/classInnerTaskSpace/#variable-task_map","title":"variable task_map","text":"<pre><code>std::unordered_map&lt;int64_t, InnerTask *&gt; InnerTaskSpace::task_map;\n</code></pre>"},{"location":"runtime/classInnerTaskSpace/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classInnerTaskSpace/#function-innertaskspace","title":"function InnerTaskSpace","text":"<pre><code>InnerTaskSpace::InnerTaskSpace () = default\n</code></pre>"},{"location":"runtime/classInnerTaskSpace/#function-add_task","title":"function add_task","text":"<pre><code>inline void InnerTaskSpace::add_task (\nint64_t key,\nInnerTask * task\n) </code></pre>"},{"location":"runtime/classInnerTaskSpace/#function-add_tasks","title":"function add_tasks","text":"<pre><code>inline void InnerTaskSpace::add_tasks (\nstd::vector&lt; int64_t &gt; &amp; keys,\nstd::vector&lt; InnerTask * &gt; &amp; tasks\n) </code></pre>"},{"location":"runtime/classInnerTaskSpace/#function-get_tasks","title":"function get_tasks","text":"<pre><code>inline void InnerTaskSpace::get_tasks (\nstd::vector&lt; int64_t &gt; &amp; keys,\nstd::vector&lt; InnerTask * &gt; &amp; tasks\n) </code></pre>"},{"location":"runtime/classInnerTaskSpace/#function-notify","title":"function notify","text":"<pre><code>inline void InnerTaskSpace::notify () </code></pre>"},{"location":"runtime/classInnerTaskSpace/#function-wait","title":"function wait","text":"<pre><code>inline void InnerTaskSpace::wait () </code></pre> <p>The documentation for this class was generated from the following file <code>src/c/backend/include/runtime.hpp</code></p>"},{"location":"runtime/classInnerWorker/","title":"Class InnerWorker","text":"<p>ClassList &gt; InnerWorker</p> <p>The C++ \"Mirror\" of Parla's Python Workers This class is used to create a C++ representation of a Parla Worker All scheduling logic should be handled by these after creation until launched by the Python callback. </p> <ul> <li><code>#include &lt;runtime.hpp&gt;</code></li> </ul>"},{"location":"runtime/classInnerWorker/#public-attributes","title":"Public Attributes","text":"Type Name std::condition_variable cv TaskStateList enqueue_buffer std::mutex mtx bool notified   = = false void * py_worker   = = nullptr bool ready   = = false InnerScheduler * scheduler   = = nullptr InnerTask * task   = = nullptr int thread_idx   = = -1"},{"location":"runtime/classInnerWorker/#public-functions","title":"Public Functions","text":"Type Name InnerWorker () = default InnerWorker (void * worker)  void assign_task (InnerTask * task)  void get_task (InnerTask ** task, bool * is_data_task)  void remove_task ()  void set_py_worker (void * worker)  void set_scheduler (InnerScheduler * scheduler)  void set_thread_idx (int idx)  void stop ()  void wait ()"},{"location":"runtime/classInnerWorker/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"runtime/classInnerWorker/#variable-cv","title":"variable cv","text":"<pre><code>std::condition_variable InnerWorker::cv;\n</code></pre>"},{"location":"runtime/classInnerWorker/#variable-enqueue_buffer","title":"variable enqueue_buffer","text":"<pre><code>TaskStateList InnerWorker::enqueue_buffer;\n</code></pre>"},{"location":"runtime/classInnerWorker/#variable-mtx","title":"variable mtx","text":"<pre><code>std::mutex InnerWorker::mtx;\n</code></pre>"},{"location":"runtime/classInnerWorker/#variable-notified","title":"variable notified","text":"<pre><code>bool InnerWorker::notified;\n</code></pre>"},{"location":"runtime/classInnerWorker/#variable-py_worker","title":"variable py_worker","text":"<pre><code>void* InnerWorker::py_worker;\n</code></pre>"},{"location":"runtime/classInnerWorker/#variable-ready","title":"variable ready","text":"<pre><code>bool InnerWorker::ready;\n</code></pre>"},{"location":"runtime/classInnerWorker/#variable-scheduler","title":"variable scheduler","text":"<pre><code>InnerScheduler* InnerWorker::scheduler;\n</code></pre>"},{"location":"runtime/classInnerWorker/#variable-task","title":"variable task","text":"<pre><code>InnerTask* InnerWorker::task;\n</code></pre>"},{"location":"runtime/classInnerWorker/#variable-thread_idx","title":"variable thread_idx","text":"<pre><code>int InnerWorker::thread_idx;\n</code></pre>"},{"location":"runtime/classInnerWorker/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classInnerWorker/#function-innerworker-12","title":"function InnerWorker [1/2]","text":"<pre><code>InnerWorker::InnerWorker () = default\n</code></pre>"},{"location":"runtime/classInnerWorker/#function-innerworker-22","title":"function InnerWorker [2/2]","text":"<pre><code>inline InnerWorker::InnerWorker (\nvoid * worker\n) </code></pre>"},{"location":"runtime/classInnerWorker/#function-assign_task","title":"function assign_task","text":"<pre><code>void InnerWorker::assign_task (\nInnerTask * task\n) </code></pre>"},{"location":"runtime/classInnerWorker/#function-get_task","title":"function get_task","text":"<pre><code>void InnerWorker::get_task (\nInnerTask ** task,\nbool * is_data_task\n) </code></pre>"},{"location":"runtime/classInnerWorker/#function-remove_task","title":"function remove_task","text":"<pre><code>void InnerWorker::remove_task () </code></pre>"},{"location":"runtime/classInnerWorker/#function-set_py_worker","title":"function set_py_worker","text":"<pre><code>inline void InnerWorker::set_py_worker (\nvoid * worker\n) </code></pre>"},{"location":"runtime/classInnerWorker/#function-set_scheduler","title":"function set_scheduler","text":"<pre><code>inline void InnerWorker::set_scheduler (\nInnerScheduler * scheduler\n) </code></pre>"},{"location":"runtime/classInnerWorker/#function-set_thread_idx","title":"function set_thread_idx","text":"<pre><code>inline void InnerWorker::set_thread_idx (\nint idx\n) </code></pre>"},{"location":"runtime/classInnerWorker/#function-stop","title":"function stop","text":"<pre><code>void InnerWorker::stop () </code></pre>"},{"location":"runtime/classInnerWorker/#function-wait","title":"function wait","text":"<pre><code>void InnerWorker::wait () </code></pre> <p>The documentation for this class was generated from the following file <code>src/c/backend/include/runtime.hpp</code></p>"},{"location":"runtime/classLauncher/","title":"Class Launcher","text":"<p>ClassList &gt; Launcher</p> <p>Inherits the following classes: SchedulerPhase</p>"},{"location":"runtime/classLauncher/#public-attributes","title":"Public Attributes","text":"Type Name std::atomic&lt; size_t &gt; num_running_tasks   = {0}"},{"location":"runtime/classLauncher/#public-functions","title":"Public Functions","text":"Type Name Launcher (InnerScheduler * scheduler, DeviceManager * devices)  virtual void enqueue (InnerTask * task) Enqueue a task to the phase. void enqueue (InnerTask * task, InnerWorker * worker)  virtual void enqueue (std::vector&lt; InnerTask * &gt; &amp; tasks) Enqueue a vector of tasks to the phase. virtual size_t get_count () Get the number of tasks enqueued (and waiting) in the phase. void run ()  virtual void run (SchedulerPhase * next_phase) Run the phase. Check tasks in the enqueued buffer, check phase condition, and move tasks to the next phase."},{"location":"runtime/classLauncher/#public-functions-inherited-from-schedulerphase","title":"Public Functions inherited from SchedulerPhase","text":"<p>See SchedulerPhase</p> Type Name SchedulerPhase () = default SchedulerPhase (InnerScheduler * scheduler, DeviceManager * devices) Constructor for the scheduler phase. virtual void enqueue (InnerTask * task) = 0Enqueue a task to the phase. virtual void enqueue (std::vector&lt; InnerTask * &gt; &amp; tasks) = 0Enqueue a vector of tasks to the phase. virtual size_t get_count () = 0Get the number of tasks enqueued (and waiting) in the phase. virtual void run (SchedulerPhase * next_phase) = 0Run the phase. Check tasks in the enqueued buffer, check phase condition, and move tasks to the next phase."},{"location":"runtime/classLauncher/#protected-attributes","title":"Protected Attributes","text":"Type Name LauncherStatus status   = {name} TaskList task_buffer WorkerList worker_buffer"},{"location":"runtime/classLauncher/#protected-attributes-inherited-from-schedulerphase","title":"Protected Attributes inherited from SchedulerPhase","text":"<p>See SchedulerPhase</p> Type Name DeviceManager * device_manager The device manager that the phase uses. TaskStateList enqueue_buffer The number of tasks enqueued (and waiting) in the phase. std::mutex mtx Mutex lock for the phase (In case of a workerthread driven scheduler, ensure only 1 thread is running the phase at a time) InnerScheduler * scheduler The scheduler that the phase belongs to."},{"location":"runtime/classLauncher/#protected-static-attributes","title":"Protected Static Attributes","text":"Type Name const std::string name   = {\"Launcher\"}"},{"location":"runtime/classLauncher/#protected-static-attributes-inherited-from-schedulerphase","title":"Protected Static Attributes inherited from SchedulerPhase","text":"<p>See SchedulerPhase</p> Type Name const std::string name   = {\"Phase\"}The name of the phase. Used for debugging and tracing."},{"location":"runtime/classLauncher/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"runtime/classLauncher/#variable-num_running_tasks","title":"variable num_running_tasks","text":"<pre><code>std::atomic&lt;size_t&gt; Launcher::num_running_tasks;\n</code></pre>"},{"location":"runtime/classLauncher/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classLauncher/#function-launcher","title":"function Launcher","text":"<pre><code>inline Launcher::Launcher (\nInnerScheduler * scheduler,\nDeviceManager * devices\n) </code></pre>"},{"location":"runtime/classLauncher/#function-enqueue-13","title":"function enqueue [1/3]","text":"<pre><code>inline virtual void Launcher::enqueue (\nInnerTask * task\n) </code></pre> <p>Implements SchedulerPhase::enqueue</p>"},{"location":"runtime/classLauncher/#function-enqueue-23","title":"function enqueue [2/3]","text":"<pre><code>void Launcher::enqueue (\nInnerTask * task,\nInnerWorker * worker\n) </code></pre>"},{"location":"runtime/classLauncher/#function-enqueue-33","title":"function enqueue [3/3]","text":"<pre><code>inline virtual void Launcher::enqueue (\nstd::vector&lt; InnerTask * &gt; &amp; tasks\n) </code></pre> <p>Implements SchedulerPhase::enqueue</p>"},{"location":"runtime/classLauncher/#function-get_count","title":"function get_count","text":"<pre><code>inline virtual size_t Launcher::get_count () </code></pre> <p>Implements SchedulerPhase::get_count</p>"},{"location":"runtime/classLauncher/#function-run-12","title":"function run [1/2]","text":"<pre><code>void Launcher::run () </code></pre>"},{"location":"runtime/classLauncher/#function-run-22","title":"function run [2/2]","text":"<p>Run the phase. Check tasks in the enqueued buffer, check phase condition, and move tasks to the next phase. <pre><code>inline virtual void Launcher::run (\nSchedulerPhase * next_phase\n) </code></pre></p> <p>Parameters:</p> <ul> <li><code>next_phase</code> The next phase to move tasks to. </li> </ul> <p>Implements SchedulerPhase::run</p>"},{"location":"runtime/classLauncher/#protected-attributes-documentation","title":"Protected Attributes Documentation","text":""},{"location":"runtime/classLauncher/#variable-status","title":"variable status","text":"<pre><code>LauncherStatus Launcher::status;\n</code></pre>"},{"location":"runtime/classLauncher/#variable-task_buffer","title":"variable task_buffer","text":"<pre><code>TaskList Launcher::task_buffer;\n</code></pre>"},{"location":"runtime/classLauncher/#variable-worker_buffer","title":"variable worker_buffer","text":"<pre><code>WorkerList Launcher::worker_buffer;\n</code></pre>"},{"location":"runtime/classLauncher/#protected-static-attributes-documentation","title":"Protected Static Attributes Documentation","text":""},{"location":"runtime/classLauncher/#variable-name","title":"variable name","text":"<pre><code>const std::string Launcher::name;\n</code></pre> <p>The documentation for this class was generated from the following file <code>src/c/backend/include/phases.hpp</code></p>"},{"location":"runtime/classLauncherStatus/","title":"Class LauncherStatus","text":"<p>ClassList &gt; LauncherStatus</p> <p>Inherits the following classes: PhaseStatus</p>"},{"location":"runtime/classLauncherStatus/#public-attributes-inherited-from-phasestatus","title":"Public Attributes inherited from PhaseStatus","text":"<p>See PhaseStatus</p> Type Name int status"},{"location":"runtime/classLauncherStatus/#public-functions-inherited-from-phasestatus","title":"Public Functions inherited from PhaseStatus","text":"<p>See PhaseStatus</p> Type Name PhaseStatus () = default PhaseStatus (std::string name)  void decrease (S state)  const int get (S state) const void increase (S state)  void print () const void reset ()  void set (S state, int value)"},{"location":"runtime/classLauncherStatus/#protected-attributes-inherited-from-phasestatus","title":"Protected Attributes inherited from PhaseStatus","text":"<p>See PhaseStatus</p> Type Name std::string name   = {\"Status\"} const int size   = {static_cast&lt;int&gt;(S::MAX)} <p>The documentation for this class was generated from the following file <code>src/c/backend/include/phases.hpp</code></p>"},{"location":"runtime/classLocalityLoadBalancingMappingPolicy/","title":"Class LocalityLoadBalancingMappingPolicy","text":"<p>ClassList &gt; LocalityLoadBalancingMappingPolicy</p> <p>Inherits the following classes: MappingPolicy</p>"},{"location":"runtime/classLocalityLoadBalancingMappingPolicy/#public-functions","title":"Public Functions","text":"Type Name MappingPolicy (DeviceManager * device_manager, PArrayTracker * parray_tracker)  virtual bool calc_score_archplacement (InnerTask * task, ArchitectureRequirement * arch_placement_req, const Mapper &amp; mapper, std::shared_ptr&lt; DeviceRequirement &gt; &amp; chosen_dev_req, Score_t * chosen_dev_score, const std::vector&lt; std::pair&lt; parray::InnerPArray *, AccessMode &gt;&gt; &amp; parray_list, std::vector&lt; bool &gt; * is_dev_assigned=nullptr) overrideCalculate a score of the architecture placement requirement. virtual bool calc_score_devplacement (InnerTask * task, const std::shared_ptr&lt; DeviceRequirement &gt; &amp; dev_placement_req, const Mapper &amp; mapper, Score_t * score, const std::vector&lt; std::pair&lt; parray::InnerPArray *, AccessMode &gt;&gt; &amp; parray_list) overrideCalculate a score of the device placement requirement. virtual bool calc_score_mdevplacement (InnerTask * task, MultiDeviceRequirements * mdev_placement_req, const Mapper &amp; mapper, std::vector&lt; std::shared_ptr&lt; DeviceRequirement &gt;&gt; * member_device_reqs, Score_t * average_score, const std::vector&lt; std::vector&lt; std::pair&lt; parray::InnerPArray *, AccessMode &gt;&gt;&gt; &amp; parray_list) overrideCalculate a score of the multi-device placement that users passed."},{"location":"runtime/classLocalityLoadBalancingMappingPolicy/#public-functions-inherited-from-mappingpolicy","title":"Public Functions inherited from MappingPolicy","text":"<p>See MappingPolicy</p> Type Name MappingPolicy (DeviceManager * device_manager, PArrayTracker * parray_tracker)  virtual bool calc_score_archplacement (InnerTask * task, ArchitectureRequirement * arch_placement_req, const Mapper &amp; mapper, std::shared_ptr&lt; DeviceRequirement &gt; &amp; chosen_dev_req, Score_t * chosen_dev_score, const std::vector&lt; std::pair&lt; parray::InnerPArray *, AccessMode &gt;&gt; &amp; parray_list, std::vector&lt; bool &gt; * is_dev_assigned=nullptr) = 0Calculate a score of the architecture placement requirement. virtual bool calc_score_devplacement (InnerTask * task, const std::shared_ptr&lt; DeviceRequirement &gt; &amp; dev_placement_req, const Mapper &amp; mapper, Score_t * score, const std::vector&lt; std::pair&lt; parray::InnerPArray *, AccessMode &gt;&gt; &amp; parray_list) = 0Calculate a score of the device placement requirement. virtual bool calc_score_mdevplacement (InnerTask * task, MultiDeviceRequirements * mdev_placement_req, const Mapper &amp; mapper, std::vector&lt; std::shared_ptr&lt; DeviceRequirement &gt;&gt; * member_device_reqs, Score_t * average_score, const std::vector&lt; std::vector&lt; std::pair&lt; parray::InnerPArray *, AccessMode &gt;&gt;&gt; &amp; parray_list) = 0Calculate a score of the multi-device placement that users passed."},{"location":"runtime/classLocalityLoadBalancingMappingPolicy/#protected-attributes-inherited-from-mappingpolicy","title":"Protected Attributes inherited from MappingPolicy","text":"<p>See MappingPolicy</p> Type Name DeviceManager * device_manager_ PArrayTracker * parray_tracker_ int rrcount   = = 0"},{"location":"runtime/classLocalityLoadBalancingMappingPolicy/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classLocalityLoadBalancingMappingPolicy/#function-mappingpolicy","title":"function MappingPolicy","text":"<pre><code>inline LocalityLoadBalancingMappingPolicy::MappingPolicy (\nDeviceManager * device_manager,\nPArrayTracker * parray_tracker\n) </code></pre>"},{"location":"runtime/classLocalityLoadBalancingMappingPolicy/#function-calc_score_archplacement","title":"function calc_score_archplacement","text":"<p>Calculate a score of the architecture placement requirement. <pre><code>virtual bool LocalityLoadBalancingMappingPolicy::calc_score_archplacement (\nInnerTask * task,\nArchitectureRequirement * arch_placement_req,\nconst Mapper &amp; mapper,\nstd::shared_ptr&lt; DeviceRequirement &gt; &amp; chosen_dev_req,\nScore_t * chosen_dev_score,\nconst std::vector&lt; std::pair&lt; parray::InnerPArray *, AccessMode &gt;&gt; &amp; parray_list,\nstd::vector&lt; bool &gt; * is_dev_assigned=nullptr\n) override\n</code></pre></p> <p>This function first iterates devices of the architecture, and calculates a score for each device based on the current states of the device (e.g., available memory and the number of vcus). It returns a device giving the best score and its score. Note that it does not choose a device for a task, but the caller, so the task mapper, will choose one of the placement options.</p> <p>Parameters:</p> <ul> <li><code>task</code> Target task for task mapping. </li> <li><code>arch_placement_req</code> Resource requirement of the architecture. </li> <li><code>mapper</code> Mapper instance to get mapping information. </li> <li><code>chosen_dev_req</code> A pointer of a chosen device and its resource requirement. This is a reference type since this function chooses a device and updates its pointer to the device requirement. </li> <li><code>chosen_dev_score</code> A pointer of a score of the chosen device. </li> <li><code>parray_list</code> A list of PArray instances used by the target task </li> <li><code>is_dev_assigned</code> Multi-device task is not allowed to be assigned to duplicated devices. This vector marks assigned devices and avoid that case. </li> </ul> <p>Returns:</p> <p>True if any device in the architecture is available </p> <p>Implements MappingPolicy::calc_score_archplacement</p>"},{"location":"runtime/classLocalityLoadBalancingMappingPolicy/#function-calc_score_devplacement","title":"function calc_score_devplacement","text":"<p>Calculate a score of the device placement requirement. <pre><code>virtual bool LocalityLoadBalancingMappingPolicy::calc_score_devplacement (\nInnerTask * task,\nconst std::shared_ptr&lt; DeviceRequirement &gt; &amp; dev_placement_req,\nconst Mapper &amp; mapper,\nScore_t * score,\nconst std::vector&lt; std::pair&lt; parray::InnerPArray *, AccessMode &gt;&gt; &amp; parray_list\n) override\n</code></pre></p> <p>This function calculates a score of a device based on the current states of the device (e.g., available memory and the number of vcus). It returns a device giving the best score and its score. Note that it does not choose a device for a task, but the caller, so the task mapper, will choose one of the placement options.</p> <p>Parameters:</p> <ul> <li><code>task</code> Target task for task mapping. </li> <li><code>dev_placement_req</code> Resource requirement of the device. </li> <li><code>mapper</code> Mapper instance to get mapping information. </li> <li><code>score</code> A pointer of a score of the device. </li> <li><code>parray_list</code> A list of PArray instances used by the target task </li> </ul> <p>Returns:</p> <p>True if a device is available </p> <p>Implements MappingPolicy::calc_score_devplacement</p>"},{"location":"runtime/classLocalityLoadBalancingMappingPolicy/#function-calc_score_mdevplacement","title":"function calc_score_mdevplacement","text":"<p>Calculate a score of the multi-device placement that users passed. <pre><code>virtual bool LocalityLoadBalancingMappingPolicy::calc_score_mdevplacement (\nInnerTask * task,\nMultiDeviceRequirements * mdev_placement_req,\nconst Mapper &amp; mapper,\nstd::vector&lt; std::shared_ptr&lt; DeviceRequirement &gt;&gt; * member_device_reqs,\nScore_t * average_score,\nconst std::vector&lt; std::vector&lt; std::pair&lt; parray::InnerPArray *, AccessMode &gt;&gt;&gt; &amp; parray_list\n) override\n</code></pre></p> <p>The placement requirement could contain multiple device or/and architecture requirements. This function calculates a score for each placement requirement by recursively calling a device or an architecture score calculation function and averages those scores. This average is used as a score of the multi-device placement and the caller, so the task mapper, will choose one of the placement options that give the best score.</p> <p>Parameters:</p> <ul> <li><code>task</code> Target task for task mapping. </li> <li><code>mdev_placement_req</code> Resource requirement of the multiple devices. </li> <li><code>mapper</code> Mapper instance to get mapping information. </li> <li><code>member_device_reqs</code> A vector of the resource requirement of the member device. </li> <li><code>chosen_dev_score</code> A pointer of a score of the multiple devices. </li> <li><code>parray_list</code> A list of PArray instances used by the target task </li> </ul> <p>Returns:</p> <p>True if all devices in the multi-device placement are available. </p> <p>Implements MappingPolicy::calc_score_mdevplacement</p> <p>The documentation for this class was generated from the following file <code>src/c/backend/include/policy.hpp</code></p>"},{"location":"runtime/classMapper/","title":"Class Mapper","text":"<p>ClassList &gt; Mapper</p> <p>Mapper phase of the scheduler.More...</p> <ul> <li><code>#include &lt;phases.hpp&gt;</code></li> </ul> <p>Inherits the following classes: SchedulerPhase</p>"},{"location":"runtime/classMapper/#public-functions","title":"Public Functions","text":"Type Name Mapper () = delete Mapper (InnerScheduler * scheduler, DeviceManager * devices, std::shared_ptr&lt; MappingPolicy &gt; policy)  size_t atomic_decr_num_mapped_tasks () Decrease the number of the total mapped tasks to the whole devices. size_t atomic_decr_num_mapped_tasks_device (DevID_t dev_id) Decrease the number of the tasks mapped to a device. size_t atomic_incr_num_mapped_tasks () Increase the number of the total mapped tasks to the whole devices. size_t atomic_incr_num_mapped_tasks_device (DevID_t dev_id) Increase the number of the tasks mapped to a device. const size_t atomic_load_dev_num_mapped_tasks_device (DevID_t dev_id) constReturn the number of mapped tasks to a single device. const size_t atomic_load_total_num_mapped_tasks () constReturn the number of total mapped tasks to the whole devices. virtual void enqueue (InnerTask * task) Enqueue a task to the phase. virtual void enqueue (std::vector&lt; InnerTask * &gt; &amp; tasks) Enqueue a vector of tasks to the phase. virtual size_t get_count () Get the number of tasks enqueued (and waiting) in the phase. virtual void run (SchedulerPhase * next_phase) Run the phase. Check tasks in the enqueued buffer, check phase condition, and move tasks to the next phase."},{"location":"runtime/classMapper/#public-functions-inherited-from-schedulerphase","title":"Public Functions inherited from SchedulerPhase","text":"<p>See SchedulerPhase</p> Type Name SchedulerPhase () = default SchedulerPhase (InnerScheduler * scheduler, DeviceManager * devices) Constructor for the scheduler phase. virtual void enqueue (InnerTask * task) = 0Enqueue a task to the phase. virtual void enqueue (std::vector&lt; InnerTask * &gt; &amp; tasks) = 0Enqueue a vector of tasks to the phase. virtual size_t get_count () = 0Get the number of tasks enqueued (and waiting) in the phase. virtual void run (SchedulerPhase * next_phase) = 0Run the phase. Check tasks in the enqueued buffer, check phase condition, and move tasks to the next phase."},{"location":"runtime/classMapper/#protected-attributes","title":"Protected Attributes","text":"Type Name std::vector&lt; CopyableAtomic&lt; size_t &gt; &gt; dev_num_mapped_tasks_ The total number of tasks mapped to and running on a single device. uint64_t dummy_dev_idx_ TaskQueue mappable_tasks std::vector&lt; InnerTask * &gt; mapped_tasks_buffer std::shared_ptr&lt; MappingPolicy &gt; policy_ MapperStatus status   = {name} std::atomic&lt; size_t &gt; total_num_mapped_tasks_   = {0}The total number of tasks mapped to and running on the whole devices."},{"location":"runtime/classMapper/#protected-attributes-inherited-from-schedulerphase","title":"Protected Attributes inherited from SchedulerPhase","text":"<p>See SchedulerPhase</p> Type Name DeviceManager * device_manager The device manager that the phase uses. TaskStateList enqueue_buffer The number of tasks enqueued (and waiting) in the phase. std::mutex mtx Mutex lock for the phase (In case of a workerthread driven scheduler, ensure only 1 thread is running the phase at a time) InnerScheduler * scheduler The scheduler that the phase belongs to."},{"location":"runtime/classMapper/#protected-static-attributes","title":"Protected Static Attributes","text":"Type Name const std::string name   = {\"Mapper\"}"},{"location":"runtime/classMapper/#protected-static-attributes-inherited-from-schedulerphase","title":"Protected Static Attributes inherited from SchedulerPhase","text":"<p>See SchedulerPhase</p> Type Name const std::string name   = {\"Phase\"}The name of the phase. Used for debugging and tracing."},{"location":"runtime/classMapper/#detailed-description","title":"Detailed Description","text":"<p>Uses constraints to assign tasks to device sets. </p>"},{"location":"runtime/classMapper/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classMapper/#function-mapper-12","title":"function Mapper [1/2]","text":"<pre><code>Mapper::Mapper () = delete\n</code></pre>"},{"location":"runtime/classMapper/#function-mapper-22","title":"function Mapper [2/2]","text":"<pre><code>inline Mapper::Mapper (\nInnerScheduler * scheduler,\nDeviceManager * devices,\nstd::shared_ptr&lt; MappingPolicy &gt; policy\n) </code></pre>"},{"location":"runtime/classMapper/#function-atomic_decr_num_mapped_tasks","title":"function atomic_decr_num_mapped_tasks","text":"<p>Decrease the number of the total mapped tasks to the whole devices. <pre><code>inline size_t Mapper::atomic_decr_num_mapped_tasks () </code></pre></p> <p>Returns:</p> <p>The number of the total mapped tasks </p>"},{"location":"runtime/classMapper/#function-atomic_decr_num_mapped_tasks_device","title":"function atomic_decr_num_mapped_tasks_device","text":"<p>Decrease the number of the tasks mapped to a device. <pre><code>inline size_t Mapper::atomic_decr_num_mapped_tasks_device (\nDevID_t dev_id\n) </code></pre></p> <p>Parameters:</p> <ul> <li><code>dev_id</code> Device global ID where a task is mapped </li> </ul> <p>Returns:</p> <p>The number of the tasks mapped to a device </p>"},{"location":"runtime/classMapper/#function-atomic_incr_num_mapped_tasks","title":"function atomic_incr_num_mapped_tasks","text":"<p>Increase the number of the total mapped tasks to the whole devices. <pre><code>inline size_t Mapper::atomic_incr_num_mapped_tasks () </code></pre></p> <p>Returns:</p> <p>The number of the total mapped tasks </p>"},{"location":"runtime/classMapper/#function-atomic_incr_num_mapped_tasks_device","title":"function atomic_incr_num_mapped_tasks_device","text":"<p>Increase the number of the tasks mapped to a device. <pre><code>inline size_t Mapper::atomic_incr_num_mapped_tasks_device (\nDevID_t dev_id\n) </code></pre></p> <p>Parameters:</p> <ul> <li><code>dev_id</code> Device global ID where a task is mapped </li> </ul> <p>Returns:</p> <p>The number of the tasks mapped to a device </p>"},{"location":"runtime/classMapper/#function-atomic_load_dev_num_mapped_tasks_device","title":"function atomic_load_dev_num_mapped_tasks_device","text":"<p>Return the number of mapped tasks to a single device. <pre><code>inline const size_t Mapper::atomic_load_dev_num_mapped_tasks_device (\nDevID_t dev_id\n) const\n</code></pre></p> <p>Parameters:</p> <ul> <li><code>dev_id</code> Device global ID where a task is mapped </li> </ul> <p>Returns:</p> <p>The old number of the tasks mapped to a device </p>"},{"location":"runtime/classMapper/#function-atomic_load_total_num_mapped_tasks","title":"function atomic_load_total_num_mapped_tasks","text":"<p>Return the number of total mapped tasks to the whole devices. <pre><code>inline const size_t Mapper::atomic_load_total_num_mapped_tasks () const\n</code></pre></p> <p>Returns:</p> <p>The old number of total mapped tasks </p>"},{"location":"runtime/classMapper/#function-enqueue-12","title":"function enqueue [1/2]","text":"<pre><code>virtual void Mapper::enqueue (\nInnerTask * task\n) </code></pre> <p>Implements SchedulerPhase::enqueue</p>"},{"location":"runtime/classMapper/#function-enqueue-22","title":"function enqueue [2/2]","text":"<pre><code>virtual void Mapper::enqueue (\nstd::vector&lt; InnerTask * &gt; &amp; tasks\n) </code></pre> <p>Implements SchedulerPhase::enqueue</p>"},{"location":"runtime/classMapper/#function-get_count","title":"function get_count","text":"<pre><code>virtual size_t Mapper::get_count () </code></pre> <p>Implements SchedulerPhase::get_count</p>"},{"location":"runtime/classMapper/#function-run","title":"function run","text":"<p>Run the phase. Check tasks in the enqueued buffer, check phase condition, and move tasks to the next phase. <pre><code>virtual void Mapper::run (\nSchedulerPhase * next_phase\n) </code></pre></p> <p>Parameters:</p> <ul> <li><code>next_phase</code> The next phase to move tasks to. </li> </ul> <p>Implements SchedulerPhase::run</p>"},{"location":"runtime/classMapper/#protected-attributes-documentation","title":"Protected Attributes Documentation","text":""},{"location":"runtime/classMapper/#variable-dev_num_mapped_tasks_","title":"variable dev_num_mapped_tasks_","text":"<pre><code>std::vector&lt;CopyableAtomic&lt;size_t&gt; &gt; Mapper::dev_num_mapped_tasks_;\n</code></pre>"},{"location":"runtime/classMapper/#variable-dummy_dev_idx_","title":"variable dummy_dev_idx_","text":"<pre><code>uint64_t Mapper::dummy_dev_idx_;\n</code></pre>"},{"location":"runtime/classMapper/#variable-mappable_tasks","title":"variable mappable_tasks","text":"<pre><code>TaskQueue Mapper::mappable_tasks;\n</code></pre>"},{"location":"runtime/classMapper/#variable-mapped_tasks_buffer","title":"variable mapped_tasks_buffer","text":"<pre><code>std::vector&lt;InnerTask *&gt; Mapper::mapped_tasks_buffer;\n</code></pre>"},{"location":"runtime/classMapper/#variable-policy_","title":"variable policy_","text":"<pre><code>std::shared_ptr&lt;MappingPolicy&gt; Mapper::policy_;\n</code></pre>"},{"location":"runtime/classMapper/#variable-status","title":"variable status","text":"<pre><code>MapperStatus Mapper::status;\n</code></pre>"},{"location":"runtime/classMapper/#variable-total_num_mapped_tasks_","title":"variable total_num_mapped_tasks_","text":"<pre><code>std::atomic&lt;size_t&gt; Mapper::total_num_mapped_tasks_;\n</code></pre>"},{"location":"runtime/classMapper/#protected-static-attributes-documentation","title":"Protected Static Attributes Documentation","text":""},{"location":"runtime/classMapper/#variable-name","title":"variable name","text":"<pre><code>const std::string Mapper::name;\n</code></pre> <p>The documentation for this class was generated from the following file <code>src/c/backend/include/phases.hpp</code></p>"},{"location":"runtime/classMapperStatus/","title":"Class MapperStatus","text":"<p>ClassList &gt; MapperStatus</p> <p>Inherits the following classes: PhaseStatus</p>"},{"location":"runtime/classMapperStatus/#public-attributes-inherited-from-phasestatus","title":"Public Attributes inherited from PhaseStatus","text":"<p>See PhaseStatus</p> Type Name int status"},{"location":"runtime/classMapperStatus/#public-functions-inherited-from-phasestatus","title":"Public Functions inherited from PhaseStatus","text":"<p>See PhaseStatus</p> Type Name PhaseStatus () = default PhaseStatus (std::string name)  void decrease (S state)  const int get (S state) const void increase (S state)  void print () const void reset ()  void set (S state, int value)"},{"location":"runtime/classMapperStatus/#protected-attributes-inherited-from-phasestatus","title":"Protected Attributes inherited from PhaseStatus","text":"<p>See PhaseStatus</p> Type Name std::string name   = {\"Status\"} const int size   = {static_cast&lt;int&gt;(S::MAX)} <p>The documentation for this class was generated from the following file <code>src/c/backend/include/phases.hpp</code></p>"},{"location":"runtime/classMappingPolicy/","title":"Class MappingPolicy","text":"<p>ClassList &gt; MappingPolicy</p> <p>Inherited by the following classes: LocalityLoadBalancingMappingPolicy</p>"},{"location":"runtime/classMappingPolicy/#public-functions","title":"Public Functions","text":"Type Name MappingPolicy (DeviceManager * device_manager, PArrayTracker * parray_tracker)  virtual bool calc_score_archplacement (InnerTask * task, ArchitectureRequirement * arch_placement_req, const Mapper &amp; mapper, std::shared_ptr&lt; DeviceRequirement &gt; &amp; chosen_dev_req, Score_t * chosen_dev_score, const std::vector&lt; std::pair&lt; parray::InnerPArray *, AccessMode &gt;&gt; &amp; parray_list, std::vector&lt; bool &gt; * is_dev_assigned=nullptr) = 0Calculate a score of the architecture placement requirement. virtual bool calc_score_devplacement (InnerTask * task, const std::shared_ptr&lt; DeviceRequirement &gt; &amp; dev_placement_req, const Mapper &amp; mapper, Score_t * score, const std::vector&lt; std::pair&lt; parray::InnerPArray *, AccessMode &gt;&gt; &amp; parray_list) = 0Calculate a score of the device placement requirement. virtual bool calc_score_mdevplacement (InnerTask * task, MultiDeviceRequirements * mdev_placement_req, const Mapper &amp; mapper, std::vector&lt; std::shared_ptr&lt; DeviceRequirement &gt;&gt; * member_device_reqs, Score_t * average_score, const std::vector&lt; std::vector&lt; std::pair&lt; parray::InnerPArray *, AccessMode &gt;&gt;&gt; &amp; parray_list) = 0Calculate a score of the multi-device placement that users passed."},{"location":"runtime/classMappingPolicy/#protected-attributes","title":"Protected Attributes","text":"Type Name DeviceManager * device_manager_ PArrayTracker * parray_tracker_ int rrcount   = = 0"},{"location":"runtime/classMappingPolicy/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classMappingPolicy/#function-mappingpolicy","title":"function MappingPolicy","text":"<pre><code>inline MappingPolicy::MappingPolicy (\nDeviceManager * device_manager,\nPArrayTracker * parray_tracker\n) </code></pre>"},{"location":"runtime/classMappingPolicy/#function-calc_score_archplacement","title":"function calc_score_archplacement","text":"<p>Calculate a score of the architecture placement requirement. <pre><code>virtual bool MappingPolicy::calc_score_archplacement (\nInnerTask * task,\nArchitectureRequirement * arch_placement_req,\nconst Mapper &amp; mapper,\nstd::shared_ptr&lt; DeviceRequirement &gt; &amp; chosen_dev_req,\nScore_t * chosen_dev_score,\nconst std::vector&lt; std::pair&lt; parray::InnerPArray *, AccessMode &gt;&gt; &amp; parray_list,\nstd::vector&lt; bool &gt; * is_dev_assigned=nullptr\n) = 0\n</code></pre></p> <p>This function first iterates devices of the architecture, and calculates a score for each device based on the current states of the device (e.g., available memory and the number of vcus). It returns a device giving the best score and its score. Note that it does not choose a device for a task, but the caller, so the task mapper, will choose one of the placement options.</p> <p>Parameters:</p> <ul> <li><code>task</code> Target task for task mapping. </li> <li><code>arch_placement_req</code> Resource requirement of the architecture. </li> <li><code>mapper</code> Mapper instance to get mapping information. </li> <li><code>chosen_dev_req</code> A pointer of a chosen device and its resource requirement. This is a reference type since this function chooses a device and updates its pointer to the device requirement. </li> <li><code>chosen_dev_score</code> A pointer of a score of the chosen device. </li> <li><code>parray_list</code> A list of PArray instances used by the target task </li> <li><code>is_dev_assigned</code> Multi-device task is not allowed to be assigned to duplicated devices. This vector marks assigned devices and avoid that case. </li> </ul> <p>Returns:</p> <p>True if any device in the architecture is available </p>"},{"location":"runtime/classMappingPolicy/#function-calc_score_devplacement","title":"function calc_score_devplacement","text":"<p>Calculate a score of the device placement requirement. <pre><code>virtual bool MappingPolicy::calc_score_devplacement (\nInnerTask * task,\nconst std::shared_ptr&lt; DeviceRequirement &gt; &amp; dev_placement_req,\nconst Mapper &amp; mapper,\nScore_t * score,\nconst std::vector&lt; std::pair&lt; parray::InnerPArray *, AccessMode &gt;&gt; &amp; parray_list\n) = 0\n</code></pre></p> <p>This function calculates a score of a device based on the current states of the device (e.g., available memory and the number of vcus). It returns a device giving the best score and its score. Note that it does not choose a device for a task, but the caller, so the task mapper, will choose one of the placement options.</p> <p>Parameters:</p> <ul> <li><code>task</code> Target task for task mapping. </li> <li><code>dev_placement_req</code> Resource requirement of the device. </li> <li><code>mapper</code> Mapper instance to get mapping information. </li> <li><code>score</code> A pointer of a score of the device. </li> <li><code>parray_list</code> A list of PArray instances used by the target task </li> </ul> <p>Returns:</p> <p>True if a device is available </p>"},{"location":"runtime/classMappingPolicy/#function-calc_score_mdevplacement","title":"function calc_score_mdevplacement","text":"<p>Calculate a score of the multi-device placement that users passed. <pre><code>virtual bool MappingPolicy::calc_score_mdevplacement (\nInnerTask * task,\nMultiDeviceRequirements * mdev_placement_req,\nconst Mapper &amp; mapper,\nstd::vector&lt; std::shared_ptr&lt; DeviceRequirement &gt;&gt; * member_device_reqs,\nScore_t * average_score,\nconst std::vector&lt; std::vector&lt; std::pair&lt; parray::InnerPArray *, AccessMode &gt;&gt;&gt; &amp; parray_list\n) = 0\n</code></pre></p> <p>The placement requirement could contain multiple device or/and architecture requirements. This function calculates a score for each placement requirement by recursively calling a device or an architecture score calculation function and averages those scores. This average is used as a score of the multi-device placement and the caller, so the task mapper, will choose one of the placement options that give the best score.</p> <p>Parameters:</p> <ul> <li><code>task</code> Target task for task mapping. </li> <li><code>mdev_placement_req</code> Resource requirement of the multiple devices. </li> <li><code>mapper</code> Mapper instance to get mapping information. </li> <li><code>member_device_reqs</code> A vector of the resource requirement of the member device. </li> <li><code>chosen_dev_score</code> A pointer of a score of the multiple devices. </li> <li><code>parray_list</code> A list of PArray instances used by the target task </li> </ul> <p>Returns:</p> <p>True if all devices in the multi-device placement are available. </p>"},{"location":"runtime/classMappingPolicy/#protected-attributes-documentation","title":"Protected Attributes Documentation","text":""},{"location":"runtime/classMappingPolicy/#variable-device_manager_","title":"variable device_manager_","text":"<pre><code>DeviceManager* MappingPolicy::device_manager_;\n</code></pre>"},{"location":"runtime/classMappingPolicy/#variable-parray_tracker_","title":"variable parray_tracker_","text":"<pre><code>PArrayTracker* MappingPolicy::parray_tracker_;\n</code></pre>"},{"location":"runtime/classMappingPolicy/#variable-rrcount","title":"variable rrcount","text":"<pre><code>int MappingPolicy::rrcount;\n</code></pre> <p>The documentation for this class was generated from the following file <code>src/c/backend/include/policy.hpp</code></p>"},{"location":"runtime/classMemoryReserver/","title":"Class MemoryReserver","text":"<p>ClassList &gt; MemoryReserver</p> <p>MemoryReserver phase of the scheduler.More...</p> <ul> <li><code>#include &lt;phases.hpp&gt;</code></li> </ul> <p>Inherits the following classes: SchedulerPhase</p>"},{"location":"runtime/classMemoryReserver/#public-functions","title":"Public Functions","text":"Type Name MemoryReserver (InnerScheduler * scheduler, DeviceManager * devices)  virtual void enqueue (InnerTask * task) Enqueue a task to the phase. virtual void enqueue (std::vector&lt; InnerTask * &gt; &amp; tasks) Enqueue a vector of tasks to the phase. virtual size_t get_count () Get the number of tasks enqueued (and waiting) in the phase. virtual void run (SchedulerPhase * next_phase) Run the phase. Check tasks in the enqueued buffer, check phase condition, and move tasks to the next phase."},{"location":"runtime/classMemoryReserver/#public-functions-inherited-from-schedulerphase","title":"Public Functions inherited from SchedulerPhase","text":"<p>See SchedulerPhase</p> Type Name SchedulerPhase () = default SchedulerPhase (InnerScheduler * scheduler, DeviceManager * devices) Constructor for the scheduler phase. virtual void enqueue (InnerTask * task) = 0Enqueue a task to the phase. virtual void enqueue (std::vector&lt; InnerTask * &gt; &amp; tasks) = 0Enqueue a vector of tasks to the phase. virtual size_t get_count () = 0Get the number of tasks enqueued (and waiting) in the phase. virtual void run (SchedulerPhase * next_phase) = 0Run the phase. Check tasks in the enqueued buffer, check phase condition, and move tasks to the next phase."},{"location":"runtime/classMemoryReserver/#protected-attributes","title":"Protected Attributes","text":"Type Name std::shared_ptr&lt; PhaseManager&lt; ResourceCategory::Persistent &gt; &gt; reservable_tasks std::vector&lt; InnerTask * &gt; reserved_tasks_buffer MemoryReserverStatus status   = {name}"},{"location":"runtime/classMemoryReserver/#protected-attributes-inherited-from-schedulerphase","title":"Protected Attributes inherited from SchedulerPhase","text":"<p>See SchedulerPhase</p> Type Name DeviceManager * device_manager The device manager that the phase uses. TaskStateList enqueue_buffer The number of tasks enqueued (and waiting) in the phase. std::mutex mtx Mutex lock for the phase (In case of a workerthread driven scheduler, ensure only 1 thread is running the phase at a time) InnerScheduler * scheduler The scheduler that the phase belongs to."},{"location":"runtime/classMemoryReserver/#protected-static-attributes","title":"Protected Static Attributes","text":"Type Name const std::string name   = {\"Memory Reserver\"}"},{"location":"runtime/classMemoryReserver/#protected-static-attributes-inherited-from-schedulerphase","title":"Protected Static Attributes inherited from SchedulerPhase","text":"<p>See SchedulerPhase</p> Type Name const std::string name   = {\"Phase\"}The name of the phase. Used for debugging and tracing."},{"location":"runtime/classMemoryReserver/#protected-functions","title":"Protected Functions","text":"Type Name bool check_resources (InnerTask * task)  void create_datamove_tasks (InnerTask * task)  void reserve_resources (InnerTask * task)"},{"location":"runtime/classMemoryReserver/#detailed-description","title":"Detailed Description","text":"<p>Reserves all 'persistent resources`.</p> <p>This phase plans task execution on the device set. Here all 'persistent resources` that have a lifetime greater than the task body are reserved and shared between tasks. Typically this means the memory that the task uses for both its input, output, and intermediate workspace. Memory usage is planned and reserved ahead of task execution to allow input data to be prefetched onto the devices through data movement tasks. </p>"},{"location":"runtime/classMemoryReserver/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classMemoryReserver/#function-memoryreserver","title":"function MemoryReserver","text":"<pre><code>inline MemoryReserver::MemoryReserver (\nInnerScheduler * scheduler,\nDeviceManager * devices\n) </code></pre>"},{"location":"runtime/classMemoryReserver/#function-enqueue-12","title":"function enqueue [1/2]","text":"<pre><code>virtual void MemoryReserver::enqueue (\nInnerTask * task\n) </code></pre> <p>Implements SchedulerPhase::enqueue</p>"},{"location":"runtime/classMemoryReserver/#function-enqueue-22","title":"function enqueue [2/2]","text":"<pre><code>virtual void MemoryReserver::enqueue (\nstd::vector&lt; InnerTask * &gt; &amp; tasks\n) </code></pre> <p>Implements SchedulerPhase::enqueue</p>"},{"location":"runtime/classMemoryReserver/#function-get_count","title":"function get_count","text":"<pre><code>virtual size_t MemoryReserver::get_count () </code></pre> <p>Implements SchedulerPhase::get_count</p>"},{"location":"runtime/classMemoryReserver/#function-run","title":"function run","text":"<p>Run the phase. Check tasks in the enqueued buffer, check phase condition, and move tasks to the next phase. <pre><code>virtual void MemoryReserver::run (\nSchedulerPhase * next_phase\n) </code></pre></p> <p>Parameters:</p> <ul> <li><code>next_phase</code> The next phase to move tasks to. </li> </ul> <p>Implements SchedulerPhase::run</p>"},{"location":"runtime/classMemoryReserver/#protected-attributes-documentation","title":"Protected Attributes Documentation","text":""},{"location":"runtime/classMemoryReserver/#variable-reservable_tasks","title":"variable reservable_tasks","text":"<pre><code>std::shared_ptr&lt;PhaseManager&lt;ResourceCategory::Persistent&gt; &gt; MemoryReserver::reservable_tasks;\n</code></pre>"},{"location":"runtime/classMemoryReserver/#variable-reserved_tasks_buffer","title":"variable reserved_tasks_buffer","text":"<pre><code>std::vector&lt;InnerTask *&gt; MemoryReserver::reserved_tasks_buffer;\n</code></pre>"},{"location":"runtime/classMemoryReserver/#variable-status","title":"variable status","text":"<pre><code>MemoryReserverStatus MemoryReserver::status;\n</code></pre>"},{"location":"runtime/classMemoryReserver/#protected-static-attributes-documentation","title":"Protected Static Attributes Documentation","text":""},{"location":"runtime/classMemoryReserver/#variable-name","title":"variable name","text":"<pre><code>const std::string MemoryReserver::name;\n</code></pre>"},{"location":"runtime/classMemoryReserver/#protected-functions-documentation","title":"Protected Functions Documentation","text":""},{"location":"runtime/classMemoryReserver/#function-check_resources","title":"function check_resources","text":"<pre><code>bool MemoryReserver::check_resources (\nInnerTask * task\n) </code></pre>"},{"location":"runtime/classMemoryReserver/#function-create_datamove_tasks","title":"function create_datamove_tasks","text":"<pre><code>void MemoryReserver::create_datamove_tasks (\nInnerTask * task\n) </code></pre>"},{"location":"runtime/classMemoryReserver/#function-reserve_resources","title":"function reserve_resources","text":"<pre><code>void MemoryReserver::reserve_resources (\nInnerTask * task\n) </code></pre> <p>The documentation for this class was generated from the following file <code>src/c/backend/include/phases.hpp</code></p>"},{"location":"runtime/classMemoryReserverStatus/","title":"Class MemoryReserverStatus","text":"<p>ClassList &gt; MemoryReserverStatus</p> <p>Inherits the following classes: PhaseStatus</p>"},{"location":"runtime/classMemoryReserverStatus/#public-attributes-inherited-from-phasestatus","title":"Public Attributes inherited from PhaseStatus","text":"<p>See PhaseStatus</p> Type Name int status"},{"location":"runtime/classMemoryReserverStatus/#public-functions-inherited-from-phasestatus","title":"Public Functions inherited from PhaseStatus","text":"<p>See PhaseStatus</p> Type Name PhaseStatus () = default PhaseStatus (std::string name)  void decrease (S state)  const int get (S state) const void increase (S state)  void print () const void reset ()  void set (S state, int value)"},{"location":"runtime/classMemoryReserverStatus/#protected-attributes-inherited-from-phasestatus","title":"Protected Attributes inherited from PhaseStatus","text":"<p>See PhaseStatus</p> Type Name std::string name   = {\"Status\"} const int size   = {static_cast&lt;int&gt;(S::MAX)} <p>The documentation for this class was generated from the following file <code>src/c/backend/include/phases.hpp</code></p>"},{"location":"runtime/classMultiDeviceRequirements/","title":"Class MultiDeviceRequirements","text":"<p>ClassList &gt; MultiDeviceRequirements</p> <p>Inherits the following classes: PlacementRequirementBase</p>"},{"location":"runtime/classMultiDeviceRequirements/#public-functions","title":"Public Functions","text":"Type Name void append_placement_req (std::shared_ptr&lt; SinglePlacementRequirementBase &gt; req)  const std::vector&lt; std::shared_ptr&lt; SinglePlacementRequirementBase &gt; &gt; &amp; get_placement_reqs_ref ()  virtual bool is_arch_req () override virtual bool is_dev_req () override virtual bool is_multidev_req () override"},{"location":"runtime/classMultiDeviceRequirements/#public-functions-inherited-from-placementrequirementbase","title":"Public Functions inherited from PlacementRequirementBase","text":"<p>See PlacementRequirementBase</p> Type Name virtual bool is_arch_req () = 0 virtual bool is_dev_req () = 0 virtual bool is_multidev_req () = 0"},{"location":"runtime/classMultiDeviceRequirements/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classMultiDeviceRequirements/#function-append_placement_req","title":"function append_placement_req","text":"<pre><code>void MultiDeviceRequirements::append_placement_req (\nstd::shared_ptr&lt; SinglePlacementRequirementBase &gt; req\n) </code></pre>"},{"location":"runtime/classMultiDeviceRequirements/#function-get_placement_reqs_ref","title":"function get_placement_reqs_ref","text":"<pre><code>const std::vector&lt; std::shared_ptr&lt; SinglePlacementRequirementBase &gt; &gt; &amp; MultiDeviceRequirements::get_placement_reqs_ref () </code></pre>"},{"location":"runtime/classMultiDeviceRequirements/#function-is_arch_req","title":"function is_arch_req","text":"<pre><code>inline virtual bool MultiDeviceRequirements::is_arch_req () override\n</code></pre> <p>Implements PlacementRequirementBase::is_arch_req</p>"},{"location":"runtime/classMultiDeviceRequirements/#function-is_dev_req","title":"function is_dev_req","text":"<pre><code>inline virtual bool MultiDeviceRequirements::is_dev_req () override\n</code></pre> <p>Implements PlacementRequirementBase::is_dev_req</p>"},{"location":"runtime/classMultiDeviceRequirements/#function-is_multidev_req","title":"function is_multidev_req","text":"<pre><code>inline virtual bool MultiDeviceRequirements::is_multidev_req () override\n</code></pre> <p>Implements PlacementRequirementBase::is_multidev_req</p> <p>The documentation for this class was generated from the following file <code>src/c/backend/include/resource_requirements.hpp</code></p>"},{"location":"runtime/classPArrayTracker/","title":"Class PArrayTracker","text":"<p>ClassList &gt; PArrayTracker</p>"},{"location":"runtime/classPArrayTracker/#public-functions","title":"Public Functions","text":"Type Name PArrayTracker (DeviceManager * deivce_manage)  bool get_parray_state (DevID_t global_dev_idx, uint64_t parray_parent_id)  void release_parray (const InnerPArray &amp; parray, Device * device) Release a PArray from a specified device. void reserve_parray (const InnerPArray &amp; parray, Device * device) Reserve PArray usage in a specified device. void track_parray (const InnerPArray &amp; parray, DevID_t dev_id) It the passed PArray instance, either as a slice or a complete array, is not being tracked but is instantiated or moved to a specific device, register the instance to the PArray tracking table and track its states. void untrack_parray (const InnerPArray &amp; parray, DevID_t dev_id) Remove a PArray from the PArray tracking table and does not track that until a task attempts to use that."},{"location":"runtime/classPArrayTracker/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classPArrayTracker/#function-parraytracker","title":"function PArrayTracker","text":"<pre><code>PArrayTracker::PArrayTracker (\nDeviceManager * deivce_manage\n) </code></pre>"},{"location":"runtime/classPArrayTracker/#function-get_parray_state","title":"function get_parray_state","text":"<pre><code>inline bool PArrayTracker::get_parray_state (\nDevID_t global_dev_idx,\nuint64_t parray_parent_id\n) </code></pre>"},{"location":"runtime/classPArrayTracker/#function-release_parray","title":"function release_parray","text":"<p>Release a PArray from a specified device. <pre><code>void PArrayTracker::release_parray (\nconst InnerPArray &amp; parray,\nDevice * device\n) </code></pre></p> <p>A PArray is released from a device when its instance does not exist and also there is no plan (none of tasks that use the PArray is mapped to the device) to be referenced in the device. </p>"},{"location":"runtime/classPArrayTracker/#function-reserve_parray","title":"function reserve_parray","text":"<p>Reserve PArray usage in a specified device. <pre><code>void PArrayTracker::reserve_parray (\nconst InnerPArray &amp; parray,\nDevice * device\n) </code></pre></p> <p>If a PArray is reserved to a specific device, it implies that the corresponding PArray instance is planned to be instantiated or is already instantiated in the device. </p>"},{"location":"runtime/classPArrayTracker/#function-track_parray","title":"function track_parray","text":"<pre><code>void PArrayTracker::track_parray (\nconst InnerPArray &amp; parray,\nDevID_t dev_id\n) </code></pre>"},{"location":"runtime/classPArrayTracker/#function-untrack_parray","title":"function untrack_parray","text":"<p>Remove a PArray from the PArray tracking table and does not track that until a task attempts to use that. <pre><code>void PArrayTracker::untrack_parray (\nconst InnerPArray &amp; parray,\nDevID_t dev_id\n) </code></pre></p> <p>This can improve look-up operation performance. </p> <p>The documentation for this class was generated from the following file <code>src/c/backend/include/parray_tracker.hpp</code></p>"},{"location":"runtime/classPhaseManager/","title":"Class PhaseManager","text":"<p>template &lt;ResourceCategory category&gt;</p> <p>ClassList &gt; PhaseManager</p> <p>Manages a group of DeviceQueues. More...</p> <ul> <li><code>#include &lt;device_queues.hpp&gt;</code></li> </ul>"},{"location":"runtime/classPhaseManager/#public-functions","title":"Public Functions","text":"Type Name PhaseManager (DeviceManager * device_manager) Initializes a DeviceQueue for each device in theDeviceManager . void enqueue (InnerTask * task) Enqueues a task to the appropriate DeviceQueue(s) . InnerTask * front ()  size_t get_num_device_queues ()  size_t get_num_devices ()  InnerTask * pop () Removed the previous head task from the queue. size_t size ()  ~PhaseManager ()"},{"location":"runtime/classPhaseManager/#protected-attributes","title":"Protected Attributes","text":"Type Name std::vector&lt; DeviceQueue&lt; category &gt; * &gt; device_queues int last_device_idx   = {0} int ndevices   = {0} std::atomic&lt; int &gt; num_tasks   = {0}"},{"location":"runtime/classPhaseManager/#detailed-description","title":"Detailed Description","text":"<p>Supports both single and multi-device tasks. Multi-device tasks are shared between DeviceQueues.</p> <p>Template parameters:</p> <ul> <li><code>category</code> the resource category (persistent/non-persistent) that this manager supervises </li> </ul>"},{"location":"runtime/classPhaseManager/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classPhaseManager/#function-phasemanager","title":"function PhaseManager","text":"<p>Initializes a DeviceQueue for each device in theDeviceManager . <pre><code>inline PhaseManager::PhaseManager (\nDeviceManager * device_manager\n) </code></pre></p> <p>Parameters:</p> <ul> <li><code>device_manager</code> the DeviceManager to initialize from </li> </ul>"},{"location":"runtime/classPhaseManager/#function-enqueue","title":"function enqueue","text":"<p>Enqueues a task to the appropriate DeviceQueue(s) . <pre><code>inline void PhaseManager::enqueue (\nInnerTask * task\n) </code></pre></p> <p>Parameters:</p> <ul> <li><code>task</code> the task to enqueue. May be single or multi-device. </li> </ul>"},{"location":"runtime/classPhaseManager/#function-front","title":"function front","text":"<pre><code>inline InnerTask * PhaseManager::front () </code></pre> <p>Returns:</p> <p>the next task that can be dequeued on any device. </p> <p>See also: DeviceQueue::front Loops over all DeviceQueues in round-robin order to find the next dequeable task. The search is restarted from the next DeviceQueue after the last successful dequeue. A success increases the last_device_idx by 1.</p> <p>If there are no tasks remaining, returns nullptr. Will infinitely loop if there are tasks remaining but none can be dequeued on any device. (invalid state).</p> <p>Note that each call to DeviceQueue::front pushes the HEAD task to a waiting queue if it is a multi-device task that hasn't reached HEAD on all instances. This modifies the internal state of the DeviceQueue. </p>"},{"location":"runtime/classPhaseManager/#function-get_num_device_queues","title":"function get_num_device_queues","text":"<pre><code>inline size_t PhaseManager::get_num_device_queues () </code></pre>"},{"location":"runtime/classPhaseManager/#function-get_num_devices","title":"function get_num_devices","text":"<pre><code>inline size_t PhaseManager::get_num_devices () </code></pre>"},{"location":"runtime/classPhaseManager/#function-pop","title":"function pop","text":"<p>Removed the previous head task from the queue. <pre><code>inline InnerTask * PhaseManager::pop () </code></pre></p> <p>Returns:</p> <p>the removed task </p> <p>See also: DeviceQueue::pop </p>"},{"location":"runtime/classPhaseManager/#function-size","title":"function size","text":"<pre><code>inline size_t PhaseManager::size () </code></pre>"},{"location":"runtime/classPhaseManager/#function-phasemanager_1","title":"function ~PhaseManager","text":"<pre><code>inline PhaseManager::~PhaseManager () </code></pre>"},{"location":"runtime/classPhaseManager/#protected-attributes-documentation","title":"Protected Attributes Documentation","text":""},{"location":"runtime/classPhaseManager/#variable-device_queues","title":"variable device_queues","text":"<pre><code>std::vector&lt;DeviceQueue&lt;category&gt; *&gt; PhaseManager&lt; category &gt;::device_queues;\n</code></pre>"},{"location":"runtime/classPhaseManager/#variable-last_device_idx","title":"variable last_device_idx","text":"<pre><code>int PhaseManager&lt; category &gt;::last_device_idx;\n</code></pre>"},{"location":"runtime/classPhaseManager/#variable-ndevices","title":"variable ndevices","text":"<pre><code>int PhaseManager&lt; category &gt;::ndevices;\n</code></pre>"},{"location":"runtime/classPhaseManager/#variable-num_tasks","title":"variable num_tasks","text":"<pre><code>std::atomic&lt;int&gt; PhaseManager&lt; category &gt;::num_tasks;\n</code></pre> <p>The documentation for this class was generated from the following file <code>src/c/backend/include/device_queues.hpp</code></p>"},{"location":"runtime/classPhaseStatus/","title":"Class PhaseStatus","text":"<p>template &lt;typename S typename S&gt;</p> <p>ClassList &gt; PhaseStatus</p> <p>Records metrics that track phase execution (e.g. success, failure, etc.) More...</p> <ul> <li><code>#include &lt;phases.hpp&gt;</code></li> </ul>"},{"location":"runtime/classPhaseStatus/#public-attributes","title":"Public Attributes","text":"Type Name int status"},{"location":"runtime/classPhaseStatus/#public-functions","title":"Public Functions","text":"Type Name PhaseStatus () = default PhaseStatus (std::string name)  void decrease (S state)  const int get (S state) const void increase (S state)  void print () const void reset ()  void set (S state, int value)"},{"location":"runtime/classPhaseStatus/#protected-attributes","title":"Protected Attributes","text":"Type Name std::string name   = {\"Status\"} const int size   = {static_cast&lt;int&gt;(S::MAX)}"},{"location":"runtime/classPhaseStatus/#detailed-description","title":"Detailed Description","text":"<p>Template parameters:</p> <ul> <li><code>S</code> The enum class that defines the states to track.</li> </ul> <p>Used to record counts of phase execution for tracing and debugging. For example, the number of successful mappings per call. </p>"},{"location":"runtime/classPhaseStatus/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"runtime/classPhaseStatus/#variable-status","title":"variable status","text":"<pre><code>int PhaseStatus&lt; S &gt;::status[static_cast&lt; int &gt;(S::MAX)];\n</code></pre>"},{"location":"runtime/classPhaseStatus/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classPhaseStatus/#function-phasestatus-12","title":"function PhaseStatus [1/2]","text":"<pre><code>PhaseStatus::PhaseStatus () = default\n</code></pre>"},{"location":"runtime/classPhaseStatus/#function-phasestatus-22","title":"function PhaseStatus [2/2]","text":"<pre><code>inline PhaseStatus::PhaseStatus (\nstd::string name\n) </code></pre>"},{"location":"runtime/classPhaseStatus/#function-decrease","title":"function decrease","text":"<pre><code>inline void PhaseStatus::decrease (\nS state\n) </code></pre>"},{"location":"runtime/classPhaseStatus/#function-get","title":"function get","text":"<pre><code>inline const int PhaseStatus::get (\nS state\n) const\n</code></pre>"},{"location":"runtime/classPhaseStatus/#function-increase","title":"function increase","text":"<pre><code>inline void PhaseStatus::increase (\nS state\n) </code></pre>"},{"location":"runtime/classPhaseStatus/#function-print","title":"function print","text":"<pre><code>inline void PhaseStatus::print () const\n</code></pre>"},{"location":"runtime/classPhaseStatus/#function-reset","title":"function reset","text":"<pre><code>inline void PhaseStatus::reset () </code></pre>"},{"location":"runtime/classPhaseStatus/#function-set","title":"function set","text":"<pre><code>inline void PhaseStatus::set (\nS state,\nint value\n) </code></pre>"},{"location":"runtime/classPhaseStatus/#protected-attributes-documentation","title":"Protected Attributes Documentation","text":""},{"location":"runtime/classPhaseStatus/#variable-name","title":"variable name","text":"<pre><code>std::string PhaseStatus&lt; S &gt;::name;\n</code></pre>"},{"location":"runtime/classPhaseStatus/#variable-size","title":"variable size","text":"<pre><code>const int PhaseStatus&lt; S &gt;::size;\n</code></pre> <p>The documentation for this class was generated from the following file <code>src/c/backend/include/phases.hpp</code></p>"},{"location":"runtime/classPlacementRequirementBase/","title":"Class PlacementRequirementBase","text":"<p>ClassList &gt; PlacementRequirementBase</p> <p>Base classes. </p> <ul> <li><code>#include &lt;resource_requirements.hpp&gt;</code></li> </ul> <p>Inherited by the following classes: MultiDeviceRequirements,  SinglePlacementRequirementBase</p>"},{"location":"runtime/classPlacementRequirementBase/#public-functions","title":"Public Functions","text":"Type Name virtual bool is_arch_req () = 0 virtual bool is_dev_req () = 0 virtual bool is_multidev_req () = 0"},{"location":"runtime/classPlacementRequirementBase/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classPlacementRequirementBase/#function-is_arch_req","title":"function is_arch_req","text":"<pre><code>virtual bool PlacementRequirementBase::is_arch_req () = 0\n</code></pre>"},{"location":"runtime/classPlacementRequirementBase/#function-is_dev_req","title":"function is_dev_req","text":"<pre><code>virtual bool PlacementRequirementBase::is_dev_req () = 0\n</code></pre>"},{"location":"runtime/classPlacementRequirementBase/#function-is_multidev_req","title":"function is_multidev_req","text":"<pre><code>virtual bool PlacementRequirementBase::is_multidev_req () = 0\n</code></pre> <p>The documentation for this class was generated from the following file <code>src/c/backend/include/resource_requirements.hpp</code></p>"},{"location":"runtime/classPlacementRequirementCollections/","title":"Class PlacementRequirementCollections","text":"<p>ClassList &gt; PlacementRequirementCollections</p> <p>Resource contains device types (architectures), specific devices, their memory and virtual computation units. </p> <ul> <li><code>#include &lt;resource_requirements.hpp&gt;</code></li> </ul>"},{"location":"runtime/classPlacementRequirementCollections/#public-functions","title":"Public Functions","text":"Type Name void append_placement_req_opt (std::shared_ptr&lt; PlacementRequirementBase &gt; dev_req)  const std::vector&lt; std::shared_ptr&lt; PlacementRequirementBase &gt; &gt; &amp; get_placement_req_opts_ref ()"},{"location":"runtime/classPlacementRequirementCollections/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classPlacementRequirementCollections/#function-append_placement_req_opt","title":"function append_placement_req_opt","text":"<pre><code>void PlacementRequirementCollections::append_placement_req_opt (\nstd::shared_ptr&lt; PlacementRequirementBase &gt; dev_req\n) </code></pre>"},{"location":"runtime/classPlacementRequirementCollections/#function-get_placement_req_opts_ref","title":"function get_placement_req_opts_ref","text":"<pre><code>const std::vector&lt; std::shared_ptr&lt; PlacementRequirementBase &gt; &gt; &amp; PlacementRequirementCollections::get_placement_req_opts_ref () </code></pre> <p>The documentation for this class was generated from the following file <code>src/c/backend/include/resource_requirements.hpp</code></p>"},{"location":"runtime/classProtectedQueue/","title":"Class ProtectedQueue","text":"<p>template &lt;typename T typename T&gt;</p> <p>ClassList &gt; ProtectedQueue</p>"},{"location":"runtime/classProtectedQueue/#public-functions","title":"Public Functions","text":"Type Name ProtectedQueue () = default ProtectedQueue (std::string name)  ProtectedQueue (std::string name, std::deque&lt; T &gt; q)  ProtectedQueue (std::string name, size_t size)  T at (size_t i)  T at_unsafe (size_t i)  size_t atomic_size ()  T back ()  T back_and_pop ()  T back_and_pop_unsafe ()  T back_unsafe ()  void clear ()  void clear_unsafe ()  bool empty ()  bool empty_unsafe ()  T front ()  T front_and_pop ()  T front_and_pop_unsafe ()  T front_unsafe ()  void lock ()  T operator[] (size_t i)  void pop_back ()  void pop_back_unsafe ()  void pop_front ()  void pop_front_unsafe ()  void push_back (T a)  void push_back (std::vector&lt; T &gt; &amp; a)  void push_back_unsafe (T a)  void push_back_unsafe (std::vector&lt; T &gt; &amp; a)  void push_front (T a)  void push_front (std::vector&lt; T &gt; &amp; a)  void push_front_unsafe (T a)  void push_front_unsafe (std::vector&lt; T &gt; &amp; a)  size_t size ()  size_t size_unsafe ()  void unlock ()"},{"location":"runtime/classProtectedQueue/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classProtectedQueue/#function-protectedqueue-14","title":"function ProtectedQueue [1/4]","text":"<pre><code>ProtectedQueue::ProtectedQueue () = default\n</code></pre>"},{"location":"runtime/classProtectedQueue/#function-protectedqueue-24","title":"function ProtectedQueue [2/4]","text":"<pre><code>inline ProtectedQueue::ProtectedQueue (\nstd::string name\n) </code></pre>"},{"location":"runtime/classProtectedQueue/#function-protectedqueue-34","title":"function ProtectedQueue [3/4]","text":"<pre><code>inline ProtectedQueue::ProtectedQueue (\nstd::string name,\nstd::deque&lt; T &gt; q\n) </code></pre>"},{"location":"runtime/classProtectedQueue/#function-protectedqueue-44","title":"function ProtectedQueue [4/4]","text":"<pre><code>inline ProtectedQueue::ProtectedQueue (\nstd::string name,\nsize_t size\n) </code></pre>"},{"location":"runtime/classProtectedQueue/#function-at","title":"function at","text":"<pre><code>inline T ProtectedQueue::at (\nsize_t i\n) </code></pre>"},{"location":"runtime/classProtectedQueue/#function-at_unsafe","title":"function at_unsafe","text":"<pre><code>inline T ProtectedQueue::at_unsafe (\nsize_t i\n) </code></pre>"},{"location":"runtime/classProtectedQueue/#function-atomic_size","title":"function atomic_size","text":"<pre><code>inline size_t ProtectedQueue::atomic_size () </code></pre>"},{"location":"runtime/classProtectedQueue/#function-back","title":"function back","text":"<pre><code>inline T ProtectedQueue::back () </code></pre>"},{"location":"runtime/classProtectedQueue/#function-back_and_pop","title":"function back_and_pop","text":"<pre><code>inline T ProtectedQueue::back_and_pop () </code></pre>"},{"location":"runtime/classProtectedQueue/#function-back_and_pop_unsafe","title":"function back_and_pop_unsafe","text":"<pre><code>inline T ProtectedQueue::back_and_pop_unsafe () </code></pre>"},{"location":"runtime/classProtectedQueue/#function-back_unsafe","title":"function back_unsafe","text":"<pre><code>inline T ProtectedQueue::back_unsafe () </code></pre>"},{"location":"runtime/classProtectedQueue/#function-clear","title":"function clear","text":"<pre><code>inline void ProtectedQueue::clear () </code></pre>"},{"location":"runtime/classProtectedQueue/#function-clear_unsafe","title":"function clear_unsafe","text":"<pre><code>inline void ProtectedQueue::clear_unsafe () </code></pre>"},{"location":"runtime/classProtectedQueue/#function-empty","title":"function empty","text":"<pre><code>inline bool ProtectedQueue::empty () </code></pre>"},{"location":"runtime/classProtectedQueue/#function-empty_unsafe","title":"function empty_unsafe","text":"<pre><code>inline bool ProtectedQueue::empty_unsafe () </code></pre>"},{"location":"runtime/classProtectedQueue/#function-front","title":"function front","text":"<pre><code>inline T ProtectedQueue::front () </code></pre>"},{"location":"runtime/classProtectedQueue/#function-front_and_pop","title":"function front_and_pop","text":"<pre><code>inline T ProtectedQueue::front_and_pop () </code></pre>"},{"location":"runtime/classProtectedQueue/#function-front_and_pop_unsafe","title":"function front_and_pop_unsafe","text":"<pre><code>inline T ProtectedQueue::front_and_pop_unsafe () </code></pre>"},{"location":"runtime/classProtectedQueue/#function-front_unsafe","title":"function front_unsafe","text":"<pre><code>inline T ProtectedQueue::front_unsafe () </code></pre>"},{"location":"runtime/classProtectedQueue/#function-lock","title":"function lock","text":"<pre><code>inline void ProtectedQueue::lock () </code></pre>"},{"location":"runtime/classProtectedQueue/#function-operator","title":"function operator[]","text":"<pre><code>inline T ProtectedQueue::operator[] (\nsize_t i\n) </code></pre>"},{"location":"runtime/classProtectedQueue/#function-pop_back","title":"function pop_back","text":"<pre><code>inline void ProtectedQueue::pop_back () </code></pre>"},{"location":"runtime/classProtectedQueue/#function-pop_back_unsafe","title":"function pop_back_unsafe","text":"<pre><code>inline void ProtectedQueue::pop_back_unsafe () </code></pre>"},{"location":"runtime/classProtectedQueue/#function-pop_front","title":"function pop_front","text":"<pre><code>inline void ProtectedQueue::pop_front () </code></pre>"},{"location":"runtime/classProtectedQueue/#function-pop_front_unsafe","title":"function pop_front_unsafe","text":"<pre><code>inline void ProtectedQueue::pop_front_unsafe () </code></pre>"},{"location":"runtime/classProtectedQueue/#function-push_back-12","title":"function push_back [1/2]","text":"<pre><code>inline void ProtectedQueue::push_back (\nT a\n) </code></pre>"},{"location":"runtime/classProtectedQueue/#function-push_back-22","title":"function push_back [2/2]","text":"<pre><code>inline void ProtectedQueue::push_back (\nstd::vector&lt; T &gt; &amp; a\n) </code></pre>"},{"location":"runtime/classProtectedQueue/#function-push_back_unsafe-12","title":"function push_back_unsafe [1/2]","text":"<pre><code>inline void ProtectedQueue::push_back_unsafe (\nT a\n) </code></pre>"},{"location":"runtime/classProtectedQueue/#function-push_back_unsafe-22","title":"function push_back_unsafe [2/2]","text":"<pre><code>inline void ProtectedQueue::push_back_unsafe (\nstd::vector&lt; T &gt; &amp; a\n) </code></pre>"},{"location":"runtime/classProtectedQueue/#function-push_front-12","title":"function push_front [1/2]","text":"<pre><code>inline void ProtectedQueue::push_front (\nT a\n) </code></pre>"},{"location":"runtime/classProtectedQueue/#function-push_front-22","title":"function push_front [2/2]","text":"<pre><code>inline void ProtectedQueue::push_front (\nstd::vector&lt; T &gt; &amp; a\n) </code></pre>"},{"location":"runtime/classProtectedQueue/#function-push_front_unsafe-12","title":"function push_front_unsafe [1/2]","text":"<pre><code>inline void ProtectedQueue::push_front_unsafe (\nT a\n) </code></pre>"},{"location":"runtime/classProtectedQueue/#function-push_front_unsafe-22","title":"function push_front_unsafe [2/2]","text":"<pre><code>inline void ProtectedQueue::push_front_unsafe (\nstd::vector&lt; T &gt; &amp; a\n) </code></pre>"},{"location":"runtime/classProtectedQueue/#function-size","title":"function size","text":"<pre><code>inline size_t ProtectedQueue::size () </code></pre>"},{"location":"runtime/classProtectedQueue/#function-size_unsafe","title":"function size_unsafe","text":"<pre><code>inline size_t ProtectedQueue::size_unsafe () </code></pre>"},{"location":"runtime/classProtectedQueue/#function-unlock","title":"function unlock","text":"<pre><code>inline void ProtectedQueue::unlock () </code></pre> <p>The documentation for this class was generated from the following file <code>src/c/backend/include/containers.hpp</code></p>"},{"location":"runtime/classProtectedVector/","title":"Class ProtectedVector","text":"<p>template &lt;typename T typename T&gt;</p> <p>ClassList &gt; ProtectedVector</p>"},{"location":"runtime/classProtectedVector/#public-functions","title":"Public Functions","text":"Type Name ProtectedVector () = default ProtectedVector (std::string name)  ProtectedVector (std::string name, std::vector&lt; T &gt; vec)  ProtectedVector (std::string name, size_t size)  T at (size_t i)  T at_unsafe (size_t i)  int atomic_size ()  T back ()  T back_and_pop ()  T back_and_pop_unsafe ()  T back_unsafe ()  void clear ()  void clear_unsafe ()  bool empty ()  bool empty_unsafe ()  T front ()  T front_and_pop ()  T front_and_pop_unsafe ()  T front_unsafe ()  T get (size_t i)  T get_unsafe (size_t i)  std::vector&lt; T &gt; &amp; get_vector ()  std::vector&lt; T &gt; get_vector_copy ()  std::vector&lt; T &gt; get_vector_copy_unsafe ()  std::vector&lt; T &gt; &amp; get_vector_unsafe ()  void lock ()  ProtectedVector &amp; operator= (ProtectedVector &amp;&amp; other) Explicit move assignment due to the atomic size member. T operator[] (size_t i)  void pop_back ()  void pop_back_unsafe ()  void push_back (T a)  void push_back (std::vector&lt; T &gt; &amp; a)  void push_back_unsafe (T a)  void push_back_unsafe (std::vector&lt; T &gt; &amp; a)  void reserve (size_t size)  void reserve_unsafe (size_t size)  void resize (size_t size)  void resize_unsafe (size_t size)  void set (size_t i, T val)  void set_unsafe (size_t i, T val)  size_t size ()  size_t size_unsafe ()  void unlock ()"},{"location":"runtime/classProtectedVector/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classProtectedVector/#function-protectedvector-14","title":"function ProtectedVector [1/4]","text":"<pre><code>ProtectedVector::ProtectedVector () = default\n</code></pre>"},{"location":"runtime/classProtectedVector/#function-protectedvector-24","title":"function ProtectedVector [2/4]","text":"<pre><code>inline ProtectedVector::ProtectedVector (\nstd::string name\n) </code></pre>"},{"location":"runtime/classProtectedVector/#function-protectedvector-34","title":"function ProtectedVector [3/4]","text":"<pre><code>inline ProtectedVector::ProtectedVector (\nstd::string name,\nstd::vector&lt; T &gt; vec\n) </code></pre>"},{"location":"runtime/classProtectedVector/#function-protectedvector-44","title":"function ProtectedVector [4/4]","text":"<pre><code>inline ProtectedVector::ProtectedVector (\nstd::string name,\nsize_t size\n) </code></pre>"},{"location":"runtime/classProtectedVector/#function-at","title":"function at","text":"<pre><code>inline T ProtectedVector::at (\nsize_t i\n) </code></pre>"},{"location":"runtime/classProtectedVector/#function-at_unsafe","title":"function at_unsafe","text":"<pre><code>inline T ProtectedVector::at_unsafe (\nsize_t i\n) </code></pre>"},{"location":"runtime/classProtectedVector/#function-atomic_size","title":"function atomic_size","text":"<pre><code>inline int ProtectedVector::atomic_size () </code></pre>"},{"location":"runtime/classProtectedVector/#function-back","title":"function back","text":"<pre><code>inline T ProtectedVector::back () </code></pre>"},{"location":"runtime/classProtectedVector/#function-back_and_pop","title":"function back_and_pop","text":"<pre><code>inline T ProtectedVector::back_and_pop () </code></pre>"},{"location":"runtime/classProtectedVector/#function-back_and_pop_unsafe","title":"function back_and_pop_unsafe","text":"<pre><code>inline T ProtectedVector::back_and_pop_unsafe () </code></pre>"},{"location":"runtime/classProtectedVector/#function-back_unsafe","title":"function back_unsafe","text":"<pre><code>inline T ProtectedVector::back_unsafe () </code></pre>"},{"location":"runtime/classProtectedVector/#function-clear","title":"function clear","text":"<pre><code>inline void ProtectedVector::clear () </code></pre>"},{"location":"runtime/classProtectedVector/#function-clear_unsafe","title":"function clear_unsafe","text":"<pre><code>inline void ProtectedVector::clear_unsafe () </code></pre>"},{"location":"runtime/classProtectedVector/#function-empty","title":"function empty","text":"<pre><code>inline bool ProtectedVector::empty () </code></pre>"},{"location":"runtime/classProtectedVector/#function-empty_unsafe","title":"function empty_unsafe","text":"<pre><code>inline bool ProtectedVector::empty_unsafe () </code></pre>"},{"location":"runtime/classProtectedVector/#function-front","title":"function front","text":"<pre><code>inline T ProtectedVector::front () </code></pre>"},{"location":"runtime/classProtectedVector/#function-front_and_pop","title":"function front_and_pop","text":"<pre><code>inline T ProtectedVector::front_and_pop () </code></pre>"},{"location":"runtime/classProtectedVector/#function-front_and_pop_unsafe","title":"function front_and_pop_unsafe","text":"<pre><code>inline T ProtectedVector::front_and_pop_unsafe () </code></pre>"},{"location":"runtime/classProtectedVector/#function-front_unsafe","title":"function front_unsafe","text":"<pre><code>inline T ProtectedVector::front_unsafe () </code></pre>"},{"location":"runtime/classProtectedVector/#function-get","title":"function get","text":"<pre><code>inline T ProtectedVector::get (\nsize_t i\n) </code></pre>"},{"location":"runtime/classProtectedVector/#function-get_unsafe","title":"function get_unsafe","text":"<pre><code>inline T ProtectedVector::get_unsafe (\nsize_t i\n) </code></pre>"},{"location":"runtime/classProtectedVector/#function-get_vector","title":"function get_vector","text":"<pre><code>inline std::vector&lt; T &gt; &amp; ProtectedVector::get_vector () </code></pre>"},{"location":"runtime/classProtectedVector/#function-get_vector_copy","title":"function get_vector_copy","text":"<pre><code>inline std::vector&lt; T &gt; ProtectedVector::get_vector_copy () </code></pre>"},{"location":"runtime/classProtectedVector/#function-get_vector_copy_unsafe","title":"function get_vector_copy_unsafe","text":"<pre><code>inline std::vector&lt; T &gt; ProtectedVector::get_vector_copy_unsafe () </code></pre>"},{"location":"runtime/classProtectedVector/#function-get_vector_unsafe","title":"function get_vector_unsafe","text":"<pre><code>inline std::vector&lt; T &gt; &amp; ProtectedVector::get_vector_unsafe () </code></pre>"},{"location":"runtime/classProtectedVector/#function-lock","title":"function lock","text":"<pre><code>inline void ProtectedVector::lock () </code></pre>"},{"location":"runtime/classProtectedVector/#function-operator","title":"function operator=","text":"<pre><code>inline ProtectedVector &amp; ProtectedVector::operator= (\nProtectedVector &amp;&amp; other\n) </code></pre>"},{"location":"runtime/classProtectedVector/#function-operator_1","title":"function operator[]","text":"<pre><code>inline T ProtectedVector::operator[] (\nsize_t i\n) </code></pre>"},{"location":"runtime/classProtectedVector/#function-pop_back","title":"function pop_back","text":"<pre><code>inline void ProtectedVector::pop_back () </code></pre>"},{"location":"runtime/classProtectedVector/#function-pop_back_unsafe","title":"function pop_back_unsafe","text":"<pre><code>inline void ProtectedVector::pop_back_unsafe () </code></pre>"},{"location":"runtime/classProtectedVector/#function-push_back-12","title":"function push_back [1/2]","text":"<pre><code>inline void ProtectedVector::push_back (\nT a\n) </code></pre>"},{"location":"runtime/classProtectedVector/#function-push_back-22","title":"function push_back [2/2]","text":"<pre><code>inline void ProtectedVector::push_back (\nstd::vector&lt; T &gt; &amp; a\n) </code></pre>"},{"location":"runtime/classProtectedVector/#function-push_back_unsafe-12","title":"function push_back_unsafe [1/2]","text":"<pre><code>inline void ProtectedVector::push_back_unsafe (\nT a\n) </code></pre>"},{"location":"runtime/classProtectedVector/#function-push_back_unsafe-22","title":"function push_back_unsafe [2/2]","text":"<pre><code>inline void ProtectedVector::push_back_unsafe (\nstd::vector&lt; T &gt; &amp; a\n) </code></pre>"},{"location":"runtime/classProtectedVector/#function-reserve","title":"function reserve","text":"<pre><code>inline void ProtectedVector::reserve (\nsize_t size\n) </code></pre>"},{"location":"runtime/classProtectedVector/#function-reserve_unsafe","title":"function reserve_unsafe","text":"<pre><code>inline void ProtectedVector::reserve_unsafe (\nsize_t size\n) </code></pre>"},{"location":"runtime/classProtectedVector/#function-resize","title":"function resize","text":"<pre><code>inline void ProtectedVector::resize (\nsize_t size\n) </code></pre>"},{"location":"runtime/classProtectedVector/#function-resize_unsafe","title":"function resize_unsafe","text":"<pre><code>inline void ProtectedVector::resize_unsafe (\nsize_t size\n) </code></pre>"},{"location":"runtime/classProtectedVector/#function-set","title":"function set","text":"<pre><code>inline void ProtectedVector::set (\nsize_t i,\nT val\n) </code></pre>"},{"location":"runtime/classProtectedVector/#function-set_unsafe","title":"function set_unsafe","text":"<pre><code>inline void ProtectedVector::set_unsafe (\nsize_t i,\nT val\n) </code></pre>"},{"location":"runtime/classProtectedVector/#function-size","title":"function size","text":"<pre><code>inline size_t ProtectedVector::size () </code></pre>"},{"location":"runtime/classProtectedVector/#function-size_unsafe","title":"function size_unsafe","text":"<pre><code>inline size_t ProtectedVector::size_unsafe () </code></pre>"},{"location":"runtime/classProtectedVector/#function-unlock","title":"function unlock","text":"<pre><code>inline void ProtectedVector::unlock () </code></pre> <p>The documentation for this class was generated from the following file <code>src/c/backend/include/containers.hpp</code></p>"},{"location":"runtime/classResourcePool/","title":"Class ResourcePool","text":"<p>ClassList &gt; ResourcePool</p> <p>A pool of resources, allows for comparisons and updates of current values. More...</p> <ul> <li><code>#include &lt;resources.hpp&gt;</code></li> </ul>"},{"location":"runtime/classResourcePool/#public-functions","title":"Public Functions","text":"Type Name ResourcePool ()  ResourcePool (V memory, V vcu, V copy)  ResourcePool (std::vector&lt; Resource &gt; &amp; resource_list, std::vector&lt; V &gt; &amp; values)  ResourcePool (std::vector&lt; std::pair&lt; Resource, V &gt;&gt; &amp; resource_list)  ResourcePool (const ResourcePool &amp; other)  const bool check_greater (const ResourcePool &amp; other) const const bool check_lesser (const ResourcePool &amp; other) const void decrease (const ResourcePool &amp; other)  const V get (Resource resource) const void increase (const ResourcePool &amp; other)  const V set (Resource resource, V value)"},{"location":"runtime/classResourcePool/#protected-attributes","title":"Protected Attributes","text":"Type Name std::array&lt; std::atomic&lt; V &gt;, resource_names.size()&gt; resources   = = {0, 0, 0}"},{"location":"runtime/classResourcePool/#detailed-description","title":"Detailed Description","text":"<p>Template parameters:</p> <ul> <li><code>T</code> The type of the resource pool. Must be an atomic type. (typically int64_t)</li> </ul> <p>NOTE: The copy operation is not thread safe. It is only for initilaization. </p>"},{"location":"runtime/classResourcePool/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classResourcePool/#function-resourcepool-15","title":"function ResourcePool [1/5]","text":"<pre><code>inline ResourcePool::ResourcePool () </code></pre>"},{"location":"runtime/classResourcePool/#function-resourcepool-25","title":"function ResourcePool [2/5]","text":"<pre><code>inline ResourcePool::ResourcePool (\nV memory,\nV vcu,\nV copy\n) </code></pre>"},{"location":"runtime/classResourcePool/#function-resourcepool-35","title":"function ResourcePool [3/5]","text":"<pre><code>inline ResourcePool::ResourcePool (\nstd::vector&lt; Resource &gt; &amp; resource_list,\nstd::vector&lt; V &gt; &amp; values\n) </code></pre>"},{"location":"runtime/classResourcePool/#function-resourcepool-45","title":"function ResourcePool [4/5]","text":"<pre><code>inline ResourcePool::ResourcePool (\nstd::vector&lt; std::pair&lt; Resource, V &gt;&gt; &amp; resource_list\n) </code></pre>"},{"location":"runtime/classResourcePool/#function-resourcepool-55","title":"function ResourcePool [5/5]","text":"<pre><code>inline ResourcePool::ResourcePool (\nconst ResourcePool &amp; other\n) </code></pre>"},{"location":"runtime/classResourcePool/#function-check_greater","title":"function check_greater","text":"<pre><code>template&lt;ResourceCategory category&gt;\ninline const bool ResourcePool::check_greater (\nconst ResourcePool &amp; other\n) const\n</code></pre>"},{"location":"runtime/classResourcePool/#function-check_lesser","title":"function check_lesser","text":"<pre><code>template&lt;ResourceCategory category&gt;\ninline const bool ResourcePool::check_lesser (\nconst ResourcePool &amp; other\n) const\n</code></pre>"},{"location":"runtime/classResourcePool/#function-decrease","title":"function decrease","text":"<pre><code>template&lt;ResourceCategory category&gt;\ninline void ResourcePool::decrease (\nconst ResourcePool &amp; other\n) </code></pre>"},{"location":"runtime/classResourcePool/#function-get","title":"function get","text":"<pre><code>inline const V ResourcePool::get (\nResource resource\n) const\n</code></pre>"},{"location":"runtime/classResourcePool/#function-increase","title":"function increase","text":"<pre><code>template&lt;ResourceCategory category&gt;\ninline void ResourcePool::increase (\nconst ResourcePool &amp; other\n) </code></pre>"},{"location":"runtime/classResourcePool/#function-set","title":"function set","text":"<pre><code>inline const V ResourcePool::set (\nResource resource,\nV value\n) </code></pre>"},{"location":"runtime/classResourcePool/#protected-attributes-documentation","title":"Protected Attributes Documentation","text":""},{"location":"runtime/classResourcePool/#variable-resources","title":"variable resources","text":"<pre><code>std::array&lt;std::atomic&lt;V&gt;, resource_names.size()&gt; ResourcePool::resources;\n</code></pre> <p>The documentation for this class was generated from the following file <code>src/c/backend/include/resources.hpp</code></p>"},{"location":"runtime/classRuntimeReserver/","title":"Class RuntimeReserver","text":"<p>ClassList &gt; RuntimeReserver</p> <p>RuntimeReserver phase of the scheduler.More...</p> <ul> <li><code>#include &lt;phases.hpp&gt;</code></li> </ul> <p>Inherits the following classes: SchedulerPhase</p>"},{"location":"runtime/classRuntimeReserver/#public-functions","title":"Public Functions","text":"Type Name RuntimeReserver (InnerScheduler * scheduler, DeviceManager * devices)  virtual void enqueue (InnerTask * task) Enqueue a task to the phase. virtual void enqueue (std::vector&lt; InnerTask * &gt; &amp; tasks) Enqueue a vector of tasks to the phase. size_t get_compute_count ()  virtual size_t get_count () Get the number of tasks enqueued (and waiting) in the phase. size_t get_movement_count ()  const std::string &amp; get_name () const const RuntimeReserverStatus &amp; get_status () const const void print_status () const virtual void run (SchedulerPhase * next_phase) Run the phase. Check tasks in the enqueued buffer, check phase condition, and move tasks to the next phase."},{"location":"runtime/classRuntimeReserver/#public-functions-inherited-from-schedulerphase","title":"Public Functions inherited from SchedulerPhase","text":"<p>See SchedulerPhase</p> Type Name SchedulerPhase () = default SchedulerPhase (InnerScheduler * scheduler, DeviceManager * devices) Constructor for the scheduler phase. virtual void enqueue (InnerTask * task) = 0Enqueue a task to the phase. virtual void enqueue (std::vector&lt; InnerTask * &gt; &amp; tasks) = 0Enqueue a vector of tasks to the phase. virtual size_t get_count () = 0Get the number of tasks enqueued (and waiting) in the phase. virtual void run (SchedulerPhase * next_phase) = 0Run the phase. Check tasks in the enqueued buffer, check phase condition, and move tasks to the next phase."},{"location":"runtime/classRuntimeReserver/#protected-attributes","title":"Protected Attributes","text":"Type Name std::vector&lt; InnerTask * &gt; launchable_tasks_buffer std::shared_ptr&lt; PhaseManager&lt; ResourceCategory::Movement &gt; &gt; movement_tasks std::shared_ptr&lt; PhaseManager&lt; ResourceCategory::NonPersistent &gt; &gt; runnable_tasks RuntimeReserverStatus status   = {name}"},{"location":"runtime/classRuntimeReserver/#protected-attributes-inherited-from-schedulerphase","title":"Protected Attributes inherited from SchedulerPhase","text":"<p>See SchedulerPhase</p> Type Name DeviceManager * device_manager The device manager that the phase uses. TaskStateList enqueue_buffer The number of tasks enqueued (and waiting) in the phase. std::mutex mtx Mutex lock for the phase (In case of a workerthread driven scheduler, ensure only 1 thread is running the phase at a time) InnerScheduler * scheduler The scheduler that the phase belongs to."},{"location":"runtime/classRuntimeReserver/#protected-static-attributes","title":"Protected Static Attributes","text":"Type Name const std::string name   = {\"Runtime Reserver\"}"},{"location":"runtime/classRuntimeReserver/#protected-static-attributes-inherited-from-schedulerphase","title":"Protected Static Attributes inherited from SchedulerPhase","text":"<p>See SchedulerPhase</p> Type Name const std::string name   = {\"Phase\"}The name of the phase. Used for debugging and tracing."},{"location":"runtime/classRuntimeReserver/#protected-functions","title":"Protected Functions","text":"Type Name bool check_data_resources (InnerTask * task)  bool check_resources (InnerTask * task)  void reserve_data_resources (InnerTask * task)  void reserve_resources (InnerTask * task)"},{"location":"runtime/classRuntimeReserver/#detailed-description","title":"Detailed Description","text":"<p>Reserves all 'non-persistent resources<code>. This plans task execution on the device set. Here all 'non-persistent resources</code> that have a lifetime equal to the task body are reserved and are not directly shared between tasks. At the moment this is only the VCUS/Threads a task uses. This phase submits the task to the launcher. </p>"},{"location":"runtime/classRuntimeReserver/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classRuntimeReserver/#function-runtimereserver","title":"function RuntimeReserver","text":"<pre><code>inline RuntimeReserver::RuntimeReserver (\nInnerScheduler * scheduler,\nDeviceManager * devices\n) </code></pre>"},{"location":"runtime/classRuntimeReserver/#function-enqueue-12","title":"function enqueue [1/2]","text":"<pre><code>virtual void RuntimeReserver::enqueue (\nInnerTask * task\n) </code></pre> <p>Implements SchedulerPhase::enqueue</p>"},{"location":"runtime/classRuntimeReserver/#function-enqueue-22","title":"function enqueue [2/2]","text":"<pre><code>virtual void RuntimeReserver::enqueue (\nstd::vector&lt; InnerTask * &gt; &amp; tasks\n) </code></pre> <p>Implements SchedulerPhase::enqueue</p>"},{"location":"runtime/classRuntimeReserver/#function-get_compute_count","title":"function get_compute_count","text":"<pre><code>size_t RuntimeReserver::get_compute_count () </code></pre>"},{"location":"runtime/classRuntimeReserver/#function-get_count","title":"function get_count","text":"<pre><code>virtual size_t RuntimeReserver::get_count () </code></pre> <p>Implements SchedulerPhase::get_count</p>"},{"location":"runtime/classRuntimeReserver/#function-get_movement_count","title":"function get_movement_count","text":"<pre><code>size_t RuntimeReserver::get_movement_count () </code></pre>"},{"location":"runtime/classRuntimeReserver/#function-get_name","title":"function get_name","text":"<pre><code>inline const std::string &amp; RuntimeReserver::get_name () const\n</code></pre>"},{"location":"runtime/classRuntimeReserver/#function-get_status","title":"function get_status","text":"<pre><code>inline const RuntimeReserverStatus &amp; RuntimeReserver::get_status () const\n</code></pre>"},{"location":"runtime/classRuntimeReserver/#function-print_status","title":"function print_status","text":"<pre><code>inline const void RuntimeReserver::print_status () const\n</code></pre>"},{"location":"runtime/classRuntimeReserver/#function-run","title":"function run","text":"<p>Run the phase. Check tasks in the enqueued buffer, check phase condition, and move tasks to the next phase. <pre><code>virtual void RuntimeReserver::run (\nSchedulerPhase * next_phase\n) </code></pre></p> <p>Parameters:</p> <ul> <li><code>next_phase</code> The next phase to move tasks to. </li> </ul> <p>Implements SchedulerPhase::run</p>"},{"location":"runtime/classRuntimeReserver/#protected-attributes-documentation","title":"Protected Attributes Documentation","text":""},{"location":"runtime/classRuntimeReserver/#variable-launchable_tasks_buffer","title":"variable launchable_tasks_buffer","text":"<pre><code>std::vector&lt;InnerTask *&gt; RuntimeReserver::launchable_tasks_buffer;\n</code></pre>"},{"location":"runtime/classRuntimeReserver/#variable-movement_tasks","title":"variable movement_tasks","text":"<pre><code>std::shared_ptr&lt;PhaseManager&lt;ResourceCategory::Movement&gt; &gt; RuntimeReserver::movement_tasks;\n</code></pre>"},{"location":"runtime/classRuntimeReserver/#variable-runnable_tasks","title":"variable runnable_tasks","text":"<pre><code>std::shared_ptr&lt;PhaseManager&lt;ResourceCategory::NonPersistent&gt; &gt; RuntimeReserver::runnable_tasks;\n</code></pre>"},{"location":"runtime/classRuntimeReserver/#variable-status","title":"variable status","text":"<pre><code>RuntimeReserverStatus RuntimeReserver::status;\n</code></pre>"},{"location":"runtime/classRuntimeReserver/#protected-static-attributes-documentation","title":"Protected Static Attributes Documentation","text":""},{"location":"runtime/classRuntimeReserver/#variable-name","title":"variable name","text":"<pre><code>const std::string RuntimeReserver::name;\n</code></pre>"},{"location":"runtime/classRuntimeReserver/#protected-functions-documentation","title":"Protected Functions Documentation","text":""},{"location":"runtime/classRuntimeReserver/#function-check_data_resources","title":"function check_data_resources","text":"<pre><code>bool RuntimeReserver::check_data_resources (\nInnerTask * task\n) </code></pre>"},{"location":"runtime/classRuntimeReserver/#function-check_resources","title":"function check_resources","text":"<pre><code>bool RuntimeReserver::check_resources (\nInnerTask * task\n) </code></pre>"},{"location":"runtime/classRuntimeReserver/#function-reserve_data_resources","title":"function reserve_data_resources","text":"<pre><code>void RuntimeReserver::reserve_data_resources (\nInnerTask * task\n) </code></pre>"},{"location":"runtime/classRuntimeReserver/#function-reserve_resources","title":"function reserve_resources","text":"<pre><code>void RuntimeReserver::reserve_resources (\nInnerTask * task\n) </code></pre> <p>The documentation for this class was generated from the following file <code>src/c/backend/include/phases.hpp</code></p>"},{"location":"runtime/classRuntimeReserverStatus/","title":"Class RuntimeReserverStatus","text":"<p>ClassList &gt; RuntimeReserverStatus</p> <p>Inherits the following classes: PhaseStatus</p>"},{"location":"runtime/classRuntimeReserverStatus/#public-attributes-inherited-from-phasestatus","title":"Public Attributes inherited from PhaseStatus","text":"<p>See PhaseStatus</p> Type Name int status"},{"location":"runtime/classRuntimeReserverStatus/#public-functions-inherited-from-phasestatus","title":"Public Functions inherited from PhaseStatus","text":"<p>See PhaseStatus</p> Type Name PhaseStatus () = default PhaseStatus (std::string name)  void decrease (S state)  const int get (S state) const void increase (S state)  void print () const void reset ()  void set (S state, int value)"},{"location":"runtime/classRuntimeReserverStatus/#protected-attributes-inherited-from-phasestatus","title":"Protected Attributes inherited from PhaseStatus","text":"<p>See PhaseStatus</p> Type Name std::string name   = {\"Status\"} const int size   = {static_cast&lt;int&gt;(S::MAX)} <p>The documentation for this class was generated from the following file <code>src/c/backend/include/phases.hpp</code></p>"},{"location":"runtime/namespaceScheduler/","title":"Namespace Scheduler","text":"<p>Namespace List &gt; Scheduler</p>"},{"location":"runtime/namespaceScheduler/#classes","title":"Classes","text":"Type Name class Status"},{"location":"runtime/namespaceScheduler/#public-types","title":"Public Types","text":"Type Name enum State"},{"location":"runtime/namespaceScheduler/#public-types-documentation","title":"Public Types Documentation","text":""},{"location":"runtime/namespaceScheduler/#enum-state","title":"enum State","text":"<pre><code>enum Scheduler::State {\nspawned,\nmapped,\nreserved,\nready,\nlaunch,\nrunning,\ncomplete,\nfailed\n};\n</code></pre> <p>The documentation for this class was generated from the following file <code>src/c/backend/include/runtime.hpp</code></p>"},{"location":"runtime/classScheduler_1_1Status/","title":"Class Scheduler::Status","text":"<p>ClassList &gt; Scheduler &gt; Status</p>"},{"location":"runtime/classScheduler_1_1Status/#public-attributes","title":"Public Attributes","text":"Type Name int status   = = {0, 0, 0, 0, 0, 0, 0, 0}"},{"location":"runtime/classScheduler_1_1Status/#public-functions","title":"Public Functions","text":"Type Name int get (int index)  void print ()  void reset ()  void set (int index, int value)  void update (State state)"},{"location":"runtime/classScheduler_1_1Status/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"runtime/classScheduler_1_1Status/#variable-status","title":"variable status","text":"<pre><code>int Scheduler::Status::status[8];\n</code></pre>"},{"location":"runtime/classScheduler_1_1Status/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classScheduler_1_1Status/#function-get","title":"function get","text":"<pre><code>inline int Scheduler::Status::get (\nint index\n) </code></pre>"},{"location":"runtime/classScheduler_1_1Status/#function-print","title":"function print","text":"<pre><code>inline void Scheduler::Status::print () </code></pre>"},{"location":"runtime/classScheduler_1_1Status/#function-reset","title":"function reset","text":"<pre><code>inline void Scheduler::Status::reset () </code></pre>"},{"location":"runtime/classScheduler_1_1Status/#function-set","title":"function set","text":"<pre><code>inline void Scheduler::Status::set (\nint index,\nint value\n) </code></pre>"},{"location":"runtime/classScheduler_1_1Status/#function-update","title":"function update","text":"<pre><code>inline void Scheduler::Status::update (\nState state\n) </code></pre> <p>The documentation for this class was generated from the following file <code>src/c/backend/include/runtime.hpp</code></p>"},{"location":"runtime/classSchedulerPhase/","title":"Class SchedulerPhase","text":"<p>ClassList &gt; SchedulerPhase</p> <p>Abstract Interface for general scheduler runtime phase. </p> <ul> <li><code>#include &lt;phases.hpp&gt;</code></li> </ul> <p>Inherited by the following classes: Launcher,  Mapper,  MemoryReserver,  RuntimeReserver</p>"},{"location":"runtime/classSchedulerPhase/#public-functions","title":"Public Functions","text":"Type Name SchedulerPhase () = default SchedulerPhase (InnerScheduler * scheduler, DeviceManager * devices) Constructor for the scheduler phase. virtual void enqueue (InnerTask * task) = 0Enqueue a task to the phase. virtual void enqueue (std::vector&lt; InnerTask * &gt; &amp; tasks) = 0Enqueue a vector of tasks to the phase. virtual size_t get_count () = 0Get the number of tasks enqueued (and waiting) in the phase. virtual void run (SchedulerPhase * next_phase) = 0Run the phase. Check tasks in the enqueued buffer, check phase condition, and move tasks to the next phase."},{"location":"runtime/classSchedulerPhase/#protected-attributes","title":"Protected Attributes","text":"Type Name DeviceManager * device_manager The device manager that the phase uses. TaskStateList enqueue_buffer The number of tasks enqueued (and waiting) in the phase. std::mutex mtx Mutex lock for the phase (In case of a workerthread driven scheduler, ensure only 1 thread is running the phase at a time) InnerScheduler * scheduler The scheduler that the phase belongs to."},{"location":"runtime/classSchedulerPhase/#protected-static-attributes","title":"Protected Static Attributes","text":"Type Name const std::string name   = {\"Phase\"}The name of the phase. Used for debugging and tracing."},{"location":"runtime/classSchedulerPhase/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classSchedulerPhase/#function-schedulerphase-12","title":"function SchedulerPhase [1/2]","text":"<pre><code>SchedulerPhase::SchedulerPhase () = default\n</code></pre>"},{"location":"runtime/classSchedulerPhase/#function-schedulerphase-22","title":"function SchedulerPhase [2/2]","text":"<p>Constructor for the scheduler phase. <pre><code>inline SchedulerPhase::SchedulerPhase (\nInnerScheduler * scheduler,\nDeviceManager * devices\n) </code></pre></p> <p>Parameters:</p> <ul> <li><code>scheduler</code> The scheduler that the phase belongs to. </li> <li><code>devices</code> The device manager that the phase uses. </li> </ul>"},{"location":"runtime/classSchedulerPhase/#function-enqueue-12","title":"function enqueue [1/2]","text":"<pre><code>virtual void SchedulerPhase::enqueue (\nInnerTask * task\n) = 0\n</code></pre>"},{"location":"runtime/classSchedulerPhase/#function-enqueue-22","title":"function enqueue [2/2]","text":"<pre><code>virtual void SchedulerPhase::enqueue (\nstd::vector&lt; InnerTask * &gt; &amp; tasks\n) = 0\n</code></pre>"},{"location":"runtime/classSchedulerPhase/#function-get_count","title":"function get_count","text":"<pre><code>virtual size_t SchedulerPhase::get_count () = 0\n</code></pre>"},{"location":"runtime/classSchedulerPhase/#function-run","title":"function run","text":"<p>Run the phase. Check tasks in the enqueued buffer, check phase condition, and move tasks to the next phase. <pre><code>virtual void SchedulerPhase::run (\nSchedulerPhase * next_phase\n) = 0\n</code></pre></p> <p>Parameters:</p> <ul> <li><code>next_phase</code> The next phase to move tasks to. </li> </ul>"},{"location":"runtime/classSchedulerPhase/#protected-attributes-documentation","title":"Protected Attributes Documentation","text":""},{"location":"runtime/classSchedulerPhase/#variable-device_manager","title":"variable device_manager","text":"<pre><code>DeviceManager* SchedulerPhase::device_manager;\n</code></pre>"},{"location":"runtime/classSchedulerPhase/#variable-enqueue_buffer","title":"variable enqueue_buffer","text":"<pre><code>TaskStateList SchedulerPhase::enqueue_buffer;\n</code></pre>"},{"location":"runtime/classSchedulerPhase/#variable-mtx","title":"variable mtx","text":"<pre><code>std::mutex SchedulerPhase::mtx;\n</code></pre>"},{"location":"runtime/classSchedulerPhase/#variable-scheduler","title":"variable scheduler","text":"<pre><code>InnerScheduler* SchedulerPhase::scheduler;\n</code></pre>"},{"location":"runtime/classSchedulerPhase/#protected-static-attributes-documentation","title":"Protected Static Attributes Documentation","text":""},{"location":"runtime/classSchedulerPhase/#variable-name","title":"variable name","text":"<pre><code>const std::string SchedulerPhase::name;\n</code></pre> <p>The documentation for this class was generated from the following file <code>src/c/backend/include/phases.hpp</code></p>"},{"location":"runtime/classSinglePlacementRequirementBase/","title":"Class SinglePlacementRequirementBase","text":"<p>ClassList &gt; SinglePlacementRequirementBase</p> <p>Inherits the following classes: PlacementRequirementBase</p> <p>Inherited by the following classes: ArchitectureRequirement,  DeviceRequirement</p>"},{"location":"runtime/classSinglePlacementRequirementBase/#public-functions-inherited-from-placementrequirementbase","title":"Public Functions inherited from PlacementRequirementBase","text":"<p>See PlacementRequirementBase</p> Type Name virtual bool is_arch_req () = 0 virtual bool is_dev_req () = 0 virtual bool is_multidev_req () = 0 <p>The documentation for this class was generated from the following file <code>src/c/backend/include/resource_requirements.hpp</code></p>"},{"location":"runtime/namespaceTask/","title":"Namespace Task","text":"<p>Namespace List &gt; Task</p>"},{"location":"runtime/namespaceTask/#classes","title":"Classes","text":"Type Name class StatusFlags"},{"location":"runtime/namespaceTask/#public-types","title":"Public Types","text":"Type Name enum State enum Status enum SynchronizationType"},{"location":"runtime/namespaceTask/#public-types-documentation","title":"Public Types Documentation","text":""},{"location":"runtime/namespaceTask/#enum-state","title":"enum State","text":"<pre><code>enum Task::State {\nCREATED = 0,\nSPAWNED = 1,\nMAPPED = 2,\nRESERVED = 3,\nREADY = 4,\nRUNNING = 5,\nRUNAHEAD = 6,\nCOMPLETED = 7\n};\n</code></pre>"},{"location":"runtime/namespaceTask/#enum-status","title":"enum Status","text":"<pre><code>enum Task::Status {\nINITIAL = 0,\nSPAWNABLE = 1,\nMAPPABLE = 2,\nRESERVABLE = 3,\nCOMPUTE_RUNNABLE = 4,\nRUNNABLE = 5\n};\n</code></pre>"},{"location":"runtime/namespaceTask/#enum-synchronizationtype","title":"enum SynchronizationType","text":"<pre><code>enum Task::SynchronizationType {\nNONE = 0,\nBLOCKING = 1,\nNON_BLOCKING = 2,\nUSER = 3\n};\n</code></pre> <p>The documentation for this class was generated from the following file <code>src/c/backend/include/runtime.hpp</code></p>"},{"location":"runtime/classTask_1_1StatusFlags/","title":"Class Task::StatusFlags","text":"<p>ClassList &gt; Task &gt; StatusFlags</p>"},{"location":"runtime/classTask_1_1StatusFlags/#public-attributes","title":"Public Attributes","text":"Type Name bool compute_runnable   = {false} bool mappable   = {false} bool reservable   = {false} bool runnable   = {false} bool spawnable   = {false}"},{"location":"runtime/classTask_1_1StatusFlags/#public-functions","title":"Public Functions","text":"Type Name StatusFlags () = default StatusFlags (bool spawnable, bool mappable, bool reservable, bool compute_runnable, bool runnable)  bool any ()"},{"location":"runtime/classTask_1_1StatusFlags/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"runtime/classTask_1_1StatusFlags/#variable-compute_runnable","title":"variable compute_runnable","text":"<pre><code>bool Task::StatusFlags::compute_runnable;\n</code></pre>"},{"location":"runtime/classTask_1_1StatusFlags/#variable-mappable","title":"variable mappable","text":"<pre><code>bool Task::StatusFlags::mappable;\n</code></pre>"},{"location":"runtime/classTask_1_1StatusFlags/#variable-reservable","title":"variable reservable","text":"<pre><code>bool Task::StatusFlags::reservable;\n</code></pre>"},{"location":"runtime/classTask_1_1StatusFlags/#variable-runnable","title":"variable runnable","text":"<pre><code>bool Task::StatusFlags::runnable;\n</code></pre>"},{"location":"runtime/classTask_1_1StatusFlags/#variable-spawnable","title":"variable spawnable","text":"<pre><code>bool Task::StatusFlags::spawnable;\n</code></pre>"},{"location":"runtime/classTask_1_1StatusFlags/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classTask_1_1StatusFlags/#function-statusflags-12","title":"function StatusFlags [1/2]","text":"<pre><code>Task::StatusFlags::StatusFlags () = default\n</code></pre>"},{"location":"runtime/classTask_1_1StatusFlags/#function-statusflags-22","title":"function StatusFlags [2/2]","text":"<pre><code>inline Task::StatusFlags::StatusFlags (\nbool spawnable,\nbool mappable,\nbool reservable,\nbool compute_runnable,\nbool runnable\n) </code></pre>"},{"location":"runtime/classTask_1_1StatusFlags/#function-any","title":"function any","text":"<pre><code>inline bool Task::StatusFlags::any () </code></pre> <p>The documentation for this class was generated from the following file <code>src/c/backend/include/runtime.hpp</code></p>"},{"location":"runtime/classTaskBarrier/","title":"Class TaskBarrier","text":"<p>ClassList &gt; TaskBarrier</p> <p>The C++ \"Mirror\" of Parla's Python TaskSets &amp; Spaces They are used as barriers for the calling thread for the completion of their members. </p> <ul> <li><code>#include &lt;runtime.hpp&gt;</code></li> </ul> <p>Inherited by the following classes: InnerTaskSpace</p>"},{"location":"runtime/classTaskBarrier/#public-attributes","title":"Public Attributes","text":"Type Name std::condition_variable cv int64_t id std::mutex mtx std::atomic&lt; int &gt; num_incomplete_tasks   = {0}"},{"location":"runtime/classTaskBarrier/#public-functions","title":"Public Functions","text":"Type Name TaskBarrier () = default TaskBarrier (int num_tasks)  Task::State _add_task (InnerTask * task)  void add_task (InnerTask * task)  void add_tasks (std::vector&lt; InnerTask * &gt; &amp; tasks)  void notify ()  void set_id (int64_t id)  void wait ()"},{"location":"runtime/classTaskBarrier/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"runtime/classTaskBarrier/#variable-cv","title":"variable cv","text":"<pre><code>std::condition_variable TaskBarrier::cv;\n</code></pre>"},{"location":"runtime/classTaskBarrier/#variable-id","title":"variable id","text":"<pre><code>int64_t TaskBarrier::id;\n</code></pre>"},{"location":"runtime/classTaskBarrier/#variable-mtx","title":"variable mtx","text":"<pre><code>std::mutex TaskBarrier::mtx;\n</code></pre>"},{"location":"runtime/classTaskBarrier/#variable-num_incomplete_tasks","title":"variable num_incomplete_tasks","text":"<pre><code>std::atomic&lt;int&gt; TaskBarrier::num_incomplete_tasks;\n</code></pre>"},{"location":"runtime/classTaskBarrier/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classTaskBarrier/#function-taskbarrier-12","title":"function TaskBarrier [1/2]","text":"<pre><code>TaskBarrier::TaskBarrier () = default\n</code></pre>"},{"location":"runtime/classTaskBarrier/#function-taskbarrier-22","title":"function TaskBarrier [2/2]","text":"<pre><code>inline TaskBarrier::TaskBarrier (\nint num_tasks\n) </code></pre>"},{"location":"runtime/classTaskBarrier/#function-_add_task","title":"function _add_task","text":"<pre><code>Task::State TaskBarrier::_add_task (\nInnerTask * task\n) </code></pre>"},{"location":"runtime/classTaskBarrier/#function-add_task","title":"function add_task","text":"<pre><code>void TaskBarrier::add_task (\nInnerTask * task\n) </code></pre>"},{"location":"runtime/classTaskBarrier/#function-add_tasks","title":"function add_tasks","text":"<pre><code>void TaskBarrier::add_tasks (\nstd::vector&lt; InnerTask * &gt; &amp; tasks\n) </code></pre>"},{"location":"runtime/classTaskBarrier/#function-notify","title":"function notify","text":"<pre><code>inline void TaskBarrier::notify () </code></pre>"},{"location":"runtime/classTaskBarrier/#function-set_id","title":"function set_id","text":"<pre><code>inline void TaskBarrier::set_id (\nint64_t id\n) </code></pre>"},{"location":"runtime/classTaskBarrier/#function-wait","title":"function wait","text":"<pre><code>inline void TaskBarrier::wait () </code></pre> <p>The documentation for this class was generated from the following file <code>src/c/backend/include/runtime.hpp</code></p>"},{"location":"runtime/classWorkerPool/","title":"Class WorkerPool","text":"<p>template &lt;typename AllWorkers_t typename AllWorkers_t, typename ActiveWorkers_t typename ActiveWorkers_t&gt;</p> <p>ClassList &gt; WorkerPool</p>"},{"location":"runtime/classWorkerPool/#public-attributes","title":"Public Attributes","text":"Type Name ActiveWorkers_t active_workers AllWorkers_t all_workers std::condition_variable cv int max_workers std::mutex mtx std::atomic&lt; int &gt; notified_workers   = {0}"},{"location":"runtime/classWorkerPool/#public-functions","title":"Public Functions","text":"Type Name WorkerPool () = default WorkerPool (int nworkers)  void add_worker (InnerWorker * worker)  int decrease_num_notified_workers ()  InnerWorker * dequeue_worker ()  void enqueue_worker (InnerWorker * worker)  int get_num_available_workers ()  int get_num_notified_workers ()  int get_num_workers ()  int increase_num_notified_workers ()  void set_num_workers (int nworkers)  void spawn_wait ()"},{"location":"runtime/classWorkerPool/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"runtime/classWorkerPool/#variable-active_workers","title":"variable active_workers","text":"<pre><code>ActiveWorkers_t WorkerPool&lt; AllWorkers_t, ActiveWorkers_t &gt;::active_workers;\n</code></pre>"},{"location":"runtime/classWorkerPool/#variable-all_workers","title":"variable all_workers","text":"<pre><code>AllWorkers_t WorkerPool&lt; AllWorkers_t, ActiveWorkers_t &gt;::all_workers;\n</code></pre>"},{"location":"runtime/classWorkerPool/#variable-cv","title":"variable cv","text":"<pre><code>std::condition_variable WorkerPool&lt; AllWorkers_t, ActiveWorkers_t &gt;::cv;\n</code></pre>"},{"location":"runtime/classWorkerPool/#variable-max_workers","title":"variable max_workers","text":"<pre><code>int WorkerPool&lt; AllWorkers_t, ActiveWorkers_t &gt;::max_workers;\n</code></pre>"},{"location":"runtime/classWorkerPool/#variable-mtx","title":"variable mtx","text":"<pre><code>std::mutex WorkerPool&lt; AllWorkers_t, ActiveWorkers_t &gt;::mtx;\n</code></pre>"},{"location":"runtime/classWorkerPool/#variable-notified_workers","title":"variable notified_workers","text":"<pre><code>std::atomic&lt;int&gt; WorkerPool&lt; AllWorkers_t, ActiveWorkers_t &gt;::notified_workers;\n</code></pre>"},{"location":"runtime/classWorkerPool/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classWorkerPool/#function-workerpool-12","title":"function WorkerPool [1/2]","text":"<pre><code>WorkerPool::WorkerPool () = default\n</code></pre>"},{"location":"runtime/classWorkerPool/#function-workerpool-22","title":"function WorkerPool [2/2]","text":"<pre><code>inline WorkerPool::WorkerPool (\nint nworkers\n) </code></pre>"},{"location":"runtime/classWorkerPool/#function-add_worker","title":"function add_worker","text":"<pre><code>void WorkerPool::add_worker (\nInnerWorker * worker\n) </code></pre>"},{"location":"runtime/classWorkerPool/#function-decrease_num_notified_workers","title":"function decrease_num_notified_workers","text":"<pre><code>int WorkerPool::decrease_num_notified_workers () </code></pre>"},{"location":"runtime/classWorkerPool/#function-dequeue_worker","title":"function dequeue_worker","text":"<pre><code>InnerWorker * WorkerPool::dequeue_worker () </code></pre>"},{"location":"runtime/classWorkerPool/#function-enqueue_worker","title":"function enqueue_worker","text":"<pre><code>void WorkerPool::enqueue_worker (\nInnerWorker * worker\n) </code></pre>"},{"location":"runtime/classWorkerPool/#function-get_num_available_workers","title":"function get_num_available_workers","text":"<pre><code>int WorkerPool::get_num_available_workers () </code></pre>"},{"location":"runtime/classWorkerPool/#function-get_num_notified_workers","title":"function get_num_notified_workers","text":"<pre><code>inline int WorkerPool::get_num_notified_workers () </code></pre>"},{"location":"runtime/classWorkerPool/#function-get_num_workers","title":"function get_num_workers","text":"<pre><code>int WorkerPool::get_num_workers () </code></pre>"},{"location":"runtime/classWorkerPool/#function-increase_num_notified_workers","title":"function increase_num_notified_workers","text":"<pre><code>int WorkerPool::increase_num_notified_workers () </code></pre>"},{"location":"runtime/classWorkerPool/#function-set_num_workers","title":"function set_num_workers","text":"<pre><code>void WorkerPool::set_num_workers (\nint nworkers\n) </code></pre>"},{"location":"runtime/classWorkerPool/#function-spawn_wait","title":"function spawn_wait","text":"<pre><code>void WorkerPool::spawn_wait () </code></pre> <p>The documentation for this class was generated from the following file <code>src/c/backend/include/runtime.hpp</code></p>"},{"location":"runtime/namespacechrono/","title":"Namespace chrono","text":"<p>Namespace List &gt; chrono</p> <p>The documentation for this class was generated from the following file <code>src/c/backend/include/gpu_utility.hpp</code></p>"},{"location":"runtime/namespaceparla/","title":"Namespace parla","text":"<p>Namespace List &gt; parla</p>"},{"location":"runtime/namespaceparla/#namespaces","title":"Namespaces","text":"Type Name namespace cython <p>The documentation for this class was generated from the following file <code>[generated]</code></p>"},{"location":"runtime/namespaceparla_1_1cython/","title":"Namespace parla::cython","text":"<p>Namespace List &gt; parla &gt; cython</p>"},{"location":"runtime/namespaceparla_1_1cython/#namespaces","title":"Namespaces","text":"Type Name namespace containers namespace core namespace cyparray namespace cyparray_state namespace device namespace device_manager namespace scheduler namespace tasks namespace variants <p>The documentation for this class was generated from the following file <code>[generated]</code></p>"},{"location":"runtime/namespaceparla_1_1cython_1_1containers/","title":"Namespace parla::cython::containers","text":"<p>Namespace List &gt; parla &gt; cython &gt; containers</p> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/containers.pyx</code></p>"},{"location":"runtime/namespaceparla_1_1cython_1_1core/","title":"Namespace parla::cython::core","text":"<p>Namespace List &gt; parla &gt; cython &gt; core</p>"},{"location":"runtime/namespaceparla_1_1cython_1_1core/#classes","title":"Classes","text":"Type Name class CyDataMovementTaskAttributes class CyTaskList class DataMovementTaskAttributes class PyInnerScheduler class PyInnerTask class PyInnerWorker class PyTaskBarrier class PyTaskSpace class Resources"},{"location":"runtime/namespaceparla_1_1cython_1_1core/#public-attributes","title":"Public Attributes","text":"Type Name int LOG_DEBUG   = =  1 int LOG_ERROR   = =  4 int LOG_FATAL   = =  5 int LOG_INFO   = =  2 int LOG_TRACE   = =  0 int LOG_WARN   = =  3 c_dependencies c_dependency   = =  dependency.c_task c_dependent   = =  &lt;InnerTask*&gt; c_dependents[i] c_dependents c_dev c_device   = =  &lt;Device*&gt; c_devices[i] c_devices c_priority c_scheduler c_self c_stream c_sync_type c_t c_task category cpp_device d   = =  dependency_list[i] list dependencies   = =  [] dependency   = =  d.inner_task dependency_list list dependents   = =  [] list devices   = =  [] fname   = =  filename.encode('utf-8') i_event   = =  &lt;uintptr_t&gt; py_event.ptr i_stream   = =  &lt;uintptr_t&gt; py_stream.ptr inner_type1   = =  cython.fused_type(PyInnerTask, PyInnerWorker) inner_type2   = =  cython.fused_type(PyInnerTask, PyInnerWorker) logging_level message msg   = =  message.encode('utf-8') msg1   = =  message1.encode('utf-8') msg2   = =  message2.encode('utf-8') name num_deps num_devices obj obj2 process py_dependency   = =  &lt;PyInnerTask&gt; c_dependency.get_py_task() py_dependent   = =  &lt;PyInnerTask&gt; c_dependent.get_py_task() py_device   = =  &lt;object&gt; c_device.get_py_device() scheduler   = =  &lt;object&gt;python_scheduler self status   = =  status_flags.mappable status_flags   = =  c_self.process_dependencies() task   = =  &lt;object&gt;python_task worker   = =  &lt;object&gt;python_worker"},{"location":"runtime/namespaceparla_1_1cython_1_1core/#public-functions","title":"Public Functions","text":"Type Name def __cinit__ (self self)  def __dealloc__ (self self)  def __init__ (self self, long long, long long, int int, idx idx, object object, python_task python_task)"},{"location":"runtime/namespaceparla_1_1cython_1_1core/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"runtime/namespaceparla_1_1cython_1_1core/#variable-log_debug","title":"variable LOG_DEBUG","text":"<pre><code>int parla::cython::core.LOG_DEBUG;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1core/#variable-log_error","title":"variable LOG_ERROR","text":"<pre><code>int parla::cython::core.LOG_ERROR;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1core/#variable-log_fatal","title":"variable LOG_FATAL","text":"<pre><code>int parla::cython::core.LOG_FATAL;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1core/#variable-log_info","title":"variable LOG_INFO","text":"<pre><code>int parla::cython::core.LOG_INFO;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1core/#variable-log_trace","title":"variable LOG_TRACE","text":"<pre><code>int parla::cython::core.LOG_TRACE;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1core/#variable-log_warn","title":"variable LOG_WARN","text":"<pre><code>int parla::cython::core.LOG_WARN;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1core/#variable-c_dependencies","title":"variable c_dependencies","text":"<pre><code>parla::cython::core.c_dependencies;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1core/#variable-c_dependency","title":"variable c_dependency","text":"<pre><code>parla::cython::core.c_dependency;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1core/#variable-c_dependent","title":"variable c_dependent","text":"<pre><code>parla::cython::core.c_dependent;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1core/#variable-c_dependents","title":"variable c_dependents","text":"<pre><code>parla::cython::core.c_dependents;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1core/#variable-c_dev","title":"variable c_dev","text":"<pre><code>parla::cython::core.c_dev;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1core/#variable-c_device","title":"variable c_device","text":"<pre><code>parla::cython::core.c_device;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1core/#variable-c_devices","title":"variable c_devices","text":"<pre><code>parla::cython::core.c_devices;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1core/#variable-c_priority","title":"variable c_priority","text":"<pre><code>parla::cython::core.c_priority;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1core/#variable-c_scheduler","title":"variable c_scheduler","text":"<pre><code>parla::cython::core.c_scheduler;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1core/#variable-c_self","title":"variable c_self","text":"<pre><code>parla::cython::core.c_self;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1core/#variable-c_stream","title":"variable c_stream","text":"<pre><code>parla::cython::core.c_stream;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1core/#variable-c_sync_type","title":"variable c_sync_type","text":"<pre><code>parla::cython::core.c_sync_type;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1core/#variable-c_t","title":"variable c_t","text":"<pre><code>parla::cython::core.c_t;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1core/#variable-c_task","title":"variable c_task","text":"<pre><code>parla::cython::core.c_task;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1core/#variable-category","title":"variable category","text":"<pre><code>parla::cython::core.category;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1core/#variable-cpp_device","title":"variable cpp_device","text":"<pre><code>parla::cython::core.cpp_device;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1core/#variable-d","title":"variable d","text":"<pre><code>parla::cython::core.d;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1core/#variable-dependencies","title":"variable dependencies","text":"<pre><code>list parla::cython::core.dependencies;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1core/#variable-dependency","title":"variable dependency","text":"<pre><code>parla::cython::core.dependency;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1core/#variable-dependency_list","title":"variable dependency_list","text":"<pre><code>parla::cython::core.dependency_list;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1core/#variable-dependents","title":"variable dependents","text":"<pre><code>list parla::cython::core.dependents;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1core/#variable-devices","title":"variable devices","text":"<pre><code>list parla::cython::core.devices;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1core/#variable-fname","title":"variable fname","text":"<pre><code>parla::cython::core.fname;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1core/#variable-i_event","title":"variable i_event","text":"<pre><code>parla::cython::core.i_event;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1core/#variable-i_stream","title":"variable i_stream","text":"<pre><code>parla::cython::core.i_stream;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1core/#variable-inner_type1","title":"variable inner_type1","text":"<pre><code>parla::cython::core.inner_type1;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1core/#variable-inner_type2","title":"variable inner_type2","text":"<pre><code>parla::cython::core.inner_type2;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1core/#variable-logging_level","title":"variable logging_level","text":"<pre><code>parla::cython::core.logging_level;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1core/#variable-message","title":"variable message","text":"<pre><code>parla::cython::core.message;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1core/#variable-msg","title":"variable msg","text":"<pre><code>parla::cython::core.msg;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1core/#variable-msg1","title":"variable msg1","text":"<pre><code>parla::cython::core.msg1;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1core/#variable-msg2","title":"variable msg2","text":"<pre><code>parla::cython::core.msg2;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1core/#variable-name","title":"variable name","text":"<pre><code>parla::cython::core.name;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1core/#variable-num_deps","title":"variable num_deps","text":"<pre><code>parla::cython::core.num_deps;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1core/#variable-num_devices","title":"variable num_devices","text":"<pre><code>parla::cython::core.num_devices;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1core/#variable-obj","title":"variable obj","text":"<pre><code>parla::cython::core.obj;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1core/#variable-obj2","title":"variable obj2","text":"<pre><code>parla::cython::core.obj2;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1core/#variable-process","title":"variable process","text":"<pre><code>parla::cython::core.process;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1core/#variable-py_dependency","title":"variable py_dependency","text":"<pre><code>parla::cython::core.py_dependency;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1core/#variable-py_dependent","title":"variable py_dependent","text":"<pre><code>parla::cython::core.py_dependent;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1core/#variable-py_device","title":"variable py_device","text":"<pre><code>parla::cython::core.py_device;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1core/#variable-scheduler","title":"variable scheduler","text":"<pre><code>parla::cython::core.scheduler;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1core/#variable-self","title":"variable self","text":"<pre><code>parla::cython::core.self;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1core/#variable-status","title":"variable status","text":"<pre><code>parla::cython::core.status;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1core/#variable-status_flags","title":"variable status_flags","text":"<pre><code>parla::cython::core.status_flags;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1core/#variable-task","title":"variable task","text":"<pre><code>parla::cython::core.task;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1core/#variable-worker","title":"variable worker","text":"<pre><code>parla::cython::core.worker;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1core/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/namespaceparla_1_1cython_1_1core/#function-__cinit__","title":"function __cinit__","text":"<pre><code>def parla::cython::core::__cinit__ (\n    self self\n) \n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1core/#function-__dealloc__","title":"function __dealloc__","text":"<pre><code>def parla::cython::core::__dealloc__ (\n    self self\n) \n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1core/#function-__init__","title":"function __init__","text":"<pre><code>def parla::cython::core::__init__ (\n    self self,\n    long long,\n    long long,\n    int int,\n    idx idx,\n    object object,\n    python_task python_task\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/core.pyx</code></p>"},{"location":"runtime/classparla_1_1cython_1_1core_1_1CyDataMovementTaskAttributes/","title":"Class parla::cython::core::CyDataMovementTaskAttributes","text":"<p>ClassList &gt; parla &gt; cython &gt; core &gt; CyDataMovementTaskAttributes</p> <p>More...</p>"},{"location":"runtime/classparla_1_1cython_1_1core_1_1CyDataMovementTaskAttributes/#public-static-attributes","title":"Public Static Attributes","text":"Type Name c_data_task"},{"location":"runtime/classparla_1_1cython_1_1core_1_1CyDataMovementTaskAttributes/#detailed-description","title":"Detailed Description","text":""},{"location":"runtime/classparla_1_1cython_1_1core_1_1CyDataMovementTaskAttributes/#public-static-attributes-documentation","title":"Public Static Attributes Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1core_1_1CyDataMovementTaskAttributes/#variable-c_data_task","title":"variable c_data_task","text":"<pre><code>parla.cython.core.CyDataMovementTaskAttributes::c_data_task;\n</code></pre> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/core.pyx</code></p>"},{"location":"runtime/classparla_1_1cython_1_1core_1_1CyTaskList/","title":"Class parla::cython::core::CyTaskList","text":"<p>ClassList &gt; parla &gt; cython &gt; core &gt; CyTaskList</p>"},{"location":"runtime/classparla_1_1cython_1_1core_1_1CyTaskList/#public-attributes","title":"Public Attributes","text":"Type Name c_task_list"},{"location":"runtime/classparla_1_1cython_1_1core_1_1CyTaskList/#public-functions","title":"Public Functions","text":"Type Name def __cinit__ (self self)"},{"location":"runtime/classparla_1_1cython_1_1core_1_1CyTaskList/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1core_1_1CyTaskList/#variable-c_task_list","title":"variable c_task_list","text":"<pre><code>parla.cython.core.CyTaskList::c_task_list;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1core_1_1CyTaskList/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1core_1_1CyTaskList/#function-__cinit__","title":"function __cinit__","text":"<pre><code>def parla::cython::core::CyTaskList::__cinit__ (\n    self self\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/core.pyx</code></p>"},{"location":"runtime/classparla_1_1cython_1_1core_1_1DataMovementTaskAttributes/","title":"Class parla::cython::core::DataMovementTaskAttributes","text":"<p>ClassList &gt; parla &gt; cython &gt; core &gt; DataMovementTaskAttributes</p> <p>More...</p>"},{"location":"runtime/classparla_1_1cython_1_1core_1_1DataMovementTaskAttributes/#public-attributes","title":"Public Attributes","text":"Type Name access_mode assigned_devices c_attrs dev_id name parray"},{"location":"runtime/classparla_1_1cython_1_1core_1_1DataMovementTaskAttributes/#public-functions","title":"Public Functions","text":"Type Name def __init__ (self self, name name, PArray py_parray, access_mode access_mode, assigned_devices assigned_devices, CyDataMovementTaskAttributes c_attrs, dev_id dev_id)"},{"location":"runtime/classparla_1_1cython_1_1core_1_1DataMovementTaskAttributes/#detailed-description","title":"Detailed Description","text":""},{"location":"runtime/classparla_1_1cython_1_1core_1_1DataMovementTaskAttributes/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1core_1_1DataMovementTaskAttributes/#variable-access_mode","title":"variable access_mode","text":"<pre><code>parla.cython.core.DataMovementTaskAttributes::access_mode;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1core_1_1DataMovementTaskAttributes/#variable-assigned_devices","title":"variable assigned_devices","text":"<pre><code>parla.cython.core.DataMovementTaskAttributes::assigned_devices;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1core_1_1DataMovementTaskAttributes/#variable-c_attrs","title":"variable c_attrs","text":"<pre><code>parla.cython.core.DataMovementTaskAttributes::c_attrs;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1core_1_1DataMovementTaskAttributes/#variable-dev_id","title":"variable dev_id","text":"<pre><code>parla.cython.core.DataMovementTaskAttributes::dev_id;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1core_1_1DataMovementTaskAttributes/#variable-name","title":"variable name","text":"<pre><code>parla.cython.core.DataMovementTaskAttributes::name;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1core_1_1DataMovementTaskAttributes/#variable-parray","title":"variable parray","text":"<pre><code>parla.cython.core.DataMovementTaskAttributes::parray;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1core_1_1DataMovementTaskAttributes/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1core_1_1DataMovementTaskAttributes/#function-__init__","title":"function __init__","text":"<pre><code>def parla::cython::core::DataMovementTaskAttributes::__init__ (\n    self self,\n    name name,\n    PArray py_parray,\n    access_mode access_mode,\n    assigned_devices assigned_devices,\n    CyDataMovementTaskAttributes c_attrs,\n    dev_id dev_id\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/core.pyx</code></p>"},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyInnerScheduler/","title":"Class parla::cython::core::PyInnerScheduler","text":"<p>ClassList &gt; parla &gt; cython &gt; core &gt; PyInnerScheduler</p>"},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyInnerScheduler/#public-attributes","title":"Public Attributes","text":"Type Name inner_scheduler"},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyInnerScheduler/#public-static-attributes","title":"Public Static Attributes","text":"Type Name c_self c_task c_worker"},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyInnerScheduler/#public-functions","title":"Public Functions","text":"Type Name def __cinit__ (self self, CyDeviceManager CyDeviceManager, cy_device_manager cy_device_manager, int int, num_workers num_workers, float float, vcus vcus, object object, python_scheduler python_scheduler)  def __dealloc__ (self self)  def __init__ (self self, CyDeviceManager CyDeviceManager, cy_device_manager cy_device_manager, int int, num_workers num_workers, float float, vcus vcus, object object, python_scheduler python_scheduler)"},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyInnerScheduler/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyInnerScheduler/#variable-inner_scheduler","title":"variable inner_scheduler","text":"<pre><code>parla.cython.core.PyInnerScheduler::inner_scheduler;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyInnerScheduler/#public-static-attributes-documentation","title":"Public Static Attributes Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyInnerScheduler/#variable-c_self","title":"variable c_self","text":"<pre><code>parla.cython.core.PyInnerScheduler::c_self;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyInnerScheduler/#variable-c_task","title":"variable c_task","text":"<pre><code>parla.cython.core.PyInnerScheduler::c_task;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyInnerScheduler/#variable-c_worker","title":"variable c_worker","text":"<pre><code>parla.cython.core.PyInnerScheduler::c_worker;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyInnerScheduler/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyInnerScheduler/#function-__cinit__","title":"function __cinit__","text":"<pre><code>def parla::cython::core::PyInnerScheduler::__cinit__ (\n    self self,\n    CyDeviceManager CyDeviceManager,\n    cy_device_manager cy_device_manager,\n    int int,\n    num_workers num_workers,\n    float float,\n    vcus vcus,\n    object object,\n    python_scheduler python_scheduler\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyInnerScheduler/#function-__dealloc__","title":"function __dealloc__","text":"<pre><code>def parla::cython::core::PyInnerScheduler::__dealloc__ (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyInnerScheduler/#function-__init__","title":"function __init__","text":"<pre><code>def parla::cython::core::PyInnerScheduler::__init__ (\n    self self,\n    CyDeviceManager CyDeviceManager,\n    cy_device_manager cy_device_manager,\n    int int,\n    num_workers num_workers,\n    float float,\n    vcus vcus,\n    object object,\n    python_scheduler python_scheduler\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/core.pyx</code></p>"},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyInnerTask/","title":"Class parla::cython::core::PyInnerTask","text":"<p>ClassList &gt; parla &gt; cython &gt; core &gt; PyInnerTask</p> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/core.pyx</code></p>"},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyInnerWorker/","title":"Class parla::cython::core::PyInnerWorker","text":"<p>ClassList &gt; parla &gt; cython &gt; core &gt; PyInnerWorker</p>"},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyInnerWorker/#public-attributes","title":"Public Attributes","text":"Type Name inner_worker"},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyInnerWorker/#public-static-attributes","title":"Public Static Attributes","text":"Type Name access_mode   = =  c_data_task.get_access_mode() c_data_task   = =  &lt;InnerDataTask *&gt; c_task c_device   = =  &lt;Device *&gt; c_devices[i] c_devices   = =  c_task.get_assigned_devices() cy_data_attrs   = =  CyDataMovementTaskAttributes() dev_id   = =  c_data_task.get_device_id(); is_data_task name   = =  c_task.get_name() num_devices   = =  c_devices.size() list py_assigned_devices   = =  [] py_device   = =  &lt;object&gt; c_device.get_py_device() py_parray   = =  &lt;object&gt; c_data_task.get_py_parray() py_task   = =  DataMovementTaskAttributes(name, py_parray, \\ access_mode, py_assigned_devices, cy_data_attrs, \\ dev_id)"},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyInnerWorker/#public-functions","title":"Public Functions","text":"Type Name def __cinit__ (self self)  def __dealloc__ (self self)  def __init__ (self self, python_worker python_worker, PyInnerScheduler PyInnerScheduler, python_scheduler python_scheduler)"},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyInnerWorker/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyInnerWorker/#variable-inner_worker","title":"variable inner_worker","text":"<pre><code>parla.cython.core.PyInnerWorker::inner_worker;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyInnerWorker/#public-static-attributes-documentation","title":"Public Static Attributes Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyInnerWorker/#variable-access_mode","title":"variable access_mode","text":"<pre><code>parla.cython.core.PyInnerWorker::access_mode;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyInnerWorker/#variable-c_data_task","title":"variable c_data_task","text":"<pre><code>parla.cython.core.PyInnerWorker::c_data_task;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyInnerWorker/#variable-c_device","title":"variable c_device","text":"<pre><code>parla.cython.core.PyInnerWorker::c_device;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyInnerWorker/#variable-c_devices","title":"variable c_devices","text":"<pre><code>parla.cython.core.PyInnerWorker::c_devices;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyInnerWorker/#variable-cy_data_attrs","title":"variable cy_data_attrs","text":"<pre><code>parla.cython.core.PyInnerWorker::cy_data_attrs;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyInnerWorker/#variable-dev_id","title":"variable dev_id","text":"<pre><code>parla.cython.core.PyInnerWorker::dev_id;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyInnerWorker/#variable-is_data_task","title":"variable is_data_task","text":"<pre><code>parla.cython.core.PyInnerWorker::is_data_task;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyInnerWorker/#variable-name","title":"variable name","text":"<pre><code>parla.cython.core.PyInnerWorker::name;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyInnerWorker/#variable-num_devices","title":"variable num_devices","text":"<pre><code>parla.cython.core.PyInnerWorker::num_devices;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyInnerWorker/#variable-py_assigned_devices","title":"variable py_assigned_devices","text":"<pre><code>list parla.cython.core.PyInnerWorker::py_assigned_devices;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyInnerWorker/#variable-py_device","title":"variable py_device","text":"<pre><code>parla.cython.core.PyInnerWorker::py_device;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyInnerWorker/#variable-py_parray","title":"variable py_parray","text":"<pre><code>parla.cython.core.PyInnerWorker::py_parray;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyInnerWorker/#variable-py_task","title":"variable py_task","text":"<pre><code>parla.cython.core.PyInnerWorker::py_task;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyInnerWorker/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyInnerWorker/#function-__cinit__","title":"function __cinit__","text":"<pre><code>def parla::cython::core::PyInnerWorker::__cinit__ (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyInnerWorker/#function-__dealloc__","title":"function __dealloc__","text":"<pre><code>def parla::cython::core::PyInnerWorker::__dealloc__ (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyInnerWorker/#function-__init__","title":"function __init__","text":"<pre><code>def parla::cython::core::PyInnerWorker::__init__ (\n    self self,\n    python_worker python_worker,\n    PyInnerScheduler PyInnerScheduler,\n    python_scheduler python_scheduler\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/core.pyx</code></p>"},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyTaskBarrier/","title":"Class parla::cython::core::PyTaskBarrier","text":"<p>ClassList &gt; parla &gt; cython &gt; core &gt; PyTaskBarrier</p>"},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyTaskBarrier/#public-attributes","title":"Public Attributes","text":"Type Name c_task_barrier"},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyTaskBarrier/#public-static-attributes","title":"Public Static Attributes","text":"Type Name c_self c_task_list   = =  cy_task_list.c_task_list cy_task_list   = =  task_list inner_task   = =  task_list[i].inner_task task   = =  inner_task.c_task"},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyTaskBarrier/#public-functions","title":"Public Functions","text":"Type Name def __cinit__ (self self)  def __dealloc__ (self self)  def __init__ (self self, task_list task_list=[])"},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyTaskBarrier/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyTaskBarrier/#variable-c_task_barrier","title":"variable c_task_barrier","text":"<pre><code>parla.cython.core.PyTaskBarrier::c_task_barrier;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyTaskBarrier/#public-static-attributes-documentation","title":"Public Static Attributes Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyTaskBarrier/#variable-c_self","title":"variable c_self","text":"<pre><code>parla.cython.core.PyTaskBarrier::c_self;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyTaskBarrier/#variable-c_task_list","title":"variable c_task_list","text":"<pre><code>parla.cython.core.PyTaskBarrier::c_task_list;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyTaskBarrier/#variable-cy_task_list","title":"variable cy_task_list","text":"<pre><code>parla.cython.core.PyTaskBarrier::cy_task_list;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyTaskBarrier/#variable-inner_task","title":"variable inner_task","text":"<pre><code>parla.cython.core.PyTaskBarrier::inner_task;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyTaskBarrier/#variable-task","title":"variable task","text":"<pre><code>parla.cython.core.PyTaskBarrier::task;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyTaskBarrier/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyTaskBarrier/#function-__cinit__","title":"function __cinit__","text":"<pre><code>def parla::cython::core::PyTaskBarrier::__cinit__ (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyTaskBarrier/#function-__dealloc__","title":"function __dealloc__","text":"<pre><code>def parla::cython::core::PyTaskBarrier::__dealloc__ (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyTaskBarrier/#function-__init__","title":"function __init__","text":"<pre><code>def parla::cython::core::PyTaskBarrier::__init__ (\n    self self,\n    task_list task_list=[]\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/core.pyx</code></p>"},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyTaskSpace/","title":"Class parla::cython::core::PyTaskSpace","text":"<p>ClassList &gt; parla &gt; cython &gt; core &gt; PyTaskSpace</p>"},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyTaskSpace/#public-attributes","title":"Public Attributes","text":"Type Name c_task_space"},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyTaskSpace/#public-static-attributes","title":"Public Static Attributes","text":"Type Name c_self inner_task   = =  task_list[i].inner_task task   = =  inner_task.c_task"},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyTaskSpace/#public-functions","title":"Public Functions","text":"Type Name def __cinit__ (self self)  def __dealloc__ (self self)  def __init__ (self self)"},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyTaskSpace/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyTaskSpace/#variable-c_task_space","title":"variable c_task_space","text":"<pre><code>parla.cython.core.PyTaskSpace::c_task_space;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyTaskSpace/#public-static-attributes-documentation","title":"Public Static Attributes Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyTaskSpace/#variable-c_self","title":"variable c_self","text":"<pre><code>parla.cython.core.PyTaskSpace::c_self;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyTaskSpace/#variable-inner_task","title":"variable inner_task","text":"<pre><code>parla.cython.core.PyTaskSpace::inner_task;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyTaskSpace/#variable-task","title":"variable task","text":"<pre><code>parla.cython.core.PyTaskSpace::task;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyTaskSpace/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyTaskSpace/#function-__cinit__","title":"function __cinit__","text":"<pre><code>def parla::cython::core::PyTaskSpace::__cinit__ (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyTaskSpace/#function-__dealloc__","title":"function __dealloc__","text":"<pre><code>def parla::cython::core::PyTaskSpace::__dealloc__ (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1core_1_1PyTaskSpace/#function-__init__","title":"function __init__","text":"<pre><code>def parla::cython::core::PyTaskSpace::__init__ (\n    self self\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/core.pyx</code></p>"},{"location":"runtime/classparla_1_1cython_1_1core_1_1Resources/","title":"Class parla::cython::core::Resources","text":"<p>ClassList &gt; parla &gt; cython &gt; core &gt; Resources</p>"},{"location":"runtime/classparla_1_1cython_1_1core_1_1Resources/#public-attributes","title":"Public Attributes","text":"Type Name resources"},{"location":"runtime/classparla_1_1cython_1_1core_1_1Resources/#public-functions","title":"Public Functions","text":"Type Name def __init__ (self self, vcus vcus)"},{"location":"runtime/classparla_1_1cython_1_1core_1_1Resources/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1core_1_1Resources/#variable-resources","title":"variable resources","text":"<pre><code>parla.cython.core.Resources::resources;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1core_1_1Resources/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1core_1_1Resources/#function-__init__","title":"function __init__","text":"<pre><code>def parla::cython::core::Resources::__init__ (\n    self self,\n    vcus vcus\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/core.pyx</code></p>"},{"location":"runtime/namespaceparla_1_1cython_1_1cyparray/","title":"Namespace parla::cython::cyparray","text":"<p>Namespace List &gt; parla &gt; cython &gt; cyparray</p>"},{"location":"runtime/namespaceparla_1_1cython_1_1cyparray/#classes","title":"Classes","text":"Type Name class CyPArray <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/cyparray.pyx</code></p>"},{"location":"runtime/classparla_1_1cython_1_1cyparray_1_1CyPArray/","title":"Class parla::cython::cyparray::CyPArray","text":"<p>ClassList &gt; parla &gt; cython &gt; cyparray &gt; CyPArray</p>"},{"location":"runtime/classparla_1_1cython_1_1cyparray_1_1CyPArray/#public-attributes","title":"Public Attributes","text":"Type Name cpp_parray"},{"location":"runtime/classparla_1_1cython_1_1cyparray_1_1CyPArray/#public-functions","title":"Public Functions","text":"Type Name def __cinit__ (self self, py_parray py_parray, uint64_t uint64_t, id id, uint64_t uint64_t, parent_id parent_id, py_parent_parray py_parent_parray, CyPArrayState CyPArrayState, parray_state parray_state, int int, num_devices num_devices)  def __dealloc__ (self self)  def __init__ (self self, py_parray py_parray, uint64_t uint64_t, id id, uint64_t uint64_t, parent_id parent_id, py_parent_parray py_parent_parray, CyPArrayState CyPArrayState, parray_state parray_state, int int, num_devices num_devices)  def set_size (self self, new_size new_size)"},{"location":"runtime/classparla_1_1cython_1_1cyparray_1_1CyPArray/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1cyparray_1_1CyPArray/#variable-cpp_parray","title":"variable cpp_parray","text":"<pre><code>parla.cython.cyparray.CyPArray::cpp_parray;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1cyparray_1_1CyPArray/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1cyparray_1_1CyPArray/#function-__cinit__","title":"function __cinit__","text":"<pre><code>def parla::cython::cyparray::CyPArray::__cinit__ (\n    self self,\n    py_parray py_parray,\n    uint64_t uint64_t,\n    id id,\n    uint64_t uint64_t,\n    parent_id parent_id,\n    py_parent_parray py_parent_parray,\n    CyPArrayState CyPArrayState,\n    parray_state parray_state,\n    int int,\n    num_devices num_devices\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1cyparray_1_1CyPArray/#function-__dealloc__","title":"function __dealloc__","text":"<pre><code>def parla::cython::cyparray::CyPArray::__dealloc__ (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1cyparray_1_1CyPArray/#function-__init__","title":"function __init__","text":"<pre><code>def parla::cython::cyparray::CyPArray::__init__ (\n    self self,\n    py_parray py_parray,\n    uint64_t uint64_t,\n    id id,\n    uint64_t uint64_t,\n    parent_id parent_id,\n    py_parent_parray py_parent_parray,\n    CyPArrayState CyPArrayState,\n    parray_state parray_state,\n    int int,\n    num_devices num_devices\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1cyparray_1_1CyPArray/#function-set_size","title":"function set_size","text":"<pre><code>def parla::cython::cyparray::CyPArray::set_size (\n    self self,\n    new_size new_size\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/cyparray.pyx</code></p>"},{"location":"runtime/namespaceparla_1_1cython_1_1cyparray__state/","title":"Namespace parla::cython::cyparray_state","text":"<p>Namespace List &gt; parla &gt; cython &gt; cyparray_state</p>"},{"location":"runtime/namespaceparla_1_1cython_1_1cyparray__state/#classes","title":"Classes","text":"Type Name class CyPArrayState <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/cyparray_state.pyx</code></p>"},{"location":"runtime/classparla_1_1cython_1_1cyparray__state_1_1CyPArrayState/","title":"Class parla::cython::cyparray_state::CyPArrayState","text":"<p>ClassList &gt; parla &gt; cython &gt; cyparray_state &gt; CyPArrayState</p>"},{"location":"runtime/classparla_1_1cython_1_1cyparray__state_1_1CyPArrayState/#public-attributes","title":"Public Attributes","text":"Type Name cpp_parray_state"},{"location":"runtime/classparla_1_1cython_1_1cyparray__state_1_1CyPArrayState/#public-functions","title":"Public Functions","text":"Type Name def __cinit__ (self self)  def __dealloc__ (self self)  def __init__ (self self)  def set_exist_on_device (self self, device_id device_id, exist exist)  def set_valid_on_device (self self, device_id device_id, valid valid)"},{"location":"runtime/classparla_1_1cython_1_1cyparray__state_1_1CyPArrayState/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1cyparray__state_1_1CyPArrayState/#variable-cpp_parray_state","title":"variable cpp_parray_state","text":"<pre><code>parla.cython.cyparray_state.CyPArrayState::cpp_parray_state;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1cyparray__state_1_1CyPArrayState/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1cyparray__state_1_1CyPArrayState/#function-__cinit__","title":"function __cinit__","text":"<pre><code>def parla::cython::cyparray_state::CyPArrayState::__cinit__ (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1cyparray__state_1_1CyPArrayState/#function-__dealloc__","title":"function __dealloc__","text":"<pre><code>def parla::cython::cyparray_state::CyPArrayState::__dealloc__ (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1cyparray__state_1_1CyPArrayState/#function-__init__","title":"function __init__","text":"<pre><code>def parla::cython::cyparray_state::CyPArrayState::__init__ (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1cyparray__state_1_1CyPArrayState/#function-set_exist_on_device","title":"function set_exist_on_device","text":"<pre><code>def parla::cython::cyparray_state::CyPArrayState::set_exist_on_device (\n    self self,\n    device_id device_id,\n    exist exist\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1cyparray__state_1_1CyPArrayState/#function-set_valid_on_device","title":"function set_valid_on_device","text":"<pre><code>def parla::cython::cyparray_state::CyPArrayState::set_valid_on_device (\n    self self,\n    device_id device_id,\n    valid valid\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/cyparray_state.pyx</code></p>"},{"location":"runtime/namespaceparla_1_1cython_1_1device/","title":"Namespace parla::cython::device","text":"<p>Namespace List &gt; parla &gt; cython &gt; device</p>"},{"location":"runtime/namespaceparla_1_1cython_1_1device/#classes","title":"Classes","text":"Type Name class CupyStream class CyCPUDevice class CyCUDADevice class CyDevice class DeviceResource class DeviceResourceRequirement class PyArchitecture class PyCPUArchitecture class PyCPUDevice class PyCUDAArchitecture class PyCUDADevice class PyDevice class Stream"},{"location":"runtime/namespaceparla_1_1cython_1_1device/#public-attributes","title":"Public Attributes","text":"Type Name PlacementSource   = =  Union[PyArchitecture, PyDevice, Tuple[PyArchitecture, DeviceResource], \\ Tuple[PyDevice, DeviceResource]]"},{"location":"runtime/namespaceparla_1_1cython_1_1device/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"runtime/namespaceparla_1_1cython_1_1device/#variable-placementsource","title":"variable PlacementSource","text":"<pre><code>parla::cython::device.PlacementSource;\n</code></pre> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/device.pyx</code></p>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1CupyStream/","title":"Class parla::cython::device::CupyStream","text":"<p>ClassList &gt; parla &gt; cython &gt; device &gt; CupyStream</p> <p>Inherits the following classes: parla::cython::device::Stream</p>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1CupyStream/#public-attributes","title":"Public Attributes","text":"Type Name active_device"},{"location":"runtime/classparla_1_1cython_1_1device_1_1CupyStream/#public-functions","title":"Public Functions","text":"Type Name def __enter__ (self self)  def __exit__ (self self, exc_type exc_type, exc_value exc_value, traceback traceback)  def __getatrr__ (self self, name name)  def __init__ (self self, device device=None, stream stream=None, non_blocking non_blocking=True)  def __repr__ (self self)  def __str__ (self self)  def create_event (self self)  def device (self self)  def stream (self self)  def synchronize (self self)  def wait_event (self self, event event)"},{"location":"runtime/classparla_1_1cython_1_1device_1_1CupyStream/#public-functions-inherited-from-parlacythondevicestream","title":"Public Functions inherited from parla::cython::device::Stream","text":"<p>See parla::cython::device::Stream</p> Type Name def __enter__ (self self)  def __exit__ (self self, exc_type exc_type, exc_val exc_val, exc_tb exc_tb)  def __init__ (self self, device device=None, stream stream=None, non_blocking non_blocking=True)  def __repr__ (self self)  def __str__ (self self)  def create_event (self self)  def device (self self)  def stream (self self)  def synchronize (self self)  def wait_event (self self)"},{"location":"runtime/classparla_1_1cython_1_1device_1_1CupyStream/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1device_1_1CupyStream/#variable-active_device","title":"variable active_device","text":"<pre><code>parla.cython.device.CupyStream::active_device;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1CupyStream/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1device_1_1CupyStream/#function-__enter__","title":"function __enter__","text":"<pre><code>def parla::cython::device::CupyStream::__enter__ (\n    self self\n) \n</code></pre> <p>Implements parla::cython::device::Stream::__enter__</p>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1CupyStream/#function-__exit__","title":"function __exit__","text":"<pre><code>def parla::cython::device::CupyStream::__exit__ (\n    self self,\n    exc_type exc_type,\n    exc_value exc_value,\n    traceback traceback\n) \n</code></pre> <p>Implements parla::cython::device::Stream::__exit__</p>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1CupyStream/#function-__getatrr__","title":"function __getatrr__","text":"<pre><code>def parla::cython::device::CupyStream::__getatrr__ (\n    self self,\n    name name\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1CupyStream/#function-__init__","title":"function __init__","text":"<pre><code>def parla::cython::device::CupyStream::__init__ (\n    self self,\n    device device=None,\n    stream stream=None,\n    non_blocking non_blocking=True\n) \n</code></pre> <p>Implements parla::cython::device::Stream::__init__</p>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1CupyStream/#function-__repr__","title":"function __repr__","text":"<pre><code>def parla::cython::device::CupyStream::__repr__ (\n    self self\n) \n</code></pre> <p>Implements parla::cython::device::Stream::__repr__</p>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1CupyStream/#function-__str__","title":"function __str__","text":"<pre><code>def parla::cython::device::CupyStream::__str__ (\n    self self\n) \n</code></pre> <p>Implements parla::cython::device::Stream::__str__</p>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1CupyStream/#function-create_event","title":"function create_event","text":"<pre><code>def parla::cython::device::CupyStream::create_event (\n    self self\n) \n</code></pre> <p>Implements parla::cython::device::Stream::create_event</p>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1CupyStream/#function-device","title":"function device","text":"<pre><code>def parla::cython::device::CupyStream::device (\n    self self\n) \n</code></pre> <p>Implements parla::cython::device::Stream::device</p>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1CupyStream/#function-stream","title":"function stream","text":"<pre><code>def parla::cython::device::CupyStream::stream (\n    self self\n) \n</code></pre> <p>Implements parla::cython::device::Stream::stream</p>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1CupyStream/#function-synchronize","title":"function synchronize","text":"<pre><code>def parla::cython::device::CupyStream::synchronize (\n    self self\n) \n</code></pre> <p>Implements parla::cython::device::Stream::synchronize</p>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1CupyStream/#function-wait_event","title":"function wait_event","text":"<pre><code>def parla::cython::device::CupyStream::wait_event (\n    self self,\n    event event\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/device.pyx</code></p>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1CyCPUDevice/","title":"Class parla::cython::device::CyCPUDevice","text":"<p>ClassList &gt; parla &gt; cython &gt; device &gt; CyCPUDevice</p> <p>More...</p> <p>Inherits the following classes: parla::cython::device::CyDevice</p>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1CyCPUDevice/#public-functions","title":"Public Functions","text":"Type Name def __cinit__ (self self, int int, dev_id dev_id, long long, mem_sz mem_sz, long long, num_vcus num_vcus, py_device py_device)  def __init__ (self self, int int, dev_id dev_id, long long, mem_sz mem_sz, long long, num_vcus num_vcus, py_device py_device)"},{"location":"runtime/classparla_1_1cython_1_1device_1_1CyCPUDevice/#public-functions-inherited-from-parlacythondevicecydevice","title":"Public Functions inherited from parla::cython::device::CyDevice","text":"<p>See parla::cython::device::CyDevice</p> Type Name def __dealloc__ (self self)"},{"location":"runtime/classparla_1_1cython_1_1device_1_1CyCPUDevice/#detailed-description","title":"Detailed Description","text":""},{"location":"runtime/classparla_1_1cython_1_1device_1_1CyCPUDevice/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1device_1_1CyCPUDevice/#function-__cinit__","title":"function __cinit__","text":"<pre><code>def parla::cython::device::CyCPUDevice::__cinit__ (\n    self self,\n    int int,\n    dev_id dev_id,\n    long long,\n    mem_sz mem_sz,\n    long long,\n    num_vcus num_vcus,\n    py_device py_device\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1CyCPUDevice/#function-__init__","title":"function __init__","text":"<pre><code>def parla::cython::device::CyCPUDevice::__init__ (\n    self self,\n    int int,\n    dev_id dev_id,\n    long long,\n    mem_sz mem_sz,\n    long long,\n    num_vcus num_vcus,\n    py_device py_device\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/device.pyx</code></p>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1CyCUDADevice/","title":"Class parla::cython::device::CyCUDADevice","text":"<p>ClassList &gt; parla &gt; cython &gt; device &gt; CyCUDADevice</p> <p>More...</p> <p>Inherits the following classes: parla::cython::device::CyDevice</p>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1CyCUDADevice/#public-functions","title":"Public Functions","text":"Type Name def __cinit__ (self self, int int, dev_id dev_id, long long, mem_sz mem_sz, long long, num_vcus num_vcus, py_device py_device)  def __init__ (self self, int int, dev_id dev_id, long long, mem_sz mem_sz, long long, num_vcus num_vcus, py_device py_device)"},{"location":"runtime/classparla_1_1cython_1_1device_1_1CyCUDADevice/#public-functions-inherited-from-parlacythondevicecydevice","title":"Public Functions inherited from parla::cython::device::CyDevice","text":"<p>See parla::cython::device::CyDevice</p> Type Name def __dealloc__ (self self)"},{"location":"runtime/classparla_1_1cython_1_1device_1_1CyCUDADevice/#detailed-description","title":"Detailed Description","text":""},{"location":"runtime/classparla_1_1cython_1_1device_1_1CyCUDADevice/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1device_1_1CyCUDADevice/#function-__cinit__","title":"function __cinit__","text":"<pre><code>def parla::cython::device::CyCUDADevice::__cinit__ (\n    self self,\n    int int,\n    dev_id dev_id,\n    long long,\n    mem_sz mem_sz,\n    long long,\n    num_vcus num_vcus,\n    py_device py_device\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1CyCUDADevice/#function-__init__","title":"function __init__","text":"<pre><code>def parla::cython::device::CyCUDADevice::__init__ (\n    self self,\n    int int,\n    dev_id dev_id,\n    long long,\n    mem_sz mem_sz,\n    long long,\n    num_vcus num_vcus,\n    py_device py_device\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/device.pyx</code></p>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1CyDevice/","title":"Class parla::cython::device::CyDevice","text":"<p>ClassList &gt; parla &gt; cython &gt; device &gt; CyDevice</p> <p>More...</p> <p>Inherited by the following classes: parla::cython::device::CyCPUDevice,  parla::cython::device::CyCUDADevice</p>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1CyDevice/#public-functions","title":"Public Functions","text":"Type Name def __dealloc__ (self self)"},{"location":"runtime/classparla_1_1cython_1_1device_1_1CyDevice/#detailed-description","title":"Detailed Description","text":""},{"location":"runtime/classparla_1_1cython_1_1device_1_1CyDevice/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1device_1_1CyDevice/#function-__dealloc__","title":"function __dealloc__","text":"<pre><code>def parla::cython::device::CyDevice::__dealloc__ (\n    self self\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/device.pyx</code></p>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1DeviceResource/","title":"Class parla::cython::device::DeviceResource","text":"<p>ClassList &gt; parla &gt; cython &gt; device &gt; DeviceResource</p>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1DeviceResource/#public-attributes","title":"Public Attributes","text":"Type Name memory_sz num_vcus"},{"location":"runtime/classparla_1_1cython_1_1device_1_1DeviceResource/#public-functions","title":"Public Functions","text":"Type Name def __init__ (self self, memory_sz memory_sz=0, num_vcus num_vcus=0)  def __repr__ (self self)"},{"location":"runtime/classparla_1_1cython_1_1device_1_1DeviceResource/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1device_1_1DeviceResource/#variable-memory_sz","title":"variable memory_sz","text":"<pre><code>parla.cython.device.DeviceResource::memory_sz;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1DeviceResource/#variable-num_vcus","title":"variable num_vcus","text":"<pre><code>parla.cython.device.DeviceResource::num_vcus;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1DeviceResource/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1device_1_1DeviceResource/#function-__init__","title":"function __init__","text":"<pre><code>def parla::cython::device::DeviceResource::__init__ (\n    self self,\n    memory_sz memory_sz=0,\n    num_vcus num_vcus=0\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1DeviceResource/#function-__repr__","title":"function __repr__","text":"<pre><code>def parla::cython::device::DeviceResource::__repr__ (\n    self self\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/device.pyx</code></p>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1DeviceResourceRequirement/","title":"Class parla::cython::device::DeviceResourceRequirement","text":"<p>ClassList &gt; parla &gt; cython &gt; device &gt; DeviceResourceRequirement</p>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1DeviceResourceRequirement/#public-attributes","title":"Public Attributes","text":"Type Name device res_req"},{"location":"runtime/classparla_1_1cython_1_1device_1_1DeviceResourceRequirement/#public-functions","title":"Public Functions","text":"Type Name def __init__ (self self, PyDevice device, DeviceResource res_req)  def __repr__ (self self)"},{"location":"runtime/classparla_1_1cython_1_1device_1_1DeviceResourceRequirement/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1device_1_1DeviceResourceRequirement/#variable-device","title":"variable device","text":"<pre><code>parla.cython.device.DeviceResourceRequirement::device;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1DeviceResourceRequirement/#variable-res_req","title":"variable res_req","text":"<pre><code>parla.cython.device.DeviceResourceRequirement::res_req;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1DeviceResourceRequirement/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1device_1_1DeviceResourceRequirement/#function-__init__","title":"function __init__","text":"<pre><code>def parla::cython::device::DeviceResourceRequirement::__init__ (\n    self self,\n    PyDevice device,\n    DeviceResource res_req\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1DeviceResourceRequirement/#function-__repr__","title":"function __repr__","text":"<pre><code>def parla::cython::device::DeviceResourceRequirement::__repr__ (\n    self self\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/device.pyx</code></p>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyArchitecture/","title":"Class parla::cython::device::PyArchitecture","text":"<p>ClassList &gt; parla &gt; cython &gt; device &gt; PyArchitecture</p> <p>More...</p> <p>Inherits the following classes: metaclass,  ABCMeta</p> <p>Inherited by the following classes: parla::cython::device::PyCPUArchitecture,  parla::cython::device::PyCUDAArchitecture</p>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyArchitecture/#public-attributes","title":"Public Attributes","text":"Type Name id"},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyArchitecture/#public-functions","title":"Public Functions","text":"Type Name def __call__ (self self, index index, * args, ** kwds)  bool __eq__ (self self, object o)  def __getitem__ (self self, param param)  def __hash__ (self self)  def __init__ (self self, name name, id id)  def __len__ (self self)  def __mul__ (self self, int num_archs)  def __repr__ (self self)  def devices (self self)  def id (self self)  def name (self self)"},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyArchitecture/#detailed-description","title":"Detailed Description","text":""},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyArchitecture/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyArchitecture/#variable-id-12","title":"variable id [1/2]","text":"<pre><code>parla.cython.device.PyArchitecture::id;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyArchitecture/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyArchitecture/#function-__call__","title":"function __call__","text":"<pre><code>def parla::cython::device::PyArchitecture::__call__ (\n    self self,\n    index index,\n    * args,\n    ** kwds\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyArchitecture/#function-__eq__","title":"function __eq__","text":"<pre><code>bool parla::cython::device::PyArchitecture::__eq__ (\n    self self,\n    object o\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyArchitecture/#function-__getitem__","title":"function __getitem__","text":"<pre><code>def parla::cython::device::PyArchitecture::__getitem__ (\n    self self,\n    param param\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyArchitecture/#function-__hash__","title":"function __hash__","text":"<pre><code>def parla::cython::device::PyArchitecture::__hash__ (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyArchitecture/#function-__init__","title":"function __init__","text":"<pre><code>def parla::cython::device::PyArchitecture::__init__ (\n    self self,\n    name name,\n    id id\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyArchitecture/#function-__len__","title":"function __len__","text":"<pre><code>def parla::cython::device::PyArchitecture::__len__ (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyArchitecture/#function-__mul__","title":"function __mul__","text":"<pre><code>def parla::cython::device::PyArchitecture::__mul__ (\n    self self,\n    int num_archs\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyArchitecture/#function-__repr__","title":"function __repr__","text":"<pre><code>def parla::cython::device::PyArchitecture::__repr__ (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyArchitecture/#function-devices","title":"function devices","text":"<pre><code>def parla::cython::device::PyArchitecture::devices (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyArchitecture/#function-id-22","title":"function id [2/2]","text":"<pre><code>def parla::cython::device::PyArchitecture::id (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyArchitecture/#function-name","title":"function name","text":"<pre><code>def parla::cython::device::PyArchitecture::name (\n    self self\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/device.pyx</code></p>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyCPUArchitecture/","title":"Class parla::cython::device::PyCPUArchitecture","text":"<p>ClassList &gt; parla &gt; cython &gt; device &gt; PyCPUArchitecture</p> <p>Inherits the following classes: parla::cython::device::PyArchitecture</p>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyCPUArchitecture/#public-attributes-inherited-from-parlacythondevicepyarchitecture","title":"Public Attributes inherited from parla::cython::device::PyArchitecture","text":"<p>See parla::cython::device::PyArchitecture</p> Type Name id"},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyCPUArchitecture/#public-functions","title":"Public Functions","text":"Type Name def __init__ (self self)  def add_device (self self, device device)"},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyCPUArchitecture/#public-functions-inherited-from-parlacythondevicepyarchitecture","title":"Public Functions inherited from parla::cython::device::PyArchitecture","text":"<p>See parla::cython::device::PyArchitecture</p> Type Name def __call__ (self self, index index, * args, ** kwds)  bool __eq__ (self self, object o)  def __getitem__ (self self, param param)  def __hash__ (self self)  def __init__ (self self, name name, id id)  def __len__ (self self)  def __mul__ (self self, int num_archs)  def __repr__ (self self)  def devices (self self)  def id (self self)  def name (self self)"},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyCPUArchitecture/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyCPUArchitecture/#function-__init__","title":"function __init__","text":"<pre><code>def parla::cython::device::PyCPUArchitecture::__init__ (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyCPUArchitecture/#function-add_device","title":"function add_device","text":"<pre><code>def parla::cython::device::PyCPUArchitecture::add_device (\n    self self,\n    device device\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/device.pyx</code></p>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyCPUDevice/","title":"Class parla::cython::device::PyCPUDevice","text":"<p>ClassList &gt; parla &gt; cython &gt; device &gt; PyCPUDevice</p> <p>More...</p> <p>Inherits the following classes: parla::cython::device::PyDevice</p>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyCPUDevice/#public-functions","title":"Public Functions","text":"Type Name def __init__ (self self, int dev_id, long mem_sz, long num_vcus)"},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyCPUDevice/#public-functions-inherited-from-parlacythondevicepydevice","title":"Public Functions inherited from parla::cython::device::PyDevice","text":"<p>See parla::cython::device::PyDevice</p> Type Name def __dealloc__ (self self)  def __enter__ (self self)  def __eq__ (self self, other other)  def __exit__ (self self, exc_type exc_type, exc_val exc_val, exc_tb exc_tb)  def __getitem__ (self self, param param)  def __hash__ (self self)  def __init__ (self self, dev_type dev_type, dev_type_name dev_type_name, int dev_id)  def __repr__ (self self)  def __str__ (self self)  def architecture (self self)  def device (self self)  def device_id (self self)  def get_cy_device (self self)  def get_global_id (self self)  def get_name (self self)  def get_type (self self)  def global_id (self self)  def global_id (self self, new_id new_id)  def id (self self)  def id (self self, new_id new_id)  def id (self self)  def query_mapped_resource (self self, res_type res_type)  def query_reserved_resource (self self, res_type res_type)  def query_resource (self self, res_type res_type)"},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyCPUDevice/#detailed-description","title":"Detailed Description","text":""},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyCPUDevice/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyCPUDevice/#function-__init__","title":"function __init__","text":"<pre><code>def parla::cython::device::PyCPUDevice::__init__ (\n    self self,\n    int dev_id,\n    long mem_sz,\n    long num_vcus\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/device.pyx</code></p>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyCUDAArchitecture/","title":"Class parla::cython::device::PyCUDAArchitecture","text":"<p>ClassList &gt; parla &gt; cython &gt; device &gt; PyCUDAArchitecture</p> <p>Inherits the following classes: parla::cython::device::PyArchitecture</p>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyCUDAArchitecture/#public-attributes-inherited-from-parlacythondevicepyarchitecture","title":"Public Attributes inherited from parla::cython::device::PyArchitecture","text":"<p>See parla::cython::device::PyArchitecture</p> Type Name id"},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyCUDAArchitecture/#public-functions","title":"Public Functions","text":"Type Name def __init__ (self self)  def add_device (self self, device device)"},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyCUDAArchitecture/#public-functions-inherited-from-parlacythondevicepyarchitecture","title":"Public Functions inherited from parla::cython::device::PyArchitecture","text":"<p>See parla::cython::device::PyArchitecture</p> Type Name def __call__ (self self, index index, * args, ** kwds)  bool __eq__ (self self, object o)  def __getitem__ (self self, param param)  def __hash__ (self self)  def __init__ (self self, name name, id id)  def __len__ (self self)  def __mul__ (self self, int num_archs)  def __repr__ (self self)  def devices (self self)  def id (self self)  def name (self self)"},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyCUDAArchitecture/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyCUDAArchitecture/#function-__init__","title":"function __init__","text":"<pre><code>def parla::cython::device::PyCUDAArchitecture::__init__ (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyCUDAArchitecture/#function-add_device","title":"function add_device","text":"<pre><code>def parla::cython::device::PyCUDAArchitecture::add_device (\n    self self,\n    device device\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/device.pyx</code></p>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyCUDADevice/","title":"Class parla::cython::device::PyCUDADevice","text":"<p>ClassList &gt; parla &gt; cython &gt; device &gt; PyCUDADevice</p> <p>More...</p> <p>Inherits the following classes: parla::cython::device::PyDevice</p>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyCUDADevice/#public-functions","title":"Public Functions","text":"Type Name def __init__ (self self, int dev_id, long mem_sz, long num_vcus)  def device (self self)"},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyCUDADevice/#public-functions-inherited-from-parlacythondevicepydevice","title":"Public Functions inherited from parla::cython::device::PyDevice","text":"<p>See parla::cython::device::PyDevice</p> Type Name def __dealloc__ (self self)  def __enter__ (self self)  def __eq__ (self self, other other)  def __exit__ (self self, exc_type exc_type, exc_val exc_val, exc_tb exc_tb)  def __getitem__ (self self, param param)  def __hash__ (self self)  def __init__ (self self, dev_type dev_type, dev_type_name dev_type_name, int dev_id)  def __repr__ (self self)  def __str__ (self self)  def architecture (self self)  def device (self self)  def device_id (self self)  def get_cy_device (self self)  def get_global_id (self self)  def get_name (self self)  def get_type (self self)  def global_id (self self)  def global_id (self self, new_id new_id)  def id (self self)  def id (self self, new_id new_id)  def id (self self)  def query_mapped_resource (self self, res_type res_type)  def query_reserved_resource (self self, res_type res_type)  def query_resource (self self, res_type res_type)"},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyCUDADevice/#detailed-description","title":"Detailed Description","text":""},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyCUDADevice/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyCUDADevice/#function-__init__","title":"function __init__","text":"<pre><code>def parla::cython::device::PyCUDADevice::__init__ (\n    self self,\n    int dev_id,\n    long mem_sz,\n    long num_vcus\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyCUDADevice/#function-device","title":"function device","text":"<pre><code>def parla::cython::device::PyCUDADevice::device (\n    self self\n) \n</code></pre> <p>Implements parla::cython::device::PyDevice::device</p> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/device.pyx</code></p>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyDevice/","title":"Class parla::cython::device::PyDevice","text":"<p>ClassList &gt; parla &gt; cython &gt; device &gt; PyDevice</p> <p>More...</p> <p>Inherited by the following classes: parla::cython::device::PyCPUDevice,  parla::cython::device::PyCUDADevice</p>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyDevice/#public-functions","title":"Public Functions","text":"Type Name def __dealloc__ (self self)  def __enter__ (self self)  def __eq__ (self self, other other)  def __exit__ (self self, exc_type exc_type, exc_val exc_val, exc_tb exc_tb)  def __getitem__ (self self, param param)  def __hash__ (self self)  def __init__ (self self, dev_type dev_type, dev_type_name dev_type_name, int dev_id)  def __repr__ (self self)  def __str__ (self self)  def architecture (self self)  def device (self self)  def device_id (self self)  def get_cy_device (self self)  def get_global_id (self self)  def get_name (self self)  def get_type (self self)  def global_id (self self)  def global_id (self self, new_id new_id)  def id (self self)  def id (self self, new_id new_id)  def id (self self)  def query_mapped_resource (self self, res_type res_type)  def query_reserved_resource (self self, res_type res_type)  def query_resource (self self, res_type res_type)"},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyDevice/#detailed-description","title":"Detailed Description","text":""},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyDevice/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyDevice/#function-__dealloc__","title":"function __dealloc__","text":"<pre><code>def parla::cython::device::PyDevice::__dealloc__ (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyDevice/#function-__enter__","title":"function __enter__","text":"<pre><code>def parla::cython::device::PyDevice::__enter__ (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyDevice/#function-__eq__","title":"function __eq__","text":"<pre><code>def parla::cython::device::PyDevice::__eq__ (\n    self self,\n    other other\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyDevice/#function-__exit__","title":"function __exit__","text":"<pre><code>def parla::cython::device::PyDevice::__exit__ (\n    self self,\n    exc_type exc_type,\n    exc_val exc_val,\n    exc_tb exc_tb\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyDevice/#function-__getitem__","title":"function __getitem__","text":"<pre><code>def parla::cython::device::PyDevice::__getitem__ (\n    self self,\n    param param\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyDevice/#function-__hash__","title":"function __hash__","text":"<pre><code>def parla::cython::device::PyDevice::__hash__ (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyDevice/#function-__init__","title":"function __init__","text":"<pre><code>def parla::cython::device::PyDevice::__init__ (\n    self self,\n    dev_type dev_type,\n    dev_type_name dev_type_name,\n    int dev_id\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyDevice/#function-__repr__","title":"function __repr__","text":"<pre><code>def parla::cython::device::PyDevice::__repr__ (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyDevice/#function-__str__","title":"function __str__","text":"<pre><code>def parla::cython::device::PyDevice::__str__ (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyDevice/#function-architecture","title":"function architecture","text":"<pre><code>def parla::cython::device::PyDevice::architecture (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyDevice/#function-device","title":"function device","text":"<pre><code>def parla::cython::device::PyDevice::device (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyDevice/#function-device_id","title":"function device_id","text":"<pre><code>def parla::cython::device::PyDevice::device_id (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyDevice/#function-get_cy_device","title":"function get_cy_device","text":"<pre><code>def parla::cython::device::PyDevice::get_cy_device (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyDevice/#function-get_global_id","title":"function get_global_id","text":"<pre><code>def parla::cython::device::PyDevice::get_global_id (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyDevice/#function-get_name","title":"function get_name","text":"<pre><code>def parla::cython::device::PyDevice::get_name (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyDevice/#function-get_type","title":"function get_type","text":"<pre><code>def parla::cython::device::PyDevice::get_type (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyDevice/#function-global_id-12","title":"function global_id [1/2]","text":"<pre><code>def parla::cython::device::PyDevice::global_id (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyDevice/#function-global_id-22","title":"function global_id [2/2]","text":"<pre><code>def parla::cython::device::PyDevice::global_id (\n    self self,\n    new_id new_id\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyDevice/#function-id-13","title":"function id [1/3]","text":"<pre><code>def parla::cython::device::PyDevice::id (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyDevice/#function-id-23","title":"function id [2/3]","text":"<pre><code>def parla::cython::device::PyDevice::id (\n    self self,\n    new_id new_id\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyDevice/#function-id-13_1","title":"function id [1/3]","text":"<pre><code>def parla::cython::device::PyDevice::id (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyDevice/#function-query_mapped_resource","title":"function query_mapped_resource","text":"<pre><code>def parla::cython::device::PyDevice::query_mapped_resource (\n    self self,\n    res_type res_type\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyDevice/#function-query_reserved_resource","title":"function query_reserved_resource","text":"<pre><code>def parla::cython::device::PyDevice::query_reserved_resource (\n    self self,\n    res_type res_type\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1PyDevice/#function-query_resource","title":"function query_resource","text":"<pre><code>def parla::cython::device::PyDevice::query_resource (\n    self self,\n    res_type res_type\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/device.pyx</code></p>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1Stream/","title":"Class parla::cython::device::Stream","text":"<p>ClassList &gt; parla &gt; cython &gt; device &gt; Stream</p> <p>Inherited by the following classes: parla::cython::device::CupyStream</p>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1Stream/#public-functions","title":"Public Functions","text":"Type Name def __enter__ (self self)  def __exit__ (self self, exc_type exc_type, exc_val exc_val, exc_tb exc_tb)  def __init__ (self self, device device=None, stream stream=None, non_blocking non_blocking=True)  def __repr__ (self self)  def __str__ (self self)  def create_event (self self)  def device (self self)  def stream (self self)  def synchronize (self self)  def wait_event (self self)"},{"location":"runtime/classparla_1_1cython_1_1device_1_1Stream/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1device_1_1Stream/#function-__enter__","title":"function __enter__","text":"<pre><code>def parla::cython::device::Stream::__enter__ (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1Stream/#function-__exit__","title":"function __exit__","text":"<pre><code>def parla::cython::device::Stream::__exit__ (\n    self self,\n    exc_type exc_type,\n    exc_val exc_val,\n    exc_tb exc_tb\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1Stream/#function-__init__","title":"function __init__","text":"<pre><code>def parla::cython::device::Stream::__init__ (\n    self self,\n    device device=None,\n    stream stream=None,\n    non_blocking non_blocking=True\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1Stream/#function-__repr__","title":"function __repr__","text":"<pre><code>def parla::cython::device::Stream::__repr__ (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1Stream/#function-__str__","title":"function __str__","text":"<pre><code>def parla::cython::device::Stream::__str__ (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1Stream/#function-create_event","title":"function create_event","text":"<pre><code>def parla::cython::device::Stream::create_event (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1Stream/#function-device","title":"function device","text":"<pre><code>def parla::cython::device::Stream::device (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1Stream/#function-stream","title":"function stream","text":"<pre><code>def parla::cython::device::Stream::stream (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1Stream/#function-synchronize","title":"function synchronize","text":"<pre><code>def parla::cython::device::Stream::synchronize (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device_1_1Stream/#function-wait_event","title":"function wait_event","text":"<pre><code>def parla::cython::device::Stream::wait_event (\n    self self\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/device.pyx</code></p>"},{"location":"runtime/namespaceparla_1_1cython_1_1device__manager/","title":"Namespace parla::cython::device_manager","text":"<p>Namespace List &gt; parla &gt; cython &gt; device_manager</p>"},{"location":"runtime/namespaceparla_1_1cython_1_1device__manager/#classes","title":"Classes","text":"Type Name class CyDeviceManager class PrintableFrozenSet class PyDeviceManager class StreamPool"},{"location":"runtime/namespaceparla_1_1cython_1_1device__manager/#public-attributes","title":"Public Attributes","text":"Type Name CUPY_ENABLED   = =  device.CUPY_ENABLED CupyStream   = =  device.CupyStream DeviceResource   = =  device.DeviceResource DeviceResourceRequirement   = =  device.DeviceResourceRequirement PyArchitecture   = =  device.PyArchitecture PyCPUArchitecture   = =  device.PyCPUArchitecture PyCPUDevice   = =  device.PyCPUDevice PyCUDAArchitecture   = =  device.PyCUDAArchitecture PyCUDADevice   = =  device.PyCUDADevice PyDevice   = =  device.PyDevice Stream   = =  device.Stream cpu   = =  PyCPUArchitecture() gpu   = =  PyCUDAArchitecture()"},{"location":"runtime/namespaceparla_1_1cython_1_1device__manager/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"runtime/namespaceparla_1_1cython_1_1device__manager/#variable-cupy_enabled","title":"variable CUPY_ENABLED","text":"<pre><code>parla::cython::device_manager.CUPY_ENABLED;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1device__manager/#variable-cupystream","title":"variable CupyStream","text":"<pre><code>parla::cython::device_manager.CupyStream;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1device__manager/#variable-deviceresource","title":"variable DeviceResource","text":"<pre><code>parla::cython::device_manager.DeviceResource;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1device__manager/#variable-deviceresourcerequirement","title":"variable DeviceResourceRequirement","text":"<pre><code>parla::cython::device_manager.DeviceResourceRequirement;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1device__manager/#variable-pyarchitecture","title":"variable PyArchitecture","text":"<pre><code>parla::cython::device_manager.PyArchitecture;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1device__manager/#variable-pycpuarchitecture","title":"variable PyCPUArchitecture","text":"<pre><code>parla::cython::device_manager.PyCPUArchitecture;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1device__manager/#variable-pycpudevice","title":"variable PyCPUDevice","text":"<pre><code>parla::cython::device_manager.PyCPUDevice;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1device__manager/#variable-pycudaarchitecture","title":"variable PyCUDAArchitecture","text":"<pre><code>parla::cython::device_manager.PyCUDAArchitecture;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1device__manager/#variable-pycudadevice","title":"variable PyCUDADevice","text":"<pre><code>parla::cython::device_manager.PyCUDADevice;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1device__manager/#variable-pydevice","title":"variable PyDevice","text":"<pre><code>parla::cython::device_manager.PyDevice;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1device__manager/#variable-stream","title":"variable Stream","text":"<pre><code>parla::cython::device_manager.Stream;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1device__manager/#variable-cpu","title":"variable cpu","text":"<pre><code>parla::cython::device_manager.cpu;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1device__manager/#variable-gpu","title":"variable gpu","text":"<pre><code>parla::cython::device_manager.gpu;\n</code></pre> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/device_manager.pyx</code></p>"},{"location":"runtime/classparla_1_1cython_1_1device__manager_1_1CyDeviceManager/","title":"Class parla::cython::device_manager::CyDeviceManager","text":"<p>ClassList &gt; parla &gt; cython &gt; device_manager &gt; CyDeviceManager</p> <p>More...</p>"},{"location":"runtime/classparla_1_1cython_1_1device__manager_1_1CyDeviceManager/#public-attributes","title":"Public Attributes","text":"Type Name cpp_device_manager_"},{"location":"runtime/classparla_1_1cython_1_1device__manager_1_1CyDeviceManager/#public-static-attributes","title":"Public Static Attributes","text":"Type Name cpp_device"},{"location":"runtime/classparla_1_1cython_1_1device__manager_1_1CyDeviceManager/#public-functions","title":"Public Functions","text":"Type Name def __cinit__ (self self)  def __dealloc__ (self self)  def __init__ (self self)"},{"location":"runtime/classparla_1_1cython_1_1device__manager_1_1CyDeviceManager/#detailed-description","title":"Detailed Description","text":""},{"location":"runtime/classparla_1_1cython_1_1device__manager_1_1CyDeviceManager/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1device__manager_1_1CyDeviceManager/#variable-cpp_device_manager_","title":"variable cpp_device_manager_","text":"<pre><code>parla.cython.device_manager.CyDeviceManager::cpp_device_manager_;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device__manager_1_1CyDeviceManager/#public-static-attributes-documentation","title":"Public Static Attributes Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1device__manager_1_1CyDeviceManager/#variable-cpp_device","title":"variable cpp_device","text":"<pre><code>parla.cython.device_manager.CyDeviceManager::cpp_device;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device__manager_1_1CyDeviceManager/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1device__manager_1_1CyDeviceManager/#function-__cinit__","title":"function __cinit__","text":"<pre><code>def parla::cython::device_manager::CyDeviceManager::__cinit__ (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device__manager_1_1CyDeviceManager/#function-__dealloc__","title":"function __dealloc__","text":"<pre><code>def parla::cython::device_manager::CyDeviceManager::__dealloc__ (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device__manager_1_1CyDeviceManager/#function-__init__","title":"function __init__","text":"<pre><code>def parla::cython::device_manager::CyDeviceManager::__init__ (\n    self self\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/device_manager.pyx</code></p>"},{"location":"runtime/classparla_1_1cython_1_1device__manager_1_1PrintableFrozenSet/","title":"Class parla::cython::device_manager::PrintableFrozenSet","text":"<p>ClassList &gt; parla &gt; cython &gt; device_manager &gt; PrintableFrozenSet</p> <p>More...</p> <p>Inherits the following classes: frozenset</p>"},{"location":"runtime/classparla_1_1cython_1_1device__manager_1_1PrintableFrozenSet/#public-functions","title":"Public Functions","text":"Type Name def __repr__ (self self)  def get_name (self self)"},{"location":"runtime/classparla_1_1cython_1_1device__manager_1_1PrintableFrozenSet/#detailed-description","title":"Detailed Description","text":""},{"location":"runtime/classparla_1_1cython_1_1device__manager_1_1PrintableFrozenSet/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1device__manager_1_1PrintableFrozenSet/#function-__repr__","title":"function __repr__","text":"<pre><code>def parla::cython::device_manager::PrintableFrozenSet::__repr__ (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device__manager_1_1PrintableFrozenSet/#function-get_name","title":"function get_name","text":"<pre><code>def parla::cython::device_manager::PrintableFrozenSet::get_name (\n    self self\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/device_manager.pyx</code></p>"},{"location":"runtime/classparla_1_1cython_1_1device__manager_1_1PyDeviceManager/","title":"Class parla::cython::device_manager::PyDeviceManager","text":"<p>ClassList &gt; parla &gt; cython &gt; device_manager &gt; PyDeviceManager</p> <p>More...</p>"},{"location":"runtime/classparla_1_1cython_1_1device__manager_1_1PyDeviceManager/#public-attributes","title":"Public Attributes","text":"Type Name cy_device_manager num_real_gpus py_registered_archs registered_devices stream_pool"},{"location":"runtime/classparla_1_1cython_1_1device__manager_1_1PyDeviceManager/#public-functions","title":"Public Functions","text":"Type Name def __dealloc__ (self self)  def __init__ (self self, dev_config dev_config=None)  def construct_resource_requirements (self self, placement_component placement_component, vcus vcus, memory memory)  def construct_single_architecture_requirements (self self, arch arch, res_req res_req)  def construct_single_device_requirements (self self, dev dev, res_req res_req)  def get_all_architectures (self self)  def get_all_devices (self self)  def get_cy_device_manager (self self)  def get_device_reqs_from_placement (self self, placement placement, vcus vcus, memory memory)  def get_num_cpus (self self)  def get_num_gpus (self self)  def globalid_to_parrayid (self self, global_dev_id global_dev_id)  def is_multidevice_placement (self self, placement_tuple placement_tuple)  def parrayid_to_globalid (self self, parray_dev_id parray_dev_id)  def parse_config_and_register_devices (self self, yaml_config yaml_config)  def print_registered_devices (self self)  def register_cpu_devices (self self, bool register_to_cuda=False)  def register_cupy_gpu_devices (self self)  def register_devices_to_cpp (self self)  def unpack_placements (self self, placement_components placement_components, vcus vcus, memory memory)"},{"location":"runtime/classparla_1_1cython_1_1device__manager_1_1PyDeviceManager/#detailed-description","title":"Detailed Description","text":""},{"location":"runtime/classparla_1_1cython_1_1device__manager_1_1PyDeviceManager/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1device__manager_1_1PyDeviceManager/#variable-cy_device_manager","title":"variable cy_device_manager","text":"<pre><code>parla.cython.device_manager.PyDeviceManager::cy_device_manager;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device__manager_1_1PyDeviceManager/#variable-num_real_gpus","title":"variable num_real_gpus","text":"<pre><code>parla.cython.device_manager.PyDeviceManager::num_real_gpus;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device__manager_1_1PyDeviceManager/#variable-py_registered_archs","title":"variable py_registered_archs","text":"<pre><code>parla.cython.device_manager.PyDeviceManager::py_registered_archs;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device__manager_1_1PyDeviceManager/#variable-registered_devices","title":"variable registered_devices","text":"<pre><code>parla.cython.device_manager.PyDeviceManager::registered_devices;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device__manager_1_1PyDeviceManager/#variable-stream_pool","title":"variable stream_pool","text":"<pre><code>parla.cython.device_manager.PyDeviceManager::stream_pool;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device__manager_1_1PyDeviceManager/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1device__manager_1_1PyDeviceManager/#function-__dealloc__","title":"function __dealloc__","text":"<pre><code>def parla::cython::device_manager::PyDeviceManager::__dealloc__ (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device__manager_1_1PyDeviceManager/#function-__init__","title":"function __init__","text":"<pre><code>def parla::cython::device_manager::PyDeviceManager::__init__ (\n    self self,\n    dev_config dev_config=None\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device__manager_1_1PyDeviceManager/#function-construct_resource_requirements","title":"function construct_resource_requirements","text":"<pre><code>def parla::cython::device_manager::PyDeviceManager::construct_resource_requirements (\n    self self,\n    placement_component placement_component,\n    vcus vcus,\n    memory memory\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device__manager_1_1PyDeviceManager/#function-construct_single_architecture_requirements","title":"function construct_single_architecture_requirements","text":"<pre><code>def parla::cython::device_manager::PyDeviceManager::construct_single_architecture_requirements (\n    self self,\n    arch arch,\n    res_req res_req\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device__manager_1_1PyDeviceManager/#function-construct_single_device_requirements","title":"function construct_single_device_requirements","text":"<pre><code>def parla::cython::device_manager::PyDeviceManager::construct_single_device_requirements (\n    self self,\n    dev dev,\n    res_req res_req\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device__manager_1_1PyDeviceManager/#function-get_all_architectures","title":"function get_all_architectures","text":"<pre><code>def parla::cython::device_manager::PyDeviceManager::get_all_architectures (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device__manager_1_1PyDeviceManager/#function-get_all_devices","title":"function get_all_devices","text":"<pre><code>def parla::cython::device_manager::PyDeviceManager::get_all_devices (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device__manager_1_1PyDeviceManager/#function-get_cy_device_manager","title":"function get_cy_device_manager","text":"<pre><code>def parla::cython::device_manager::PyDeviceManager::get_cy_device_manager (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device__manager_1_1PyDeviceManager/#function-get_device_reqs_from_placement","title":"function get_device_reqs_from_placement","text":"<pre><code>def parla::cython::device_manager::PyDeviceManager::get_device_reqs_from_placement (\n    self self,\n    placement placement,\n    vcus vcus,\n    memory memory\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device__manager_1_1PyDeviceManager/#function-get_num_cpus","title":"function get_num_cpus","text":"<pre><code>def parla::cython::device_manager::PyDeviceManager::get_num_cpus (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device__manager_1_1PyDeviceManager/#function-get_num_gpus","title":"function get_num_gpus","text":"<pre><code>def parla::cython::device_manager::PyDeviceManager::get_num_gpus (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device__manager_1_1PyDeviceManager/#function-globalid_to_parrayid","title":"function globalid_to_parrayid","text":"<pre><code>def parla::cython::device_manager::PyDeviceManager::globalid_to_parrayid (\n    self self,\n    global_dev_id global_dev_id\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device__manager_1_1PyDeviceManager/#function-is_multidevice_placement","title":"function is_multidevice_placement","text":"<pre><code>def parla::cython::device_manager::PyDeviceManager::is_multidevice_placement (\n    self self,\n    placement_tuple placement_tuple\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device__manager_1_1PyDeviceManager/#function-parrayid_to_globalid","title":"function parrayid_to_globalid","text":"<pre><code>def parla::cython::device_manager::PyDeviceManager::parrayid_to_globalid (\n    self self,\n    parray_dev_id parray_dev_id\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device__manager_1_1PyDeviceManager/#function-parse_config_and_register_devices","title":"function parse_config_and_register_devices","text":"<pre><code>def parla::cython::device_manager::PyDeviceManager::parse_config_and_register_devices (\n    self self,\n    yaml_config yaml_config\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device__manager_1_1PyDeviceManager/#function-print_registered_devices","title":"function print_registered_devices","text":"<pre><code>def parla::cython::device_manager::PyDeviceManager::print_registered_devices (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device__manager_1_1PyDeviceManager/#function-register_cpu_devices","title":"function register_cpu_devices","text":"<pre><code>def parla::cython::device_manager::PyDeviceManager::register_cpu_devices (\n    self self,\n    bool register_to_cuda=False\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device__manager_1_1PyDeviceManager/#function-register_cupy_gpu_devices","title":"function register_cupy_gpu_devices","text":"<pre><code>def parla::cython::device_manager::PyDeviceManager::register_cupy_gpu_devices (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device__manager_1_1PyDeviceManager/#function-register_devices_to_cpp","title":"function register_devices_to_cpp","text":"<pre><code>def parla::cython::device_manager::PyDeviceManager::register_devices_to_cpp (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device__manager_1_1PyDeviceManager/#function-unpack_placements","title":"function unpack_placements","text":"<pre><code>def parla::cython::device_manager::PyDeviceManager::unpack_placements (\n    self self,\n    placement_components placement_components,\n    vcus vcus,\n    memory memory\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/device_manager.pyx</code></p>"},{"location":"runtime/classparla_1_1cython_1_1device__manager_1_1StreamPool/","title":"Class parla::cython::device_manager::StreamPool","text":"<p>ClassList &gt; parla &gt; cython &gt; device_manager &gt; StreamPool</p>"},{"location":"runtime/classparla_1_1cython_1_1device__manager_1_1StreamPool/#public-attributes","title":"Public Attributes","text":"Type Name StreamClass"},{"location":"runtime/classparla_1_1cython_1_1device__manager_1_1StreamPool/#public-functions","title":"Public Functions","text":"Type Name def __init__ (self self, device_list device_list, per_device per_device=8)  def __repr__ (self self)  def __summarize__ (self self)  def get_stream (self self, device device)  def return_stream (self self, stream stream)"},{"location":"runtime/classparla_1_1cython_1_1device__manager_1_1StreamPool/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1device__manager_1_1StreamPool/#variable-streamclass","title":"variable StreamClass","text":"<pre><code>parla.cython.device_manager.StreamPool::StreamClass;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device__manager_1_1StreamPool/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1device__manager_1_1StreamPool/#function-__init__","title":"function __init__","text":"<pre><code>def parla::cython::device_manager::StreamPool::__init__ (\n    self self,\n    device_list device_list,\n    per_device per_device=8\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device__manager_1_1StreamPool/#function-__repr__","title":"function __repr__","text":"<pre><code>def parla::cython::device_manager::StreamPool::__repr__ (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device__manager_1_1StreamPool/#function-__summarize__","title":"function __summarize__","text":"<pre><code>def parla::cython::device_manager::StreamPool::__summarize__ (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device__manager_1_1StreamPool/#function-get_stream","title":"function get_stream","text":"<pre><code>def parla::cython::device_manager::StreamPool::get_stream (\n    self self,\n    device device\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1device__manager_1_1StreamPool/#function-return_stream","title":"function return_stream","text":"<pre><code>def parla::cython::device_manager::StreamPool::return_stream (\n    self self,\n    stream stream\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/device_manager.pyx</code></p>"},{"location":"runtime/namespaceparla_1_1cython_1_1scheduler/","title":"Namespace parla::cython::scheduler","text":"<p>Namespace List &gt; parla &gt; cython &gt; scheduler</p>"},{"location":"runtime/namespaceparla_1_1cython_1_1scheduler/#classes","title":"Classes","text":"Type Name class ControllableThread class Scheduler class SchedulerContext class SchedulerException class TaskBodyException class WorkerThread class WorkerThreadException class _SchedulerLocals"},{"location":"runtime/namespaceparla_1_1cython_1_1scheduler/#public-attributes","title":"Public Attributes","text":"Type Name ComputeTask   = =  tasks.ComputeTask DataMovementTask   = =  tasks.DataMovementTask PyInnerScheduler   = =  core.PyInnerScheduler PyInnerTask   = =  core.PyInnerTask PyInnerWorker   = =  core.PyInnerWorker Task   = =  tasks.Task TaskSpace   = =  tasks.TaskSpace create_env   = =  tasks.create_env nvtx   = =  NVTXTracer"},{"location":"runtime/namespaceparla_1_1cython_1_1scheduler/#public-functions","title":"Public Functions","text":"Type Name def get_device_manager ()  def get_scheduler_context ()  def get_stream_pool ()"},{"location":"runtime/namespaceparla_1_1cython_1_1scheduler/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"runtime/namespaceparla_1_1cython_1_1scheduler/#variable-computetask","title":"variable ComputeTask","text":"<pre><code>parla::cython::scheduler.ComputeTask;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1scheduler/#variable-datamovementtask","title":"variable DataMovementTask","text":"<pre><code>parla::cython::scheduler.DataMovementTask;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1scheduler/#variable-pyinnerscheduler","title":"variable PyInnerScheduler","text":"<pre><code>parla::cython::scheduler.PyInnerScheduler;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1scheduler/#variable-pyinnertask","title":"variable PyInnerTask","text":"<pre><code>parla::cython::scheduler.PyInnerTask;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1scheduler/#variable-pyinnerworker","title":"variable PyInnerWorker","text":"<pre><code>parla::cython::scheduler.PyInnerWorker;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1scheduler/#variable-task","title":"variable Task","text":"<pre><code>parla::cython::scheduler.Task;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1scheduler/#variable-taskspace","title":"variable TaskSpace","text":"<pre><code>parla::cython::scheduler.TaskSpace;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1scheduler/#variable-create_env","title":"variable create_env","text":"<pre><code>parla::cython::scheduler.create_env;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1scheduler/#variable-nvtx","title":"variable nvtx","text":"<pre><code>parla::cython::scheduler.nvtx;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1scheduler/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/namespaceparla_1_1cython_1_1scheduler/#function-get_device_manager","title":"function get_device_manager","text":"<pre><code>def parla::cython::scheduler::get_device_manager () \n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1scheduler/#function-get_scheduler_context","title":"function get_scheduler_context","text":"<pre><code>def parla::cython::scheduler::get_scheduler_context () \n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1scheduler/#function-get_stream_pool","title":"function get_stream_pool","text":"<pre><code>def parla::cython::scheduler::get_stream_pool () \n</code></pre> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/scheduler.pyx</code></p>"},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1ControllableThread/","title":"Class parla::cython::scheduler::ControllableThread","text":"<p>ClassList &gt; parla &gt; cython &gt; scheduler &gt; ControllableThread</p> <p>Inherits the following classes: threading.Thread</p> <p>Inherited by the following classes: parla::cython::scheduler::Scheduler,  parla::cython::scheduler::WorkerThread</p>"},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1ControllableThread/#public-functions","title":"Public Functions","text":"Type Name def __init__ (self self)  def run (self self)  def stop (self self)"},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1ControllableThread/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1ControllableThread/#function-__init__","title":"function __init__","text":"<pre><code>def parla::cython::scheduler::ControllableThread::__init__ (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1ControllableThread/#function-run","title":"function run","text":"<pre><code>def parla::cython::scheduler::ControllableThread::run (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1ControllableThread/#function-stop","title":"function stop","text":"<pre><code>def parla::cython::scheduler::ControllableThread::stop (\n    self self\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/scheduler.pyx</code></p>"},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1Scheduler/","title":"Class parla::cython::scheduler::Scheduler","text":"<p>ClassList &gt; parla &gt; cython &gt; scheduler &gt; Scheduler</p> <p>Inherits the following classes: parla::cython::scheduler::ControllableThread,  parla::cython::scheduler::SchedulerContext</p>"},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1Scheduler/#public-attributes","title":"Public Attributes","text":"Type Name default_taskspace device_manager exception_stack inner_scheduler start_monitor worker_threads"},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1Scheduler/#public-functions","title":"Public Functions","text":"Type Name def __enter__ (self self)  def __exit__ (self self, exc_type exc_type, exc_val exc_val, exc_tb exc_tb)  def __init__ (self self, device_manager device_manager, n_threads n_threads=6, period period=0.001)  def assign_task (self self, task task, worker worker)  def get_device_reqs_from_placement (self self, placement placement, vcus vcus, memory memory)  def get_num_notified_workers (self self)  def get_num_running_tasks (self self)  def get_parray_state (self self, int global_dev_id, parray_parent_id parray_parent_id)  def release_parray (self self, CyPArray cy_parray, int global_dev_id)  def reserve_parray (self self, CyPArray cy_parray, int global_dev_id)  def run (self self)  def scheduler (self self)  def spawn_task (self self, task task)  def spawn_wait (self self)  def stop (self self)  def stop_callback (self self)"},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1Scheduler/#public-functions-inherited-from-parlacythonschedulercontrollablethread","title":"Public Functions inherited from parla::cython::scheduler::ControllableThread","text":"<p>See parla::cython::scheduler::ControllableThread</p> Type Name def __init__ (self self)  def run (self self)  def stop (self self)"},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1Scheduler/#public-functions-inherited-from-parlacythonschedulerschedulercontext","title":"Public Functions inherited from parla::cython::scheduler::SchedulerContext","text":"<p>See parla::cython::scheduler::SchedulerContext</p> Type Name def __enter__ (self self)  def __exit__ (self self, exc_type exc_type, exc_val exc_val, exc_tb exc_tb)  \"Scheduler\" scheduler (self self)"},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1Scheduler/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1Scheduler/#variable-default_taskspace","title":"variable default_taskspace","text":"<pre><code>parla.cython.scheduler.Scheduler::default_taskspace;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1Scheduler/#variable-device_manager","title":"variable device_manager","text":"<pre><code>parla.cython.scheduler.Scheduler::device_manager;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1Scheduler/#variable-exception_stack","title":"variable exception_stack","text":"<pre><code>parla.cython.scheduler.Scheduler::exception_stack;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1Scheduler/#variable-inner_scheduler","title":"variable inner_scheduler","text":"<pre><code>parla.cython.scheduler.Scheduler::inner_scheduler;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1Scheduler/#variable-start_monitor","title":"variable start_monitor","text":"<pre><code>parla.cython.scheduler.Scheduler::start_monitor;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1Scheduler/#variable-worker_threads","title":"variable worker_threads","text":"<pre><code>parla.cython.scheduler.Scheduler::worker_threads;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1Scheduler/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1Scheduler/#function-__enter__","title":"function __enter__","text":"<pre><code>def parla::cython::scheduler::Scheduler::__enter__ (\n    self self\n) \n</code></pre> <p>Implements parla::cython::scheduler::SchedulerContext::__enter__</p>"},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1Scheduler/#function-__exit__","title":"function __exit__","text":"<pre><code>def parla::cython::scheduler::Scheduler::__exit__ (\n    self self,\n    exc_type exc_type,\n    exc_val exc_val,\n    exc_tb exc_tb\n) \n</code></pre> <p>Implements parla::cython::scheduler::SchedulerContext::__exit__</p>"},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1Scheduler/#function-__init__","title":"function __init__","text":"<pre><code>def parla::cython::scheduler::Scheduler::__init__ (\n    self self,\n    device_manager device_manager,\n    n_threads n_threads=6,\n    period period=0.001\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1Scheduler/#function-assign_task","title":"function assign_task","text":"<pre><code>def parla::cython::scheduler::Scheduler::assign_task (\n    self self,\n    task task,\n    worker worker\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1Scheduler/#function-get_device_reqs_from_placement","title":"function get_device_reqs_from_placement","text":"<pre><code>def parla::cython::scheduler::Scheduler::get_device_reqs_from_placement (\n    self self,\n    placement placement,\n    vcus vcus,\n    memory memory\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1Scheduler/#function-get_num_notified_workers","title":"function get_num_notified_workers","text":"<pre><code>def parla::cython::scheduler::Scheduler::get_num_notified_workers (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1Scheduler/#function-get_num_running_tasks","title":"function get_num_running_tasks","text":"<pre><code>def parla::cython::scheduler::Scheduler::get_num_running_tasks (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1Scheduler/#function-get_parray_state","title":"function get_parray_state","text":"<pre><code>def parla::cython::scheduler::Scheduler::get_parray_state (\n    self self,\n    int global_dev_id,\n    parray_parent_id parray_parent_id\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1Scheduler/#function-release_parray","title":"function release_parray","text":"<pre><code>def parla::cython::scheduler::Scheduler::release_parray (\n    self self,\n    CyPArray cy_parray,\n    int global_dev_id\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1Scheduler/#function-reserve_parray","title":"function reserve_parray","text":"<pre><code>def parla::cython::scheduler::Scheduler::reserve_parray (\n    self self,\n    CyPArray cy_parray,\n    int global_dev_id\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1Scheduler/#function-run","title":"function run","text":"<pre><code>def parla::cython::scheduler::Scheduler::run (\n    self self\n) \n</code></pre> <p>Implements parla::cython::scheduler::ControllableThread::run</p>"},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1Scheduler/#function-scheduler","title":"function scheduler","text":"<pre><code>def parla::cython::scheduler::Scheduler::scheduler (\n    self self\n) \n</code></pre> <p>Implements parla::cython::scheduler::SchedulerContext::scheduler</p>"},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1Scheduler/#function-spawn_task","title":"function spawn_task","text":"<pre><code>def parla::cython::scheduler::Scheduler::spawn_task (\n    self self,\n    task task\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1Scheduler/#function-spawn_wait","title":"function spawn_wait","text":"<pre><code>def parla::cython::scheduler::Scheduler::spawn_wait (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1Scheduler/#function-stop","title":"function stop","text":"<pre><code>def parla::cython::scheduler::Scheduler::stop (\n    self self\n) \n</code></pre> <p>Implements parla::cython::scheduler::ControllableThread::stop</p>"},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1Scheduler/#function-stop_callback","title":"function stop_callback","text":"<pre><code>def parla::cython::scheduler::Scheduler::stop_callback (\n    self self\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/scheduler.pyx</code></p>"},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1SchedulerContext/","title":"Class parla::cython::scheduler::SchedulerContext","text":"<p>ClassList &gt; parla &gt; cython &gt; scheduler &gt; SchedulerContext</p> <p>Inherited by the following classes: parla::cython::scheduler::Scheduler,  parla::cython::scheduler::WorkerThread</p>"},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1SchedulerContext/#public-functions","title":"Public Functions","text":"Type Name def __enter__ (self self)  def __exit__ (self self, exc_type exc_type, exc_val exc_val, exc_tb exc_tb)  \"Scheduler\" scheduler (self self)"},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1SchedulerContext/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1SchedulerContext/#function-__enter__","title":"function __enter__","text":"<pre><code>def parla::cython::scheduler::SchedulerContext::__enter__ (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1SchedulerContext/#function-__exit__","title":"function __exit__","text":"<pre><code>def parla::cython::scheduler::SchedulerContext::__exit__ (\n    self self,\n    exc_type exc_type,\n    exc_val exc_val,\n    exc_tb exc_tb\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1SchedulerContext/#function-scheduler","title":"function scheduler","text":"<pre><code>\"Scheduler\" parla::cython::scheduler::SchedulerContext::scheduler (\n    self self\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/scheduler.pyx</code></p>"},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1SchedulerException/","title":"Class parla::cython::scheduler::SchedulerException","text":"<p>ClassList &gt; parla &gt; cython &gt; scheduler &gt; SchedulerException</p> <p>Inherits the following classes: RuntimeError</p> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/scheduler.pyx</code></p>"},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1TaskBodyException/","title":"Class parla::cython::scheduler::TaskBodyException","text":"<p>ClassList &gt; parla &gt; cython &gt; scheduler &gt; TaskBodyException</p> <p>Inherits the following classes: RuntimeError</p> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/scheduler.pyx</code></p>"},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1WorkerThread/","title":"Class parla::cython::scheduler::WorkerThread","text":"<p>ClassList &gt; parla &gt; cython &gt; scheduler &gt; WorkerThread</p> <p>Inherits the following classes: parla::cython::scheduler::ControllableThread,  parla::cython::scheduler::SchedulerContext</p>"},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1WorkerThread/#public-attributes","title":"Public Attributes","text":"Type Name index inner_worker status task task_attrs"},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1WorkerThread/#public-functions","title":"Public Functions","text":"Type Name def __init__ (self self, scheduler scheduler, index index)  def assign_task (self self, task task)  def remove_task (self self)  def run (self self)  def scheduler (self self)  def start (self self, initialize initialize=True)  def stop (self self)"},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1WorkerThread/#public-functions-inherited-from-parlacythonschedulercontrollablethread","title":"Public Functions inherited from parla::cython::scheduler::ControllableThread","text":"<p>See parla::cython::scheduler::ControllableThread</p> Type Name def __init__ (self self)  def run (self self)  def stop (self self)"},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1WorkerThread/#public-functions-inherited-from-parlacythonschedulerschedulercontext","title":"Public Functions inherited from parla::cython::scheduler::SchedulerContext","text":"<p>See parla::cython::scheduler::SchedulerContext</p> Type Name def __enter__ (self self)  def __exit__ (self self, exc_type exc_type, exc_val exc_val, exc_tb exc_tb)  \"Scheduler\" scheduler (self self)"},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1WorkerThread/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1WorkerThread/#variable-index","title":"variable index","text":"<pre><code>parla.cython.scheduler.WorkerThread::index;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1WorkerThread/#variable-inner_worker","title":"variable inner_worker","text":"<pre><code>parla.cython.scheduler.WorkerThread::inner_worker;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1WorkerThread/#variable-status","title":"variable status","text":"<pre><code>parla.cython.scheduler.WorkerThread::status;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1WorkerThread/#variable-task","title":"variable task","text":"<pre><code>parla.cython.scheduler.WorkerThread::task;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1WorkerThread/#variable-task_attrs","title":"variable task_attrs","text":"<pre><code>parla.cython.scheduler.WorkerThread::task_attrs;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1WorkerThread/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1WorkerThread/#function-__init__","title":"function __init__","text":"<pre><code>def parla::cython::scheduler::WorkerThread::__init__ (\n    self self,\n    scheduler scheduler,\n    index index\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1WorkerThread/#function-assign_task","title":"function assign_task","text":"<pre><code>def parla::cython::scheduler::WorkerThread::assign_task (\n    self self,\n    task task\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1WorkerThread/#function-remove_task","title":"function remove_task","text":"<pre><code>def parla::cython::scheduler::WorkerThread::remove_task (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1WorkerThread/#function-run","title":"function run","text":"<pre><code>def parla::cython::scheduler::WorkerThread::run (\n    self self\n) \n</code></pre> <p>Implements parla::cython::scheduler::ControllableThread::run</p>"},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1WorkerThread/#function-scheduler","title":"function scheduler","text":"<pre><code>def parla::cython::scheduler::WorkerThread::scheduler (\n    self self\n) \n</code></pre> <p>Implements parla::cython::scheduler::SchedulerContext::scheduler</p>"},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1WorkerThread/#function-start","title":"function start","text":"<pre><code>def parla::cython::scheduler::WorkerThread::start (\n    self self,\n    initialize initialize=True\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1WorkerThread/#function-stop","title":"function stop","text":"<pre><code>def parla::cython::scheduler::WorkerThread::stop (\n    self self\n) \n</code></pre> <p>Implements parla::cython::scheduler::ControllableThread::stop</p> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/scheduler.pyx</code></p>"},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1WorkerThreadException/","title":"Class parla::cython::scheduler::WorkerThreadException","text":"<p>ClassList &gt; parla &gt; cython &gt; scheduler &gt; WorkerThreadException</p> <p>Inherits the following classes: RuntimeError</p> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/scheduler.pyx</code></p>"},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1__SchedulerLocals/","title":"Class parla::cython::scheduler::_SchedulerLocals","text":"<p>ClassList &gt; parla &gt; cython &gt; scheduler &gt; _SchedulerLocals</p> <p>Inherits the following classes: threading.local</p>"},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1__SchedulerLocals/#public-functions","title":"Public Functions","text":"Type Name def __init__ (self self)  def scheduler_context (self self)"},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1__SchedulerLocals/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1__SchedulerLocals/#function-__init__","title":"function __init__","text":"<pre><code>def parla::cython::scheduler::_SchedulerLocals::__init__ (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1scheduler_1_1__SchedulerLocals/#function-scheduler_context","title":"function scheduler_context","text":"<pre><code>def parla::cython::scheduler::_SchedulerLocals::scheduler_context (\n    self self\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/scheduler.pyx</code></p>"},{"location":"runtime/namespaceparla_1_1cython_1_1tasks/","title":"Namespace parla::cython::tasks","text":"<p>Namespace List &gt; parla &gt; cython &gt; tasks</p>"},{"location":"runtime/namespaceparla_1_1cython_1_1tasks/#classes","title":"Classes","text":"Type Name class AtomicTaskList class AtomicTaskSpace class BackendTaskList class BackendTaskSpace class CPUEnvironment class ComputeTask A compute task is a task that executes a user defined Python function on a device. class DataMovementTask A data movement task is a task that moves data between devices. class GPUEnvironment class Task Python Task interface. class TaskCollection class TaskCompleted This state specifies that a task has completed execution. class TaskCreated This state specifies that a task has been created but not yet spawned. class TaskEnvironment A TaskEnvironment is a collection of devices or other TaskEnvironments used to coordinate and synchronize kernels in theTask body. class TaskException This state specifies that a task has completed execution with an exception. class TaskList class TaskMapped This state specifies that a task has been mapped to a device set, but not yet resered its resources there. class TaskReady This state specifies that a task is \"ready\" to be launched. class TaskReserved This state specifies that a task has reserved its persistent resources (e.g. class TaskRunahead State: A task is executing in a stream but the body has completed. class TaskRunning This state specifies that a task is executing in a stream. class TaskSpace class TaskSpawned This state specifies that a task is ready to be mapped to a specific device set. class TaskState Abstract base class for Task State. class TerminalEnvironment An endpoint TaskEnvironment representing a single device. class _TaskLocals"},{"location":"runtime/namespaceparla_1_1cython_1_1tasks/#public-attributes","title":"Public Attributes","text":"Type Name DeviceResourceRequirement   = =  device.DeviceResourceRequirement DeviceType   = =  PyDeviceType None PyArchitecture   = =  device.PyArchitecture PyCPUDevice   = =  device.PyCPUDevice PyCUDAArchitecture   = =  device.PyCUDAArchitecture PyCUDADevice   = =  device.PyCUDADevice PyDevice   = =  device.PyDevice TaskAwaitTasks   = =  namedtuple(\"AwaitTasks\", [\"dependencies\", \"value_task\"]) barrier   = =  BackendTaskList(barrier) cpu   = =  device_manager.cpu create depth dim i   = =  i.tasks index   = =  index_list[i] index_list istart   = =  max(i.start, lower_boundary) if i.start is not None else lower_boundary istep   = =  i.step or 1 istop   = =  min(i.stop, upper_boundary) if i.stop is not None else upper_boundary keys   = =  tasks.keys() lower_boundary max_dim new_index new_tasks output remainder shape   = =  None tuple shape_flag   = =  (shape is not None) start tuple start_flag   = =  (start is not None) task   = =  tasks[i] task_list task_locals   = =  _TaskLocals() tasks   = =  tasks.tasks upper_boundary"},{"location":"runtime/namespaceparla_1_1cython_1_1tasks/#public-functions","title":"Public Functions","text":"Type Name def create_device_env (device device) Create a terminal device environment from a PyDevice. def create_env (sources sources) Create the union TaskEnvironment from a list of TaskEnvironments or PyDevices. def parse_index (prefix prefix, index index, step step, stop stop)"},{"location":"runtime/namespaceparla_1_1cython_1_1tasks/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"runtime/namespaceparla_1_1cython_1_1tasks/#variable-deviceresourcerequirement","title":"variable DeviceResourceRequirement","text":"<pre><code>parla::cython::tasks.DeviceResourceRequirement;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1tasks/#variable-devicetype","title":"variable DeviceType","text":"<pre><code>parla::cython::tasks.DeviceType;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1tasks/#variable-none","title":"variable None","text":"<pre><code>parla::cython::tasks.None;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1tasks/#variable-pyarchitecture","title":"variable PyArchitecture","text":"<pre><code>parla::cython::tasks.PyArchitecture;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1tasks/#variable-pycpudevice","title":"variable PyCPUDevice","text":"<pre><code>parla::cython::tasks.PyCPUDevice;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1tasks/#variable-pycudaarchitecture","title":"variable PyCUDAArchitecture","text":"<pre><code>parla::cython::tasks.PyCUDAArchitecture;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1tasks/#variable-pycudadevice","title":"variable PyCUDADevice","text":"<pre><code>parla::cython::tasks.PyCUDADevice;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1tasks/#variable-pydevice","title":"variable PyDevice","text":"<pre><code>parla::cython::tasks.PyDevice;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1tasks/#variable-taskawaittasks","title":"variable TaskAwaitTasks","text":"<pre><code>parla::cython::tasks.TaskAwaitTasks;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1tasks/#variable-barrier","title":"variable barrier","text":"<pre><code>parla::cython::tasks.barrier;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1tasks/#variable-cpu","title":"variable cpu","text":"<pre><code>parla::cython::tasks.cpu;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1tasks/#variable-create","title":"variable create","text":"<pre><code>parla::cython::tasks.create;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1tasks/#variable-depth","title":"variable depth","text":"<pre><code>parla::cython::tasks.depth;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1tasks/#variable-dim","title":"variable dim","text":"<pre><code>parla::cython::tasks.dim;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1tasks/#variable-i","title":"variable i","text":"<pre><code>parla::cython::tasks.i;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1tasks/#variable-index","title":"variable index","text":"<pre><code>parla::cython::tasks.index;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1tasks/#variable-index_list","title":"variable index_list","text":"<pre><code>parla::cython::tasks.index_list;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1tasks/#variable-istart","title":"variable istart","text":"<pre><code>parla::cython::tasks.istart;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1tasks/#variable-istep","title":"variable istep","text":"<pre><code>int parla::cython::tasks::istep;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1tasks/#variable-istop","title":"variable istop","text":"<pre><code>int parla::cython::tasks::istop;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1tasks/#variable-keys","title":"variable keys","text":"<pre><code>parla::cython::tasks.keys;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1tasks/#variable-lower_boundary","title":"variable lower_boundary","text":"<pre><code>parla::cython::tasks.lower_boundary;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1tasks/#variable-max_dim","title":"variable max_dim","text":"<pre><code>parla::cython::tasks.max_dim;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1tasks/#variable-new_index","title":"variable new_index","text":"<pre><code>parla::cython::tasks.new_index;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1tasks/#variable-new_tasks","title":"variable new_tasks","text":"<pre><code>parla::cython::tasks.new_tasks;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1tasks/#variable-output","title":"variable output","text":"<pre><code>parla::cython::tasks.output;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1tasks/#variable-remainder","title":"variable remainder","text":"<pre><code>parla::cython::tasks.remainder;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1tasks/#variable-shape","title":"variable shape","text":"<pre><code>parla::cython::tasks.shape;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1tasks/#variable-shape_flag","title":"variable shape_flag","text":"<pre><code>tuple parla::cython::tasks::shape_flag;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1tasks/#variable-start","title":"variable start","text":"<pre><code>parla::cython::tasks.start;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1tasks/#variable-start_flag","title":"variable start_flag","text":"<pre><code>tuple parla::cython::tasks.start_flag;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1tasks/#variable-task","title":"variable task","text":"<pre><code>parla::cython::tasks.task;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1tasks/#variable-task_list","title":"variable task_list","text":"<pre><code>parla::cython::tasks.task_list;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1tasks/#variable-task_locals","title":"variable task_locals","text":"<pre><code>parla::cython::tasks.task_locals;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1tasks/#variable-tasks","title":"variable tasks","text":"<pre><code>parla::cython::tasks.tasks;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1tasks/#variable-upper_boundary","title":"variable upper_boundary","text":"<pre><code>parla::cython::tasks.upper_boundary;\n</code></pre>"},{"location":"runtime/namespaceparla_1_1cython_1_1tasks/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/namespaceparla_1_1cython_1_1tasks/#function-create_device_env","title":"function create_device_env","text":"<p>Create a terminal device environment from a PyDevice. <pre><code>def parla::cython::tasks::create_device_env (\n    device device\n) \n</code></pre></p> <p>Parameters:</p> <ul> <li><code>device</code> The PyDevice to create the environment from. </li> </ul>"},{"location":"runtime/namespaceparla_1_1cython_1_1tasks/#function-create_env","title":"function create_env","text":"<p>Create the union TaskEnvironment from a list of TaskEnvironments or PyDevices. <pre><code>def parla::cython::tasks::create_env (\n    sources sources\n) \n</code></pre></p> <p>Parameters:</p> <ul> <li><code>sources</code> The list of PyDevices (or Environments) to create the new environment from. </li> </ul>"},{"location":"runtime/namespaceparla_1_1cython_1_1tasks/#function-parse_index","title":"function parse_index","text":"<pre><code>def parla::cython::tasks::parse_index (\n    prefix prefix,\n    index index,\n    step step,\n    stop stop\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/tasks.pyx</code></p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1AtomicTaskList/","title":"Class parla::cython::tasks::AtomicTaskList","text":"<p>ClassList &gt; parla &gt; cython &gt; tasks &gt; AtomicTaskList</p> <p>Inherits the following classes: parla::cython::tasks::TaskList</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1AtomicTaskList/#public-attributes","title":"Public Attributes","text":"Type Name inner_barrier"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1AtomicTaskList/#public-functions","title":"Public Functions","text":"Type Name def __add__ (self self, other other)  def __iadd__ (self self, other other)  def __init__ (self self, tasks tasks, name name=None, flatten flatten=True)  def __repr__ (self self)  def wait (self self)"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1AtomicTaskList/#public-functions-inherited-from-parlacythontaskstasklist","title":"Public Functions inherited from parla::cython::tasks::TaskList","text":"<p>See parla::cython::tasks::TaskList</p> Type Name def __add__ (self self, other other)  def __getitem__ (self self, index index)  def __iadd__ (self self, other other)  def __init__ (self self, tasks tasks, name name=None, flatten flatten=True)  def __repr__ (self self)"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1AtomicTaskList/#public-functions-inherited-from-parlacythontaskstaskcollection","title":"Public Functions inherited from parla::cython::tasks::TaskCollection","text":"<p>See parla::cython::tasks::TaskCollection</p> Type Name def __add__ (self self, other other)  def __await__ (self self)  def __contains__ (self self, task task)  def __eq__ (self self, other other)  def __hash__ (self self)  def __iadd__ (self self, other other)  def __init__ (self self, tasks tasks, name name=None, flatten flatten=True)  def __iter__ (self self)  def __len__ (self self)  def __ne__ (self self, other other)  def __repr__ (self self)  def __str__ (self self)  def tasks (self self)"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1AtomicTaskList/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1AtomicTaskList/#variable-inner_barrier","title":"variable inner_barrier","text":"<pre><code>parla.cython.tasks.AtomicTaskList::inner_barrier;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1AtomicTaskList/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1AtomicTaskList/#function-__add__","title":"function __add__","text":"<pre><code>def parla::cython::tasks::AtomicTaskList::__add__ (\n    self self,\n    other other\n) \n</code></pre> <p>Implements parla::cython::tasks::TaskList::__add__</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1AtomicTaskList/#function-__iadd__","title":"function __iadd__","text":"<pre><code>def parla::cython::tasks::AtomicTaskList::__iadd__ (\n    self self,\n    other other\n) \n</code></pre> <p>Implements parla::cython::tasks::TaskList::__iadd__</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1AtomicTaskList/#function-__init__","title":"function __init__","text":"<pre><code>def parla::cython::tasks::AtomicTaskList::__init__ (\n    self self,\n    tasks tasks,\n    name name=None,\n    flatten flatten=True\n) \n</code></pre> <p>Implements parla::cython::tasks::TaskList::__init__</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1AtomicTaskList/#function-__repr__","title":"function __repr__","text":"<pre><code>def parla::cython::tasks::AtomicTaskList::__repr__ (\n    self self\n) \n</code></pre> <p>Implements parla::cython::tasks::TaskList::__repr__</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1AtomicTaskList/#function-wait","title":"function wait","text":"<pre><code>def parla::cython::tasks::AtomicTaskList::wait (\n    self self\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/tasks.pyx</code></p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1AtomicTaskSpace/","title":"Class parla::cython::tasks::AtomicTaskSpace","text":"<p>ClassList &gt; parla &gt; cython &gt; tasks &gt; AtomicTaskSpace</p> <p>Inherits the following classes: parla::cython::tasks::TaskSpace</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1AtomicTaskSpace/#public-attributes","title":"Public Attributes","text":"Type Name inner_space"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1AtomicTaskSpace/#public-attributes-inherited-from-parlacythontaskstaskspace","title":"Public Attributes inherited from parla::cython::tasks::TaskSpace","text":"<p>See parla::cython::tasks::TaskSpace</p> Type Name shape start"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1AtomicTaskSpace/#public-functions","title":"Public Functions","text":"Type Name def __getitem__ (self self, index index)  def __init__ (self self, name name=\"\", create create=True, shape shape=None, start start=None)  def __repr__ (self self)  def wait (self self)"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1AtomicTaskSpace/#public-functions-inherited-from-parlacythontaskstaskspace","title":"Public Functions inherited from parla::cython::tasks::TaskSpace","text":"<p>See parla::cython::tasks::TaskSpace</p> Type Name def __add__ (self self, other other)  def __getitem__ (self self, index index)  def __iadd__ (self self, other other)  def __init__ (self self, name name=\"\", create create=True, shape shape=None, start start=None)  def __repr__ (self self)  def name (self self)  def tasks (self self)  def view (self self)"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1AtomicTaskSpace/#public-functions-inherited-from-parlacythontaskstaskcollection","title":"Public Functions inherited from parla::cython::tasks::TaskCollection","text":"<p>See parla::cython::tasks::TaskCollection</p> Type Name def __add__ (self self, other other)  def __await__ (self self)  def __contains__ (self self, task task)  def __eq__ (self self, other other)  def __hash__ (self self)  def __iadd__ (self self, other other)  def __init__ (self self, tasks tasks, name name=None, flatten flatten=True)  def __iter__ (self self)  def __len__ (self self)  def __ne__ (self self, other other)  def __repr__ (self self)  def __str__ (self self)  def tasks (self self)"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1AtomicTaskSpace/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1AtomicTaskSpace/#variable-inner_space","title":"variable inner_space","text":"<pre><code>parla.cython.tasks.AtomicTaskSpace::inner_space;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1AtomicTaskSpace/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1AtomicTaskSpace/#function-__getitem__","title":"function __getitem__","text":"<pre><code>def parla::cython::tasks::AtomicTaskSpace::__getitem__ (\n    self self,\n    index index\n) \n</code></pre> <p>Implements parla::cython::tasks::TaskSpace::__getitem__</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1AtomicTaskSpace/#function-__init__","title":"function __init__","text":"<pre><code>def parla::cython::tasks::AtomicTaskSpace::__init__ (\n    self self,\n    name name=\"\",\n    create create=True,\n    shape shape=None,\n    start start=None\n) \n</code></pre> <p>Implements parla::cython::tasks::TaskSpace::__init__</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1AtomicTaskSpace/#function-__repr__","title":"function __repr__","text":"<pre><code>def parla::cython::tasks::AtomicTaskSpace::__repr__ (\n    self self\n) \n</code></pre> <p>Implements parla::cython::tasks::TaskSpace::__repr__</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1AtomicTaskSpace/#function-wait","title":"function wait","text":"<pre><code>def parla::cython::tasks::AtomicTaskSpace::wait (\n    self self\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/tasks.pyx</code></p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1BackendTaskList/","title":"Class parla::cython::tasks::BackendTaskList","text":"<p>ClassList &gt; parla &gt; cython &gt; tasks &gt; BackendTaskList</p> <p>Inherits the following classes: parla::cython::tasks::TaskList</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1BackendTaskList/#public-attributes","title":"Public Attributes","text":"Type Name inner_barrier"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1BackendTaskList/#public-functions","title":"Public Functions","text":"Type Name def __init__ (self self, tasks tasks, name name=None, flatten flatten=True)  def __repr__ (self self)  def wait (self self)"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1BackendTaskList/#public-functions-inherited-from-parlacythontaskstasklist","title":"Public Functions inherited from parla::cython::tasks::TaskList","text":"<p>See parla::cython::tasks::TaskList</p> Type Name def __add__ (self self, other other)  def __getitem__ (self self, index index)  def __iadd__ (self self, other other)  def __init__ (self self, tasks tasks, name name=None, flatten flatten=True)  def __repr__ (self self)"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1BackendTaskList/#public-functions-inherited-from-parlacythontaskstaskcollection","title":"Public Functions inherited from parla::cython::tasks::TaskCollection","text":"<p>See parla::cython::tasks::TaskCollection</p> Type Name def __add__ (self self, other other)  def __await__ (self self)  def __contains__ (self self, task task)  def __eq__ (self self, other other)  def __hash__ (self self)  def __iadd__ (self self, other other)  def __init__ (self self, tasks tasks, name name=None, flatten flatten=True)  def __iter__ (self self)  def __len__ (self self)  def __ne__ (self self, other other)  def __repr__ (self self)  def __str__ (self self)  def tasks (self self)"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1BackendTaskList/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1BackendTaskList/#variable-inner_barrier","title":"variable inner_barrier","text":"<pre><code>parla.cython.tasks.BackendTaskList::inner_barrier;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1BackendTaskList/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1BackendTaskList/#function-__init__","title":"function __init__","text":"<pre><code>def parla::cython::tasks::BackendTaskList::__init__ (\n    self self,\n    tasks tasks,\n    name name=None,\n    flatten flatten=True\n) \n</code></pre> <p>Implements parla::cython::tasks::TaskList::__init__</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1BackendTaskList/#function-__repr__","title":"function __repr__","text":"<pre><code>def parla::cython::tasks::BackendTaskList::__repr__ (\n    self self\n) \n</code></pre> <p>Implements parla::cython::tasks::TaskList::__repr__</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1BackendTaskList/#function-wait","title":"function wait","text":"<pre><code>def parla::cython::tasks::BackendTaskList::wait (\n    self self\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/tasks.pyx</code></p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1BackendTaskSpace/","title":"Class parla::cython::tasks::BackendTaskSpace","text":"<p>ClassList &gt; parla &gt; cython &gt; tasks &gt; BackendTaskSpace</p> <p>Inherits the following classes: parla::cython::tasks::TaskSpace</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1BackendTaskSpace/#public-attributes","title":"Public Attributes","text":"Type Name inner_space"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1BackendTaskSpace/#public-attributes-inherited-from-parlacythontaskstaskspace","title":"Public Attributes inherited from parla::cython::tasks::TaskSpace","text":"<p>See parla::cython::tasks::TaskSpace</p> Type Name shape start"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1BackendTaskSpace/#public-functions","title":"Public Functions","text":"Type Name def __getitem__ (self self, index index)  def __init__ (self self, name name=\"\", create create=True, shape shape=None, start start=None)  def __repr__ (self self)  def wait (self self)"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1BackendTaskSpace/#public-functions-inherited-from-parlacythontaskstaskspace","title":"Public Functions inherited from parla::cython::tasks::TaskSpace","text":"<p>See parla::cython::tasks::TaskSpace</p> Type Name def __add__ (self self, other other)  def __getitem__ (self self, index index)  def __iadd__ (self self, other other)  def __init__ (self self, name name=\"\", create create=True, shape shape=None, start start=None)  def __repr__ (self self)  def name (self self)  def tasks (self self)  def view (self self)"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1BackendTaskSpace/#public-functions-inherited-from-parlacythontaskstaskcollection","title":"Public Functions inherited from parla::cython::tasks::TaskCollection","text":"<p>See parla::cython::tasks::TaskCollection</p> Type Name def __add__ (self self, other other)  def __await__ (self self)  def __contains__ (self self, task task)  def __eq__ (self self, other other)  def __hash__ (self self)  def __iadd__ (self self, other other)  def __init__ (self self, tasks tasks, name name=None, flatten flatten=True)  def __iter__ (self self)  def __len__ (self self)  def __ne__ (self self, other other)  def __repr__ (self self)  def __str__ (self self)  def tasks (self self)"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1BackendTaskSpace/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1BackendTaskSpace/#variable-inner_space","title":"variable inner_space","text":"<pre><code>parla.cython.tasks.BackendTaskSpace::inner_space;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1BackendTaskSpace/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1BackendTaskSpace/#function-__getitem__","title":"function __getitem__","text":"<pre><code>def parla::cython::tasks::BackendTaskSpace::__getitem__ (\n    self self,\n    index index\n) \n</code></pre> <p>Implements parla::cython::tasks::TaskSpace::__getitem__</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1BackendTaskSpace/#function-__init__","title":"function __init__","text":"<pre><code>def parla::cython::tasks::BackendTaskSpace::__init__ (\n    self self,\n    name name=\"\",\n    create create=True,\n    shape shape=None,\n    start start=None\n) \n</code></pre> <p>Implements parla::cython::tasks::TaskSpace::__init__</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1BackendTaskSpace/#function-__repr__","title":"function __repr__","text":"<pre><code>def parla::cython::tasks::BackendTaskSpace::__repr__ (\n    self self\n) \n</code></pre> <p>Implements parla::cython::tasks::TaskSpace::__repr__</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1BackendTaskSpace/#function-wait","title":"function wait","text":"<pre><code>def parla::cython::tasks::BackendTaskSpace::wait (\n    self self\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/tasks.pyx</code></p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1CPUEnvironment/","title":"Class parla::cython::tasks::CPUEnvironment","text":"<p>ClassList &gt; parla &gt; cython &gt; tasks &gt; CPUEnvironment</p> <p>Inherits the following classes: parla::cython::tasks::TerminalEnvironment</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1CPUEnvironment/#public-attributes-inherited-from-parlacythontasksterminalenvironment","title":"Public Attributes inherited from parla::cython::tasks::TerminalEnvironment","text":"<p>See parla::cython::tasks::TerminalEnvironment</p> Type Name is_terminal"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1CPUEnvironment/#public-attributes-inherited-from-parlacythontaskstaskenvironment","title":"Public Attributes inherited from parla::cython::tasks::TaskEnvironment","text":"<p>See parla::cython::tasks::TaskEnvironment</p> Type Name blocking device_dict device_list env_list event_dict is_terminal stream_list"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1CPUEnvironment/#public-functions","title":"Public Functions","text":"Type Name def __enter__ (self self)  def __exit__ (self self, exc_type exc_type, exc_val exc_val, exc_tb exc_tb)  def __getitem__ (self self, index index)  def __init__ (self self, device device, blocking blocking=False)  def __len__ (self self)  def __repr__ (self self)  def finalize (self self)  def return_streams (self self)"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1CPUEnvironment/#public-functions-inherited-from-parlacythontasksterminalenvironment","title":"Public Functions inherited from parla::cython::tasks::TerminalEnvironment","text":"<p>See parla::cython::tasks::TerminalEnvironment</p> Type Name def __call__ (self self)  def __eq__ (self self, other other)  def __getitem__ (self self, index index)  def __hash__ (self self)  def __init__ (self self, device device, blocking blocking=False)  def __len__ (self self)  def __repr__ (self self)  def architecture (self self)  def contexts (self self)  def create_event (self self, stream stream=None, tag tag='default') Create a CUDA event on the current stream. def device (self self)  def devices (self self)  def record_event (self self, stream stream=None, tag tag='default') Record a CUDA event on the current stream. def synchronize_event (self self, tag tag='default') Synchronize host thread to the tagged CUDA event (sleep or waiting). def wait_event (self self, stream stream=None, tag tag='default') Submit a cross-stream wait on the tagged CUDA event to the current stream. def write_events_to_task (self self, task task) Record event pointers in C++ task. def write_streams_to_task (self self, task task) Record stream pointers into C++ task. def write_to_task (self self, task task) Store stream and event pointers in C++ task."},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1CPUEnvironment/#public-functions-inherited-from-parlacythontaskstaskenvironment","title":"Public Functions inherited from parla::cython::tasks::TaskEnvironment","text":"<p>See parla::cython::tasks::TaskEnvironment</p> Type Name def __contains__ (self self, obj obj)  def __contains__ (self self, obj obj)  def __enter__ (self self)  def __exit__ (self self, exc_type exc_type, exc_val exc_val, exc_tb exc_tb)  def __getitem__ (self self, index index)  def __init__ (self self, environment_list environment_list, blocking blocking=False)  def __len__ (self self)  def __repr__ (self self)  def contexts (self self)  def create_events (self self, tags tags=['default'])  def cupy_stream (self self)  def device (self self)  def devices (self self)  def finalize (self self)  def get_all_devices (self self)  def get_cupy_devices (self self)  def get_devices (self self, arch arch)  def get_library_device (self self)  def get_parla_device (self self)  def global_ids (self self)  def gpu_id (self self)  def gpu_ids (self self)  def has (self self, device_type device_type)  def loop (self self, envlist envlist=None)  def parfor (self self, envlist envlist=None)  def record_events (self self, tags tags=['default'])  def retrieve (self self, key key)  def return_streams (self self)  def storage (self self)  def store (self self, key key, value value)  def stream (self self)  def streams (self self)  def synchronize (self self, events events=False, tags tags=['default'], return_to_pool return_to_pool=True)  def synchronize_events (self self, env env, tags tags=['default'])  def wait_events (self self, env env, tags tags=['default'])  def write_streams_to_task (self self, task task)  def write_to_task (self self, task task)"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1CPUEnvironment/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1CPUEnvironment/#function-__enter__","title":"function __enter__","text":"<pre><code>def parla::cython::tasks::CPUEnvironment::__enter__ (\n    self self\n) \n</code></pre> <p>Implements parla::cython::tasks::TaskEnvironment::__enter__</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1CPUEnvironment/#function-__exit__","title":"function __exit__","text":"<pre><code>def parla::cython::tasks::CPUEnvironment::__exit__ (\n    self self,\n    exc_type exc_type,\n    exc_val exc_val,\n    exc_tb exc_tb\n) \n</code></pre> <p>Implements parla::cython::tasks::TaskEnvironment::__exit__</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1CPUEnvironment/#function-__getitem__","title":"function __getitem__","text":"<pre><code>def parla::cython::tasks::CPUEnvironment::__getitem__ (\n    self self,\n    index index\n) \n</code></pre> <p>Implements parla::cython::tasks::TerminalEnvironment::__getitem__</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1CPUEnvironment/#function-__init__","title":"function __init__","text":"<pre><code>def parla::cython::tasks::CPUEnvironment::__init__ (\n    self self,\n    device device,\n    blocking blocking=False\n) \n</code></pre> <p>Implements parla::cython::tasks::TerminalEnvironment::__init__</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1CPUEnvironment/#function-__len__","title":"function __len__","text":"<pre><code>def parla::cython::tasks::CPUEnvironment::__len__ (\n    self self\n) \n</code></pre> <p>Implements parla::cython::tasks::TerminalEnvironment::__len__</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1CPUEnvironment/#function-__repr__","title":"function __repr__","text":"<pre><code>def parla::cython::tasks::CPUEnvironment::__repr__ (\n    self self\n) \n</code></pre> <p>Implements parla::cython::tasks::TerminalEnvironment::__repr__</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1CPUEnvironment/#function-finalize","title":"function finalize","text":"<pre><code>def parla::cython::tasks::CPUEnvironment::finalize (\n    self self\n) \n</code></pre> <p>Implements parla::cython::tasks::TaskEnvironment::finalize</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1CPUEnvironment/#function-return_streams","title":"function return_streams","text":"<pre><code>def parla::cython::tasks::CPUEnvironment::return_streams (\n    self self\n) \n</code></pre> <p>Implements parla::cython::tasks::TaskEnvironment::return_streams</p> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/tasks.pyx</code></p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1ComputeTask/","title":"Class parla::cython::tasks::ComputeTask","text":"<p>ClassList &gt; parla &gt; cython &gt; tasks &gt; ComputeTask</p> <p>A compute task is a task that executes a user defined Python function on a device. </p> <p>Inherits the following classes: parla::cython::tasks::Task</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1ComputeTask/#public-attributes","title":"Public Attributes","text":"Type Name args base_function dataflow func"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1ComputeTask/#public-attributes-inherited-from-parlacythontaskstask","title":"Public Attributes inherited from parla::cython::tasks::Task","text":"<p>See parla::cython::tasks::Task</p> Type Name dependencies id idx inner_task name priority runahead scheduler state taskspace"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1ComputeTask/#public-functions","title":"Public Functions","text":"Type Name def __init__ (self self, taskspace taskspace=None, idx idx=None, state state=TaskCreated(), scheduler scheduler=None, name name=None) Create a new task empty object. def cleanup (self self) Cleanup the task by removing the function, arguments, and references to its data objects. def instantiate (self self, function function, args args, dependencies dependencies=None, dataflow dataflow=None, priority priority=0, runahead runahead=SyncType.BLOCKING) Instantiate the task with a function and arguments."},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1ComputeTask/#public-functions-inherited-from-parlacythontaskstask","title":"Public Functions inherited from parla::cython::tasks::Task","text":"<p>See parla::cython::tasks::Task</p> Type Name def __await__ (self self)  def __await__ (self self)  def __hash__ (self self)  def __init__ (self self, taskspace taskspace=None, idx idx=None, state state=TaskCreated(), scheduler scheduler=None, name name=None) Create a new task empty object. def __repr__ (self self)  def add_dataflow (self self, dataflow dataflow)  def add_dependencies (self self, dependency_list dependency_list, process process=False)  def add_event (self self, event event)  def add_stream (self self, stream stream)  def env (self self) The active TaskEnvironment of the task. def env (self self, v v)  def environment (self self) The active TaskEnvironment of the task. def environment (self self, env env)  def get_assigned_devices (self self)  def get_dependencies (self self)  def get_dependents (self self)  str get_name (self self) Get the name of the task. def get_num_blocking_dependencies (self self)  def get_num_dependencies (self self)  def get_num_dependents (self self)  def get_num_unmapped_dependencies (self self)  def get_state (self self) Get the state of the task (from the C++ runtime) def handle_runahead_dependencies (self self) Wait (or synchronize) on all events that the task depends on. def instantiate (self self, dependencies dependencies=None, list_of_dev_reqs list_of_dev_reqs=[], priority priority=None, dataflow dataflow=None, runahead runahead=SyncType.BLOCKING) Add metadata to a blank task object. def notify_dependents_wrapper (self self) Mock dependents interface only used for testing. def py_handle_runahead_dependencies (self self) Wait (or synchronize) on all events that the task depends on. def result (self self) The return value of the task body. def run (self self) Run the task body. def set_complete (self self)  def set_device_reqs (self self, device_reqs device_reqs) Set the device requirements of the task. def set_scheduler (self self, scheduler scheduler) Set the scheduler the task has been spawned by. def set_state (self self, state state) Set the state of the task (passed to the C++ runtime) str unpack_name (self self) Create the name of the task from the taskspace and index. def update_name (self self) Update the name of the task from the taskspace and index."},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1ComputeTask/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1ComputeTask/#variable-args","title":"variable args","text":"<pre><code>parla.cython.tasks.ComputeTask::args;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1ComputeTask/#variable-base_function","title":"variable base_function","text":"<pre><code>parla.cython.tasks.ComputeTask::base_function;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1ComputeTask/#variable-dataflow","title":"variable dataflow","text":"<pre><code>parla.cython.tasks.ComputeTask::dataflow;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1ComputeTask/#variable-func","title":"variable func","text":"<pre><code>parla.cython.tasks.ComputeTask::func;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1ComputeTask/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1ComputeTask/#function-__init__","title":"function __init__","text":"<p>Create a new task empty object. <pre><code>def parla::cython::tasks::ComputeTask::__init__ (\n    self self,\n    taskspace taskspace=None,\n    idx idx=None,\n    state state=TaskCreated (),\n    scheduler scheduler=None,\n    name name=None\n) \n</code></pre></p> <p>Task objects are always created empty on first reference and are populated by the runtime when they are spawned. </p> <p>Implements parla::cython::tasks::Task::__init__</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1ComputeTask/#function-cleanup","title":"function cleanup","text":"<pre><code>def parla::cython::tasks::ComputeTask::cleanup (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1ComputeTask/#function-instantiate","title":"function instantiate","text":"<p>Instantiate the task with a function and arguments. <pre><code>def parla::cython::tasks::ComputeTask::instantiate (\n    self self,\n    function function,\n    args args,\n    dependencies dependencies=None,\n    dataflow dataflow=None,\n    priority priority=0,\n    runahead runahead=SyncType.BLOCKING\n) \n</code></pre></p> <p>Parameters:</p> <ul> <li><code>function</code> The function to execute. </li> <li><code>args</code> The arguments to the function. </li> <li><code>dependencies</code> A list of tasks that this task depends on. </li> <li><code>dataflow</code> The dataflow object that describes the data dependencies of the task. (Crosspy and data direction (IN/OUT/INOUT)) </li> <li><code>priority</code> The priority of the task. </li> <li><code>runahead</code> The type of synchronization the task uses for runahead scheduling. </li> </ul> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/tasks.pyx</code></p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1DataMovementTask/","title":"Class parla::cython::tasks::DataMovementTask","text":"<p>ClassList &gt; parla &gt; cython &gt; tasks &gt; DataMovementTask</p> <p>A data movement task is a task that moves data between devices. More...</p> <p>Inherits the following classes: parla::cython::tasks::Task</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1DataMovementTask/#public-attributes","title":"Public Attributes","text":"Type Name access_mode assigned_devices dev_id name parray runahead scheduler"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1DataMovementTask/#public-attributes-inherited-from-parlacythontaskstask","title":"Public Attributes inherited from parla::cython::tasks::Task","text":"<p>See parla::cython::tasks::Task</p> Type Name dependencies id idx inner_task name priority runahead scheduler state taskspace"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1DataMovementTask/#public-functions","title":"Public Functions","text":"Type Name def __init__ (self self, PArray parray=None, access_mode access_mode=None, List assigned_devices=None, taskspace taskspace=None, idx idx=0, state state=TaskCreated(), scheduler scheduler=None, name name=None)  def instantiate (self self, core.DataMovementTaskAttributes attrs, scheduler scheduler, runahead runahead=SyncType.BLOCKING) Instantiate the data movement task with attributes from the C++ runtime."},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1DataMovementTask/#public-functions-inherited-from-parlacythontaskstask","title":"Public Functions inherited from parla::cython::tasks::Task","text":"<p>See parla::cython::tasks::Task</p> Type Name def __await__ (self self)  def __await__ (self self)  def __hash__ (self self)  def __init__ (self self, taskspace taskspace=None, idx idx=None, state state=TaskCreated(), scheduler scheduler=None, name name=None) Create a new task empty object. def __repr__ (self self)  def add_dataflow (self self, dataflow dataflow)  def add_dependencies (self self, dependency_list dependency_list, process process=False)  def add_event (self self, event event)  def add_stream (self self, stream stream)  def env (self self) The active TaskEnvironment of the task. def env (self self, v v)  def environment (self self) The active TaskEnvironment of the task. def environment (self self, env env)  def get_assigned_devices (self self)  def get_dependencies (self self)  def get_dependents (self self)  str get_name (self self) Get the name of the task. def get_num_blocking_dependencies (self self)  def get_num_dependencies (self self)  def get_num_dependents (self self)  def get_num_unmapped_dependencies (self self)  def get_state (self self) Get the state of the task (from the C++ runtime) def handle_runahead_dependencies (self self) Wait (or synchronize) on all events that the task depends on. def instantiate (self self, dependencies dependencies=None, list_of_dev_reqs list_of_dev_reqs=[], priority priority=None, dataflow dataflow=None, runahead runahead=SyncType.BLOCKING) Add metadata to a blank task object. def notify_dependents_wrapper (self self) Mock dependents interface only used for testing. def py_handle_runahead_dependencies (self self) Wait (or synchronize) on all events that the task depends on. def result (self self) The return value of the task body. def run (self self) Run the task body. def set_complete (self self)  def set_device_reqs (self self, device_reqs device_reqs) Set the device requirements of the task. def set_scheduler (self self, scheduler scheduler) Set the scheduler the task has been spawned by. def set_state (self self, state state) Set the state of the task (passed to the C++ runtime) str unpack_name (self self) Create the name of the task from the taskspace and index. def update_name (self self) Update the name of the task from the taskspace and index."},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1DataMovementTask/#detailed-description","title":"Detailed Description","text":"<p>It is not user defined. </p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1DataMovementTask/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1DataMovementTask/#variable-access_mode","title":"variable access_mode","text":"<pre><code>parla.cython.tasks.DataMovementTask::access_mode;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1DataMovementTask/#variable-assigned_devices","title":"variable assigned_devices","text":"<pre><code>parla.cython.tasks.DataMovementTask::assigned_devices;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1DataMovementTask/#variable-dev_id","title":"variable dev_id","text":"<pre><code>parla.cython.tasks.DataMovementTask::dev_id;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1DataMovementTask/#variable-name","title":"variable name","text":"<pre><code>parla.cython.tasks.DataMovementTask::name;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1DataMovementTask/#variable-parray","title":"variable parray","text":"<pre><code>parla.cython.tasks.DataMovementTask::parray;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1DataMovementTask/#variable-runahead","title":"variable runahead","text":"<pre><code>parla.cython.tasks.DataMovementTask::runahead;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1DataMovementTask/#variable-scheduler","title":"variable scheduler","text":"<pre><code>parla.cython.tasks.DataMovementTask::scheduler;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1DataMovementTask/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1DataMovementTask/#function-__init__","title":"function __init__","text":"<pre><code>def parla::cython::tasks::DataMovementTask::__init__ (\n    self self,\n    PArray parray=None,\n    access_mode access_mode=None,\n    List assigned_devices=None,\n    taskspace taskspace=None,\n    idx idx=0,\n    state state=TaskCreated (),\n    scheduler scheduler=None,\n    name name=None\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1DataMovementTask/#function-instantiate","title":"function instantiate","text":"<p>Instantiate the data movement task with attributes from the C++ runtime. <pre><code>def parla::cython::tasks::DataMovementTask::instantiate (\n    self self,\n    core.DataMovementTaskAttributes attrs,\n    scheduler scheduler,\n    runahead runahead=SyncType.BLOCKING\n) \n</code></pre></p> <p>Parameters:</p> <ul> <li><code>attrs</code> The attributes of the data movement task. </li> <li><code>scheduler</code> The scheduler that the task is created under. </li> <li><code>runahead</code> The type of synchronization the task uses for runahead scheduling. </li> </ul> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/tasks.pyx</code></p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1GPUEnvironment/","title":"Class parla::cython::tasks::GPUEnvironment","text":"<p>ClassList &gt; parla &gt; cython &gt; tasks &gt; GPUEnvironment</p> <p>Inherits the following classes: parla::cython::tasks::TerminalEnvironment</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1GPUEnvironment/#public-attributes","title":"Public Attributes","text":"Type Name active_stream"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1GPUEnvironment/#public-attributes-inherited-from-parlacythontasksterminalenvironment","title":"Public Attributes inherited from parla::cython::tasks::TerminalEnvironment","text":"<p>See parla::cython::tasks::TerminalEnvironment</p> Type Name is_terminal"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1GPUEnvironment/#public-attributes-inherited-from-parlacythontaskstaskenvironment","title":"Public Attributes inherited from parla::cython::tasks::TaskEnvironment","text":"<p>See parla::cython::tasks::TaskEnvironment</p> Type Name blocking device_dict device_list env_list event_dict is_terminal stream_list"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1GPUEnvironment/#public-functions","title":"Public Functions","text":"Type Name def __enter__ (self self)  def __exit__ (self self, exc_type exc_type, exc_val exc_val, exc_tb exc_tb)  def __init__ (self self, device device, blocking blocking=False)  def __repr__ (self self)  def finalize (self self)  def return_streams (self self)"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1GPUEnvironment/#public-functions-inherited-from-parlacythontasksterminalenvironment","title":"Public Functions inherited from parla::cython::tasks::TerminalEnvironment","text":"<p>See parla::cython::tasks::TerminalEnvironment</p> Type Name def __call__ (self self)  def __eq__ (self self, other other)  def __getitem__ (self self, index index)  def __hash__ (self self)  def __init__ (self self, device device, blocking blocking=False)  def __len__ (self self)  def __repr__ (self self)  def architecture (self self)  def contexts (self self)  def create_event (self self, stream stream=None, tag tag='default') Create a CUDA event on the current stream. def device (self self)  def devices (self self)  def record_event (self self, stream stream=None, tag tag='default') Record a CUDA event on the current stream. def synchronize_event (self self, tag tag='default') Synchronize host thread to the tagged CUDA event (sleep or waiting). def wait_event (self self, stream stream=None, tag tag='default') Submit a cross-stream wait on the tagged CUDA event to the current stream. def write_events_to_task (self self, task task) Record event pointers in C++ task. def write_streams_to_task (self self, task task) Record stream pointers into C++ task. def write_to_task (self self, task task) Store stream and event pointers in C++ task."},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1GPUEnvironment/#public-functions-inherited-from-parlacythontaskstaskenvironment","title":"Public Functions inherited from parla::cython::tasks::TaskEnvironment","text":"<p>See parla::cython::tasks::TaskEnvironment</p> Type Name def __contains__ (self self, obj obj)  def __contains__ (self self, obj obj)  def __enter__ (self self)  def __exit__ (self self, exc_type exc_type, exc_val exc_val, exc_tb exc_tb)  def __getitem__ (self self, index index)  def __init__ (self self, environment_list environment_list, blocking blocking=False)  def __len__ (self self)  def __repr__ (self self)  def contexts (self self)  def create_events (self self, tags tags=['default'])  def cupy_stream (self self)  def device (self self)  def devices (self self)  def finalize (self self)  def get_all_devices (self self)  def get_cupy_devices (self self)  def get_devices (self self, arch arch)  def get_library_device (self self)  def get_parla_device (self self)  def global_ids (self self)  def gpu_id (self self)  def gpu_ids (self self)  def has (self self, device_type device_type)  def loop (self self, envlist envlist=None)  def parfor (self self, envlist envlist=None)  def record_events (self self, tags tags=['default'])  def retrieve (self self, key key)  def return_streams (self self)  def storage (self self)  def store (self self, key key, value value)  def stream (self self)  def streams (self self)  def synchronize (self self, events events=False, tags tags=['default'], return_to_pool return_to_pool=True)  def synchronize_events (self self, env env, tags tags=['default'])  def wait_events (self self, env env, tags tags=['default'])  def write_streams_to_task (self self, task task)  def write_to_task (self self, task task)"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1GPUEnvironment/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1GPUEnvironment/#variable-active_stream","title":"variable active_stream","text":"<pre><code>parla.cython.tasks.GPUEnvironment::active_stream;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1GPUEnvironment/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1GPUEnvironment/#function-__enter__","title":"function __enter__","text":"<pre><code>def parla::cython::tasks::GPUEnvironment::__enter__ (\n    self self\n) \n</code></pre> <p>Implements parla::cython::tasks::TaskEnvironment::__enter__</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1GPUEnvironment/#function-__exit__","title":"function __exit__","text":"<pre><code>def parla::cython::tasks::GPUEnvironment::__exit__ (\n    self self,\n    exc_type exc_type,\n    exc_val exc_val,\n    exc_tb exc_tb\n) \n</code></pre> <p>Implements parla::cython::tasks::TaskEnvironment::__exit__</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1GPUEnvironment/#function-__init__","title":"function __init__","text":"<pre><code>def parla::cython::tasks::GPUEnvironment::__init__ (\n    self self,\n    device device,\n    blocking blocking=False\n) \n</code></pre> <p>Implements parla::cython::tasks::TerminalEnvironment::__init__</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1GPUEnvironment/#function-__repr__","title":"function __repr__","text":"<pre><code>def parla::cython::tasks::GPUEnvironment::__repr__ (\n    self self\n) \n</code></pre> <p>Implements parla::cython::tasks::TerminalEnvironment::__repr__</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1GPUEnvironment/#function-finalize","title":"function finalize","text":"<pre><code>def parla::cython::tasks::GPUEnvironment::finalize (\n    self self\n) \n</code></pre> <p>Implements parla::cython::tasks::TaskEnvironment::finalize</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1GPUEnvironment/#function-return_streams","title":"function return_streams","text":"<pre><code>def parla::cython::tasks::GPUEnvironment::return_streams (\n    self self\n) \n</code></pre> <p>Implements parla::cython::tasks::TaskEnvironment::return_streams</p> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/tasks.pyx</code></p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1Task/","title":"Class parla::cython::tasks::Task","text":"<p>ClassList &gt; parla &gt; cython &gt; tasks &gt; Task</p> <p>Python Task interface.More...</p> <p>Inherited by the following classes: parla::cython::tasks::ComputeTask,  parla::cython::tasks::DataMovementTask</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1Task/#public-attributes","title":"Public Attributes","text":"Type Name dependencies id idx inner_task name priority runahead scheduler state taskspace"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1Task/#public-functions","title":"Public Functions","text":"Type Name def __await__ (self self)  def __await__ (self self)  def __hash__ (self self)  def __init__ (self self, taskspace taskspace=None, idx idx=None, state state=TaskCreated(), scheduler scheduler=None, name name=None) Create a new task empty object. def __repr__ (self self)  def add_dataflow (self self, dataflow dataflow)  def add_dependencies (self self, dependency_list dependency_list, process process=False)  def add_event (self self, event event)  def add_stream (self self, stream stream)  def env (self self) The active TaskEnvironment of the task. def env (self self, v v)  def environment (self self) The active TaskEnvironment of the task. def environment (self self, env env)  def get_assigned_devices (self self)  def get_dependencies (self self)  def get_dependents (self self)  str get_name (self self) Get the name of the task. def get_num_blocking_dependencies (self self)  def get_num_dependencies (self self)  def get_num_dependents (self self)  def get_num_unmapped_dependencies (self self)  def get_state (self self) Get the state of the task (from the C++ runtime) def handle_runahead_dependencies (self self) Wait (or synchronize) on all events that the task depends on. def instantiate (self self, dependencies dependencies=None, list_of_dev_reqs list_of_dev_reqs=[], priority priority=None, dataflow dataflow=None, runahead runahead=SyncType.BLOCKING) Add metadata to a blank task object. def notify_dependents_wrapper (self self) Mock dependents interface only used for testing. def py_handle_runahead_dependencies (self self) Wait (or synchronize) on all events that the task depends on. def result (self self) The return value of the task body. def run (self self) Run the task body. def set_complete (self self)  def set_device_reqs (self self, device_reqs device_reqs) Set the device requirements of the task. def set_scheduler (self self, scheduler scheduler) Set the scheduler the task has been spawned by. def set_state (self self, state state) Set the state of the task (passed to the C++ runtime) str unpack_name (self self) Create the name of the task from the taskspace and index. def update_name (self self) Update the name of the task from the taskspace and index."},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1Task/#detailed-description","title":"Detailed Description","text":"<p>This class is used to represent a task in the task graph.</p> <p>A task is a unit of work that can be executed asynchronously. Tasks are created by calling the spawn decorator on a python code block. Tasks are scheduled for execution as soon as they are created.</p> <p>The task class is a wrapper around a C++ task object. The C++ task object is created when the task is spawned and is destroyed when all references to the task are gone. The python interface stores the Python function task body and passes all metadata (mapping and precedence constraints) to the C++ runtime on creations. </p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1Task/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1Task/#variable-dependencies","title":"variable dependencies","text":"<pre><code>parla.cython.tasks.Task::dependencies;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1Task/#variable-id","title":"variable id","text":"<pre><code>parla.cython.tasks.Task::id;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1Task/#variable-idx","title":"variable idx","text":"<pre><code>parla.cython.tasks.Task::idx;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1Task/#variable-inner_task","title":"variable inner_task","text":"<pre><code>parla.cython.tasks.Task::inner_task;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1Task/#variable-name","title":"variable name","text":"<pre><code>parla.cython.tasks.Task::name;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1Task/#variable-priority","title":"variable priority","text":"<pre><code>parla.cython.tasks.Task::priority;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1Task/#variable-runahead","title":"variable runahead","text":"<pre><code>parla.cython.tasks.Task::runahead;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1Task/#variable-scheduler","title":"variable scheduler","text":"<pre><code>parla.cython.tasks.Task::scheduler;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1Task/#variable-state","title":"variable state","text":"<pre><code>parla.cython.tasks.Task::state;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1Task/#variable-taskspace","title":"variable taskspace","text":"<pre><code>parla.cython.tasks.Task::taskspace;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1Task/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1Task/#function-__await__-12","title":"function __await__ [1/2]","text":"<pre><code>def parla::cython::tasks::Task::__await__ (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1Task/#function-__await__-12_1","title":"function __await__ [1/2]","text":"<pre><code>def parla::cython::tasks::Task::__await__ (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1Task/#function-__hash__","title":"function __hash__","text":"<pre><code>def parla::cython::tasks::Task::__hash__ (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1Task/#function-__init__","title":"function __init__","text":"<p>Create a new task empty object. <pre><code>def parla::cython::tasks::Task::__init__ (\n    self self,\n    taskspace taskspace=None,\n    idx idx=None,\n    state state=TaskCreated (),\n    scheduler scheduler=None,\n    name name=None\n) \n</code></pre></p> <p>Task objects are always created empty on first reference and are populated by the runtime when they are spawned. </p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1Task/#function-__repr__","title":"function __repr__","text":"<pre><code>def parla::cython::tasks::Task::__repr__ (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1Task/#function-add_dataflow","title":"function add_dataflow","text":"<pre><code>def parla::cython::tasks::Task::add_dataflow (\n    self self,\n    dataflow dataflow\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1Task/#function-add_dependencies","title":"function add_dependencies","text":"<pre><code>def parla::cython::tasks::Task::add_dependencies (\n    self self,\n    dependency_list dependency_list,\n    process process=False\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1Task/#function-add_event","title":"function add_event","text":"<pre><code>def parla::cython::tasks::Task::add_event (\n    self self,\n    event event\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1Task/#function-add_stream","title":"function add_stream","text":"<pre><code>def parla::cython::tasks::Task::add_stream (\n    self self,\n    stream stream\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1Task/#function-env-12","title":"function env [1/2]","text":"<pre><code>def parla::cython::tasks::Task::env (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1Task/#function-env-22","title":"function env [2/2]","text":"<pre><code>def parla::cython::tasks::Task::env (\n    self self,\n    v v\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1Task/#function-environment-12","title":"function environment [1/2]","text":"<pre><code>def parla::cython::tasks::Task::environment (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1Task/#function-environment-22","title":"function environment [2/2]","text":"<pre><code>def parla::cython::tasks::Task::environment (\n    self self,\n    env env\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1Task/#function-get_assigned_devices","title":"function get_assigned_devices","text":"<pre><code>def parla::cython::tasks::Task::get_assigned_devices (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1Task/#function-get_dependencies","title":"function get_dependencies","text":"<pre><code>def parla::cython::tasks::Task::get_dependencies (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1Task/#function-get_dependents","title":"function get_dependents","text":"<pre><code>def parla::cython::tasks::Task::get_dependents (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1Task/#function-get_name","title":"function get_name","text":"<p>Get the name of the task. <pre><code>str parla::cython::tasks::Task::get_name (\n    self self\n) \n</code></pre></p> <p>Returns:</p> <p>The name of the task. </p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1Task/#function-get_num_blocking_dependencies","title":"function get_num_blocking_dependencies","text":"<pre><code>def parla::cython::tasks::Task::get_num_blocking_dependencies (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1Task/#function-get_num_dependencies","title":"function get_num_dependencies","text":"<pre><code>def parla::cython::tasks::Task::get_num_dependencies (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1Task/#function-get_num_dependents","title":"function get_num_dependents","text":"<pre><code>def parla::cython::tasks::Task::get_num_dependents (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1Task/#function-get_num_unmapped_dependencies","title":"function get_num_unmapped_dependencies","text":"<pre><code>def parla::cython::tasks::Task::get_num_unmapped_dependencies (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1Task/#function-get_state","title":"function get_state","text":"<pre><code>def parla::cython::tasks::Task::get_state (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1Task/#function-handle_runahead_dependencies","title":"function handle_runahead_dependencies","text":"<p>Wait (or synchronize) on all events that the task depends on. <pre><code>def parla::cython::tasks::Task::handle_runahead_dependencies (\n    self self\n) \n</code></pre></p> <p>This handles the synchronization through the C++ interface. </p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1Task/#function-instantiate","title":"function instantiate","text":"<p>Add metadata to a blank task object. <pre><code>def parla::cython::tasks::Task::instantiate (\n    self self,\n    dependencies dependencies=None,\n    list_of_dev_reqs list_of_dev_reqs=[],\n    priority priority=None,\n    dataflow dataflow=None,\n    runahead runahead=SyncType.BLOCKING\n) \n</code></pre></p> <p>Includes dependencies, device requirements, priority, and dataflow. </p> <p>Parameters:</p> <ul> <li><code>dependencies</code> A list of tasks that this task depends on. </li> <li><code>list_of_dev_reqs</code> A list of device requirements/constraints for this task. </li> <li><code>priority</code> The priority of the task. </li> <li><code>dataflow</code> The collection of CrossPy objects and dependence direction (IN/OUT/INOUT). </li> <li><code>runahead</code> The runahead synchronization type of the task. Defaults to SyncType.BLOCKING. </li> </ul>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1Task/#function-notify_dependents_wrapper","title":"function notify_dependents_wrapper","text":"<p>Mock dependents interface only used for testing. <pre><code>def parla::cython::tasks::Task::notify_dependents_wrapper (\n    self self\n) \n</code></pre></p> <p>Notify dependents should be called internall by the scheduler </p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1Task/#function-py_handle_runahead_dependencies","title":"function py_handle_runahead_dependencies","text":"<p>Wait (or synchronize) on all events that the task depends on. <pre><code>def parla::cython::tasks::Task::py_handle_runahead_dependencies (\n    self self\n) \n</code></pre></p> <p>This handles the synchronization through the Python interface. </p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1Task/#function-result","title":"function result","text":"<p>The return value of the task body. <pre><code>def parla::cython::tasks::Task::result (\n    self self\n) \n</code></pre></p> <p>This is only valid after the task has completed.</p> <p>Returns:</p> <p>The return value of the task body or an exception if the task threw an exception. Returns None if the task has not completed. </p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1Task/#function-run","title":"function run","text":"<pre><code>def parla::cython::tasks::Task::run (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1Task/#function-set_complete","title":"function set_complete","text":"<pre><code>def parla::cython::tasks::Task::set_complete (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1Task/#function-set_device_reqs","title":"function set_device_reqs","text":"<p>Set the device requirements of the task. <pre><code>def parla::cython::tasks::Task::set_device_reqs (\n    self self,\n    device_reqs device_reqs\n) \n</code></pre></p> <p>Parameters:</p> <ul> <li><code>device_reqs</code> A list of device requirements. Each device requirement can be a single device, a single architecture, or a tuple of devices and architectures. </li> </ul>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1Task/#function-set_scheduler","title":"function set_scheduler","text":"<pre><code>def parla::cython::tasks::Task::set_scheduler (\n    self self,\n    scheduler scheduler\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1Task/#function-set_state","title":"function set_state","text":"<pre><code>def parla::cython::tasks::Task::set_state (\n    self self,\n    state state\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1Task/#function-unpack_name","title":"function unpack_name","text":"<p>Create the name of the task from the taskspace and index. <pre><code>str parla::cython::tasks::Task::unpack_name (\n    self self\n) \n</code></pre></p> <p>Returns:</p> <p>The name of the task. </p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1Task/#function-update_name","title":"function update_name","text":"<pre><code>def parla::cython::tasks::Task::update_name (\n    self self\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/tasks.pyx</code></p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskCollection/","title":"Class parla::cython::tasks::TaskCollection","text":"<p>ClassList &gt; parla &gt; cython &gt; tasks &gt; TaskCollection</p> <p>Inherited by the following classes: parla::cython::tasks::TaskList,  parla::cython::tasks::TaskSpace</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskCollection/#public-functions","title":"Public Functions","text":"Type Name def __add__ (self self, other other)  def __await__ (self self)  def __contains__ (self self, task task)  def __eq__ (self self, other other)  def __hash__ (self self)  def __iadd__ (self self, other other)  def __init__ (self self, tasks tasks, name name=None, flatten flatten=True)  def __iter__ (self self)  def __len__ (self self)  def __ne__ (self self, other other)  def __repr__ (self self)  def __str__ (self self)  def tasks (self self)"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskCollection/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskCollection/#function-__add__","title":"function __add__","text":"<pre><code>def parla::cython::tasks::TaskCollection::__add__ (\n    self self,\n    other other\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskCollection/#function-__await__","title":"function __await__","text":"<pre><code>def parla::cython::tasks::TaskCollection::__await__ (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskCollection/#function-__contains__","title":"function __contains__","text":"<pre><code>def parla::cython::tasks::TaskCollection::__contains__ (\n    self self,\n    task task\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskCollection/#function-__eq__","title":"function __eq__","text":"<pre><code>def parla::cython::tasks::TaskCollection::__eq__ (\n    self self,\n    other other\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskCollection/#function-__hash__","title":"function __hash__","text":"<pre><code>def parla::cython::tasks::TaskCollection::__hash__ (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskCollection/#function-__iadd__","title":"function __iadd__","text":"<pre><code>def parla::cython::tasks::TaskCollection::__iadd__ (\n    self self,\n    other other\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskCollection/#function-__init__","title":"function __init__","text":"<pre><code>def parla::cython::tasks::TaskCollection::__init__ (\n    self self,\n    tasks tasks,\n    name name=None,\n    flatten flatten=True\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskCollection/#function-__iter__","title":"function __iter__","text":"<pre><code>def parla::cython::tasks::TaskCollection::__iter__ (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskCollection/#function-__len__","title":"function __len__","text":"<pre><code>def parla::cython::tasks::TaskCollection::__len__ (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskCollection/#function-__ne__","title":"function __ne__","text":"<pre><code>def parla::cython::tasks::TaskCollection::__ne__ (\n    self self,\n    other other\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskCollection/#function-__repr__","title":"function __repr__","text":"<pre><code>def parla::cython::tasks::TaskCollection::__repr__ (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskCollection/#function-__str__","title":"function __str__","text":"<pre><code>def parla::cython::tasks::TaskCollection::__str__ (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskCollection/#function-tasks","title":"function tasks","text":"<pre><code>def parla::cython::tasks::TaskCollection::tasks (\n    self self\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/tasks.pyx</code></p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskCompleted/","title":"Class parla::cython::tasks::TaskCompleted","text":"<p>ClassList &gt; parla &gt; cython &gt; tasks &gt; TaskCompleted</p> <p>This state specifies that a task has completed execution. </p> <p>Inherits the following classes: parla::cython::tasks::TaskState</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskCompleted/#public-attributes","title":"Public Attributes","text":"Type Name return_value"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskCompleted/#public-functions","title":"Public Functions","text":"Type Name def __init__ (self self, ret ret)  def __repr__ (self self)  def is_terminal (self self)  def value (self self)"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskCompleted/#public-functions-inherited-from-parlacythontaskstaskstate","title":"Public Functions inherited from parla::cython::tasks::TaskState","text":"<p>See parla::cython::tasks::TaskState</p> Type Name bool is_terminal (self self)  int value (self self)"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskCompleted/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskCompleted/#variable-return_value","title":"variable return_value","text":"<pre><code>parla.cython.tasks.TaskCompleted::return_value;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskCompleted/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskCompleted/#function-__init__","title":"function __init__","text":"<pre><code>def parla::cython::tasks::TaskCompleted::__init__ (\n    self self,\n    ret ret\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskCompleted/#function-__repr__","title":"function __repr__","text":"<pre><code>def parla::cython::tasks::TaskCompleted::__repr__ (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskCompleted/#function-is_terminal","title":"function is_terminal","text":"<pre><code>def parla::cython::tasks::TaskCompleted::is_terminal (\n    self self\n) \n</code></pre> <p>Implements parla::cython::tasks::TaskState::is_terminal</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskCompleted/#function-value","title":"function value","text":"<pre><code>def parla::cython::tasks::TaskCompleted::value (\n    self self\n) \n</code></pre> <p>Implements parla::cython::tasks::TaskState::value</p> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/tasks.pyx</code></p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskCreated/","title":"Class parla::cython::tasks::TaskCreated","text":"<p>ClassList &gt; parla &gt; cython &gt; tasks &gt; TaskCreated</p> <p>This state specifies that a task has been created but not yet spawned. </p> <p>Inherits the following classes: parla::cython::tasks::TaskState</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskCreated/#public-functions","title":"Public Functions","text":"Type Name def is_terminal (self self)  def value (self self)"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskCreated/#public-functions-inherited-from-parlacythontaskstaskstate","title":"Public Functions inherited from parla::cython::tasks::TaskState","text":"<p>See parla::cython::tasks::TaskState</p> Type Name bool is_terminal (self self)  int value (self self)"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskCreated/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskCreated/#function-is_terminal","title":"function is_terminal","text":"<pre><code>def parla::cython::tasks::TaskCreated::is_terminal (\n    self self\n) \n</code></pre> <p>Implements parla::cython::tasks::TaskState::is_terminal</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskCreated/#function-value","title":"function value","text":"<pre><code>def parla::cython::tasks::TaskCreated::value (\n    self self\n) \n</code></pre> <p>Implements parla::cython::tasks::TaskState::value</p> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/tasks.pyx</code></p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskEnvironment/","title":"Class parla::cython::tasks::TaskEnvironment","text":"<p>ClassList &gt; parla &gt; cython &gt; tasks &gt; TaskEnvironment</p> <p>A TaskEnvironment is a collection of devices or other TaskEnvironments used to coordinate and synchronize kernels in theTask body.</p> <p>Inherited by the following classes: parla::cython::tasks::TerminalEnvironment</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskEnvironment/#public-attributes","title":"Public Attributes","text":"Type Name blocking device_dict device_list env_list event_dict is_terminal stream_list"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskEnvironment/#public-functions","title":"Public Functions","text":"Type Name def __contains__ (self self, obj obj)  def __contains__ (self self, obj obj)  def __enter__ (self self)  def __exit__ (self self, exc_type exc_type, exc_val exc_val, exc_tb exc_tb)  def __getitem__ (self self, index index)  def __init__ (self self, environment_list environment_list, blocking blocking=False)  def __len__ (self self)  def __repr__ (self self)  def contexts (self self)  def create_events (self self, tags tags=['default'])  def cupy_stream (self self)  def device (self self)  def devices (self self)  def finalize (self self)  def get_all_devices (self self)  def get_cupy_devices (self self)  def get_devices (self self, arch arch)  def get_library_device (self self)  def get_parla_device (self self)  def global_ids (self self)  def gpu_id (self self)  def gpu_ids (self self)  def has (self self, device_type device_type)  def loop (self self, envlist envlist=None)  def parfor (self self, envlist envlist=None)  def record_events (self self, tags tags=['default'])  def retrieve (self self, key key)  def return_streams (self self)  def storage (self self)  def store (self self, key key, value value)  def stream (self self)  def streams (self self)  def synchronize (self self, events events=False, tags tags=['default'], return_to_pool return_to_pool=True)  def synchronize_events (self self, env env, tags tags=['default'])  def wait_events (self self, env env, tags tags=['default'])  def write_streams_to_task (self self, task task)  def write_to_task (self self, task task)"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskEnvironment/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskEnvironment/#variable-blocking","title":"variable blocking","text":"<pre><code>parla.cython.tasks.TaskEnvironment::blocking;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskEnvironment/#variable-device_dict","title":"variable device_dict","text":"<pre><code>parla.cython.tasks.TaskEnvironment::device_dict;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskEnvironment/#variable-device_list","title":"variable device_list","text":"<pre><code>parla.cython.tasks.TaskEnvironment::device_list;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskEnvironment/#variable-env_list","title":"variable env_list","text":"<pre><code>parla.cython.tasks.TaskEnvironment::env_list;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskEnvironment/#variable-event_dict","title":"variable event_dict","text":"<pre><code>parla.cython.tasks.TaskEnvironment::event_dict;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskEnvironment/#variable-is_terminal","title":"variable is_terminal","text":"<pre><code>parla.cython.tasks.TaskEnvironment::is_terminal;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskEnvironment/#variable-stream_list","title":"variable stream_list","text":"<pre><code>parla.cython.tasks.TaskEnvironment::stream_list;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskEnvironment/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskEnvironment/#function-__contains__-12","title":"function __contains__ [1/2]","text":"<pre><code>def parla::cython::tasks::TaskEnvironment::__contains__ (\n    self self,\n    obj obj\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskEnvironment/#function-__contains__-12_1","title":"function __contains__ [1/2]","text":"<pre><code>def parla::cython::tasks::TaskEnvironment::__contains__ (\n    self self,\n    obj obj\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskEnvironment/#function-__enter__","title":"function __enter__","text":"<pre><code>def parla::cython::tasks::TaskEnvironment::__enter__ (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskEnvironment/#function-__exit__","title":"function __exit__","text":"<pre><code>def parla::cython::tasks::TaskEnvironment::__exit__ (\n    self self,\n    exc_type exc_type,\n    exc_val exc_val,\n    exc_tb exc_tb\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskEnvironment/#function-__getitem__","title":"function __getitem__","text":"<pre><code>def parla::cython::tasks::TaskEnvironment::__getitem__ (\n    self self,\n    index index\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskEnvironment/#function-__init__","title":"function __init__","text":"<pre><code>def parla::cython::tasks::TaskEnvironment::__init__ (\n    self self,\n    environment_list environment_list,\n    blocking blocking=False\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskEnvironment/#function-__len__","title":"function __len__","text":"<pre><code>def parla::cython::tasks::TaskEnvironment::__len__ (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskEnvironment/#function-__repr__","title":"function __repr__","text":"<pre><code>def parla::cython::tasks::TaskEnvironment::__repr__ (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskEnvironment/#function-contexts","title":"function contexts","text":"<pre><code>def parla::cython::tasks::TaskEnvironment::contexts (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskEnvironment/#function-create_events","title":"function create_events","text":"<pre><code>def parla::cython::tasks::TaskEnvironment::create_events (\n    self self,\n    tags tags=['default']\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskEnvironment/#function-cupy_stream","title":"function cupy_stream","text":"<pre><code>def parla::cython::tasks::TaskEnvironment::cupy_stream (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskEnvironment/#function-device","title":"function device","text":"<pre><code>def parla::cython::tasks::TaskEnvironment::device (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskEnvironment/#function-devices","title":"function devices","text":"<pre><code>def parla::cython::tasks::TaskEnvironment::devices (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskEnvironment/#function-finalize","title":"function finalize","text":"<pre><code>def parla::cython::tasks::TaskEnvironment::finalize (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskEnvironment/#function-get_all_devices","title":"function get_all_devices","text":"<pre><code>def parla::cython::tasks::TaskEnvironment::get_all_devices (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskEnvironment/#function-get_cupy_devices","title":"function get_cupy_devices","text":"<pre><code>def parla::cython::tasks::TaskEnvironment::get_cupy_devices (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskEnvironment/#function-get_devices","title":"function get_devices","text":"<pre><code>def parla::cython::tasks::TaskEnvironment::get_devices (\n    self self,\n    arch arch\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskEnvironment/#function-get_library_device","title":"function get_library_device","text":"<pre><code>def parla::cython::tasks::TaskEnvironment::get_library_device (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskEnvironment/#function-get_parla_device","title":"function get_parla_device","text":"<pre><code>def parla::cython::tasks::TaskEnvironment::get_parla_device (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskEnvironment/#function-global_ids","title":"function global_ids","text":"<pre><code>def parla::cython::tasks::TaskEnvironment::global_ids (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskEnvironment/#function-gpu_id","title":"function gpu_id","text":"<pre><code>def parla::cython::tasks::TaskEnvironment::gpu_id (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskEnvironment/#function-gpu_ids","title":"function gpu_ids","text":"<pre><code>def parla::cython::tasks::TaskEnvironment::gpu_ids (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskEnvironment/#function-has","title":"function has","text":"<pre><code>def parla::cython::tasks::TaskEnvironment::has (\n    self self,\n    device_type device_type\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskEnvironment/#function-loop","title":"function loop","text":"<pre><code>def parla::cython::tasks::TaskEnvironment::loop (\n    self self,\n    envlist envlist=None\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskEnvironment/#function-parfor","title":"function parfor","text":"<pre><code>def parla::cython::tasks::TaskEnvironment::parfor (\n    self self,\n    envlist envlist=None\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskEnvironment/#function-record_events","title":"function record_events","text":"<pre><code>def parla::cython::tasks::TaskEnvironment::record_events (\n    self self,\n    tags tags=['default']\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskEnvironment/#function-retrieve","title":"function retrieve","text":"<pre><code>def parla::cython::tasks::TaskEnvironment::retrieve (\n    self self,\n    key key\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskEnvironment/#function-return_streams","title":"function return_streams","text":"<pre><code>def parla::cython::tasks::TaskEnvironment::return_streams (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskEnvironment/#function-storage","title":"function storage","text":"<pre><code>def parla::cython::tasks::TaskEnvironment::storage (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskEnvironment/#function-store","title":"function store","text":"<pre><code>def parla::cython::tasks::TaskEnvironment::store (\n    self self,\n    key key,\n    value value\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskEnvironment/#function-stream","title":"function stream","text":"<pre><code>def parla::cython::tasks::TaskEnvironment::stream (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskEnvironment/#function-streams","title":"function streams","text":"<pre><code>def parla::cython::tasks::TaskEnvironment::streams (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskEnvironment/#function-synchronize","title":"function synchronize","text":"<pre><code>def parla::cython::tasks::TaskEnvironment::synchronize (\n    self self,\n    events events=False,\n    tags tags=['default'],\n    return_to_pool return_to_pool=True\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskEnvironment/#function-synchronize_events","title":"function synchronize_events","text":"<pre><code>def parla::cython::tasks::TaskEnvironment::synchronize_events (\n    self self,\n    env env,\n    tags tags=['default']\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskEnvironment/#function-wait_events","title":"function wait_events","text":"<pre><code>def parla::cython::tasks::TaskEnvironment::wait_events (\n    self self,\n    env env,\n    tags tags=['default']\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskEnvironment/#function-write_streams_to_task","title":"function write_streams_to_task","text":"<pre><code>def parla::cython::tasks::TaskEnvironment::write_streams_to_task (\n    self self,\n    task task\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskEnvironment/#function-write_to_task","title":"function write_to_task","text":"<pre><code>def parla::cython::tasks::TaskEnvironment::write_to_task (\n    self self,\n    task task\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/tasks.pyx</code></p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskException/","title":"Class parla::cython::tasks::TaskException","text":"<p>ClassList &gt; parla &gt; cython &gt; tasks &gt; TaskException</p> <p>This state specifies that a task has completed execution with an exception. </p> <p>Inherits the following classes: parla::cython::tasks::TaskState</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskException/#public-attributes","title":"Public Attributes","text":"Type Name exception traceback"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskException/#public-functions","title":"Public Functions","text":"Type Name def __init__ (self self, exc exc=None, tb tb=None)  def __repr__ (self self)  def is_terminal (self self)  def value (self self)"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskException/#public-functions-inherited-from-parlacythontaskstaskstate","title":"Public Functions inherited from parla::cython::tasks::TaskState","text":"<p>See parla::cython::tasks::TaskState</p> Type Name bool is_terminal (self self)  int value (self self)"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskException/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskException/#variable-exception","title":"variable exception","text":"<pre><code>parla.cython.tasks.TaskException::exception;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskException/#variable-traceback","title":"variable traceback","text":"<pre><code>parla.cython.tasks.TaskException::traceback;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskException/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskException/#function-__init__","title":"function __init__","text":"<pre><code>def parla::cython::tasks::TaskException::__init__ (\n    self self,\n    exc exc=None,\n    tb tb=None\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskException/#function-__repr__","title":"function __repr__","text":"<pre><code>def parla::cython::tasks::TaskException::__repr__ (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskException/#function-is_terminal","title":"function is_terminal","text":"<pre><code>def parla::cython::tasks::TaskException::is_terminal (\n    self self\n) \n</code></pre> <p>Implements parla::cython::tasks::TaskState::is_terminal</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskException/#function-value","title":"function value","text":"<pre><code>def parla::cython::tasks::TaskException::value (\n    self self\n) \n</code></pre> <p>Implements parla::cython::tasks::TaskState::value</p> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/tasks.pyx</code></p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskList/","title":"Class parla::cython::tasks::TaskList","text":"<p>ClassList &gt; parla &gt; cython &gt; tasks &gt; TaskList</p> <p>Inherits the following classes: parla::cython::tasks::TaskCollection</p> <p>Inherited by the following classes: parla::cython::tasks::AtomicTaskList,  parla::cython::tasks::BackendTaskList</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskList/#public-functions","title":"Public Functions","text":"Type Name def __add__ (self self, other other)  def __getitem__ (self self, index index)  def __iadd__ (self self, other other)  def __init__ (self self, tasks tasks, name name=None, flatten flatten=True)  def __repr__ (self self)"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskList/#public-functions-inherited-from-parlacythontaskstaskcollection","title":"Public Functions inherited from parla::cython::tasks::TaskCollection","text":"<p>See parla::cython::tasks::TaskCollection</p> Type Name def __add__ (self self, other other)  def __await__ (self self)  def __contains__ (self self, task task)  def __eq__ (self self, other other)  def __hash__ (self self)  def __iadd__ (self self, other other)  def __init__ (self self, tasks tasks, name name=None, flatten flatten=True)  def __iter__ (self self)  def __len__ (self self)  def __ne__ (self self, other other)  def __repr__ (self self)  def __str__ (self self)  def tasks (self self)"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskList/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskList/#function-__add__","title":"function __add__","text":"<pre><code>def parla::cython::tasks::TaskList::__add__ (\n    self self,\n    other other\n) \n</code></pre> <p>Implements parla::cython::tasks::TaskCollection::__add__</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskList/#function-__getitem__","title":"function __getitem__","text":"<pre><code>def parla::cython::tasks::TaskList::__getitem__ (\n    self self,\n    index index\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskList/#function-__iadd__","title":"function __iadd__","text":"<pre><code>def parla::cython::tasks::TaskList::__iadd__ (\n    self self,\n    other other\n) \n</code></pre> <p>Implements parla::cython::tasks::TaskCollection::__iadd__</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskList/#function-__init__","title":"function __init__","text":"<pre><code>def parla::cython::tasks::TaskList::__init__ (\n    self self,\n    tasks tasks,\n    name name=None,\n    flatten flatten=True\n) \n</code></pre> <p>Implements parla::cython::tasks::TaskCollection::__init__</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskList/#function-__repr__","title":"function __repr__","text":"<pre><code>def parla::cython::tasks::TaskList::__repr__ (\n    self self\n) \n</code></pre> <p>Implements parla::cython::tasks::TaskCollection::__repr__</p> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/tasks.pyx</code></p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskMapped/","title":"Class parla::cython::tasks::TaskMapped","text":"<p>ClassList &gt; parla &gt; cython &gt; tasks &gt; TaskMapped</p> <p>This state specifies that a task has been mapped to a device set, but not yet resered its resources there. </p> <p>Inherits the following classes: parla::cython::tasks::TaskState</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskMapped/#public-functions","title":"Public Functions","text":"Type Name def is_terminal (self self)  def value (self self)"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskMapped/#public-functions-inherited-from-parlacythontaskstaskstate","title":"Public Functions inherited from parla::cython::tasks::TaskState","text":"<p>See parla::cython::tasks::TaskState</p> Type Name bool is_terminal (self self)  int value (self self)"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskMapped/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskMapped/#function-is_terminal","title":"function is_terminal","text":"<pre><code>def parla::cython::tasks::TaskMapped::is_terminal (\n    self self\n) \n</code></pre> <p>Implements parla::cython::tasks::TaskState::is_terminal</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskMapped/#function-value","title":"function value","text":"<pre><code>def parla::cython::tasks::TaskMapped::value (\n    self self\n) \n</code></pre> <p>Implements parla::cython::tasks::TaskState::value</p> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/tasks.pyx</code></p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskReady/","title":"Class parla::cython::tasks::TaskReady","text":"<p>ClassList &gt; parla &gt; cython &gt; tasks &gt; TaskReady</p> <p>This state specifies that a task is \"ready\" to be launched. More...</p> <p>Inherits the following classes: parla::cython::tasks::TaskState</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskReady/#public-functions","title":"Public Functions","text":"Type Name def is_terminal (self self)  def value (self self)"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskReady/#public-functions-inherited-from-parlacythontaskstaskstate","title":"Public Functions inherited from parla::cython::tasks::TaskState","text":"<p>See parla::cython::tasks::TaskState</p> Type Name bool is_terminal (self self)  int value (self self)"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskReady/#detailed-description","title":"Detailed Description","text":"<p>Its dependencies have been dispatched to hardware queues (or have completed) </p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskReady/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskReady/#function-is_terminal","title":"function is_terminal","text":"<pre><code>def parla::cython::tasks::TaskReady::is_terminal (\n    self self\n) \n</code></pre> <p>Implements parla::cython::tasks::TaskState::is_terminal</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskReady/#function-value","title":"function value","text":"<pre><code>def parla::cython::tasks::TaskReady::value (\n    self self\n) \n</code></pre> <p>Implements parla::cython::tasks::TaskState::value</p> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/tasks.pyx</code></p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskReserved/","title":"Class parla::cython::tasks::TaskReserved","text":"<p>ClassList &gt; parla &gt; cython &gt; tasks &gt; TaskReserved</p> <p>This state specifies that a task has reserved its persistent resources (e.g. More...</p> <p>Inherits the following classes: parla::cython::tasks::TaskState</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskReserved/#public-functions","title":"Public Functions","text":"Type Name def is_terminal (self self)  def value (self self)"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskReserved/#public-functions-inherited-from-parlacythontaskstaskstate","title":"Public Functions inherited from parla::cython::tasks::TaskState","text":"<p>See parla::cython::tasks::TaskState</p> Type Name bool is_terminal (self self)  int value (self self)"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskReserved/#detailed-description","title":"Detailed Description","text":"<p>memory) on its device set. Data movement tasks have been created </p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskReserved/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskReserved/#function-is_terminal","title":"function is_terminal","text":"<pre><code>def parla::cython::tasks::TaskReserved::is_terminal (\n    self self\n) \n</code></pre> <p>Implements parla::cython::tasks::TaskState::is_terminal</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskReserved/#function-value","title":"function value","text":"<pre><code>def parla::cython::tasks::TaskReserved::value (\n    self self\n) \n</code></pre> <p>Implements parla::cython::tasks::TaskState::value</p> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/tasks.pyx</code></p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskRunahead/","title":"Class parla::cython::tasks::TaskRunahead","text":"<p>ClassList &gt; parla &gt; cython &gt; tasks &gt; TaskRunahead</p> <p>State: A task is executing in a stream but the body has completed. </p> <p>Inherits the following classes: parla::cython::tasks::TaskState</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskRunahead/#public-attributes","title":"Public Attributes","text":"Type Name return_value"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskRunahead/#public-functions","title":"Public Functions","text":"Type Name def __init__ (self self, ret ret)  def __repr__ (self self)  def is_terminal (self self)  def value (self self)"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskRunahead/#public-functions-inherited-from-parlacythontaskstaskstate","title":"Public Functions inherited from parla::cython::tasks::TaskState","text":"<p>See parla::cython::tasks::TaskState</p> Type Name bool is_terminal (self self)  int value (self self)"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskRunahead/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskRunahead/#variable-return_value","title":"variable return_value","text":"<pre><code>parla.cython.tasks.TaskRunahead::return_value;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskRunahead/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskRunahead/#function-__init__","title":"function __init__","text":"<pre><code>def parla::cython::tasks::TaskRunahead::__init__ (\n    self self,\n    ret ret\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskRunahead/#function-__repr__","title":"function __repr__","text":"<pre><code>def parla::cython::tasks::TaskRunahead::__repr__ (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskRunahead/#function-is_terminal","title":"function is_terminal","text":"<pre><code>def parla::cython::tasks::TaskRunahead::is_terminal (\n    self self\n) \n</code></pre> <p>Implements parla::cython::tasks::TaskState::is_terminal</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskRunahead/#function-value","title":"function value","text":"<pre><code>def parla::cython::tasks::TaskRunahead::value (\n    self self\n) \n</code></pre> <p>Implements parla::cython::tasks::TaskState::value</p> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/tasks.pyx</code></p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskRunning/","title":"Class parla::cython::tasks::TaskRunning","text":"<p>ClassList &gt; parla &gt; cython &gt; tasks &gt; TaskRunning</p> <p>This state specifies that a task is executing in a stream. </p> <p>Inherits the following classes: parla::cython::tasks::TaskState</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskRunning/#public-attributes","title":"Public Attributes","text":"Type Name args dependencies func"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskRunning/#public-functions","title":"Public Functions","text":"Type Name def __init__ (self self, func func, args args, Optional dependencies)  def __repr__ (self self)  def clear_dependencies (self self)  def is_terminal (self self)  def value (self self)"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskRunning/#public-functions-inherited-from-parlacythontaskstaskstate","title":"Public Functions inherited from parla::cython::tasks::TaskState","text":"<p>See parla::cython::tasks::TaskState</p> Type Name bool is_terminal (self self)  int value (self self)"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskRunning/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskRunning/#variable-args","title":"variable args","text":"<pre><code>parla.cython.tasks.TaskRunning::args;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskRunning/#variable-dependencies","title":"variable dependencies","text":"<pre><code>parla.cython.tasks.TaskRunning::dependencies;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskRunning/#variable-func","title":"variable func","text":"<pre><code>parla.cython.tasks.TaskRunning::func;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskRunning/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskRunning/#function-__init__","title":"function __init__","text":"<pre><code>def parla::cython::tasks::TaskRunning::__init__ (\n    self self,\n    func func,\n    args args,\n    Optional dependencies\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskRunning/#function-__repr__","title":"function __repr__","text":"<pre><code>def parla::cython::tasks::TaskRunning::__repr__ (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskRunning/#function-clear_dependencies","title":"function clear_dependencies","text":"<pre><code>def parla::cython::tasks::TaskRunning::clear_dependencies (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskRunning/#function-is_terminal","title":"function is_terminal","text":"<pre><code>def parla::cython::tasks::TaskRunning::is_terminal (\n    self self\n) \n</code></pre> <p>Implements parla::cython::tasks::TaskState::is_terminal</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskRunning/#function-value","title":"function value","text":"<pre><code>def parla::cython::tasks::TaskRunning::value (\n    self self\n) \n</code></pre> <p>Implements parla::cython::tasks::TaskState::value</p> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/tasks.pyx</code></p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskSpace/","title":"Class parla::cython::tasks::TaskSpace","text":"<p>ClassList &gt; parla &gt; cython &gt; tasks &gt; TaskSpace</p> <p>Inherits the following classes: parla::cython::tasks::TaskCollection</p> <p>Inherited by the following classes: parla::cython::tasks::AtomicTaskSpace,  parla::cython::tasks::BackendTaskSpace</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskSpace/#public-attributes","title":"Public Attributes","text":"Type Name shape start"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskSpace/#public-functions","title":"Public Functions","text":"Type Name def __add__ (self self, other other)  def __getitem__ (self self, index index)  def __iadd__ (self self, other other)  def __init__ (self self, name name=\"\", create create=True, shape shape=None, start start=None)  def __repr__ (self self)  def name (self self)  def tasks (self self)  def view (self self)"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskSpace/#public-functions-inherited-from-parlacythontaskstaskcollection","title":"Public Functions inherited from parla::cython::tasks::TaskCollection","text":"<p>See parla::cython::tasks::TaskCollection</p> Type Name def __add__ (self self, other other)  def __await__ (self self)  def __contains__ (self self, task task)  def __eq__ (self self, other other)  def __hash__ (self self)  def __iadd__ (self self, other other)  def __init__ (self self, tasks tasks, name name=None, flatten flatten=True)  def __iter__ (self self)  def __len__ (self self)  def __ne__ (self self, other other)  def __repr__ (self self)  def __str__ (self self)  def tasks (self self)"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskSpace/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskSpace/#variable-shape","title":"variable shape","text":"<pre><code>parla.cython.tasks.TaskSpace::shape;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskSpace/#variable-start","title":"variable start","text":"<pre><code>parla.cython.tasks.TaskSpace::start;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskSpace/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskSpace/#function-__add__","title":"function __add__","text":"<pre><code>def parla::cython::tasks::TaskSpace::__add__ (\n    self self,\n    other other\n) \n</code></pre> <p>Implements parla::cython::tasks::TaskCollection::__add__</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskSpace/#function-__getitem__","title":"function __getitem__","text":"<pre><code>def parla::cython::tasks::TaskSpace::__getitem__ (\n    self self,\n    index index\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskSpace/#function-__iadd__","title":"function __iadd__","text":"<pre><code>def parla::cython::tasks::TaskSpace::__iadd__ (\n    self self,\n    other other\n) \n</code></pre> <p>Implements parla::cython::tasks::TaskCollection::__iadd__</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskSpace/#function-__init__","title":"function __init__","text":"<pre><code>def parla::cython::tasks::TaskSpace::__init__ (\n    self self,\n    name name=\"\",\n    create create=True,\n    shape shape=None,\n    start start=None\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskSpace/#function-__repr__","title":"function __repr__","text":"<pre><code>def parla::cython::tasks::TaskSpace::__repr__ (\n    self self\n) \n</code></pre> <p>Implements parla::cython::tasks::TaskCollection::__repr__</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskSpace/#function-name","title":"function name","text":"<pre><code>def parla::cython::tasks::TaskSpace::name (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskSpace/#function-tasks","title":"function tasks","text":"<pre><code>def parla::cython::tasks::TaskSpace::tasks (\n    self self\n) \n</code></pre> <p>Implements parla::cython::tasks::TaskCollection::tasks</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskSpace/#function-view","title":"function view","text":"<pre><code>def parla::cython::tasks::TaskSpace::view (\n    self self\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/tasks.pyx</code></p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskSpawned/","title":"Class parla::cython::tasks::TaskSpawned","text":"<p>ClassList &gt; parla &gt; cython &gt; tasks &gt; TaskSpawned</p> <p>This state specifies that a task is ready to be mapped to a specific device set. </p> <p>Inherits the following classes: parla::cython::tasks::TaskState</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskSpawned/#public-functions","title":"Public Functions","text":"Type Name def is_terminal (self self)  def value (self self)"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskSpawned/#public-functions-inherited-from-parlacythontaskstaskstate","title":"Public Functions inherited from parla::cython::tasks::TaskState","text":"<p>See parla::cython::tasks::TaskState</p> Type Name bool is_terminal (self self)  int value (self self)"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskSpawned/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskSpawned/#function-is_terminal","title":"function is_terminal","text":"<pre><code>def parla::cython::tasks::TaskSpawned::is_terminal (\n    self self\n) \n</code></pre> <p>Implements parla::cython::tasks::TaskState::is_terminal</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskSpawned/#function-value","title":"function value","text":"<pre><code>def parla::cython::tasks::TaskSpawned::value (\n    self self\n) \n</code></pre> <p>Implements parla::cython::tasks::TaskState::value</p> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/tasks.pyx</code></p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskState/","title":"Class parla::cython::tasks::TaskState","text":"<p>ClassList &gt; parla &gt; cython &gt; tasks &gt; TaskState</p> <p>Abstract base class for Task State.</p> <p>Inherits the following classes: object,  metaclass,  ABCMeta</p> <p>Inherited by the following classes: parla::cython::tasks::TaskCompleted,  parla::cython::tasks::TaskCreated,  parla::cython::tasks::TaskException,  parla::cython::tasks::TaskMapped,  parla::cython::tasks::TaskReady,  parla::cython::tasks::TaskReserved,  parla::cython::tasks::TaskRunahead,  parla::cython::tasks::TaskRunning,  parla::cython::tasks::TaskSpawned</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskState/#public-functions","title":"Public Functions","text":"Type Name bool is_terminal (self self)  int value (self self)"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskState/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskState/#function-is_terminal","title":"function is_terminal","text":"<pre><code>bool parla::cython::tasks::TaskState::is_terminal (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TaskState/#function-value","title":"function value","text":"<pre><code>int parla::cython::tasks::TaskState::value (\n    self self\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/tasks.pyx</code></p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TerminalEnvironment/","title":"Class parla::cython::tasks::TerminalEnvironment","text":"<p>ClassList &gt; parla &gt; cython &gt; tasks &gt; TerminalEnvironment</p> <p>An endpoint TaskEnvironment representing a single device.More...</p> <p>Inherits the following classes: parla::cython::tasks::TaskEnvironment</p> <p>Inherited by the following classes: parla::cython::tasks::CPUEnvironment,  parla::cython::tasks::GPUEnvironment</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TerminalEnvironment/#public-attributes","title":"Public Attributes","text":"Type Name is_terminal"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TerminalEnvironment/#public-attributes-inherited-from-parlacythontaskstaskenvironment","title":"Public Attributes inherited from parla::cython::tasks::TaskEnvironment","text":"<p>See parla::cython::tasks::TaskEnvironment</p> Type Name blocking device_dict device_list env_list event_dict is_terminal stream_list"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TerminalEnvironment/#public-functions","title":"Public Functions","text":"Type Name def __call__ (self self)  def __eq__ (self self, other other)  def __getitem__ (self self, index index)  def __hash__ (self self)  def __init__ (self self, device device, blocking blocking=False)  def __len__ (self self)  def __repr__ (self self)  def architecture (self self)  def contexts (self self)  def create_event (self self, stream stream=None, tag tag='default') Create a CUDA event on the current stream. def device (self self)  def devices (self self)  def record_event (self self, stream stream=None, tag tag='default') Record a CUDA event on the current stream. def synchronize_event (self self, tag tag='default') Synchronize host thread to the tagged CUDA event (sleep or waiting). def wait_event (self self, stream stream=None, tag tag='default') Submit a cross-stream wait on the tagged CUDA event to the current stream. def write_events_to_task (self self, task task) Record event pointers in C++ task. def write_streams_to_task (self self, task task) Record stream pointers into C++ task. def write_to_task (self self, task task) Store stream and event pointers in C++ task."},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TerminalEnvironment/#public-functions-inherited-from-parlacythontaskstaskenvironment","title":"Public Functions inherited from parla::cython::tasks::TaskEnvironment","text":"<p>See parla::cython::tasks::TaskEnvironment</p> Type Name def __contains__ (self self, obj obj)  def __contains__ (self self, obj obj)  def __enter__ (self self)  def __exit__ (self self, exc_type exc_type, exc_val exc_val, exc_tb exc_tb)  def __getitem__ (self self, index index)  def __init__ (self self, environment_list environment_list, blocking blocking=False)  def __len__ (self self)  def __repr__ (self self)  def contexts (self self)  def create_events (self self, tags tags=['default'])  def cupy_stream (self self)  def device (self self)  def devices (self self)  def finalize (self self)  def get_all_devices (self self)  def get_cupy_devices (self self)  def get_devices (self self, arch arch)  def get_library_device (self self)  def get_parla_device (self self)  def global_ids (self self)  def gpu_id (self self)  def gpu_ids (self self)  def has (self self, device_type device_type)  def loop (self self, envlist envlist=None)  def parfor (self self, envlist envlist=None)  def record_events (self self, tags tags=['default'])  def retrieve (self self, key key)  def return_streams (self self)  def storage (self self)  def store (self self, key key, value value)  def stream (self self)  def streams (self self)  def synchronize (self self, events events=False, tags tags=['default'], return_to_pool return_to_pool=True)  def synchronize_events (self self, env env, tags tags=['default'])  def wait_events (self self, env env, tags tags=['default'])  def write_streams_to_task (self self, task task)  def write_to_task (self self, task task)"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TerminalEnvironment/#detailed-description","title":"Detailed Description","text":"<p>These are where most actual computation will take place.</p> <p>A TerminalEnviornment is an edpoint TaskEnvironment that is made of a single device (CPU or GPU). If they are a GPU they will set the current CuPy context accordingly. </p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TerminalEnvironment/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TerminalEnvironment/#variable-is_terminal","title":"variable is_terminal","text":"<pre><code>parla.cython.tasks.TerminalEnvironment::is_terminal;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TerminalEnvironment/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TerminalEnvironment/#function-__call__","title":"function __call__","text":"<pre><code>def parla::cython::tasks::TerminalEnvironment::__call__ (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TerminalEnvironment/#function-__eq__","title":"function __eq__","text":"<pre><code>def parla::cython::tasks::TerminalEnvironment::__eq__ (\n    self self,\n    other other\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TerminalEnvironment/#function-__getitem__","title":"function __getitem__","text":"<pre><code>def parla::cython::tasks::TerminalEnvironment::__getitem__ (\n    self self,\n    index index\n) \n</code></pre> <p>Implements parla::cython::tasks::TaskEnvironment::__getitem__</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TerminalEnvironment/#function-__hash__","title":"function __hash__","text":"<pre><code>def parla::cython::tasks::TerminalEnvironment::__hash__ (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TerminalEnvironment/#function-__init__","title":"function __init__","text":"<pre><code>def parla::cython::tasks::TerminalEnvironment::__init__ (\n    self self,\n    device device,\n    blocking blocking=False\n) \n</code></pre> <p>Implements parla::cython::tasks::TaskEnvironment::__init__</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TerminalEnvironment/#function-__len__","title":"function __len__","text":"<pre><code>def parla::cython::tasks::TerminalEnvironment::__len__ (\n    self self\n) \n</code></pre> <p>Implements parla::cython::tasks::TaskEnvironment::__len__</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TerminalEnvironment/#function-__repr__","title":"function __repr__","text":"<pre><code>def parla::cython::tasks::TerminalEnvironment::__repr__ (\n    self self\n) \n</code></pre> <p>Implements parla::cython::tasks::TaskEnvironment::__repr__</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TerminalEnvironment/#function-architecture","title":"function architecture","text":"<pre><code>def parla::cython::tasks::TerminalEnvironment::architecture (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TerminalEnvironment/#function-contexts","title":"function contexts","text":"<pre><code>def parla::cython::tasks::TerminalEnvironment::contexts (\n    self self\n) \n</code></pre> <p>Implements parla::cython::tasks::TaskEnvironment::contexts</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TerminalEnvironment/#function-create_event","title":"function create_event","text":"<p>Create a CUDA event on the current stream. <pre><code>def parla::cython::tasks::TerminalEnvironment::create_event (\n    self self,\n    stream stream=None,\n    tag tag='default'\n) \n</code></pre></p> <p>It can be used for synchronization or cross-stream waiting. It is not recorded by default at creation. </p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TerminalEnvironment/#function-device","title":"function device","text":"<pre><code>def parla::cython::tasks::TerminalEnvironment::device (\n    self self\n) \n</code></pre> <p>Implements parla::cython::tasks::TaskEnvironment::device</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TerminalEnvironment/#function-devices","title":"function devices","text":"<pre><code>def parla::cython::tasks::TerminalEnvironment::devices (\n    self self\n) \n</code></pre> <p>Implements parla::cython::tasks::TaskEnvironment::devices</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TerminalEnvironment/#function-record_event","title":"function record_event","text":"<pre><code>def parla::cython::tasks::TerminalEnvironment::record_event (\n    self self,\n    stream stream=None,\n    tag tag='default'\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TerminalEnvironment/#function-synchronize_event","title":"function synchronize_event","text":"<pre><code>def parla::cython::tasks::TerminalEnvironment::synchronize_event (\n    self self,\n    tag tag='default'\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TerminalEnvironment/#function-wait_event","title":"function wait_event","text":"<p>Submit a cross-stream wait on the tagged CUDA event to the current stream. <pre><code>def parla::cython::tasks::TerminalEnvironment::wait_event (\n    self self,\n    stream stream=None,\n    tag tag='default'\n) \n</code></pre></p> <p>All further work submitted on the current stream will wait until the tagged event is recorded. </p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TerminalEnvironment/#function-write_events_to_task","title":"function write_events_to_task","text":"<pre><code>def parla::cython::tasks::TerminalEnvironment::write_events_to_task (\n    self self,\n    task task\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TerminalEnvironment/#function-write_streams_to_task","title":"function write_streams_to_task","text":"<pre><code>def parla::cython::tasks::TerminalEnvironment::write_streams_to_task (\n    self self,\n    task task\n) \n</code></pre> <p>Implements parla::cython::tasks::TaskEnvironment::write_streams_to_task</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1TerminalEnvironment/#function-write_to_task","title":"function write_to_task","text":"<pre><code>def parla::cython::tasks::TerminalEnvironment::write_to_task (\n    self self,\n    task task\n) \n</code></pre> <p>Implements parla::cython::tasks::TaskEnvironment::write_to_task</p> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/tasks.pyx</code></p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1__TaskLocals/","title":"Class parla::cython::tasks::_TaskLocals","text":"<p>ClassList &gt; parla &gt; cython &gt; tasks &gt; _TaskLocals</p> <p>Inherits the following classes: threading.local</p>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1__TaskLocals/#public-attributes","title":"Public Attributes","text":"Type Name spawn_count task_scopes"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1__TaskLocals/#public-functions","title":"Public Functions","text":"Type Name def __init__ (self self)  def ctx (self self)  def ctx (self self, v v)  def global_tasks (self self)  def global_tasks (self self, v v)"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1__TaskLocals/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1__TaskLocals/#variable-spawn_count","title":"variable spawn_count","text":"<pre><code>parla.cython.tasks._TaskLocals::spawn_count;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1__TaskLocals/#variable-task_scopes","title":"variable task_scopes","text":"<pre><code>parla.cython.tasks._TaskLocals::task_scopes;\n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1__TaskLocals/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1__TaskLocals/#function-__init__","title":"function __init__","text":"<pre><code>def parla::cython::tasks::_TaskLocals::__init__ (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1__TaskLocals/#function-ctx-12","title":"function ctx [1/2]","text":"<pre><code>def parla::cython::tasks::_TaskLocals::ctx (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1__TaskLocals/#function-ctx-22","title":"function ctx [2/2]","text":"<pre><code>def parla::cython::tasks::_TaskLocals::ctx (\n    self self,\n    v v\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1__TaskLocals/#function-global_tasks-12","title":"function global_tasks [1/2]","text":"<pre><code>def parla::cython::tasks::_TaskLocals::global_tasks (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1tasks_1_1__TaskLocals/#function-global_tasks-22","title":"function global_tasks [2/2]","text":"<pre><code>def parla::cython::tasks::_TaskLocals::global_tasks (\n    self self,\n    v v\n) \n</code></pre> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/tasks.pyx</code></p>"},{"location":"runtime/namespaceparla_1_1cython_1_1variants/","title":"Namespace parla::cython::variants","text":"<p>Namespace List &gt; parla &gt; cython &gt; variants</p>"},{"location":"runtime/namespaceparla_1_1cython_1_1variants/#classes","title":"Classes","text":"Type Name class VariantDefinitionError Error for an invalid function variant definition. class _VariantFunction Function wrapper that dispatches to different architecture targets."},{"location":"runtime/namespaceparla_1_1cython_1_1variants/#public-functions","title":"Public Functions","text":"Type Name def specialize (func func) Decorator to create a function with specialized variants for different architectures."},{"location":"runtime/namespaceparla_1_1cython_1_1variants/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/namespaceparla_1_1cython_1_1variants/#function-specialize","title":"function specialize","text":"<p>Decorator to create a function with specialized variants for different architectures. <pre><code>def parla::cython::variants::specialize (\n    func func\n) \n</code></pre></p> <p>The default implementation is the decorated function.</p> <p>A decorator to declare that this function has specialized variants for specific architectures. The decorated function is the default implemention, used when no specialized implementation is available. The default can just be <code>raise NotImplementedError()</code> in cases where no default implementation is possible. To provide a specialized variant use the <code>variant</code> member of the main function: .. testsetup:: from parla.function_decorators import * </p> <p>@specialized </p> <p>... def f(): ... raise NotImplementedError() </p> <p>@f.variant(architecture) </p> <p>... def f_gpu(): ... ... <code>architecture</code> above will often by something like <code>cpu</code> or <code>gpu</code>, but is extensible. Multiple architectures can be specified as separate parameters to use the same implementation on multiple architectures: <code>@f.variant(CPU, FPGA)</code>. Each architecture can only be used once on a given function. Architecture specialized functions are called just like any other function, but the implementation which is called is selected based on where the code executes. The compiler will make the choice when it is compiling for a specific target. </p> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/variants.pyx</code></p>"},{"location":"runtime/classparla_1_1cython_1_1variants_1_1VariantDefinitionError/","title":"Class parla::cython::variants::VariantDefinitionError","text":"<p>ClassList &gt; parla &gt; cython &gt; variants &gt; VariantDefinitionError</p> <p>Error for an invalid function variant definition. </p> <p>Inherits the following classes: ValueError</p> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/variants.pyx</code></p>"},{"location":"runtime/classparla_1_1cython_1_1variants_1_1__VariantFunction/","title":"Class parla::cython::variants::_VariantFunction","text":"<p>ClassList &gt; parla &gt; cython &gt; variants &gt; _VariantFunction</p> <p>Function wrapper that dispatches to different architecture targets. More...</p> <p>Inherits the following classes: object</p>"},{"location":"runtime/classparla_1_1cython_1_1variants_1_1__VariantFunction/#public-functions","title":"Public Functions","text":"Type Name def __call__ (self self, * args, ** kwargs) Call the function, dispatching to the appropriate variant. def __init__ (self self, func func)  def __repr__ (self self)  def get_variant (self self, spec_key spec_key) Get the variant for a given specialization key. def variant (self self, spec_list spec_list, override override=False) Decorator to declare a variant of this function for a specific architecture."},{"location":"runtime/classparla_1_1cython_1_1variants_1_1__VariantFunction/#detailed-description","title":"Detailed Description","text":"<p>Specialization is only supported on the architecture level. Specifying specifications for specific devices (e.g. gpu(0) )is not supported. </p>"},{"location":"runtime/classparla_1_1cython_1_1variants_1_1__VariantFunction/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classparla_1_1cython_1_1variants_1_1__VariantFunction/#function-__call__","title":"function __call__","text":"<pre><code>def parla::cython::variants::_VariantFunction::__call__ (\n    self self,\n    * args,\n    ** kwargs\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1variants_1_1__VariantFunction/#function-__init__","title":"function __init__","text":"<pre><code>def parla::cython::variants::_VariantFunction::__init__ (\n    self self,\n    func func\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1variants_1_1__VariantFunction/#function-__repr__","title":"function __repr__","text":"<pre><code>def parla::cython::variants::_VariantFunction::__repr__ (\n    self self\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1variants_1_1__VariantFunction/#function-get_variant","title":"function get_variant","text":"<pre><code>def parla::cython::variants::_VariantFunction::get_variant (\n    self self,\n    spec_key spec_key\n) \n</code></pre>"},{"location":"runtime/classparla_1_1cython_1_1variants_1_1__VariantFunction/#function-variant","title":"function variant","text":"<p>Decorator to declare a variant of this function for a specific architecture. <pre><code>def parla::cython::variants::_VariantFunction::variant (\n    self self,\n    spec_list spec_list,\n    override override=False\n) \n</code></pre></p> <p>Parameters:</p> <ul> <li><code>spec_list</code> A list of architectures to specialize this function for. Can be a single architecture, or a list of architectures. Each architecture can be a tuple of architectures to specialize for a multidevice configuration. </li> <li><code>override</code> If true, allow overriding an existing variant for one of the given architectures. </li> </ul> <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/variants.pyx</code></p>"},{"location":"runtime/namespaceparray/","title":"Namespace parray","text":"<p>Namespace List &gt; parray</p>"},{"location":"runtime/namespaceparray/#classes","title":"Classes","text":"Type Name class InnerPArray class PArrayState <p>The documentation for this class was generated from the following file <code>src/c/backend/include/parray.hpp</code></p>"},{"location":"runtime/classparray_1_1InnerPArray/","title":"Class parray::InnerPArray","text":"<p>ClassList &gt; parray &gt; InnerPArray</p>"},{"location":"runtime/classparray_1_1InnerPArray/#public-attributes","title":"Public Attributes","text":"Type Name uint64_t id std::vector&lt; CopyableAtomic&lt; size_t &gt; &gt; num_active_tasks Track the number of tasks that are using or are planning to use this PArray. uint64_t parent_id"},{"location":"runtime/classparray_1_1InnerPArray/#public-functions","title":"Public Functions","text":"Type Name InnerPArray () = delete InnerPArray (void * py_parray, uint64_t id, uint64_t parent_id, InnerPArray * parent_parray, PArrayState * state, DevID_t num_devices)  void add_task (InnerTask * task) Add a pointer of the task that will use this PArray to the task list. void decr_num_active_tasks (DevID_t global_dev_id) Decrease the counter for the active tasks that use this PArray. bool exists_on_device (uint64_t device_id) Return True if there is an PArray copy (possibly invalid) on this device. size_t get_num_active_tasks (DevID_t global_dev_id) Get the number of counter for the active tasks that use this PArray. InnerPArray * get_parent_parray () Return a pointer of the parent PArray. uint64_t get_parray_parentid () Return the parent id of the current instance. void * get_py_parray () Return the instance of Python PArray. const uint64_t get_size () constGet current size (in bytes) of each copy of the PArray if it is a subarray, return the subarray's size. TaskList &amp; get_task_list_ref () Get a reference to a list of tasks who are using this PArray. void incr_num_active_tasks (DevID_t global_dev_id) Increase the counter for the active tasks that use this PArray. void set_size (uint64_t new_size) Set the size of the PArray. bool valid_on_device (uint64_t device_id) Return True if there is an PArray copy and its coherence state is valid on this device."},{"location":"runtime/classparray_1_1InnerPArray/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"runtime/classparray_1_1InnerPArray/#variable-id","title":"variable id","text":"<pre><code>uint64_t parray::InnerPArray::id;\n</code></pre>"},{"location":"runtime/classparray_1_1InnerPArray/#variable-num_active_tasks","title":"variable num_active_tasks","text":"<p>Track the number of tasks that are using or are planning to use this PArray. <pre><code>std::vector&lt;CopyableAtomic&lt;size_t&gt; &gt; parray::InnerPArray::num_active_tasks;\n</code></pre></p> <p>NOTE that this counter is not necessarily matching to the size of the <code>_task_lists</code>. This is because <code>_task_lists</code> does not remove a task after it is completed (since it is not worth to remove that compared to restructuring overheads), but this counter is decreased. This is used to provide more accurate PArray placement information to the task mapping step. </p>"},{"location":"runtime/classparray_1_1InnerPArray/#variable-parent_id","title":"variable parent_id","text":"<pre><code>uint64_t parray::InnerPArray::parent_id;\n</code></pre>"},{"location":"runtime/classparray_1_1InnerPArray/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classparray_1_1InnerPArray/#function-innerparray-12","title":"function InnerPArray [1/2]","text":"<pre><code>parray::InnerPArray::InnerPArray () = delete\n</code></pre>"},{"location":"runtime/classparray_1_1InnerPArray/#function-innerparray-22","title":"function InnerPArray [2/2]","text":"<pre><code>parray::InnerPArray::InnerPArray (\nvoid * py_parray,\nuint64_t id,\nuint64_t parent_id,\nInnerPArray * parent_parray,\nPArrayState * state,\nDevID_t num_devices\n) </code></pre>"},{"location":"runtime/classparray_1_1InnerPArray/#function-add_task","title":"function add_task","text":"<pre><code>void parray::InnerPArray::add_task (\nInnerTask * task\n) </code></pre>"},{"location":"runtime/classparray_1_1InnerPArray/#function-decr_num_active_tasks","title":"function decr_num_active_tasks","text":"<pre><code>void parray::InnerPArray::decr_num_active_tasks (\nDevID_t global_dev_id\n) </code></pre>"},{"location":"runtime/classparray_1_1InnerPArray/#function-exists_on_device","title":"function exists_on_device","text":"<pre><code>bool parray::InnerPArray::exists_on_device (\nuint64_t device_id\n) </code></pre>"},{"location":"runtime/classparray_1_1InnerPArray/#function-get_num_active_tasks","title":"function get_num_active_tasks","text":"<pre><code>size_t parray::InnerPArray::get_num_active_tasks (\nDevID_t global_dev_id\n) </code></pre>"},{"location":"runtime/classparray_1_1InnerPArray/#function-get_parent_parray","title":"function get_parent_parray","text":"<pre><code>InnerPArray * parray::InnerPArray::get_parent_parray () </code></pre>"},{"location":"runtime/classparray_1_1InnerPArray/#function-get_parray_parentid","title":"function get_parray_parentid","text":"<pre><code>uint64_t parray::InnerPArray::get_parray_parentid () </code></pre>"},{"location":"runtime/classparray_1_1InnerPArray/#function-get_py_parray","title":"function get_py_parray","text":"<pre><code>void * parray::InnerPArray::get_py_parray () </code></pre>"},{"location":"runtime/classparray_1_1InnerPArray/#function-get_size","title":"function get_size","text":"<pre><code>const uint64_t parray::InnerPArray::get_size () const\n</code></pre>"},{"location":"runtime/classparray_1_1InnerPArray/#function-get_task_list_ref","title":"function get_task_list_ref","text":"<pre><code>TaskList &amp; parray::InnerPArray::get_task_list_ref () </code></pre>"},{"location":"runtime/classparray_1_1InnerPArray/#function-incr_num_active_tasks","title":"function incr_num_active_tasks","text":"<pre><code>void parray::InnerPArray::incr_num_active_tasks (\nDevID_t global_dev_id\n) </code></pre>"},{"location":"runtime/classparray_1_1InnerPArray/#function-set_size","title":"function set_size","text":"<pre><code>void parray::InnerPArray::set_size (\nuint64_t new_size\n) </code></pre>"},{"location":"runtime/classparray_1_1InnerPArray/#function-valid_on_device","title":"function valid_on_device","text":"<pre><code>bool parray::InnerPArray::valid_on_device (\nuint64_t device_id\n) </code></pre> <p>The documentation for this class was generated from the following file <code>src/c/backend/include/parray.hpp</code></p>"},{"location":"runtime/classparray_1_1PArrayState/","title":"Class parray::PArrayState","text":"<p>ClassList &gt; parray &gt; PArrayState</p>"},{"location":"runtime/classparray_1_1PArrayState/#public-functions","title":"Public Functions","text":"Type Name PArrayState ()  bool exists_on_device (int device_id)  void set_exist_on_device (int device_id, bool exist)  void set_valid_on_device (int device_id, bool valid)  bool valid_on_device (int device_id)"},{"location":"runtime/classparray_1_1PArrayState/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/classparray_1_1PArrayState/#function-parraystate","title":"function PArrayState","text":"<pre><code>parray::PArrayState::PArrayState () </code></pre>"},{"location":"runtime/classparray_1_1PArrayState/#function-exists_on_device","title":"function exists_on_device","text":"<pre><code>bool parray::PArrayState::exists_on_device (\nint device_id\n) </code></pre>"},{"location":"runtime/classparray_1_1PArrayState/#function-set_exist_on_device","title":"function set_exist_on_device","text":"<pre><code>void parray::PArrayState::set_exist_on_device (\nint device_id,\nbool exist\n) </code></pre>"},{"location":"runtime/classparray_1_1PArrayState/#function-set_valid_on_device","title":"function set_valid_on_device","text":"<pre><code>void parray::PArrayState::set_valid_on_device (\nint device_id,\nbool valid\n) </code></pre>"},{"location":"runtime/classparray_1_1PArrayState/#function-valid_on_device","title":"function valid_on_device","text":"<pre><code>bool parray::PArrayState::valid_on_device (\nint device_id\n) </code></pre> <p>The documentation for this class was generated from the following file <code>src/c/backend/include/parray_state.hpp</code></p>"},{"location":"runtime/namespacestd/","title":"Namespace std","text":"<p>Namespace List &gt; std</p> <p>The documentation for this class was generated from the following file <code>src/c/backend/include/gpu_utility.hpp</code></p>"},{"location":"runtime/namespacestd_1_1chrono__literals/","title":"Namespace std::chrono_literals","text":"<p>Namespace List &gt; chrono_literals</p> <p>The documentation for this class was generated from the following file <code>src/c/backend/include/runtime.hpp</code></p>"},{"location":"runtime/namespacestd_1_1literals_1_1string__view__literals/","title":"Namespace std::literals::string_view_literals","text":"<p>Namespace List &gt; string_view_literals</p> <p>The documentation for this class was generated from the following file <code>src/c/backend/include/resources.hpp</code></p>"},{"location":"runtime/namespacethreading/","title":"Namespace threading","text":"<p>Namespace List &gt; threading</p> <p>The documentation for this class was generated from the following file <code>[generated]</code></p>"},{"location":"runtime/dir_68267d1309a1af8e8297ef4c3efbcdba/","title":"Dir src","text":"<p>FileList &gt; src</p>"},{"location":"runtime/dir_68267d1309a1af8e8297ef4c3efbcdba/#directories","title":"Directories","text":"Type Name dir c dir python <p>The documentation for this class was generated from the following file <code>src/</code></p>"},{"location":"runtime/dir_3b19ecf29356981f494745fbef7e56bf/","title":"Dir src/c","text":"<p>FileList &gt; c</p>"},{"location":"runtime/dir_3b19ecf29356981f494745fbef7e56bf/#directories","title":"Directories","text":"Type Name dir backend <p>The documentation for this class was generated from the following file <code>src/c/</code></p>"},{"location":"runtime/dir_b48a98ad0002a6944a483ceab1796856/","title":"Dir src/c/backend","text":"<p>FileList &gt; backend</p>"},{"location":"runtime/dir_b48a98ad0002a6944a483ceab1796856/#files","title":"Files","text":"Type Name file device.cpp file device_manager.cpp file parray.cpp file parray_state.cpp file parray_tracker.cpp file phases.cpp file policy.cpp file resource_requirements.cpp file resources.cpp file scheduler.cpp file task.cpp"},{"location":"runtime/dir_b48a98ad0002a6944a483ceab1796856/#directories","title":"Directories","text":"Type Name dir impl_none dir include <p>The documentation for this class was generated from the following file <code>src/c/backend/</code></p>"},{"location":"runtime/device_8cpp/","title":"File device.cpp","text":"<p>FileList &gt; backend &gt; device.cpp</p> <p>Go to the source code of this file.</p> <ul> <li><code>#include \"include/device.hpp\"</code></li> <li><code>#include \"include/resource_requirements.hpp\"</code></li> </ul> <p>The documentation for this class was generated from the following file <code>src/c/backend/device.cpp</code></p>"},{"location":"runtime/device_8cpp_source/","title":"File device.cpp","text":"<p>File List &gt; backend &gt; device.cpp</p> <p>Go to the documentation of this file. </p> <pre><code>#include \"include/device.hpp\"\n#include \"include/resource_requirements.hpp\"\n\nconst bool\nDevice::check_resource_availability(DeviceRequirement *dev_req) const {\nreturn get_resource_pool().check_greater&lt;ResourceCategory::All&gt;(\ndev_req-&gt;res_req());\n}\n</code></pre>"},{"location":"runtime/device__manager_8cpp/","title":"File device_manager.cpp","text":"<p>FileList &gt; backend &gt; device_manager.cpp</p> <p>Go to the source code of this file.</p> <ul> <li><code>#include \"include/device_manager.hpp\"</code></li> </ul> <p>The documentation for this class was generated from the following file <code>src/c/backend/device_manager.cpp</code></p>"},{"location":"runtime/device__manager_8cpp_source/","title":"File device_manager.cpp","text":"<p>File List &gt; backend &gt; device_manager.cpp</p> <p>Go to the documentation of this file. </p> <pre><code>#include \"include/device_manager.hpp\"\n</code></pre>"},{"location":"runtime/parray_8cpp/","title":"File parray.cpp","text":"<p>FileList &gt; backend &gt; parray.cpp</p> <p>Go to the source code of this file.</p> <ul> <li><code>#include \"parray.hpp\"</code></li> <li><code>#include &lt;cstdint&gt;</code></li> <li><code>#include &lt;unordered_map&gt;</code></li> </ul>"},{"location":"runtime/parray_8cpp/#namespaces","title":"Namespaces","text":"Type Name namespace parray <p>The documentation for this class was generated from the following file <code>src/c/backend/parray.cpp</code></p>"},{"location":"runtime/parray_8cpp_source/","title":"File parray.cpp","text":"<p>File List &gt; backend &gt; parray.cpp</p> <p>Go to the documentation of this file. </p> <pre><code>#include \"parray.hpp\"\n#include &lt;cstdint&gt;\n#include &lt;unordered_map&gt;\n\nnamespace parray {\n\nInnerPArray::InnerPArray(void *py_parray, uint64_t id, uint64_t parent_id,\nInnerPArray *parent_parray, PArrayState *state,\nDevID_t num_devices)\n: _py_parray(py_parray), id(id), parent_id(parent_id),\n_parent_parray(parent_parray), _state(state), _num_devices(num_devices) {\nnum_active_tasks.resize(num_devices);\n}\n\nconst uint64_t InnerPArray::get_size() const { return this-&gt;_size; }\n\nvoid InnerPArray::set_size(uint64_t new_size) { this-&gt;_size = new_size; }\n\nbool InnerPArray::exists_on_device(uint64_t device_id) {\nreturn this-&gt;_state-&gt;exists_on_device(device_id);\n}\n\nbool InnerPArray::valid_on_device(uint64_t device_id) {\nreturn this-&gt;_state-&gt;valid_on_device(device_id);\n}\n\nvoid InnerPArray::add_task(InnerTask *task) {\n// This pushing is thread-safe.\nthis-&gt;_task_lists.push_back(task);\n}\n\nvoid InnerPArray::incr_num_active_tasks(DevID_t global_dev_id) {\nif (this-&gt;_parent_parray != nullptr) {\nthis-&gt;_parent_parray-&gt;num_active_tasks[global_dev_id].fetch_add(\n1, std::memory_order_relaxed);\n} else {\nthis-&gt;num_active_tasks[global_dev_id].fetch_add(1,\nstd::memory_order_relaxed);\n}\n}\n\nvoid InnerPArray::decr_num_active_tasks(DevID_t global_dev_id) {\nif (this-&gt;_parent_parray != nullptr) {\nthis-&gt;_parent_parray-&gt;num_active_tasks[global_dev_id].fetch_sub(\n1, std::memory_order_relaxed);\n} else {\nthis-&gt;num_active_tasks[global_dev_id].fetch_sub(1,\nstd::memory_order_relaxed);\n}\n}\n\nsize_t InnerPArray::get_num_active_tasks(DevID_t global_dev_id) {\nif (this-&gt;_parent_parray != nullptr) {\nreturn this-&gt;_parent_parray-&gt;num_active_tasks[global_dev_id].load(\nstd::memory_order_relaxed);\n} else {\nreturn this-&gt;num_active_tasks[global_dev_id].load(\nstd::memory_order_relaxed);\n}\n}\n\nTaskList &amp;InnerPArray::get_task_list_ref() { return this-&gt;_task_lists; }\n\nvoid *InnerPArray::get_py_parray() { return this-&gt;_py_parray; }\n\nuint64_t InnerPArray::get_parray_parentid() { return this-&gt;parent_id; }\n\nInnerPArray *InnerPArray::get_parent_parray() {\nif (this-&gt;_parent_parray == nullptr) {\nreturn this;\n}\nreturn this-&gt;_parent_parray;\n}\n\n} // namespace parray\n</code></pre>"},{"location":"runtime/parray__state_8cpp/","title":"File parray_state.cpp","text":"<p>FileList &gt; backend &gt; parray_state.cpp</p> <p>Go to the source code of this file.</p> <ul> <li><code>#include \"parray_state.hpp\"</code></li> <li><code>#include &lt;unordered_map&gt;</code></li> </ul>"},{"location":"runtime/parray__state_8cpp/#namespaces","title":"Namespaces","text":"Type Name namespace parray <p>The documentation for this class was generated from the following file <code>src/c/backend/parray_state.cpp</code></p>"},{"location":"runtime/parray__state_8cpp_source/","title":"File parray_state.cpp","text":"<p>File List &gt; backend &gt; parray_state.cpp</p> <p>Go to the documentation of this file. </p> <pre><code>#include \"parray_state.hpp\"\n#include &lt;unordered_map&gt;\n\nnamespace parray {\nPArrayState::PArrayState() {}\n\nbool PArrayState::exists_on_device(int device_id) {\nif (auto findit = this-&gt;_exist_on_device.find(device_id);\nfindit != this-&gt;_exist_on_device.end()) {\nreturn findit-&gt;second;\n} else {\nreturn false;\n}\n}\n\nbool PArrayState::valid_on_device(int device_id) {\nif (auto findit = this-&gt;_valid_on_device.find(device_id);\nfindit != this-&gt;_valid_on_device.end()) {\nreturn findit-&gt;second;\n} else {\nreturn false;\n}\n}\n\nvoid PArrayState::set_exist_on_device(int device_id, bool exist) {\nthis-&gt;_exist_on_device[device_id] = exist;\n}\n\nvoid PArrayState::set_valid_on_device(int device_id, bool valid) {\nthis-&gt;_valid_on_device[device_id] = valid;\n}\n} // namespace parray\n</code></pre>"},{"location":"runtime/parray__tracker_8cpp/","title":"File parray_tracker.cpp","text":"<p>FileList &gt; backend &gt; parray_tracker.cpp</p> <p>Go to the source code of this file.</p> <ul> <li><code>#include \"include/parray_tracker.hpp\"</code></li> </ul> <p>The documentation for this class was generated from the following file <code>src/c/backend/parray_tracker.cpp</code></p>"},{"location":"runtime/parray__tracker_8cpp_source/","title":"File parray_tracker.cpp","text":"<p>File List &gt; backend &gt; parray_tracker.cpp</p> <p>Go to the documentation of this file. </p> <pre><code>#include \"include/parray_tracker.hpp\"\n\nPArrayTracker::PArrayTracker(DeviceManager *device_manager)\n: device_manager_(device_manager) {\nthis-&gt;managed_parrays_.resize(\ndevice_manager-&gt;template get_num_devices&lt;DeviceType::All&gt;());\n}\n\nvoid PArrayTracker::track_parray(const InnerPArray &amp;parray, DevID_t dev_id) {\n// This function is called when a PArray is mapped to a device.\n// Since `managed_parrays_` holds information of the PArrays that\n// have already instantiated or will be moved, set its state to \"true\".\nthis-&gt;managed_parrays_[dev_id].insert({parray.parent_id, true});\n}\n\nvoid PArrayTracker::untrack_parray(const InnerPArray &amp;parray, DevID_t dev_id) {\n// TODO(hc): as we don't have policy regarding this, we are not using\n//           it. we may need this if look-up operation is not cheap\n//           anymore.\nthis-&gt;managed_parrays_[dev_id].erase(parray.parent_id);\n}\n\nvoid PArrayTracker::reserve_parray(const InnerPArray &amp;parray, Device *device) {\nDevID_t dev_global_id = device-&gt;get_global_id();\nbool first_reservation{false};\nthis-&gt;mtx.lock();\nif (this-&gt;managed_parrays_[dev_global_id].find(parray.parent_id) ==\nthis-&gt;managed_parrays_[dev_global_id].end()) {\nthis-&gt;track_parray(parray, dev_global_id);\nfirst_reservation = true;\n}\nif (this-&gt;managed_parrays_[dev_global_id][parray.parent_id] == false or\nfirst_reservation) {\nthis-&gt;managed_parrays_[dev_global_id][parray.parent_id] = true;\n// Allocate memory for a PArray to a specified device.\nResourcePool_t &amp;dev_mapped_pool = device-&gt;get_mapped_pool();\nResourcePool_t parray_resource;\nparray_resource.set(Resource::Memory, parray.get_size());\ndev_mapped_pool.template increase&lt;ResourceCategory::Persistent&gt;(\nparray_resource);\n// std::cout &lt;&lt; \"[PArrayTracker] PArray ID:\" &lt;&lt; parray.id &lt;&lt; \"(parent id:\"\n// &lt;&lt;\n//   parray.parent_id &lt;&lt; \") allocates \"\n//   &lt;&lt; parray.get_size() &lt;&lt; \"Bytes in Device \" &lt;&lt; device-&gt;get_name() &lt;&lt;\n//   \"\\n\";\n}\nthis-&gt;mtx.unlock();\n}\n\nvoid PArrayTracker::release_parray(const InnerPArray &amp;parray, Device *device) {\nDevID_t dev_global_id = device-&gt;get_global_id();\nthis-&gt;mtx.lock();\nif (this-&gt;managed_parrays_[dev_global_id].find(parray.parent_id) ==\nthis-&gt;managed_parrays_[dev_global_id].end()) {\nreturn;\n}\nif (this-&gt;managed_parrays_[dev_global_id][parray.parent_id] == true) {\nthis-&gt;managed_parrays_[dev_global_id][parray.parent_id] = false;\n// Release memory for a PArray to a specified device.\nResourcePool_t &amp;dev_mapped_pool = device-&gt;get_mapped_pool();\nResourcePool_t parray_resource;\nparray_resource.set(Resource::Memory, parray.get_size());\n// XXX It is possible that the memory size of the PArray is bigger than\n// the allocated memory size in the device. This is because in the PArray\n// coherency protocol, a parent PArray of the slice evicts its slices\n// from a device and in this case, the coherency protocol can only view\n// the parent, not its subarrays, so to speak slices.\n// Therefore, it is possible that the tracker allocates the memory size of\n// the slice, as it is set at __init__() of the slice PArray and can be\n// seen, but deallocates the memory byte size of its parent PArray. This\n// makes the mapped memory size counter to a negative number, which we do\n// not prefer. Instead, we set 0 if the counter could be a negative number.\n// This is more accurate than just using parent PArray size for allocation\n// and deallocation.\n// TODO(hc): To resolve this, we may need another slice control layer for\n//           each PArray that tracks the slices.\nif (dev_mapped_pool.template check_greater&lt;ResourceCategory::Persistent&gt;(\nparray_resource)) {\ndev_mapped_pool.template decrease&lt;ResourceCategory::Persistent&gt;(\nparray_resource);\n} else {\ndev_mapped_pool.set(Resource::Memory, 0);\n}\n// std::cout &lt;&lt; \"[PArrayTracker] PArray ID:\" &lt;&lt; parray.id &lt;&lt; \"(parent id:\"\n// &lt;&lt;\n//   parray.parent_id &lt;&lt; \") releases \"\n//   &lt;&lt; parray.get_size() &lt;&lt; \"Bytes in Device \" &lt;&lt; device-&gt;get_name() &lt;&lt;\n//   \"\\n\";\n}\nthis-&gt;mtx.unlock();\n}\n</code></pre>"},{"location":"runtime/phases_8cpp/","title":"File phases.cpp","text":"<p>FileList &gt; backend &gt; phases.cpp</p> <p>Go to the source code of this file.</p> <ul> <li><code>#include \"include/phases.hpp\"</code></li> <li><code>#include \"include/device.hpp\"</code></li> <li><code>#include \"include/parray.hpp\"</code></li> <li><code>#include \"include/policy.hpp\"</code></li> <li><code>#include \"include/profiling.hpp\"</code></li> <li><code>#include \"include/resource_requirements.hpp\"</code></li> <li><code>#include \"include/resources.hpp\"</code></li> <li><code>#include \"include/runtime.hpp\"</code></li> <li><code>#include &lt;algorithm&gt;</code></li> <li><code>#include &lt;random&gt;</code></li> <li><code>#include &lt;utility&gt;</code></li> </ul> <p>The documentation for this class was generated from the following file <code>src/c/backend/phases.cpp</code></p>"},{"location":"runtime/phases_8cpp_source/","title":"File phases.cpp","text":"<p>File List &gt; backend &gt; phases.cpp</p> <p>Go to the documentation of this file. </p> <pre><code>#include \"include/phases.hpp\"\n#include \"include/device.hpp\"\n#include \"include/parray.hpp\"\n#include \"include/policy.hpp\"\n#include \"include/profiling.hpp\"\n#include \"include/resource_requirements.hpp\"\n#include \"include/resources.hpp\"\n#include \"include/runtime.hpp\"\n#include &lt;algorithm&gt;\n#include &lt;random&gt;\n#include &lt;utility&gt;\n\n/**************************/\n// Mapper Implementation\n\nvoid Mapper::enqueue(InnerTask *task) { this-&gt;mappable_tasks.push_back(task); }\n\nvoid Mapper::enqueue(std::vector&lt;InnerTask *&gt; &amp;tasks) {\nthis-&gt;mappable_tasks.push_back(tasks);\n}\n\nsize_t Mapper::get_count() {\nsize_t count = this-&gt;mappable_tasks.atomic_size();\nreturn count;\n}\n\nvoid Mapper::run(SchedulerPhase *next_phase) {\n\nNVTX_RANGE(\"Mapper::run\", NVTX_COLOR_LIGHT_GREEN)\n\n//std::cout &lt;&lt; \"Mapper::run\" &lt;&lt; std::endl;\n\nMemoryReserver *memory_reserver = dynamic_cast&lt;MemoryReserver *&gt;(next_phase);\n\n// TODO: Refactor this so its readable without as many nested conditionals\n\n// This is a non-critical region\n// Comment(wlr): Why is this a noncritical region?\n// Comment(lhc): Only one thread performs this function.\n\n// Assumptions:\n// Scheduler maps a task to a device.\n// Scheduler does not reserve any resource at this phase.\n\nbool has_task = true;\n\nhas_task = this-&gt;get_count() &gt; 0;\nwhile (has_task) {\n//Comment(wlr): this assumes the task is always able to be mapped.\nInnerTask *task = this-&gt;mappable_tasks.front_and_pop();\nPlacementRequirementCollections &amp;placement_req_options =\ntask-&gt;get_placement_req_options();\nstd::vector&lt;std::shared_ptr&lt;PlacementRequirementBase&gt;&gt;\nplacement_req_options_vec =\nplacement_req_options.get_placement_req_opts_ref();\nstd::vector&lt;std::vector&lt;std::pair&lt;parray::InnerPArray *, AccessMode&gt;&gt;&gt;\n&amp;parray_list = task-&gt;parray_list;\n// A set of chosen devices to a task.\nScore_t best_score{-1};\nstd::vector&lt;std::shared_ptr&lt;DeviceRequirement&gt;&gt; chosen_devices;\n\n// Iterate all placement requirements passed by users and calculate\n// scores based on a policy.\nfor (std::shared_ptr&lt;PlacementRequirementBase&gt; base_req :\nplacement_req_options_vec) {\nif (base_req-&gt;is_multidev_req()) {\n// Multi-device placement requirements.\n// std::cout &lt;&lt; \"[Multi-device requirement]\\n\";\nMultiDeviceRequirements *mdev_reqs =\ndynamic_cast&lt;MultiDeviceRequirements *&gt;(base_req.get());\nstd::vector&lt;std::shared_ptr&lt;DeviceRequirement&gt;&gt; mdev_reqs_vec;\nScore_t score{0};\nbool is_req_available = policy_-&gt;calc_score_mdevplacement(\ntask, mdev_reqs, *this, &amp;mdev_reqs_vec, &amp;score, parray_list);\nif (!is_req_available) {\ncontinue;\n}\nif (best_score &lt;= score) {\nbest_score = score;\nchosen_devices.swap(mdev_reqs_vec);\n}\n} else if (base_req-&gt;is_dev_req()) {\n// A single device placement requirement.\nstd::shared_ptr&lt;DeviceRequirement&gt; dev_req =\nstd::dynamic_pointer_cast&lt;DeviceRequirement&gt;(base_req);\nScore_t score{0};\nbool is_req_available = policy_-&gt;calc_score_devplacement(\ntask, dev_req, *this, &amp;score, parray_list[0]);\nif (!is_req_available) {\ncontinue;\n}\nif (best_score &lt;= score) {\nassert(dev_req != nullptr);\nbest_score = score;\nchosen_devices.clear();\nchosen_devices.emplace_back(dev_req);\n}\n} else if (base_req-&gt;is_arch_req()) {\n// A single architecture placement requirement.\nArchitectureRequirement *arch_req =\ndynamic_cast&lt;ArchitectureRequirement *&gt;(base_req.get());\nstd::shared_ptr&lt;DeviceRequirement&gt; chosen_dev_req{nullptr};\nScore_t chosen_dev_score{0};\n// std::cout &lt;&lt; \"[Mapper] Task name:\" &lt;&lt; task-&gt;get_name() &lt;&lt; \", \" &lt;&lt; \"Checking arch requirement.\"\n//           &lt;&lt; \"\\n\";\nbool is_req_available = policy_-&gt;calc_score_archplacement(\ntask, arch_req, *this, chosen_dev_req, &amp;chosen_dev_score,\nparray_list[0]);\nif (!is_req_available) {\ncontinue;\n}\nif (best_score &lt;= chosen_dev_score) {\nassert(chosen_dev_req != nullptr);\nbest_score = chosen_dev_score;\nchosen_devices.clear();\nchosen_devices.emplace_back(chosen_dev_req);\n}\n}\n}\n\n\nif (chosen_devices.empty()) {\n// It means that none of the devices is available for this task.\n// If it is, re-enqueue the task to the mappable task queue.\nthis-&gt;enqueue(task);\n//std::cout &lt;&lt; \"Task has not been mapped\" &lt;&lt; std::endl;\n} else {\nstd::vector&lt;std::vector&lt;std::pair&lt;parray::InnerPArray *, AccessMode&gt;&gt;&gt;\n*parray_list = &amp;(task-&gt;parray_list);\nfor (size_t i = 0; i &lt; chosen_devices.size(); ++i) {\nassert(chosen_devices[i] != nullptr);\nDevice *chosen_device = chosen_devices[i]-&gt;device();\nDevID_t global_dev_id = chosen_device-&gt;get_global_id();\ntask-&gt;assigned_devices.push_back(chosen_device);\ntask-&gt;device_constraints.insert(\n{chosen_device-&gt;get_global_id(), chosen_devices[i]-&gt;res_req()});\nthis-&gt;atomic_incr_num_mapped_tasks_device(\nchosen_device-&gt;get_global_id());\nfor (size_t j = 0; j &lt; (*parray_list)[i].size(); ++j) {\nparray::InnerPArray *parray = (*parray_list)[i][j].first;\nthis-&gt;scheduler-&gt;get_parray_tracker()-&gt;reserve_parray(*parray,\nchosen_device);\nparray-&gt;incr_num_active_tasks(global_dev_id);\n}\n}\n\n#if 0\n      std::cout &lt;&lt; \"[Mapper] Task name:\" &lt;&lt; task-&gt;get_name() &lt;&lt; \", \" &lt;&lt; task\n                &lt;&lt; \"\\n\";\n      for (size_t i = 0; i &lt; task-&gt;assigned_devices.size(); ++i) {\n        std::cout &lt;&lt; \"\\t [\" &lt;&lt; i &lt;&lt; \"] \"\n                  &lt;&lt; task-&gt;assigned_devices[i]-&gt;get_name() &lt;&lt; \"\\n\";\n        /*\n        auto res = task-&gt;device_constraints[task-&gt;assigned_devices[i]\n                                                -&gt;get_global_id()];\n        std::cout &lt;&lt; \"\\t memory:\" &lt;&lt; res.get(Resource::Memory)\n                  &lt;&lt; \", vcu:\" &lt;&lt; res.get(Resource::VCU) &lt;&lt; \"\\n\";\n        */\n      }\n#endif\n\nthis-&gt;mapped_tasks_buffer.push_back(task);\nthis-&gt;atomic_incr_num_mapped_tasks();\n}\nhas_task = this-&gt;get_count() &gt; 0;\n} // while there are mappable tasks\n\nfor (InnerTask *mapped_task : this-&gt;mapped_tasks_buffer) {\nmapped_task-&gt;notify_dependents(this-&gt;enqueue_buffer, Task::MAPPED);\nthis-&gt;scheduler-&gt;enqueue_tasks(this-&gt;enqueue_buffer);\nthis-&gt;enqueue_buffer.clear();\n\nbool enqueue_flag =\n(mapped_task-&gt;num_unreserved_dependencies.fetch_sub(1) == 1);\n\nif (enqueue_flag) {\nmapped_task-&gt;set_status(Task::RESERVABLE);\nmemory_reserver-&gt;enqueue(mapped_task);\n}\n}\nthis-&gt;mapped_tasks_buffer.clear();\n}\n\n/**************************/\n// Reserved Phase implementation\n\nvoid MemoryReserver::enqueue(InnerTask *task) {\nthis-&gt;reservable_tasks-&gt;enqueue(task);\n}\n\nvoid MemoryReserver::enqueue(std::vector&lt;InnerTask *&gt; &amp;tasks) {\nfor (InnerTask *task : tasks) {\nthis-&gt;enqueue(task);\n}\n}\n\nsize_t MemoryReserver::get_count() {\nsize_t count = this-&gt;reservable_tasks-&gt;size();\nreturn count;\n}\n\nbool MemoryReserver::check_resources(InnerTask *task) {\nbool status = true;\nfor (Device *device : task-&gt;assigned_devices) {\nResourcePool_t &amp;task_pool =\ntask-&gt;device_constraints[device-&gt;get_global_id()];\nResourcePool_t &amp;device_pool = device-&gt;get_reserved_pool();\n\nstatus = device_pool.check_greater&lt;ResourceCategory::Persistent&gt;(task_pool);\n\nif (!status) {\nbreak;\n}\n}\nreturn status;\n}\n\nvoid MemoryReserver::reserve_resources(InnerTask *task) {\n// TODO(wlr): Add runtime error check if resource failure\n\nfor (Device *device : task-&gt;assigned_devices) {\nResourcePool_t &amp;task_pool =\ntask-&gt;device_constraints[device-&gt;get_global_id()];\nResourcePool_t &amp;device_pool = device-&gt;get_reserved_pool();\ndevice_pool.decrease&lt;ResourceCategory::Persistent&gt;(task_pool);\n}\n}\n\nvoid MemoryReserver::create_datamove_tasks(InnerTask *task) {\n// Get a list of the parrays the current task holds.\nconst std::vector&lt;std::vector&lt;std::pair&lt;parray::InnerPArray *, AccessMode&gt;&gt;&gt;\n&amp;parray_list = task-&gt;parray_list;\nstd::string task_base_name = task-&gt;get_name();\nstd::vector&lt;InnerTask *&gt; data_tasks;\ndata_tasks.reserve(parray_list.size());\n\nfor (size_t i = 0; i &lt; parray_list.size(); ++i) {\nfor (size_t j = 0; j &lt; parray_list[i].size(); ++j) {\n// Create a data movement task for each PArray.\nparray::InnerPArray *parray = parray_list[i][j].first;\nAccessMode access_mode = parray_list[i][j].second;\nInnerDataTask *datamove_task = new InnerDataTask(\n// TODO(hc): id should be updated!\ntask_base_name + \".dm.\" + std::to_string(i), 0, parray, access_mode,\ni);\nauto &amp;parray_task_list = parray-&gt;get_parent_parray()-&gt;get_task_list_ref();\n// Find dependency intersection between compute and data movement tasks.\n\n// TODO(hc): This is not the complete implementation.\n//           We will use a concurrent map for parray's\n//           task list as an optimization.\n\nstd::vector&lt;void *&gt; compute_task_dependencies = task-&gt;get_dependencies();\nstd::vector&lt;InnerTask *&gt; data_task_dependencies;\nfor (size_t k = 0; k &lt; compute_task_dependencies.size(); ++k) {\nInnerTask *parray_dependency =\nstatic_cast&lt;InnerTask *&gt;(compute_task_dependencies[k]);\n// The task list in PArray is currently thread safe since\n// we do not remove tasks from the list but just keep even completed\n// task as its implementation is easier.\nfor (size_t t = 0; t &lt; parray_task_list.size_unsafe(); ++t) {\nif (parray_task_list.at_unsafe(t)-&gt;id == parray_dependency-&gt;id) {\ndata_task_dependencies.push_back(parray_dependency);\n}\n}\n}\n\n// TODO(hc): pass false to add_dependencies() as optimization.\ndatamove_task-&gt;add_dependencies(data_task_dependencies, true);\n// Copy assigned devices to a compute task to a data movement task.\n// TODO(hc): When we support xpy, it should be devices corresponding\n//           to placements of the local partition.\nauto device = task-&gt;get_assigned_devices()[i];\ndatamove_task-&gt;add_assigned_device(device);\n\ndatamove_task-&gt;device_constraints.emplace(\nstd::piecewise_construct,\nstd::forward_as_tuple(device-&gt;get_global_id()),\nstd::forward_as_tuple(0, 0, 1));\n\ndata_tasks.push_back(datamove_task);\n// Add the created data movement task to a reserved task queue.\nthis-&gt;scheduler-&gt;increase_num_active_tasks();\nthis-&gt;reserved_tasks_buffer.push_back(datamove_task);\n}\n}\n\n// Create dependencies between data move task and compute tasks.\ntask-&gt;add_dependencies(data_tasks, true);\n}\n\nvoid MemoryReserver::run(SchedulerPhase *next_phase) {\nNVTX_RANGE(\"MemoryReserver::run\", NVTX_COLOR_LIGHT_GREEN)\n\n//std::cout &lt;&lt; \"MemoryReserver::run\" &lt;&lt; std::endl;\n\nRuntimeReserver *runtime_reserver =\ndynamic_cast&lt;RuntimeReserver *&gt;(next_phase);\n\n// Only one thread can reserve memory at a time.\n// Useful for a multi-threaded scheduler. Not needed for a single-threaded.\n// std::unique_lock&lt;std::mutex&gt; lock(this-&gt;mtx);\n\n// TODO:: Dummy implementation that just passes tasks through\nbool has_task = this-&gt;get_count() &gt; 0;\nwhile (has_task) {\nInnerTask *task = this-&gt;reservable_tasks-&gt;front();\n\nif (task == nullptr) {\nthrow std::runtime_error(\"MemoryReserver::run: task is nullptr\");\n}\n\n// Is there enough memory on the devices to schedule this task?\nbool can_reserve = this-&gt;check_resources(task);\nif (can_reserve) {\nthis-&gt;reserve_resources(task);\nthis-&gt;reservable_tasks-&gt;pop();\nthis-&gt;create_datamove_tasks(task);\nthis-&gt;reserved_tasks_buffer.push_back(task);\n} else {\n// TODO:(wlr) we need some break condition to allow the scheduler to\n// continue if not enough resources are available Hochan, do you\n// have any ideas? One failure per scheduler loop (written here) is\n// bad. Is one failure per device per scheduler loop better?\nbreak;\n}\n\nhas_task = this-&gt;get_count() &gt; 0;\n}\n\nfor (InnerTask *reserved_task : this-&gt;reserved_tasks_buffer) {\nreserved_task-&gt;notify_dependents(this-&gt;enqueue_buffer, Task::RESERVED);\nthis-&gt;scheduler-&gt;enqueue_tasks(this-&gt;enqueue_buffer);\nthis-&gt;enqueue_buffer.clear();\n\n// TODO:(wlr) Create and possibly enqueue data movement tasks\n\n// Possibly enqueue this task\nbool enqueue_flag =\n(reserved_task-&gt;num_blocking_dependencies.fetch_sub(1) == 1);\nif (enqueue_flag) {\nreserved_task-&gt;set_status(Task::RUNNABLE);\nruntime_reserver-&gt;enqueue(reserved_task);\n}\n}\n\nthis-&gt;reserved_tasks_buffer.clear();\n}\n\n/**************************/\n// Ready Phase implementation\n\nvoid RuntimeReserver::enqueue(InnerTask *task) {\nbool is_data_task = task-&gt;is_data_task();\nif (!is_data_task) {\n// std::cout &lt;&lt; \"RuntimeReserver::enqueue: compute task\" &lt;&lt; std::endl;\nthis-&gt;runnable_tasks-&gt;enqueue(task);\n} else {\n// std::cout &lt;&lt; \"RuntimeReserver::enqueue: data task\" &lt;&lt; std::endl;\nthis-&gt;movement_tasks-&gt;enqueue(task);\n}\n}\n\nvoid RuntimeReserver::enqueue(std::vector&lt;InnerTask *&gt; &amp;tasks) {\nfor (InnerTask *task : tasks) {\nthis-&gt;enqueue(task);\n}\n}\n\nsize_t RuntimeReserver::get_compute_count() {\nsize_t count = this-&gt;runnable_tasks-&gt;size();\nreturn count;\n}\n\nsize_t RuntimeReserver::get_movement_count() {\nsize_t count = this-&gt;movement_tasks-&gt;size();\nreturn count;\n}\n\nsize_t RuntimeReserver::get_count() {\nsize_t count = this-&gt;get_compute_count() + this-&gt;get_movement_count();\nreturn count;\n}\n\nbool RuntimeReserver::check_resources(InnerTask *task) {\nbool status = true;\nfor (Device *device : task-&gt;assigned_devices) {\nResourcePool_t &amp;task_pool =\ntask-&gt;device_constraints[device-&gt;get_global_id()];\nResourcePool_t &amp;device_pool = device-&gt;get_reserved_pool();\n\nstatus =\ndevice_pool.check_greater&lt;ResourceCategory::NonPersistent&gt;(task_pool);\n\nif (!status) {\nbreak;\n}\n}\nreturn status;\n}\n\nbool RuntimeReserver::check_data_resources(InnerTask *task) {\nbool status = true;\nfor (Device *device : task-&gt;assigned_devices) {\nResourcePool_t &amp;task_pool =\ntask-&gt;device_constraints[device-&gt;get_global_id()];\nResourcePool_t &amp;device_pool = device-&gt;get_reserved_pool();\n\nstatus = device_pool.check_greater&lt;ResourceCategory::Movement&gt;(task_pool);\n\nif (!status) {\nbreak;\n}\n}\nreturn status;\n}\n\nvoid RuntimeReserver::reserve_resources(InnerTask *task) {\n// TODO(wlr): Add runtime error check if resource failure\nfor (Device *device : task-&gt;assigned_devices) {\nResourcePool_t &amp;task_pool =\ntask-&gt;device_constraints[device-&gt;get_global_id()];\nResourcePool_t &amp;device_pool = device-&gt;get_reserved_pool();\ndevice_pool.decrease&lt;ResourceCategory::NonPersistent&gt;(task_pool);\n}\n}\n\nvoid RuntimeReserver::reserve_data_resources(InnerTask *task) {\n// TODO(wlr): Add runtime error check if resource failure\nfor (Device *device : task-&gt;assigned_devices) {\nResourcePool_t &amp;task_pool =\ntask-&gt;device_constraints[device-&gt;get_global_id()];\nResourcePool_t &amp;device_pool = device-&gt;get_reserved_pool();\ndevice_pool.decrease&lt;ResourceCategory::Movement&gt;(task_pool);\n}\n}\n\nvoid RuntimeReserver::run(SchedulerPhase *next_phase) {\nNVTX_RANGE(\"RuntimeReserver::run\", NVTX_COLOR_LIGHT_GREEN)\n\n//std::cout &lt;&lt; \"RuntimeReserver::run\" &lt;&lt; std::endl;\n\nLauncher *launcher = dynamic_cast&lt;Launcher *&gt;(next_phase);\n\n// Only one thread can reserve runtime resources at a time.\n// Useful for a multi-threaded scheduler. Not needed for a single-threaded.\n// std::unique_lock&lt;std::mutex&gt; lock(this-&gt;mtx);\n\n// Try to launch as many compute tasks as possible\nint fail_count = 0;\nint max_fail = this-&gt;runnable_tasks-&gt;get_num_devices() * 2;\nbool has_task = true;\nint num_tasks = 0;\nwhile (has_task &amp;&amp; (fail_count &lt; max_fail)) {\nnum_tasks = this-&gt;get_compute_count();\nhas_task = num_tasks &gt; 0;\nif (has_task) {\nInnerTask *task = this-&gt;runnable_tasks-&gt;front();\nbool has_resources = check_resources(task);\nif (has_resources) {\nbool has_thread = scheduler-&gt;workers.get_num_available_workers() &gt; 0;\nif (has_thread) {\nInnerTask *task = this-&gt;runnable_tasks-&gt;pop();\nInnerWorker *worker = scheduler-&gt;workers.dequeue_worker();\n// Decrease Resources\nthis-&gt;reserve_resources(task);\nlauncher-&gt;enqueue(task, worker);\nthis-&gt;status.increase(RuntimeReserverState::Success);\n} else {\nthis-&gt;status.increase(RuntimeReserverState::NoWorker);\nfail_count++; // += max_fail;\n//break;        // No more workers available\n}\n} else {\nthis-&gt;status.increase(RuntimeReserverState::NoResource);\nfail_count++;\n//break; // No more resources available\n}\n} else {\nthis-&gt;status.increase(RuntimeReserverState::NoTask);\nfail_count++; //+= max_fail;\n//break;        // No more tasks available\n}\n}\n\n// Try to launch as many data movement tasks as possible\nhas_task = true;\nnum_tasks = 0;\nwhile (has_task) {\nnum_tasks = this-&gt;get_movement_count();\n// std::cout &lt;&lt; \"RuntimeReserver::run: num movement tasks: \" &lt;&lt; num_tasks\n//           &lt;&lt; std::endl;\nhas_task = num_tasks &gt; 0;\nif (has_task) {\nInnerTask *task = this-&gt;movement_tasks-&gt;front();\nbool has_resources = check_data_resources(task);\nif (has_resources) {\nbool has_thread = scheduler-&gt;workers.get_num_available_workers() &gt; 0;\nif (has_thread) {\nInnerTask *task = this-&gt;movement_tasks-&gt;pop();\nInnerWorker *worker = scheduler-&gt;workers.dequeue_worker();\n// Decrease Resources\nthis-&gt;reserve_data_resources(task);\nlauncher-&gt;enqueue(task, worker);\nthis-&gt;status.increase(RuntimeReserverState::Success);\n} else {\nthis-&gt;status.increase(RuntimeReserverState::NoWorker);\nbreak; // No more workers available\n}\n} else {\nthis-&gt;status.increase(RuntimeReserverState::NoResource);\nbreak; // No more resources available\n}\n} else {\nthis-&gt;status.increase(RuntimeReserverState::NoTask);\nbreak; // No more tasks available\n}\n}\n}\n\n/**************************/\n// Launcher Phase implementation\n\nvoid Launcher::enqueue(InnerTask *task, InnerWorker *worker) {\nNVTX_RANGE(\"Launcher::enqueue\", NVTX_COLOR_LIGHT_GREEN)\n\n//std::cout &lt;&lt; \"Launcher::enqueue\" &lt;&lt; std::endl;\n\n// Immediately launch task\ntask-&gt;set_state(Task::RUNNING);\nthis-&gt;num_running_tasks++;\n\n// Assign task to thread and notify via c++ condition variable.\n// No GIL needed until worker wakes.\nworker-&gt;assign_task(task);\n\n// std::cout &lt;&lt; \"Assigned \" &lt;&lt; task-&gt;name &lt;&lt; \" to \" &lt;&lt; worker-&gt;thread_idx\n//          &lt;&lt; std::endl;\nLOG_INFO(WORKER, \"Assigned {} to {}\", task, worker);\n}\n\nvoid Launcher::run() {\nthrow std::runtime_error(\"Launcher::run() not implemented.\");\n}\n</code></pre>"},{"location":"runtime/policy_8cpp/","title":"File policy.cpp","text":"<p>FileList &gt; backend &gt; policy.cpp</p> <p>Go to the source code of this file.</p> <ul> <li><code>#include \"include/policy.hpp\"</code></li> <li><code>#include \"include/phases.hpp\"</code></li> </ul> <p>The documentation for this class was generated from the following file <code>src/c/backend/policy.cpp</code></p>"},{"location":"runtime/policy_8cpp_source/","title":"File policy.cpp","text":"<p>File List &gt; backend &gt; policy.cpp</p> <p>Go to the documentation of this file. </p> <pre><code>#include \"include/policy.hpp\"\n#include \"include/phases.hpp\"\n\nbool LocalityLoadBalancingMappingPolicy::calc_score_devplacement(\nInnerTask *task,\nconst std::shared_ptr&lt;DeviceRequirement&gt; &amp;dev_placement_req,\nconst Mapper &amp;mapper, Score_t *score,\nconst std::vector&lt;std::pair&lt;parray::InnerPArray *, AccessMode&gt;&gt;\n&amp;parray_list) {\nconst Device &amp;device = *(dev_placement_req-&gt;device());\nDevID_t global_dev_id = device.get_global_id();\n//std::cout &lt;&lt; \"[Locality-aware- and Load-balancing mapping policy]\\n\";\n\n// Check device resource availability.\nif (!device.check_resource_availability(dev_placement_req.get())) {\n//std::cout &lt;&lt; \"Device resource failure!\" &lt;&lt; std::endl;\nreturn false;\n}\n\n// PArray locality.\nScore_t local_data{0}, nonlocal_data{0};\nfor (size_t i = 0; i &lt; parray_list.size(); ++i) {\nInnerPArray *parray = parray_list[i].first;\nif (parray_tracker_-&gt;get_parray_state(global_dev_id, parray-&gt;parent_id)) {\nlocal_data += parray-&gt;get_size();\n} else {\nnonlocal_data += parray-&gt;get_size();\n}\n}\nResource_t device_memory_size = device.query_resource(Resource::Memory);\nlocal_data /= device_memory_size;\nnonlocal_data /= device_memory_size;\n\n#if 0\n  // TODO(hc): This metric is duplicated with data locality.\n  // Check how many dependencies are mapped to the device candidate\n  // being checked.\n  // Note that this only considers dependencies specified in a task\n  // @spawn decorator. So to speak, it considers immediate dependencies\n  // and does not consider the whole dependency subtree.\n  TaskList &amp;dependencies = task-&gt;dependencies;\n  size_t num_dependencies_on_device{0};\n  for (size_t i = 0; i &lt; dependencies.size_unsafe(); ++i) {\n    InnerTask *dependency = dependencies.at_unsafe(i);\n    for (Device *dependency_devices : dependency-&gt;assigned_devices) {\n      if (dependency_devices-&gt;get_global_id() == device.get_global_id()) {\n        ++num_dependencies_on_device;\n        break;\n      }\n    }\n  }\n  // std::cout &lt;&lt; num_dependencies_on_device &lt;&lt; \" of the \" &lt;&lt; task-&gt;get_name()\n  //           &lt;&lt; \"s dependencies have been mapped to device \" &lt;&lt;\n  //           device.get_name()\n  //           &lt;&lt; \"\\n\";\n#endif\n\n// TODO(hc): memory load; but let me postpone this implementation because\n//           it may require nested for loops.\n\n// Calculate device load balancing.\nsize_t total_num_mapped_tasks = mapper.atomic_load_total_num_mapped_tasks();\nsize_t num_tasks_to_device =\nmapper.atomic_load_dev_num_mapped_tasks_device(device.get_global_id());\ndouble normalizd_device_load{0};\nif (total_num_mapped_tasks != 0) {\nnormalizd_device_load =\nnum_tasks_to_device / double(total_num_mapped_tasks);\n}\n\n// Avoid negative score and make this focus on load balancing if data\n// is not used.\n*score = 50;\n*score += (30.0 * local_data - 30.0 * nonlocal_data - 10 * normalizd_device_load);\n\n// std::cout &lt;&lt; \"Device \" &lt;&lt; device.get_name() &lt;&lt; \"'s score: \" &lt;&lt; *score &lt;&lt;\n//   \" for task \"&lt;&lt; task-&gt;get_name() &lt;&lt; \" local data: \" &lt;&lt; local_data &lt;&lt;\n//   \" non local data:\" &lt;&lt; nonlocal_data &lt;&lt; \" normalized device load:\" &lt;&lt;\n//   normalizd_device_load &lt;&lt; \"\\n\";\n// std::cout &lt;&lt; \"\\t[Device Requirement in device Requirement]\\n\"\n//           &lt;&lt; \"\\t\\t\" &lt;&lt; dev_placement_req-&gt;device()-&gt;get_name() &lt;&lt; \" -&gt; \"\n//           &lt;&lt; dev_placement_req-&gt;res_req().get(Resource::Memory) &lt;&lt; \"B, VCU\"\n//           &lt;&lt; dev_placement_req-&gt;res_req().get(Resource::VCU) &lt;&lt; \"\\n\";\nreturn true;\n}\n\nbool LocalityLoadBalancingMappingPolicy::calc_score_archplacement(\nInnerTask *task, ArchitectureRequirement *arch_placement_req,\nconst Mapper &amp;mapper, std::shared_ptr&lt;DeviceRequirement&gt; &amp;chosen_dev_req,\nScore_t *chosen_dev_score,\nconst std::vector&lt;std::pair&lt;parray::InnerPArray *, AccessMode&gt;&gt;\n&amp;parray_list, std::vector&lt;bool&gt; *is_dev_assigned) {\nScore_t best_score{0};\nstd::shared_ptr&lt;DeviceRequirement&gt; best_device_req{nullptr};\n// std::cout &lt;&lt; task-&gt;get_name() &lt;&lt; \"inside arch req mapping. \" &lt;&lt; std::endl;\n//TODO(wlr): Is this unused??\nuint32_t i{0};\nbool is_arch_available{false};\n// For now the architecture placement has one resource requirement\n// regardless of the devices of the architecture. In the future,\n// we will allow a separate placement for each device.\nauto placement_options = arch_placement_req-&gt;GetDeviceRequirementOptions();\nint n_options = placement_options.size();\nint start_idx = ++this-&gt;rrcount;\n\nfor (int k = 0; k &lt; n_options; k++){\nint idx = (start_idx+k)%n_options;\nstd::shared_ptr&lt;DeviceRequirement&gt; dev_req = placement_options[idx];\nScore_t score{0};\nDevID_t dev_global_id = dev_req-&gt;device()-&gt;get_global_id();\nif (is_dev_assigned != nullptr &amp;&amp;\n(*is_dev_assigned)[dev_global_id] == true) {\n// If this architecture placement is the member of a\n// multi-device task and this visiting device is already chosen\n// as one of the placements, skip it.\ncontinue;\n}\nbool is_dev_available =\nthis-&gt;calc_score_devplacement(task, dev_req, mapper, &amp;score,\nparray_list);\nif (!is_dev_available) {\ncontinue;\n}\nis_arch_available = true;\nif (best_score &lt;= score) {\nbest_score = score;\nbest_device_req = dev_req;\n}\n++i;\n}\nassert(best_device_req != nullptr);\nchosen_dev_req = best_device_req;\n*chosen_dev_score = best_score;\nreturn is_arch_available;\n}\n\nbool LocalityLoadBalancingMappingPolicy::calc_score_mdevplacement(\nInnerTask *task, MultiDeviceRequirements *mdev_placement_req,\nconst Mapper &amp;mapper,\nstd::vector&lt;std::shared_ptr&lt;DeviceRequirement&gt;&gt; *member_device_reqs,\nScore_t *average_score,\nconst std::vector&lt;\nstd::vector&lt;std::pair&lt;parray::InnerPArray *, AccessMode&gt;&gt;&gt;\n&amp;parray_list) {\n*average_score = 0;\nconst std::vector&lt;std::shared_ptr&lt;SinglePlacementRequirementBase&gt;&gt;\n&amp;placement_reqs_vec = mdev_placement_req-&gt;get_placement_reqs_ref();\nmember_device_reqs-&gt;resize(placement_reqs_vec.size());\n// Task mapper does not allow to map a multi-device task to the same device\n// multiple times. This vector marks an assigned device and filter it\n// out at the next device decision.\nstd::vector&lt;bool&gt; is_dev_assigned(\nthis-&gt;device_manager_-&gt;get_num_devices&lt;DeviceType::All&gt;(), false);\n// Iterate requirements of the devices specified in multi-device placement.\n// All of the member devices should be available.\nfor (DevID_t did = 0; did &lt; placement_reqs_vec.size(); ++did) {\nstd::shared_ptr&lt;SinglePlacementRequirementBase&gt; placement_req =\nplacement_reqs_vec[did];\nstd::shared_ptr&lt;DeviceRequirement&gt; dev_req{nullptr};\nScore_t score{0};\nbool is_member_device_available{false};\nif (placement_req-&gt;is_dev_req()) {\ndev_req = std::dynamic_pointer_cast&lt;DeviceRequirement&gt;(placement_req);\nDevID_t dev_global_id = dev_req-&gt;device()-&gt;get_global_id();\nif (!is_dev_assigned[dev_global_id]) {\nis_member_device_available =\nthis-&gt;calc_score_devplacement(task, dev_req, mapper, &amp;score,\nparray_list[did]);\nif (is_member_device_available) {\nis_dev_assigned[dev_global_id] = true;\n}\n}\n} else if (placement_req-&gt;is_arch_req()) {\nArchitectureRequirement *arch_req =\ndynamic_cast&lt;ArchitectureRequirement *&gt;(placement_req.get());\nis_member_device_available = this-&gt;calc_score_archplacement(\ntask, arch_req, mapper, dev_req, &amp;score, parray_list[did],\n&amp;is_dev_assigned);\nif (is_member_device_available) {\nDevID_t dev_global_id = dev_req-&gt;device()-&gt;get_global_id();\nis_dev_assigned[dev_global_id] = true;\n}\n}\nassert(dev_req != nullptr);\n(*member_device_reqs)[did] = dev_req;\n*average_score += score;\nif (!is_member_device_available) {\n// If any of the device candidates is not available,\n// return false and exclude this option from task mapping.\nreturn false;\n}\n}\n*average_score /= placement_reqs_vec.size();\nreturn true;\n}\n</code></pre>"},{"location":"runtime/resource__requirements_8cpp/","title":"File resource_requirements.cpp","text":"<p>FileList &gt; backend &gt; resource_requirements.cpp</p> <p>Go to the source code of this file.</p> <ul> <li><code>#include \"include/resource_requirements.hpp\"</code></li> </ul> <p>The documentation for this class was generated from the following file <code>src/c/backend/resource_requirements.cpp</code></p>"},{"location":"runtime/resource__requirements_8cpp_source/","title":"File resource_requirements.cpp","text":"<p>File List &gt; backend &gt; resource_requirements.cpp</p> <p>Go to the documentation of this file. </p> <pre><code>#include \"include/resource_requirements.hpp\"\n\nvoid PlacementRequirementCollections::append_placement_req_opt(\nstd::shared_ptr&lt;PlacementRequirementBase&gt; req) {\nplacement_reqs_.emplace_back(std::shared_ptr&lt;PlacementRequirementBase&gt;(req));\n}\n\nconst std::vector&lt;std::shared_ptr&lt;PlacementRequirementBase&gt;&gt; &amp;\nPlacementRequirementCollections::get_placement_req_opts_ref() {\nreturn placement_reqs_;\n}\n\nvoid MultiDeviceRequirements::append_placement_req(\nstd::shared_ptr&lt;SinglePlacementRequirementBase&gt; req) {\nplacement_reqs_.emplace_back(\nstd::shared_ptr&lt;SinglePlacementRequirementBase&gt;(req));\n}\n\nconst std::vector&lt;std::shared_ptr&lt;SinglePlacementRequirementBase&gt;&gt; &amp;\nMultiDeviceRequirements::get_placement_reqs_ref() {\nreturn placement_reqs_;\n}\n\nvoid ArchitectureRequirement::append_placement_req_opt(\nstd::shared_ptr&lt;DeviceRequirement&gt; req) {\nplacement_reqs_.emplace_back(std::shared_ptr&lt;DeviceRequirement&gt;(req));\n}\n\nconst std::vector&lt;std::shared_ptr&lt;DeviceRequirement&gt;&gt; &amp;\nArchitectureRequirement::GetDeviceRequirementOptions() {\nreturn placement_reqs_;\n}\n</code></pre>"},{"location":"runtime/resources_8cpp/","title":"File resources.cpp","text":"<p>FileList &gt; backend &gt; resources.cpp</p> <p>Go to the source code of this file.</p> <ul> <li><code>#include \"include/resources.hpp\"</code></li> <li><code>#include \"include/containers.hpp\"</code></li> </ul> <p>The documentation for this class was generated from the following file <code>src/c/backend/resources.cpp</code></p>"},{"location":"runtime/resources_8cpp_source/","title":"File resources.cpp","text":"<p>File List &gt; backend &gt; resources.cpp</p> <p>Go to the documentation of this file. </p> <pre><code>#include \"include/resources.hpp\"\n#include \"include/containers.hpp\"\n\n// Removed for gcc 8.3.0 support\n// template class ResourcePool&lt;std::atomic&lt;Resource_t&gt;&gt;;\n</code></pre>"},{"location":"runtime/scheduler_8cpp/","title":"File scheduler.cpp","text":"<p>FileList &gt; backend &gt; scheduler.cpp</p> <p>Go to the source code of this file.</p> <ul> <li><code>#include \"include/phases.hpp\"</code></li> <li><code>#include \"include/policy.hpp\"</code></li> <li><code>#include \"include/resources.hpp\"</code></li> <li><code>#include \"include/runtime.hpp\"</code></li> <li><code>#include &lt;new&gt;</code></li> </ul> <p>The documentation for this class was generated from the following file <code>src/c/backend/scheduler.cpp</code></p>"},{"location":"runtime/scheduler_8cpp_source/","title":"File scheduler.cpp","text":"<p>File List &gt; backend &gt; scheduler.cpp</p> <p>Go to the documentation of this file. </p> <pre><code>#include \"include/phases.hpp\"\n#include \"include/policy.hpp\"\n#include \"include/resources.hpp\"\n#include \"include/runtime.hpp\"\n\n#include &lt;new&gt;\n\n#ifdef PARLA_ENABLE_LOGGING\nnamespace binlog {\nint global_reset_count = 0;\n}\n#endif\n\n// Worker Implementation\n\nvoid InnerWorker::wait() {\nNVTX_RANGE(\"worker:wait\", NVTX_COLOR_CYAN)\nLOG_INFO(WORKER, \"Worker waiting: {}\", this-&gt;thread_idx);\nstd::unique_lock&lt;std::mutex&gt; lck(mtx);\n// std::cout &lt;&lt; \"Waiting for task (C++) \" &lt;&lt; this-&gt;thread_idx &lt;&lt; std::endl;\ncv.wait(lck, [this] { return this-&gt;notified; });\n// std::cout &lt;&lt; \"Task assigned (C++) \" &lt;&lt; this-&gt;thread_idx &lt;&lt; \" \"\n//           &lt;&lt; this-&gt;ready &lt;&lt; std::endl;\nthis-&gt;scheduler-&gt;increase_num_notified_workers();\n}\n\nvoid InnerWorker::assign_task(InnerTask *task) {\nNVTX_RANGE(\"worker:assign_task\", NVTX_COLOR_CYAN)\n// std::cout &lt;&lt; \"Assigning task (C++) \" &lt;&lt; this-&gt;thread_idx &lt;&lt; \" \"\n//           &lt;&lt; this-&gt;ready &lt;&lt; std::endl;\nassert(ready == false);\nstd::unique_lock&lt;std::mutex&gt; lck(mtx);\nthis-&gt;task = task;\nthis-&gt;ready = true;\nthis-&gt;notified = true;\ncv.notify_one();\n}\n\nvoid InnerWorker::get_task(InnerTask **task, bool *is_data_task) {\nthis-&gt;scheduler-&gt;decrease_num_notified_workers();\n*task = this-&gt;task;\n*is_data_task = this-&gt;task-&gt;is_data_task();\n}\n\nvoid InnerWorker::remove_task() {\n// std::cout &lt;&lt; \"Removing task (C++) \" &lt;&lt; this-&gt;thread_idx &lt;&lt; \" \"\n//           &lt;&lt; this-&gt;task-&gt;name &lt;&lt; std::endl;\nstd::unique_lock&lt;std::mutex&gt; lck(mtx);\nthis-&gt;task = nullptr;\nthis-&gt;ready = false;\nthis-&gt;notified = false;\n}\n\nvoid InnerWorker::stop() {\n// signal cv so that we can terminate\nstd::unique_lock&lt;std::mutex&gt; lck(mtx);\nLOG_INFO(WORKER, \"Worker stopping: {}\", this-&gt;thread_idx);\nthis-&gt;notified = true;\ncv.notify_all();\n}\n// WorkerPool Implementation\n\ntemplate &lt;typename AllWorkers_t, typename ActiveWorkers_t&gt;\nvoid WorkerPool&lt;AllWorkers_t, ActiveWorkers_t&gt;::enqueue_worker(\nInnerWorker *worker) {\nthis-&gt;active_workers.push_back(worker);\n// std::cout &lt;&lt; \"Enqueued Worker ID: \" &lt;&lt; worker-&gt;thread_idx &lt;&lt; std::endl;\n// std::cout &lt;&lt; \"Active workers: \" &lt;&lt; this-&gt;active_workers.atomic_size()\n//           &lt;&lt; std::endl;\n}\n\ntemplate &lt;typename AllWorkers_t, typename ActiveWorkers_t&gt;\nInnerWorker *WorkerPool&lt;AllWorkers_t, ActiveWorkers_t&gt;::dequeue_worker() {\nInnerWorker *worker = this-&gt;active_workers.back_and_pop();\n// std::cout &lt;&lt; \"Dequeued Worker ID: \" &lt;&lt; worker-&gt;thread_idx &lt;&lt; std::endl;\nreturn worker;\n}\n\ntemplate &lt;typename AllWorkers_t, typename ActiveWorkers_t&gt;\nvoid WorkerPool&lt;AllWorkers_t, ActiveWorkers_t&gt;::add_worker(\nInnerWorker *worker) {\n// std::cout &lt;&lt; \"Adding worker: \" &lt;&lt; worker-&gt;thread_idx &lt;&lt; std::endl;\nthis-&gt;all_workers.push_back(worker);\nassert(this-&gt;all_workers.size() &lt;= this-&gt;max_workers);\n}\n\ntemplate &lt;typename AllWorkers_t, typename ActiveWorkers_t&gt;\nint WorkerPool&lt;AllWorkers_t, ActiveWorkers_t&gt;::get_num_available_workers() {\nauto num_workers = this-&gt;active_workers.atomic_size();\n// std::cout &lt;&lt; \"Available workers: \" &lt;&lt; num_workers &lt;&lt; std::endl;\nreturn num_workers;\n}\n\ntemplate &lt;typename AllWorkers_t, typename ActiveWorkers_t&gt;\nint WorkerPool&lt;AllWorkers_t, ActiveWorkers_t&gt;::get_num_workers() {\nreturn this-&gt;max_workers;\n}\n\ntemplate &lt;typename AllWorkers_t, typename ActiveWorkers_t&gt;\nvoid WorkerPool&lt;AllWorkers_t, ActiveWorkers_t&gt;::set_num_workers(int nworkers) {\nthis-&gt;max_workers = nworkers;\n}\n\ntemplate &lt;typename AllWorkers_t, typename ActiveWorkers_t&gt;\nint WorkerPool&lt;AllWorkers_t, ActiveWorkers_t&gt;::increase_num_notified_workers() {\nint before = this-&gt;notified_workers.fetch_add(1);\nreturn before;\n}\n\ntemplate &lt;typename AllWorkers_t, typename ActiveWorkers_t&gt;\nint WorkerPool&lt;AllWorkers_t, ActiveWorkers_t&gt;::decrease_num_notified_workers() {\nint before = this-&gt;notified_workers.fetch_sub(1);\nreturn before;\n}\n\ntemplate &lt;typename AllWorkers_t, typename ActiveWorkers_t&gt;\nvoid WorkerPool&lt;AllWorkers_t, ActiveWorkers_t&gt;::spawn_wait() {\n\nstd::this_thread::sleep_for(std::chrono::nanoseconds(1000));\n}\n\ntemplate class WorkerPool&lt;WorkerQueue, WorkerQueue&gt;;\n\n// Scheduler Implementation\n\nInnerScheduler::InnerScheduler(DeviceManager *device_manager)\n: device_manager_(device_manager), parray_tracker_(device_manager) {\n\n// A dummy task count is used to keep the scheduler alive.\n// NOTE: At least one task must be added to the scheduler by the main thread,\n// otherwise the runtime will finish immediately\n// this-&gt;increase_num_active_tasks();\n\nthis-&gt;workers.set_num_workers(1);\n\n// Mapping policy\nstd::shared_ptr&lt;LocalityLoadBalancingMappingPolicy&gt; mapping_policy =\nstd::make_shared&lt;LocalityLoadBalancingMappingPolicy&gt;(\ndevice_manager, &amp;this-&gt;parray_tracker_);\n\n// Initialize the phases\nthis-&gt;mapper = new Mapper(this, device_manager, std::move(mapping_policy));\nthis-&gt;memory_reserver = new MemoryReserver(this, device_manager);\nthis-&gt;runtime_reserver = new RuntimeReserver(this, device_manager);\nthis-&gt;launcher = new Launcher(this, device_manager);\n// this-&gt;resources = std::make_shared &lt; ResourcePool&lt;std::atomic&lt;int64_t&gt;&gt;();\n}\n\nInnerScheduler::~InnerScheduler() {\ndelete this-&gt;mapper;\ndelete this-&gt;memory_reserver;\ndelete this-&gt;runtime_reserver;\ndelete this-&gt;launcher;\n}\n\nvoid InnerScheduler::set_num_workers(int nworkers) {\nthis-&gt;workers.set_num_workers(nworkers);\n}\n\nvoid InnerScheduler::set_py_scheduler(void *py_scheduler) {\nthis-&gt;py_scheduler = py_scheduler;\n}\n\nvoid InnerScheduler::set_stop_callback(stopfunc_t stop_callback) {\nthis-&gt;stop_callback = stop_callback;\n}\n\nvoid InnerScheduler::run() {\nNVTX_RANGE(\"Scheduler::run\", NVTX_COLOR_RED)\nunsigned long long iteration_count = 0;\nwhile (this-&gt;should_run.load()) {\nauto status = this-&gt;activate();\nif (this-&gt;sleep_flag) {\nstd::this_thread::sleep_for(std::chrono::milliseconds(this-&gt;sleep_time));\n}\n}\n}\n\nvoid InnerScheduler::stop() {\nLOG_INFO(SCHEDULER, \"Stopping scheduler\");\nthis-&gt;should_run = false;\nlaunch_stop_callback(this-&gt;stop_callback, this-&gt;py_scheduler);\nLOG_INFO(SCHEDULER, \"Stopped scheduler\");\n}\n\nScheduler::Status InnerScheduler::activate() {\n// std::cout&lt;&lt; \"Scheduler Activated\" &lt;&lt; std::endl;\n\nthis-&gt;mapper-&gt;run(this-&gt;memory_reserver);\nthis-&gt;memory_reserver-&gt;run(this-&gt;runtime_reserver);\nthis-&gt;runtime_reserver-&gt;run(this-&gt;launcher);\n\n// LOG_TRACE(SCHEDULER, \"ReadyPhase Status: {}\", this-&gt;runtime_reserver);\nreturn this-&gt;status;\n}\n\nvoid InnerScheduler::activate_wrapper() { this-&gt;activate(); }\n\nvoid InnerScheduler::spawn_task(InnerTask *task) {\nLOG_INFO(SCHEDULER, \"Spawning task: {}\", task);\nNVTX_RANGE(\"Scheduler::spawn_task\", NVTX_COLOR_RED)\n\nauto status = task-&gt;process_dependencies();\nthis-&gt;increase_num_active_tasks();\ntask-&gt;set_state(Task::SPAWNED);\nthis-&gt;enqueue_task(task, status);\n}\n\nvoid InnerScheduler::enqueue_task(InnerTask *task, Task::StatusFlags status) {\n// TODO: Change this to appropriate phase as it becomes implemented\nLOG_INFO(SCHEDULER, \"Enqueing task: {}, Status: {}\", task, status);\nif (status.mappable &amp;&amp; (task-&gt;get_state() &lt; Task::MAPPED)) {\nLOG_INFO(SCHEDULER, \"Enqueing task: {} to mapper\", task);\ntask-&gt;set_status(Task::MAPPABLE);\nthis-&gt;mapper-&gt;enqueue(task);\n} else if (status.reservable &amp;&amp; (task-&gt;get_state() == Task::MAPPED)) {\ntask-&gt;set_status(Task::RESERVABLE);\nLOG_INFO(SCHEDULER, \"Enqueing task: {} to memory reserver\", task);\nthis-&gt;memory_reserver-&gt;enqueue(task);\n} else if (status.runnable &amp;&amp; (task-&gt;get_state() == Task::RESERVED)) {\ntask-&gt;set_status(Task::RUNNABLE);\n// std::cout &lt;&lt; \"ENQUEUE FROM CALLBACK\" &lt;&lt; std::endl;\nLOG_INFO(SCHEDULER, \"Enqueing task: {} to runtime reserver\", task);\nthis-&gt;runtime_reserver-&gt;enqueue(task);\n}\n}\n\nvoid InnerScheduler::enqueue_tasks(TaskStateList &amp;tasks) {\n// LOG_INFO(SCHEDULER, \"Enqueing tasks: {}\", tasks);\nfor (auto task_status : tasks) {\nthis-&gt;enqueue_task(task_status.first, task_status.second);\n}\n}\n\nvoid InnerScheduler::add_worker(InnerWorker *worker) {\nLOG_INFO(SCHEDULER, \"Adding worker {} to pool\", worker);\nthis-&gt;workers.add_worker(worker);\n}\n\nvoid InnerScheduler::enqueue_worker(InnerWorker *worker) {\nLOG_INFO(SCHEDULER, \"Enqueuing worker: {} is ready.\", worker);\nthis-&gt;workers.enqueue_worker(worker);\n}\n\nvoid InnerScheduler::task_cleanup_presync(InnerWorker *worker, InnerTask *task,\nint state) {\nNVTX_RANGE(\"Scheduler::task_cleanup_presync\", NVTX_COLOR_MAGENTA)\nLOG_INFO(WORKER, \"Cleaning up: {} on  {}\", task, worker);\n\n// std::cout &lt;&lt; \"CLEANUP PRE SYNC: \" &lt;&lt; state &lt;&lt; \" \" &lt;&lt; Task::RUNAHEAD\n//           &lt;&lt; std::endl;\n\n// std::cout &lt;&lt; \"Task state: \" &lt;&lt; state &lt;&lt; std::endl;\nif (state == Task::RUNAHEAD) {\n\n// Notify dependents that they can be scheduled\nauto &amp;enqueue_buffer = worker-&gt;enqueue_buffer;\ntask-&gt;notify_dependents(enqueue_buffer, Task::RUNAHEAD);\nif (enqueue_buffer.size() &gt; 0) {\nthis-&gt;enqueue_tasks(enqueue_buffer);\nenqueue_buffer.clear();\n}\n}\n}\n\nvoid InnerScheduler::task_cleanup_postsync(InnerWorker *worker, InnerTask *task,\nint state) {\nNVTX_RANGE(\"Scheduler::task_cleanup_postsync\", NVTX_COLOR_MAGENTA)\n\n// std::cout &lt;&lt; \"Task Cleanup Post Sync\" &lt;&lt; std::endl;\n\nif (state == Task::RUNAHEAD) {\nthis-&gt;decrease_num_active_tasks();\ntask-&gt;notify_dependents_completed();\n}\n\n// Release all resources for this task on all devices\nfor (size_t i = 0; i &lt; task-&gt;assigned_devices.size(); ++i) {\nDevice *device = task-&gt;assigned_devices[i];\nDevID_t dev_id = device-&gt;get_global_id();\nResourcePool_t &amp;device_pool = device-&gt;get_reserved_pool();\nResourcePool_t &amp;task_pool =\ntask-&gt;device_constraints[device-&gt;get_global_id()];\n\n// TODO(wlr): This needs to be changed to not release PARRAY resources\ndevice_pool.increase&lt;ResourceCategory::All&gt;(task_pool);\n\n// PArrays could be evicted even during task barrier continuation.\n// However, these PArrays will be allocated and tracked\n// again after the task restarts.\nif (!task-&gt;is_data_task()) {\nfor (size_t j = 0; j &lt; task-&gt;parray_list[i].size(); ++j) {\nparray::InnerPArray *parray = task-&gt;parray_list[i][j].first;\nparray-&gt;decr_num_active_tasks(dev_id);\n// This PArray is not released from the PArray tracker here,\n// but when it is EVICTED, it will check the number of referneces\n// and will be released if that is 0.\n}\n}\n}\n\n// Clear all assigned streams from the task\ntask-&gt;streams.clear();\nthis-&gt;launcher-&gt;num_running_tasks--;\nworker-&gt;remove_task();\n\nif (state == Task::RUNNING) {\ntask-&gt;reset();\nauto status = task-&gt;process_dependencies();\nthis-&gt;enqueue_task(task, status);\n}\n\nthis-&gt;enqueue_worker(worker);\n}\n\nvoid InnerScheduler::task_cleanup(InnerWorker *worker, InnerTask *task,\nint state) {\nNVTX_RANGE(\"Scheduler::task_cleanup\", NVTX_COLOR_MAGENTA)\n\ntask_cleanup_presync(worker, task, state);\n// synchronize task enviornment\ntask-&gt;synchronize_events();\ntask_cleanup_postsync(worker, task, state);\n}\n\nint InnerScheduler::get_num_active_tasks() { return this-&gt;num_active_tasks; }\n\nvoid InnerScheduler::increase_num_active_tasks() {\nint count = this-&gt;num_active_tasks.fetch_add(1);\n// std::cout &lt;&lt; \"Increasing num active tasks: \" &lt;&lt; count + 1 &lt;&lt; std::endl;\n}\n\nvoid InnerScheduler::decrease_num_active_tasks() {\n\nint count = this-&gt;num_active_tasks.fetch_sub(1) - 1;\n\n// std::cout &lt;&lt; \"Decreasing num active tasks: \" &lt;&lt; count &lt;&lt; std::endl;\n\nif (count == 0) {\nthis-&gt;stop();\n}\n}\n\nint InnerScheduler::increase_num_notified_workers() {\nreturn this-&gt;workers.increase_num_notified_workers();\n}\n\nint InnerScheduler::decrease_num_notified_workers() {\nreturn this-&gt;workers.decrease_num_notified_workers();\n}\n\nint InnerScheduler::get_num_running_tasks() {\nreturn this-&gt;launcher-&gt;get_count();\n}\n\nint InnerScheduler::get_num_ready_tasks() {\nreturn this-&gt;runtime_reserver-&gt;get_count();\n}\n\nvoid InnerScheduler::spawn_wait() { this-&gt;workers.spawn_wait(); }\n</code></pre>"},{"location":"runtime/dir_e8f04c5daeb71f4cc4524828a1d702ea/","title":"Dir src/c/backend/impl_none","text":"<p>FileList &gt; backend &gt; impl_none</p>"},{"location":"runtime/dir_e8f04c5daeb71f4cc4524828a1d702ea/#files","title":"Files","text":"Type Name file utility.cpp <p>The documentation for this class was generated from the following file <code>src/c/backend/impl_none/</code></p>"},{"location":"runtime/utility_8cpp/","title":"File utility.cpp","text":"<p>FileList &gt; backend &gt; impl_none &gt; utility.cpp</p> <p>Go to the source code of this file.</p> <ul> <li><code>#include &lt;gpu_utility.hpp&gt;</code></li> </ul>"},{"location":"runtime/utility_8cpp/#public-functions","title":"Public Functions","text":"Type Name void event_synchronize (uintptr_t event_ptr)  void event_wait (uintptr_t event_ptr, uintptr_t stream_ptr)  void gpu_busy_sleep (const int device, const unsigned long t, uintptr_t stream_ptr)  void stream_synchronize (uintptr_t stream_ptr)"},{"location":"runtime/utility_8cpp/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/utility_8cpp/#function-event_synchronize","title":"function event_synchronize","text":"<pre><code>void event_synchronize (\nuintptr_t event_ptr\n) </code></pre>"},{"location":"runtime/utility_8cpp/#function-event_wait","title":"function event_wait","text":"<pre><code>void event_wait (\nuintptr_t event_ptr,\nuintptr_t stream_ptr\n) </code></pre>"},{"location":"runtime/utility_8cpp/#function-gpu_busy_sleep","title":"function gpu_busy_sleep","text":"<pre><code>void gpu_busy_sleep (\nconst int device,\nconst unsigned long t,\nuintptr_t stream_ptr\n) </code></pre>"},{"location":"runtime/utility_8cpp/#function-stream_synchronize","title":"function stream_synchronize","text":"<pre><code>void stream_synchronize (\nuintptr_t stream_ptr\n) </code></pre> <p>The documentation for this class was generated from the following file <code>src/c/backend/impl_none/utility.cpp</code></p>"},{"location":"runtime/utility_8cpp_source/","title":"File utility.cpp","text":"<p>File List &gt; backend &gt; impl_none &gt; utility.cpp</p> <p>Go to the documentation of this file. </p> <pre><code>#include &lt;gpu_utility.hpp&gt;\n\nvoid gpu_busy_sleep(const int device, const unsigned long t,\nuintptr_t stream_ptr) {\nprintf(\"gpu_busy_sleep() is not implemented for this backend.\\n\");\n}\n\nvoid event_synchronize(uintptr_t event_ptr){};\nvoid event_wait(uintptr_t event_ptr, uintptr_t stream_ptr){};\nvoid stream_synchronize(uintptr_t stream_ptr){};\n</code></pre>"},{"location":"runtime/dir_aac5c5009c3d7239aa4d388e6e5c1a52/","title":"Dir src/c/backend/include","text":"<p>FileList &gt; backend &gt; include</p>"},{"location":"runtime/dir_aac5c5009c3d7239aa4d388e6e5c1a52/#files","title":"Files","text":"Type Name file atomic_wrapper.hpp Provides a copyable atomic class for use in STL containers. file containers.hpp Provides interface for thread-safe containers. file device.hpp Provides interface for abstract device object. file device_manager.hpp Provides interface for device initialization and management. file device_queues.hpp Provides interface for task queues and collections of task queues for multidevice tasks. file gpu_utility.hpp Provides architecture independent interface to event and stream creation &amp; synchronization. file parray.hpp Provides C++ interface to PArray State and ID. file parray_state.hpp Provides C++ interface to parray coherency. file parray_tracker.hpp Provides interface to scheduler tracking of parray data objects. file phases.hpp Interface for scheduler runtime phases. file policy.hpp Interface for mapping policies. file profiling.hpp Provides macros for NVTX profiling and BINLOG tracing. file resource_requirements.hpp Provides task constraint classes to hold potential placement locations and architectures. file resources.hpp Provides a resource pool for tracking resource usage. file runtime.hpp The core C++ runtime for Parla. Includes the main scheduler and task classes. <p>The documentation for this class was generated from the following file <code>src/c/backend/include/</code></p>"},{"location":"runtime/atomic__wrapper_8hpp/","title":"File atomic_wrapper.hpp","text":"<p>FileList &gt; backend &gt; include &gt; atomic_wrapper.hpp</p> <p>Go to the source code of this file.</p> <p>Provides a copyable atomic class for use in STL containers. </p> <ul> <li><code>#include &lt;atomic&gt;</code></li> </ul>"},{"location":"runtime/atomic__wrapper_8hpp/#classes","title":"Classes","text":"Type Name class CopyableAtomic &lt;typename T&gt;A copyable atomic class inherited from std::atomic. <p>The documentation for this class was generated from the following file <code>src/c/backend/include/atomic_wrapper.hpp</code></p>"},{"location":"runtime/atomic__wrapper_8hpp_source/","title":"File atomic_wrapper.hpp","text":"<p>File List &gt; backend &gt; include &gt; atomic_wrapper.hpp</p> <p>Go to the documentation of this file. </p> <pre><code>#ifndef PARLA_ATOMIC_WRAPPER_HPP\n#define PARLA_ATOMIC_WRAPPER_HPP\n\n#include &lt;atomic&gt;\n\ntemplate &lt;typename T&gt; class CopyableAtomic : public std::atomic&lt;T&gt; {\n\npublic:\nCopyableAtomic() : std::atomic&lt;T&gt;(T{}) {}\nconstexpr CopyableAtomic(T base) : std::atomic&lt;T&gt;(base) {}\n\nconstexpr CopyableAtomic(const CopyableAtomic&lt;T&gt; &amp;other)\n: CopyableAtomic(other.load(std::memory_order_relaxed)) {}\n\nCopyableAtomic &amp;operator=(const CopyableAtomic&lt;T&gt; &amp;other) {\nthis-&gt;store(other.load(std::memory_order_relaxed),\nstd::memory_order_relaxed);\nreturn *this;\n}\n};\n\n#endif\n</code></pre>"},{"location":"runtime/containers_8hpp/","title":"File containers.hpp","text":"<p>FileList &gt; backend &gt; include &gt; containers.hpp</p> <p>Go to the source code of this file.</p> <p>Provides interface for thread-safe containers. </p> <ul> <li><code>#include &lt;iostream&gt;</code></li> <li><code>#include &lt;deque&gt;</code></li> <li><code>#include &lt;list&gt;</code></li> <li><code>#include &lt;map&gt;</code></li> <li><code>#include &lt;vector&gt;</code></li> <li><code>#include &lt;queue&gt;</code></li> <li><code>#include &lt;stack&gt;</code></li> <li><code>#include &lt;atomic&gt;</code></li> <li><code>#include &lt;condition_variable&gt;</code></li> <li><code>#include &lt;mutex&gt;</code></li> <li><code>#include &lt;string&gt;</code></li> <li><code>#include &lt;assert.h&gt;</code></li> <li><code>#include &lt;chrono&gt;</code></li> </ul>"},{"location":"runtime/containers_8hpp/#classes","title":"Classes","text":"Type Name class ProtectedQueue &lt;typename T&gt; class ProtectedVector &lt;typename T&gt;"},{"location":"runtime/containers_8hpp/#macros","title":"Macros","text":"Type Name define PARLA_CONTAINERS_HPP"},{"location":"runtime/containers_8hpp/#macro-definition-documentation","title":"Macro Definition Documentation","text":""},{"location":"runtime/containers_8hpp/#define-parla_containers_hpp","title":"define PARLA_CONTAINERS_HPP","text":"<pre><code>#define PARLA_CONTAINERS_HPP \n</code></pre> <p>The documentation for this class was generated from the following file <code>src/c/backend/include/containers.hpp</code></p>"},{"location":"runtime/containers_8hpp_source/","title":"File containers.hpp","text":"<p>File List &gt; backend &gt; include &gt; containers.hpp</p> <p>Go to the documentation of this file. </p> <pre><code>#pragma once\n#ifndef PARLA_CONTAINERS_HPP\n#define PARLA_CONTAINERS_HPP\n\n#include &lt;iostream&gt;\n\n#include &lt;deque&gt;\n#include &lt;list&gt;\n#include &lt;map&gt;\n#include &lt;vector&gt;\n\n#include &lt;queue&gt;\n#include &lt;stack&gt;\n\n#include &lt;atomic&gt;\n#include &lt;condition_variable&gt;\n#include &lt;mutex&gt;\n#include &lt;string&gt;\n\n#include &lt;assert.h&gt;\n#include &lt;chrono&gt;\n\n/* Header only implementations of thread-safe data structures and helpers */\n/* This will probably grow and change signifigantly as development continues and\n * needs and bottlenecks change.*/\n\n// By default, types are not atomic,\n// template &lt;typename T&gt; auto constexpr is_atomic = false;\n// but std::atomic&lt;T&gt; types are,\n// template &lt;typename T&gt; auto constexpr is_atomic&lt;std::atomic&lt;T&gt;&gt; = true;\n// as well as std::atomic_flag.\n// template &lt;&gt; auto constexpr is_atomic&lt;std::atomic_flag&gt; = true;\n\ntemplate &lt;typename T&gt; class ProtectedVector {\n\nprivate:\nstd::vector&lt;T&gt; vec = std::vector&lt;T&gt;();\nstd::atomic&lt;int&gt; length{0};\nstd::mutex mtx;\nstd::string name;\n\npublic:\nProtectedVector() = default;\n\nProtectedVector(std::string name) {\nthis-&gt;mtx.lock();\nthis-&gt;name = name;\nthis-&gt;mtx.unlock();\n}\n\nProtectedVector(std::string name, std::vector&lt;T&gt; vec) {\nthis-&gt;mtx.lock();\nthis-&gt;name = name;\nthis-&gt;vec = vec;\nthis-&gt;mtx.unlock();\n}\n\nProtectedVector(std::string name, size_t size) {\nthis-&gt;mtx.lock();\nthis-&gt;name = name;\nthis-&gt;vec.reserve(size);\nthis-&gt;mtx.unlock();\n}\n\nProtectedVector &amp;operator=(ProtectedVector &amp;&amp;other) {\nthis-&gt;length.exchange(other.length);\nthis-&gt;vec = std::move(other.vec);\n// The string should be small\nthis-&gt;name = std::move(other.name);\nreturn *this;\n}\n\nvoid lock() { this-&gt;mtx.lock(); }\n\nvoid unlock() { this-&gt;mtx.unlock(); }\n\nvoid push_back(T a) {\nthis-&gt;mtx.lock();\nthis-&gt;vec.push_back(a);\nthis-&gt;mtx.unlock();\nthis-&gt;length++;\n}\n\nvoid push_back(std::vector&lt;T&gt; &amp;a) {\nthis-&gt;mtx.lock();\nthis-&gt;vec.insert(this-&gt;vec.end(), a.begin(), a.end());\nthis-&gt;mtx.unlock();\nthis-&gt;length += a.size();\n}\n\nvoid push_back_unsafe(T a) {\nthis-&gt;vec.push_back(a);\nthis-&gt;length++;\n}\n\nvoid push_back_unsafe(std::vector&lt;T&gt; &amp;a) {\nthis-&gt;vec.insert(this-&gt;vec.end(), a.begin(), a.end());\nthis-&gt;length += a.size();\n}\n\nvoid pop_back() {\nthis-&gt;mtx.lock();\nthis-&gt;vec.pop_back();\nthis-&gt;mtx.unlock();\nthis-&gt;length--;\n}\n\nvoid pop_back_unsafe() {\nthis-&gt;vec.pop_back();\nthis-&gt;length--;\n}\n\nint atomic_size() { return this-&gt;length.load(); }\n\nsize_t size() {\nthis-&gt;mtx.lock();\nint size = this-&gt;vec.size();\nthis-&gt;mtx.unlock();\nreturn size;\n}\n\nsize_t size_unsafe() { return this-&gt;vec.size(); }\n\nT operator[](size_t i) {\nthis-&gt;mtx.lock();\nauto val = this-&gt;vec[i];\nthis-&gt;mtx.unlock();\nreturn val;\n}\n\nT at(size_t i) {\nthis-&gt;mtx.lock();\nT val = this-&gt;vec.at(i);\nthis-&gt;mtx.unlock();\nreturn val;\n}\n\nT at_unsafe(size_t i) { return this-&gt;vec.at(i); }\n\nT back() {\nthis-&gt;mtx.lock();\nT val = this-&gt;vec.back();\nthis-&gt;mtx.unlock();\nreturn val;\n}\n\ninline T back_unsafe() { return this-&gt;vec.back(); }\n\nT back_and_pop() {\nthis-&gt;mtx.lock();\nT val = this-&gt;back_unsafe();\nthis-&gt;pop_back_unsafe();\nthis-&gt;mtx.unlock();\nreturn val;\n}\n\ninline T back_and_pop_unsafe() {\nT val = this-&gt;back_unsafe();\nthis-&gt;pop_back_unsafe();\nreturn val;\n}\n\nT front() {\nthis-&gt;mtx.lock();\nT val = this-&gt;vec.front();\nthis-&gt;mtx.unlock();\nreturn val;\n}\n\ninline T front_unsafe() { return this-&gt;vec.front(); }\n\n// TODO(hc): I think this can be just called \"pop\"\n// TODO(wlr): I wasn't sure since STL container `pop` doesn't return the old\n// head.\nT front_and_pop() {\nthis-&gt;mtx.lock();\nT val = this-&gt;front_unsafe();\nthis-&gt;pop_front_unsafe();\nthis-&gt;mtx.unlock();\nreturn val;\n}\n\nT front_and_pop_unsafe() {\nT val = this-&gt;front_unsafe();\nthis-&gt;pop_front_unsafe();\nreturn val;\n}\n\nvoid clear() {\nthis-&gt;mtx.lock();\nthis-&gt;vec.clear();\nthis-&gt;mtx.unlock();\nthis-&gt;length = 0;\n}\n\ninline void clear_unsafe() {\nthis-&gt;vec.clear();\nthis-&gt;length = 0;\n}\n\nvoid reserve(size_t size) {\nthis-&gt;mtx.lock();\nthis-&gt;vec.reserve(size);\nthis-&gt;mtx.unlock();\n}\n\ninline void reserve_unsafe(size_t size) { this-&gt;vec.reserve(size); }\n\nvoid resize(size_t size) {\nthis-&gt;mtx.lock();\nthis-&gt;vec.resize(size);\nthis-&gt;mtx.unlock();\n}\n\nvoid resize_unsafe(size_t size) { this-&gt;vec.resize(size); }\n\nT get(size_t i) {\nthis-&gt;mtx.lock();\nT val = this-&gt;vec[i];\nthis-&gt;mtx.unlock();\nreturn val;\n}\n\ninline T get_unsafe(size_t i) { return this-&gt;vec[i]; }\n\nvoid set(size_t i, T val) {\nthis-&gt;mtx.lock();\nthis-&gt;vec[i] = val;\nthis-&gt;mtx.unlock();\n}\n\ninline void set_unsafe(size_t i, T val) { this-&gt;vec[i] = val; }\n\nstd::vector&lt;T&gt; get_vector_copy() {\nthis-&gt;mtx.lock();\nstd::vector&lt;T&gt; vec = this-&gt;vec;\nthis-&gt;mtx.unlock();\nreturn vec;\n}\n\ninline std::vector&lt;T&gt; get_vector_copy_unsafe() {\nstd::vector&lt;T&gt; vec = this-&gt;vec;\nreturn vec;\n}\n\nstd::vector&lt;T&gt; &amp;get_vector() {\nthis-&gt;mtx.lock();\nstd::vector&lt;T&gt; &amp;vec = this-&gt;vec;\nthis-&gt;mtx.unlock();\nreturn vec;\n}\n\nstd::vector&lt;T&gt; &amp;get_vector_unsafe() {\nthis-&gt;mtx.lock();\nstd::vector&lt;T&gt; &amp;vec = this-&gt;vec;\nthis-&gt;mtx.unlock();\nreturn vec;\n}\n\nbool empty() {\nthis-&gt;mtx.lock();\nbool empty = this-&gt;vec.empty();\nthis-&gt;mtx.unlock();\nreturn empty;\n}\n\ninline bool empty_unsafe() { return this-&gt;vec.empty(); }\n};\n\ntemplate &lt;typename T&gt; class ProtectedQueue {\n\nprivate:\nstd::deque&lt;T&gt; q = std::deque&lt;T&gt;();\nstd::atomic&lt;int&gt; length{0};\nstd::mutex mtx;\nstd::string name;\n\npublic:\nProtectedQueue() = default;\n\nProtectedQueue(std::string name) {\nthis-&gt;mtx.lock();\nthis-&gt;name = name;\nthis-&gt;mtx.unlock();\n}\n\nProtectedQueue(std::string name, std::deque&lt;T&gt; q) {\nthis-&gt;mtx.lock();\nthis-&gt;name = name;\nthis-&gt;q = q;\nthis-&gt;mtx.unlock();\n}\n\nProtectedQueue(std::string name, size_t size) {\nthis-&gt;mtx.lock();\nthis-&gt;name = name;\nthis-&gt;q.reserve(size);\nthis-&gt;mtx.unlock();\n}\n\nvoid lock() { this-&gt;mtx.lock(); }\n\nvoid unlock() { this-&gt;mtx.unlock(); }\n\nvoid push_back(T a) {\nthis-&gt;mtx.lock();\nthis-&gt;q.push_back(a);\nthis-&gt;mtx.unlock();\nthis-&gt;length++;\n}\n\ninline void push_back_unsafe(T a) {\nthis-&gt;q.push_back(a);\nthis-&gt;length++;\n}\n\nvoid push_back(std::vector&lt;T&gt; &amp;a) {\nthis-&gt;mtx.lock();\nfor (auto val : a) {\nthis-&gt;push_back_unsafe(val);\n}\nthis-&gt;mtx.unlock();\n}\n\ninline void push_back_unsafe(std::vector&lt;T&gt; &amp;a) {\nfor (auto val : a) {\nthis-&gt;push_back_unsafe(val);\n}\n}\n\nvoid push_front(T a) {\nthis-&gt;mtx.lock();\nthis-&gt;q.push_back(a);\nthis-&gt;mtx.unlock();\nthis-&gt;length++;\n}\n\ninline void push_front_unsafe(T a) {\nthis-&gt;q.push_back(a);\nthis-&gt;length++;\n}\n\nvoid push_front(std::vector&lt;T&gt; &amp;a) {\nthis-&gt;mtx.lock();\nfor (auto val : a) {\nthis-&gt;push_back_unsafe(val);\n}\nthis-&gt;mtx.unlock();\n}\n\ninline void push_front_unsafe(std::vector&lt;T&gt; &amp;a) {\nfor (auto val : a) {\nthis-&gt;push_back_unsafe(val);\n}\n}\n\nvoid pop_back() {\nthis-&gt;mtx.lock();\nthis-&gt;q.pop_back();\nthis-&gt;mtx.unlock();\nthis-&gt;length--;\n}\n\ninline void pop_back_unsafe() {\nthis-&gt;q.pop_back();\nthis-&gt;length--;\n}\n\nvoid pop_front() {\nthis-&gt;mtx.lock();\nthis-&gt;q.pop_front();\nthis-&gt;mtx.unlock();\nthis-&gt;length--;\n}\n\ninline void pop_front_unsafe() {\nthis-&gt;q.pop_front();\nthis-&gt;length--;\n}\n\nsize_t atomic_size() { return this-&gt;length.load(); }\n\nsize_t size() {\nthis-&gt;mtx.lock();\nint size = this-&gt;q.size();\nthis-&gt;mtx.unlock();\nreturn size;\n}\n\nsize_t size_unsafe() { return this-&gt;q.size(); }\n\nT operator[](size_t i) {\nthis-&gt;mtx.lock();\nauto val = this-&gt;q[i];\nthis-&gt;mtx.unlock();\nreturn val;\n}\n\nT at(size_t i) {\nthis-&gt;mtx.lock();\nT val = this-&gt;q.at(i);\nthis-&gt;mtx.unlock();\nreturn val;\n}\n\ninline T at_unsafe(size_t i) { return this-&gt;q.at(i); }\n\nT back() {\nthis-&gt;mtx.lock();\nT val = this-&gt;q.back();\nthis-&gt;mtx.unlock();\nreturn val;\n}\n\ninline T back_unsafe() { return this-&gt;q.back(); }\n\nT back_and_pop() {\nthis-&gt;mtx.lock();\nT val = this-&gt;back_unsafe();\nthis-&gt;pop_back_unsafe();\nthis-&gt;mtx.unlock();\nreturn val;\n}\n\ninline T back_and_pop_unsafe() {\nT val = this-&gt;back_unsafe();\nthis-&gt;pop_back_unsafe();\nreturn val;\n}\n\nT front() {\nthis-&gt;mtx.lock();\nT val = this-&gt;q.front();\nthis-&gt;mtx.unlock();\nreturn val;\n}\n\ninline T front_unsafe() { return this-&gt;q.front(); }\n\nT front_and_pop() {\nthis-&gt;mtx.lock();\nT val = this-&gt;front_unsafe();\nthis-&gt;pop_front_unsafe();\nthis-&gt;mtx.unlock();\nreturn val;\n}\n\ninline T front_and_pop_unsafe() {\nT val = this-&gt;front_unsafe();\nthis-&gt;pop_front_unsafe();\nreturn val;\n}\n\nvoid clear() {\nthis-&gt;mtx.lock();\nthis-&gt;q.clear();\nthis-&gt;mtx.unlock();\nthis-&gt;length = 0;\n}\n\ninline void clear_unsafe() {\nthis-&gt;q.clear();\nthis-&gt;length = 0;\n}\n\nbool empty() {\nthis-&gt;mtx.lock();\nbool empty = this-&gt;q.empty();\nthis-&gt;mtx.unlock();\nreturn empty;\n}\n\ninline bool empty_unsafe() { return this-&gt;q.empty(); }\n};\n\n#endif // PARLA_CONTAINERS_HPP\n</code></pre>"},{"location":"runtime/device_8hpp/","title":"File device.hpp","text":"<p>FileList &gt; backend &gt; include &gt; device.hpp</p> <p>Go to the source code of this file.</p> <p>Provides interface for abstract device object. </p> <ul> <li><code>#include \"resources.hpp\"</code></li> <li><code>#include &lt;atomic&gt;</code></li> <li><code>#include &lt;iostream&gt;</code></li> <li><code>#include &lt;string&gt;</code></li> <li><code>#include &lt;unordered_map&gt;</code></li> <li><code>#include &lt;vector&gt;</code></li> </ul>"},{"location":"runtime/device_8hpp/#classes","title":"Classes","text":"Type Name class CPUDevice class CUDADevice class Device Devices can be distinguished from other devices by a class type and its index."},{"location":"runtime/device_8hpp/#public-types","title":"Public Types","text":"Type Name typedef uint32_t DevID_t enum DeviceType Architecture types for devices. typedef Resource_t MemorySz_t typedef ResourcePool ResourcePool_t typedef Resource_t VCU_t"},{"location":"runtime/device_8hpp/#public-attributes","title":"Public Attributes","text":"Type Name constexpr const int NUM_DEVICE_TYPES   = = architecture_types.size() const std::array&lt; std::string, NUM_DEVICE_TYPES &gt; architecture_names   = { \"CPU\", \"CUDA\"} constexpr const std::array architecture_types   = {DeviceType::CPU, DeviceType::CUDA}"},{"location":"runtime/device_8hpp/#macros","title":"Macros","text":"Type Name define PARLA_DEVICE_HPP"},{"location":"runtime/device_8hpp/#public-types-documentation","title":"Public Types Documentation","text":""},{"location":"runtime/device_8hpp/#typedef-devid_t","title":"typedef DevID_t","text":"<pre><code>using DevID_t =  uint32_t;\n</code></pre>"},{"location":"runtime/device_8hpp/#enum-devicetype","title":"enum DeviceType","text":"<pre><code>enum DeviceType {\nAll = -1,\nCPU = 0,\nCUDA = 1\n};\n</code></pre>"},{"location":"runtime/device_8hpp/#typedef-memorysz_t","title":"typedef MemorySz_t","text":"<pre><code>using MemorySz_t =  Resource_t;\n</code></pre>"},{"location":"runtime/device_8hpp/#typedef-resourcepool_t","title":"typedef ResourcePool_t","text":"<pre><code>using ResourcePool_t =  ResourcePool;\n</code></pre>"},{"location":"runtime/device_8hpp/#typedef-vcu_t","title":"typedef VCU_t","text":"<pre><code>using VCU_t =  Resource_t;\n</code></pre>"},{"location":"runtime/device_8hpp/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"runtime/device_8hpp/#variable-num_device_types","title":"variable NUM_DEVICE_TYPES","text":"<pre><code>constexpr const int NUM_DEVICE_TYPES;\n</code></pre>"},{"location":"runtime/device_8hpp/#variable-architecture_names","title":"variable architecture_names","text":"<pre><code>const std::array&lt;std::string, NUM_DEVICE_TYPES&gt; architecture_names;\n</code></pre>"},{"location":"runtime/device_8hpp/#variable-architecture_types","title":"variable architecture_types","text":"<pre><code>constexpr const std::array architecture_types;\n</code></pre>"},{"location":"runtime/device_8hpp/#macro-definition-documentation","title":"Macro Definition Documentation","text":""},{"location":"runtime/device_8hpp/#define-parla_device_hpp","title":"define PARLA_DEVICE_HPP","text":"<pre><code>#define PARLA_DEVICE_HPP \n</code></pre> <p>The documentation for this class was generated from the following file <code>src/c/backend/include/device.hpp</code></p>"},{"location":"runtime/device_8hpp_source/","title":"File device.hpp","text":"<p>File List &gt; backend &gt; include &gt; device.hpp</p> <p>Go to the documentation of this file. </p> <pre><code>#pragma once\n#ifndef PARLA_DEVICE_HPP\n#define PARLA_DEVICE_HPP\n\n#include \"resources.hpp\"\n#include &lt;atomic&gt;\n#include &lt;iostream&gt;\n#include &lt;string&gt;\n#include &lt;unordered_map&gt;\n#include &lt;vector&gt;\n\nusing DevID_t = uint32_t;\nusing MemorySz_t = Resource_t;\nusing VCU_t = Resource_t;\n// using ResourcePool_t = ResourcePool&lt;std::atomic&lt;Resource_t&gt;&gt;;\nusing ResourcePool_t = ResourcePool;\n\nclass DeviceRequirement;\n\nenum class DeviceType { All = -1, CPU = 0, CUDA = 1 };\n\ninline const constexpr std::array architecture_types{DeviceType::CPU,\nDeviceType::CUDA};\ninline const constexpr int NUM_DEVICE_TYPES = architecture_types.size();\ninline const std::array&lt;std::string, NUM_DEVICE_TYPES&gt; architecture_names{\n\"CPU\", \"CUDA\"};\n\nclass Device {\n\npublic:\nDevice() = delete;\n\nDevice(DeviceType arch, DevID_t dev_id, MemorySz_t mem_sz, VCU_t num_vcus,\nvoid *py_dev, int copy_engines = 2)\n: py_dev_(py_dev), dev_id_(dev_id), dev_type_(arch) {\n\nres_.set(Resource::VCU, num_vcus);\nres_.set(Resource::Memory, mem_sz);\nres_.set(Resource::Copy, copy_engines);\n\nreserved_res_.set(Resource::VCU, num_vcus);\nreserved_res_.set(Resource::Memory, mem_sz);\nreserved_res_.set(Resource::Copy, copy_engines);\n\nmapped_res_.set(Resource::VCU, 0);\nmapped_res_.set(Resource::Memory, 0);\nmapped_res_.set(Resource::Copy, 0);\n}\n\nconst DevID_t get_id() const { return dev_id_; }\n\nconst std::string get_name() const {\nreturn architecture_names[static_cast&lt;int&gt;(this-&gt;dev_type_)] + \":\" +\nstd::to_string(dev_id_);\n}\n\nconst Resource_t query_resource(Resource type) const {\nreturn this-&gt;res_.get(type);\n}\n\nconst Resource_t query_reserved_resource(Resource type) const {\nreturn this-&gt;reserved_res_.get(type);\n}\n\nconst Resource_t query_mapped_resource(Resource type) const {\nreturn this-&gt;mapped_res_.get(type);\n}\n\nconst DeviceType get_type() const { return dev_type_; }\n\n// Comment(wlr): Maybe max resource pool should be const?\n\nconst ResourcePool_t &amp;get_resource_pool() const { return res_; }\n\nResourcePool_t &amp;get_mapped_pool() { return mapped_res_; }\n\nResourcePool_t &amp;get_reserved_pool() { return reserved_res_; }\n\nvoid *get_py_device() { return py_dev_; }\nvoid set_global_id(DevID_t global_id) { dev_global_id_ = global_id; }\nconst DevID_t get_global_id() const { return dev_global_id_; }\n\nconst MemorySz_t get_memory_size() const {\nreturn res_.get(Resource::Memory);\n}\n\nconst VCU_t get_num_vcus() const { return res_.get(Resource::VCU); }\n\nconst Resource_t get_max_resource(Resource type) const {\nreturn this-&gt;res_.get(type);\n}\n\nconst Resource_t get_reserved_resource(Resource type) const {\nreturn this-&gt;reserved_res_.get(type);\n}\n\nconst Resource_t get_mapped_resource(Resource type) const {\nreturn this-&gt;mapped_res_.get(type);\n}\n\nconst bool check_resource_availability(DeviceRequirement *dev_req) const;\n\nprotected:\nDeviceType dev_type_;\nDevID_t dev_id_;\nDevID_t dev_global_id_;\nResourcePool_t res_;\nResourcePool_t mapped_res_;\nResourcePool_t reserved_res_;\nvoid *py_dev_;\nstd::unordered_map&lt;std::string, size_t&gt; resource_map_;\n};\n\nclass CUDADevice : public Device {\npublic:\nCUDADevice(DevID_t dev_id, size_t mem_sz, size_t num_vcus, void *py_dev)\n: Device(DeviceType::CUDA, dev_id, mem_sz, num_vcus, py_dev, 3) {}\n\nprivate:\n};\n\nclass CPUDevice : public Device {\npublic:\nCPUDevice(DevID_t dev_id, size_t mem_sz, size_t num_vcus, void *py_dev)\n: Device(DeviceType::CPU, dev_id, mem_sz, num_vcus, py_dev, 4) {}\n\nprivate:\n};\n#endif\n</code></pre>"},{"location":"runtime/device__manager_8hpp/","title":"File device_manager.hpp","text":"<p>FileList &gt; backend &gt; include &gt; device_manager.hpp</p> <p>Go to the source code of this file.</p> <p>Provides interface for device initialization and management. </p> <ul> <li><code>#include \"device.hpp\"</code></li> <li><code>#include &lt;iostream&gt;</code></li> <li><code>#include &lt;vector&gt;</code></li> </ul>"},{"location":"runtime/device__manager_8hpp/#classes","title":"Classes","text":"Type Name class DeviceManager <code>DeviceManager</code> registers/provides devices and their information on the current system to the Parla runtime."},{"location":"runtime/device__manager_8hpp/#public-types","title":"Public Types","text":"Type Name typedef uint32_t DevID_t"},{"location":"runtime/device__manager_8hpp/#macros","title":"Macros","text":"Type Name define PARLA_DEVICE_MANAGER_HPP"},{"location":"runtime/device__manager_8hpp/#public-types-documentation","title":"Public Types Documentation","text":""},{"location":"runtime/device__manager_8hpp/#typedef-devid_t","title":"typedef DevID_t","text":"<pre><code>using DevID_t =  uint32_t;\n</code></pre>"},{"location":"runtime/device__manager_8hpp/#macro-definition-documentation","title":"Macro Definition Documentation","text":""},{"location":"runtime/device__manager_8hpp/#define-parla_device_manager_hpp","title":"define PARLA_DEVICE_MANAGER_HPP","text":"<pre><code>#define PARLA_DEVICE_MANAGER_HPP \n</code></pre> <p>The documentation for this class was generated from the following file <code>src/c/backend/include/device_manager.hpp</code></p>"},{"location":"runtime/device__manager_8hpp_source/","title":"File device_manager.hpp","text":"<p>File List &gt; backend &gt; include &gt; device_manager.hpp</p> <p>Go to the documentation of this file. </p> <pre><code>#pragma once\n#ifndef PARLA_DEVICE_MANAGER_HPP\n#define PARLA_DEVICE_MANAGER_HPP\n\n#include \"device.hpp\"\n\n#include &lt;iostream&gt;\n#include &lt;vector&gt;\n\nusing DevID_t = uint32_t;\n\nclass DeviceManager {\npublic:\nDeviceManager() {}\nDeviceManager(const DeviceManager &amp;) = delete;\n\nvoid register_device(Device *new_dev) {\nnew_dev-&gt;set_global_id(this-&gt;last_dev_id_++);\nconst int idx = static_cast&lt;int&gt;(new_dev-&gt;get_type());\narch_devices_[idx].emplace_back(new_dev);\nall_devices_.emplace_back(new_dev);\n}\n\nvoid print_registered_devices() {\nstd::cout &lt;&lt; \"C++ device list:\\n\";\nfor (DeviceType dev_type : architecture_types) {\nint i = static_cast&lt;int&gt;(dev_type);\nstd::cout &lt;&lt; \"Device type: \" &lt;&lt; i &lt;&lt; \"\\n\";\nauto device_list = arch_devices_[i];\n\nfor (auto j = 0; j &lt; device_list.size(); ++j) {\nauto device = device_list[j];\nstd::cout &lt;&lt; \"Device \" &lt;&lt; j &lt;&lt; \": \" &lt;&lt; device-&gt;get_name()\n&lt;&lt; \"\\n\\t mem. sz:\" &lt;&lt; device-&gt;get_memory_size()\n&lt;&lt; \", num. vcus:\" &lt;&lt; device-&gt;get_num_vcus() &lt;&lt; \"\\n\";\n}\n}\n}\n\ntemplate &lt;DeviceType T&gt; int get_num_devices() {\nif constexpr (T == DeviceType::All) {\nreturn all_devices_.size();\n} else if constexpr (T == DeviceType::CPU) {\nreturn arch_devices_[static_cast&lt;int&gt;(DeviceType::CPU)].size();\n} else if constexpr (T == DeviceType::CUDA) {\nreturn arch_devices_[static_cast&lt;int&gt;(DeviceType::CUDA)].size();\n}\n}\n\nint get_num_devices(DeviceType dev_type) {\nswitch (dev_type) {\ncase DeviceType::CPU:\nreturn get_num_devices&lt;DeviceType::CPU&gt;();\ncase DeviceType::CUDA:\nreturn get_num_devices&lt;DeviceType::CUDA&gt;();\ndefault:\nreturn get_num_devices&lt;DeviceType::All&gt;();\n}\n}\n\ntemplate &lt;DeviceType T&gt; std::vector&lt;Device *&gt; &amp;get_devices() {\nif constexpr (T == DeviceType::CPU) {\nreturn arch_devices_[static_cast&lt;int&gt;(DeviceType::CPU)];\n} else if constexpr (T == DeviceType::CUDA) {\nreturn arch_devices_[static_cast&lt;int&gt;(DeviceType::CUDA)];\n} else if constexpr (T == DeviceType::All) {\nreturn all_devices_;\n}\n}\n\nDevice *get_device_by_parray_id(DevID_t parray_dev_id) const {\nDevID_t global_dev_id = this-&gt;parrayid_to_globalid(parray_dev_id);\nreturn all_devices_[global_dev_id];\n}\n\nDevice *get_device_by_global_id(DevID_t global_dev_id) const {\nreturn all_devices_[global_dev_id];\n}\n\nstd::vector&lt;Device *&gt; &amp;get_devices(DeviceType dev_type) {\nswitch (dev_type) {\ncase DeviceType::CPU:\nreturn get_devices&lt;DeviceType::CPU&gt;();\ncase DeviceType::CUDA:\nreturn get_devices&lt;DeviceType::CUDA&gt;();\ndefault:\nreturn get_devices&lt;DeviceType::All&gt;();\n}\n}\n\nsize_t get_num_devices() { return all_devices_.size(); }\n\n// TODO(hc): use a customized type for device id.\n\nconst DevID_t globalid_to_parrayid(DevID_t global_dev_id) const {\nDevice *dev = all_devices_[global_dev_id];\nif (dev-&gt;get_type() == DeviceType::CPU) {\nreturn -1;\n} else {\nreturn dev-&gt;get_id();\n}\n}\n\nconst int parrayid_to_globalid(DevID_t parray_dev_id) const {\nif (parray_dev_id == -1) {\n// XXX: This assumes that a CPU device is always single and\n//      is added at first.\n//      Otherwise, we need a loop iterating all devices and\n//      comparing device ids.\nreturn 0;\n} else {\nreturn parray_dev_id + 1;\n}\n}\n\nprotected:\n// Global device id counter\n// When used in Scheduler, we assume that only a single device manager holds\n// all devices.\nDevID_t last_dev_id_ = 0;\n\n// Store devices by architecture type\nstd::array&lt;std::vector&lt;Device *&gt;, NUM_DEVICE_TYPES&gt; arch_devices_;\n// Stores all devices in the system\nstd::vector&lt;Device *&gt; all_devices_;\n};\n\n#endif\n</code></pre>"},{"location":"runtime/device__queues_8hpp/","title":"File device_queues.hpp","text":"<p>FileList &gt; backend &gt; include &gt; device_queues.hpp</p> <p>Go to the source code of this file.</p> <p>Provides interface for task queues and collections of task queues for multidevice tasks. </p> <ul> <li><code>#include \"device_manager.hpp\"</code></li> <li><code>#include \"runtime.hpp\"</code></li> </ul>"},{"location":"runtime/device__queues_8hpp/#classes","title":"Classes","text":"Type Name class DeviceQueue &lt;category&gt;Per-device container for tasks that are waiting to be dequeued. class PhaseManager &lt;category&gt;Manages a group of DeviceQueues. <p>The documentation for this class was generated from the following file <code>src/c/backend/include/device_queues.hpp</code></p>"},{"location":"runtime/device__queues_8hpp_source/","title":"File device_queues.hpp","text":"<p>File List &gt; backend &gt; include &gt; device_queues.hpp</p> <p>Go to the documentation of this file. </p> <pre><code>#ifndef PARLA_DEVICE_QUEUES_HPP\n#define PARLA_DEVICE_QUEUES_HPP\n\n#include \"device_manager.hpp\"\n#include \"runtime.hpp\"\n\n// TODO(wlr): FIXME Change these back to smart pointers. I'm leaking memory\n// here...\n\ntemplate &lt;ResourceCategory category&gt; class DeviceQueue {\nusing MixedQueue_t = TaskQueue;\nusing MDQueue_t = TaskQueue;\n\npublic:\nDeviceQueue() = default;\nDeviceQueue(Device *device) : device(device) {}\n\nDevice *get_device() { return device; }\n\nvoid enqueue(InnerTask *task) {\n// std::cout &lt;&lt; \"DeviceQueue::enqueue() - \" &lt;&lt; task-&gt;get_name() &lt;&lt;\n// std::endl;\n\n// std::cout &lt;&lt; \"Mixed Queue size: \" &lt;&lt; mixed_queue.size() &lt;&lt; std::endl;\nthis-&gt;mixed_queue.push_back(task);\nnum_tasks++;\n};\n\nInnerTask *front() {\n\n// std::cout &lt;&lt; \"DeviceQueue::front()\" &lt;&lt; std::endl;\n// std::cout &lt;&lt; \"Waiting Queue size: \" &lt;&lt; waiting_queue.size() &lt;&lt; std::endl;\n// std::cout &lt;&lt; \"Mixed Queue size: \" &lt;&lt; mixed_queue.size() &lt;&lt; std::endl;\n\n// First, check any waiting multi-device tasks\nif (!waiting_queue.empty()) {\nInnerTask *head = waiting_queue.front();\nint waiting_count = head-&gt;get_num_instances&lt;category&gt;();\n\n// std::cout &lt;&lt; \"MD Head: \" &lt;&lt; head-&gt;get_name()\n//           &lt;&lt; \" Instances: \" &lt;&lt; waiting_count\n//           &lt;&lt; \" Removed: \" &lt;&lt; head-&gt;get_removed&lt;category&gt;() &lt;&lt;\n//           std::endl;\n\n// Any MD task that is no longer waiting should be blocking\nif (waiting_count &lt; 1) {\n// Remove from waiting queue if dequeued by last instance\nif (head-&gt;get_removed&lt;category&gt;()) {\n// TODO(wlr): Should I remove this here?\nwaiting_queue.pop_front();\n\n// TODO(wlr): Should num_tasks include waiting tasks?\n// (1)\n// this-&gt;num_tasks--;\n}\nreturn nullptr;\n}\n}\n\nif (!mixed_queue.empty()) {\nInnerTask *head = mixed_queue.front();\nint prev_waiting_count = head-&gt;decrement_num_instances&lt;category&gt;();\n\n// std::cout &lt;&lt; \"Mixed Head: \" &lt;&lt; head-&gt;get_name()\n//           &lt;&lt; \" Instances: \" &lt;&lt; prev_waiting_count\n//           &lt;&lt; \" Removed: \" &lt;&lt; head-&gt;get_removed&lt;category&gt;() &lt;&lt;\n//           std::endl;\n\n// Check if the task is waiting for other instances\nif (prev_waiting_count &lt;= 1) {\n// std::cout &lt;&lt; \"Return task: \" &lt;&lt; head-&gt;get_name() &lt;&lt; std::endl;\nreturn head;\n} else {\n// If the task is still waiting, move it to the waiting queue\n// std::cout &lt;&lt; \"Moving to waiting queue\" &lt;&lt; std::endl;\nwaiting_queue.push_back(head);\nmixed_queue.pop_front();\n\n// TODO(wlr): Should num_tasks include waiting tasks?\n// (2)\nthis-&gt;num_tasks--;\n}\n}\n\nreturn nullptr;\n}\n\nInnerTask *pop() {\n// std::cout &lt;&lt; \"DeviceQueue::pop()\" &lt;&lt; std::endl;\nInnerTask *task = front();\nif (task != nullptr) {\n// std::cout &lt;&lt; \"Popping task: \" &lt;&lt; task-&gt;get_name() &lt;&lt; std::endl;\nmixed_queue.pop_front();\n// Set removed status so task can be pruned from other queues\ntask-&gt;set_removed&lt;category&gt;(true);\nnum_tasks--;\n}\nreturn task;\n}\n\ninline size_t size() { return num_tasks.load(); }\ninline bool empty() { return mixed_queue.empty() &amp;&amp; waiting_queue.empty(); }\n\nprotected:\nDevice *device;\nMixedQueue_t mixed_queue;\nMDQueue_t waiting_queue;\nstd::atomic&lt;int&gt; num_tasks{0};\n};\n\n// TODO(wlr): I don't know what to name this.\ntemplate &lt;ResourceCategory category&gt; class PhaseManager {\npublic:\nPhaseManager(DeviceManager *device_manager) {\n// std::cout &lt;&lt; \"Initializing PhaseManager\" &lt;&lt; std::endl;\n\nfor (const DeviceType dev_type : architecture_types) {\nthis-&gt;ndevices += device_manager-&gt;get_num_devices(dev_type);\n\nfor (Device *device : device_manager-&gt;get_devices(dev_type)) {\nthis-&gt;device_queues.emplace_back(new DeviceQueue&lt;category&gt;(device));\n// std::cout &lt;&lt; \"Initialized DeviceQueue for Device: \"\n//           &lt;&lt; device-&gt;get_name() &lt;&lt; std::endl;\n}\n\nthis-&gt;last_device_idx = 0;\n}\n\n// std::cout &lt;&lt; \"Initialized PhaseManager with \" &lt;&lt; this-&gt;ndevices\n//           &lt;&lt; \" devices\" &lt;&lt; std::endl;\n// std::cout &lt;&lt; \"Initialized PhaseManager with \" &lt;&lt;\n// this-&gt;device_queues.size()\n//           &lt;&lt; \" queues\" &lt;&lt; std::endl;\n}\n\n~PhaseManager() {\nfor (auto &amp;queue : this-&gt;device_queues) {\ndelete queue;\n}\n}\n\nvoid enqueue(InnerTask *task) {\n// std::cout &lt;&lt; \"pointer: \" &lt;&lt; reinterpret_cast&lt;void *&gt;(this) &lt;&lt; std::endl;\n// std::cout &lt;&lt; \"ndevices: \" &lt;&lt; this-&gt;ndevices &lt;&lt; std::endl;\n// std::cout &lt;&lt; \"nqueues: \" &lt;&lt; this-&gt;device_queues.size() &lt;&lt; std::endl;\n// std::cout &lt;&lt; \"Enqueuing task to phase manager: \" &lt;&lt; task-&gt;get_name()\n//           &lt;&lt; std::endl;\ntask-&gt;set_num_instances&lt;category&gt;();\nfor (auto device : task-&gt;assigned_devices) {\nthis-&gt;device_queues[device-&gt;get_global_id()]-&gt;enqueue(task);\n}\nthis-&gt;num_tasks++;\n}\n\nInnerTask *front() {\n// TODO(wlr): Hochan, can you check this?\n// I'm not sure if this is the right way to loop over dequeable tasks\n// Should we drain each device first, or try each device in\n// turn?\n\n// std::cout &lt;&lt; \"PhaseManager::front\" &lt;&lt; std::endl;\n\nint start_idx = last_device_idx;\nint end_idx = start_idx + ndevices;\nint current_idx = start_idx;\n\nbool has_task = this-&gt;size() &gt; 0;\n// std::cout &lt;&lt; \"Size of PhaseManager: \" &lt;&lt; this-&gt;size() &lt;&lt; std::endl;\nwhile (has_task) {\n\n// std::cout &lt;&lt; \"Size of PhaseManager: \" &lt;&lt; this-&gt;size() &lt;&lt; std::endl;\n\n// Loop over all devices starting from after last success location\nfor (int i = start_idx; i &lt; end_idx; ++i) {\ncurrent_idx = i % ndevices;\n\n// Try to get a non-waiting task\n// std::cout &lt;&lt; \"Trying DeviceQueue \" &lt;&lt; current_idx &lt;&lt; \" Device: \"\n//          &lt;&lt;\n//          this-&gt;device_queues[current_idx]-&gt;get_device()-&gt;get_name()\n//          &lt;&lt; std::endl;\n\nInnerTask *task = this-&gt;device_queues[current_idx]-&gt;front();\nif (task != nullptr) {\n// std::cout &lt;&lt; \"Not null.\" &lt;&lt; std::endl;\n// std::cout &lt;&lt; \"Found task: \" &lt;&lt; task-&gt;get_name() &lt;&lt; std::endl;\nthis-&gt;last_device_idx = ++current_idx;\nreturn task;\n}\n}\n\nhas_task = this-&gt;size() &gt; 0;\n}\n\n// If we get here, there are no tasks that can be dequeued\n// This should only happen if called on an empty phase\n// std::cout &lt;&lt; \"No tasks found\" &lt;&lt; std::endl;\nreturn nullptr;\n}\n\nInnerTask *pop() {\n// std::cout &lt;&lt; \"PhaseManager::pop\" &lt;&lt; std::endl;\nint idx = (this-&gt;last_device_idx - 1) % this-&gt;ndevices;\n// std::cout &lt;&lt; \"Popping from DeviceQueue \" &lt;&lt; idx &lt;&lt; std::endl;\nInnerTask *task = this-&gt;device_queues[idx]-&gt;pop();\n// std::cout &lt;&lt; \"Popped task: \" &lt;&lt; task-&gt;get_name() &lt;&lt; std::endl;\nthis-&gt;num_tasks--;\nreturn task;\n}\n\ninline size_t size() { return this-&gt;num_tasks.load(); }\ninline size_t get_num_devices() { return this-&gt;ndevices; }\ninline size_t get_num_device_queues() { return this-&gt;device_queues.size(); }\n\nprotected:\nstd::vector&lt;DeviceQueue&lt;category&gt; *&gt; device_queues;\n\nint last_device_idx{0};\n// DeviceType last_device_type{CPU};\n\nint ndevices{0};\nstd::atomic&lt;int&gt; num_tasks{0};\n};\n\n#endif // PARLA_DEVICE_QUEUE_HPP\n</code></pre>"},{"location":"runtime/gpu__utility_8hpp/","title":"File gpu_utility.hpp","text":"<p>FileList &gt; backend &gt; include &gt; gpu_utility.hpp</p> <p>Go to the source code of this file.</p> <p>Provides architecture independent interface to event and stream creation &amp; synchronization. </p> <ul> <li><code>#include &lt;chrono&gt;</code></li> <li><code>#include &lt;cstdint&gt;</code></li> <li><code>#include &lt;cstdio&gt;</code></li> <li><code>#include &lt;stdio.h&gt;</code></li> <li><code>#include &lt;sys/time.h&gt;</code></li> <li><code>#include &lt;unistd.h&gt;</code></li> </ul>"},{"location":"runtime/gpu__utility_8hpp/#namespaces","title":"Namespaces","text":"Type Name namespace chrono namespace std"},{"location":"runtime/gpu__utility_8hpp/#public-functions","title":"Public Functions","text":"Type Name void cpu_busy_sleep (unsigned int micro)  void event_synchronize (uintptr_t event_ptr)  void event_wait (uintptr_t event_ptr, uintptr_t stream_ptr)  void gpu_busy_sleep (const int device, const unsigned long cycles, uintptr_t stream_ptr)  void stream_synchronize (uintptr_t stream_ptr)"},{"location":"runtime/gpu__utility_8hpp/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/gpu__utility_8hpp/#function-cpu_busy_sleep","title":"function cpu_busy_sleep","text":"<pre><code>inline void cpu_busy_sleep (\nunsigned int micro\n) </code></pre>"},{"location":"runtime/gpu__utility_8hpp/#function-event_synchronize","title":"function event_synchronize","text":"<pre><code>void event_synchronize (\nuintptr_t event_ptr\n) </code></pre>"},{"location":"runtime/gpu__utility_8hpp/#function-event_wait","title":"function event_wait","text":"<pre><code>void event_wait (\nuintptr_t event_ptr,\nuintptr_t stream_ptr\n) </code></pre>"},{"location":"runtime/gpu__utility_8hpp/#function-gpu_busy_sleep","title":"function gpu_busy_sleep","text":"<pre><code>void gpu_busy_sleep (\nconst int device,\nconst unsigned long cycles,\nuintptr_t stream_ptr\n) </code></pre>"},{"location":"runtime/gpu__utility_8hpp/#function-stream_synchronize","title":"function stream_synchronize","text":"<pre><code>void stream_synchronize (\nuintptr_t stream_ptr\n) </code></pre> <p>The documentation for this class was generated from the following file <code>src/c/backend/include/gpu_utility.hpp</code></p>"},{"location":"runtime/gpu__utility_8hpp_source/","title":"File gpu_utility.hpp","text":"<p>File List &gt; backend &gt; include &gt; gpu_utility.hpp</p> <p>Go to the documentation of this file. </p> <pre><code>#ifndef PARLA_CUDA_UTILITY_H\n#define PARLA_CUDA_UTILITY_H\n\n#include &lt;chrono&gt;\n#include &lt;cstdint&gt;\n#include &lt;cstdio&gt;\n#include &lt;stdio.h&gt;\n#include &lt;sys/time.h&gt;\n#include &lt;unistd.h&gt;\n\n#if defined(PARLA_ENABLE_CUDA)\n#include &lt;cuda.h&gt;\n#include &lt;cuda_runtime_api.h&gt;\n#endif\n\nusing namespace std;\nusing namespace chrono;\n\nvoid gpu_busy_sleep(const int device, const unsigned long cycles,\nuintptr_t stream_ptr);\n\n// Busy sleep for a given number of microseconds\ninline void cpu_busy_sleep(unsigned int micro) {\n// compute_range r(\"sleep::busy\", nvtx3::rgb{0, 127, 127});\n// int count = 0;\nauto block = std::chrono::microseconds(micro);\nauto time_start = std::chrono::high_resolution_clock::now();\n\nauto now = std::chrono::high_resolution_clock::now();\nauto elapsed =\nstd::chrono::duration_cast&lt;std::chrono::microseconds&gt;(now - time_start);\n\ndo {\nnow = std::chrono::high_resolution_clock::now();\nelapsed =\nstd::chrono::duration_cast&lt;std::chrono::microseconds&gt;(now - time_start);\n} while (elapsed.count() &lt; micro);\n}\n\nvoid event_synchronize(uintptr_t event_ptr);\nvoid event_wait(uintptr_t event_ptr, uintptr_t stream_ptr);\nvoid stream_synchronize(uintptr_t stream_ptr);\n\n#endif // PARLA_CUDA_UTILITY_H\n</code></pre>"},{"location":"runtime/parray_8hpp/","title":"File parray.hpp","text":"<p>FileList &gt; backend &gt; include &gt; parray.hpp</p> <p>Go to the source code of this file.</p> <p>Provides C++ interface to PArray State and ID. More...</p> <ul> <li><code>#include \"containers.hpp\"</code></li> <li><code>#include \"include/atomic_wrapper.hpp\"</code></li> <li><code>#include \"include/device.hpp\"</code></li> <li><code>#include \"parray_state.hpp\"</code></li> <li><code>#include &lt;cstdint&gt;</code></li> <li><code>#include &lt;unordered_map&gt;</code></li> <li><code>#include &lt;vector&gt;</code></li> </ul>"},{"location":"runtime/parray_8hpp/#namespaces","title":"Namespaces","text":"Type Name namespace parray"},{"location":"runtime/parray_8hpp/#classes","title":"Classes","text":"Type Name class InnerPArray"},{"location":"runtime/parray_8hpp/#public-types","title":"Public Types","text":"Type Name typedef ProtectedVector&lt; InnerTask * &gt; TaskList"},{"location":"runtime/parray_8hpp/#detailed-description","title":"Detailed Description","text":"<p>This file contains the inner C++ parray interface. Allows access to coherency and parent/child relations without accessing the Python interpreter. </p>"},{"location":"runtime/parray_8hpp/#public-types-documentation","title":"Public Types Documentation","text":""},{"location":"runtime/parray_8hpp/#typedef-tasklist","title":"typedef TaskList","text":"<pre><code>using TaskList =  ProtectedVector&lt;InnerTask *&gt;;\n</code></pre> <p>The documentation for this class was generated from the following file <code>src/c/backend/include/parray.hpp</code></p>"},{"location":"runtime/parray_8hpp_source/","title":"File parray.hpp","text":"<p>File List &gt; backend &gt; include &gt; parray.hpp</p> <p>Go to the documentation of this file. </p> <pre><code>#pragma once\n\n#include \"containers.hpp\"\n#include \"include/atomic_wrapper.hpp\"\n#include \"include/device.hpp\"\n#include \"parray_state.hpp\"\n#include &lt;cstdint&gt;\n#include &lt;unordered_map&gt;\n#include &lt;vector&gt;\n\nclass InnerTask;\n\nusing TaskList = ProtectedVector&lt;InnerTask *&gt;;\n\nnamespace parray {\n// PArray C++ interface which provides some information that will be used for\n// scheduling task\nclass InnerPArray {\npublic:\nuint64_t id;        // unique ID of the PArray\nuint64_t parent_id; // unique ID of the parent PArray\n\nstd::vector&lt;CopyableAtomic&lt;size_t&gt;&gt; num_active_tasks;\n\nInnerPArray() = delete;\nInnerPArray(void *, uint64_t, uint64_t, InnerPArray *, PArrayState *,\nDevID_t);\n\nconst uint64_t get_size() const;\n\nvoid set_size(uint64_t new_size);\n\nbool exists_on_device(uint64_t device_id);\n\nbool valid_on_device(uint64_t device_id);\n\nvoid add_task(InnerTask *task);\n\nvoid incr_num_active_tasks(DevID_t global_dev_id);\n\nvoid decr_num_active_tasks(DevID_t global_dev_id);\n\nsize_t get_num_active_tasks(DevID_t global_dev_id);\n\n// TODO(hc): I will replace this list with a concurrent map.\nTaskList &amp;get_task_list_ref();\n\nvoid *get_py_parray();\n\nuint64_t get_parray_parentid();\n\nInnerPArray *get_parent_parray();\n\nprivate:\nuint64_t _size; // number of bytes consumed by each copy of the array/subarray\nInnerPArray *_parent_parray;\nPArrayState\n*_state; // state of a PArray (subarray share this object with its parent)\nDevID_t _num_devices;\n\n// TODO(hc): this should be a concurrent map.\n//           this requires freuqent addition/removal.\n//           I will use this map: https://github.com/greg7mdp/parallel-hashmap\n//           I have used this for a while and it is good.\nTaskList _task_lists;\n\nvoid *_py_parray;\n};\n} // namespace parray\n</code></pre>"},{"location":"runtime/parray__state_8hpp/","title":"File parray_state.hpp","text":"<p>FileList &gt; backend &gt; include &gt; parray_state.hpp</p> <p>Go to the source code of this file.</p> <p>Provides C++ interface to parray coherency. </p> <ul> <li><code>#include &lt;unordered_map&gt;</code></li> </ul>"},{"location":"runtime/parray__state_8hpp/#namespaces","title":"Namespaces","text":"Type Name namespace parray"},{"location":"runtime/parray__state_8hpp/#classes","title":"Classes","text":"Type Name class PArrayState <p>The documentation for this class was generated from the following file <code>src/c/backend/include/parray_state.hpp</code></p>"},{"location":"runtime/parray__state_8hpp_source/","title":"File parray_state.hpp","text":"<p>File List &gt; backend &gt; include &gt; parray_state.hpp</p> <p>Go to the documentation of this file. </p> <pre><code>#pragma once\n\n#include &lt;unordered_map&gt;\n\nnamespace parray {\n// A Class that keep record of PArray's state\n// Multiple PArray may share the same state object\nclass PArrayState {\npublic:\nPArrayState();\n\n// Return True if there is an PArray copy (possibly invalid) on this device\nbool exists_on_device(int device_id);\n\n// Return True if there is an PArray copy and its coherence state is valid on\n// this device\nbool valid_on_device(int device_id);\n\n// set the exist status of PArray on a device\nvoid set_exist_on_device(int device_id, bool exist);\n\n// set the valid status of PArray on a device\nvoid set_valid_on_device(int device_id, bool valid);\n\nprivate:\nstd::unordered_map&lt;int, bool&gt;\n_exist_on_device; // a mapping between device_id and exist status\nstd::unordered_map&lt;int, bool&gt;\n_valid_on_device; // a mapping between device_id and valid status\n};\n} // namespace parray\n</code></pre>"},{"location":"runtime/parray__tracker_8hpp/","title":"File parray_tracker.hpp","text":"<p>FileList &gt; backend &gt; include &gt; parray_tracker.hpp</p> <p>Go to the source code of this file.</p> <p>Provides interface to scheduler tracking of parray data objects. </p> <ul> <li><code>#include \"include/device_manager.hpp\"</code></li> <li><code>#include \"include/parray.hpp\"</code></li> </ul>"},{"location":"runtime/parray__tracker_8hpp/#classes","title":"Classes","text":"Type Name class PArrayTracker <p>The documentation for this class was generated from the following file <code>src/c/backend/include/parray_tracker.hpp</code></p>"},{"location":"runtime/parray__tracker_8hpp_source/","title":"File parray_tracker.hpp","text":"<p>File List &gt; backend &gt; include &gt; parray_tracker.hpp</p> <p>Go to the documentation of this file. </p> <pre><code>#ifndef PARLA_PARRAY_TRACKER_HPP\n#define PARLA_PARRAY_TRACKER_HPP\n\n#include \"include/device_manager.hpp\"\n#include \"include/parray.hpp\"\n\nusing namespace parray;\n\nclass PArrayTracker {\npublic:\nPArrayTracker(DeviceManager *deivce_manage);\n\nvoid track_parray(const InnerPArray &amp;parray, DevID_t dev_id);\n\nvoid untrack_parray(const InnerPArray &amp;parray, DevID_t dev_id);\n\nvoid reserve_parray(const InnerPArray &amp;parray, Device *device);\n\nvoid release_parray(const InnerPArray &amp;parray, Device *device);\n\nbool get_parray_state(DevID_t global_dev_idx, uint64_t parray_parent_id) {\nmtx.lock();\nbool state = this-&gt;managed_parrays_[global_dev_idx][parray_parent_id];\nmtx.unlock();\nreturn state;\n}\n\nprivate:\nDeviceManager *device_manager_;\nstd::vector&lt;std::unordered_map&lt;uint64_t, bool&gt;&gt; managed_parrays_;\nstd::mutex mtx;\n};\n\n#endif\n</code></pre>"},{"location":"runtime/phases_8hpp/","title":"File phases.hpp","text":"<p>FileList &gt; backend &gt; include &gt; phases.hpp</p> <p>Go to the source code of this file.</p> <p>Interface for scheduler runtime phases. More...</p> <ul> <li><code>#include \"atomic_wrapper.hpp\"</code></li> <li><code>#include \"containers.hpp\"</code></li> <li><code>#include \"device.hpp\"</code></li> <li><code>#include \"device_manager.hpp\"</code></li> <li><code>#include \"device_queues.hpp\"</code></li> <li><code>#include \"policy.hpp\"</code></li> <li><code>#include \"resources.hpp\"</code></li> <li><code>#include \"runtime.hpp\"</code></li> <li><code>#include &lt;memory&gt;</code></li> <li><code>#include &lt;string&gt;</code></li> </ul>"},{"location":"runtime/phases_8hpp/#classes","title":"Classes","text":"Type Name class Launcher class LauncherStatus class Mapper Mapper phase of the scheduler. class MapperStatus class MemoryReserver MemoryReserver phase of the scheduler. class MemoryReserverStatus class PhaseStatus &lt;typename S&gt;Records metrics that track phase execution (e.g. success, failure, etc.) class RuntimeReserver RuntimeReserver phase of the scheduler. class RuntimeReserverStatus class SchedulerPhase Abstract Interface for general scheduler runtime phase."},{"location":"runtime/phases_8hpp/#public-types","title":"Public Types","text":"Type Name enum LauncherState enum MapperState enum MemoryReserverState enum RuntimeReserverState"},{"location":"runtime/phases_8hpp/#macros","title":"Macros","text":"Type Name define PARLA_PHASES_HPP"},{"location":"runtime/phases_8hpp/#detailed-description","title":"Detailed Description","text":"<p>This file contains the interface for scheduler runtime phases. This includes classes for Task Mapping, Task Resource Reservation, and Task Launching. </p>"},{"location":"runtime/phases_8hpp/#public-types-documentation","title":"Public Types Documentation","text":""},{"location":"runtime/phases_8hpp/#enum-launcherstate","title":"enum LauncherState","text":"<pre><code>enum LauncherState {\nFailure = 0,\nSuccess = 1,\nMAX = 2\n};\n</code></pre>"},{"location":"runtime/phases_8hpp/#enum-mapperstate","title":"enum MapperState","text":"<pre><code>enum MapperState {\nFailure = 0,\nSuccess = 1,\nMAX = 2\n};\n</code></pre>"},{"location":"runtime/phases_8hpp/#enum-memoryreserverstate","title":"enum MemoryReserverState","text":"<pre><code>enum MemoryReserverState {\nFailure = 0,\nSuccess = 1,\nMAX = 2\n};\n</code></pre>"},{"location":"runtime/phases_8hpp/#enum-runtimereserverstate","title":"enum RuntimeReserverState","text":"<pre><code>enum RuntimeReserverState {\nFailure = 0,\nNoTask = 1,\nNoResource = 2,\nNoWorker = 3,\nSuccess = 4,\nMAX = 5\n};\n</code></pre>"},{"location":"runtime/phases_8hpp/#macro-definition-documentation","title":"Macro Definition Documentation","text":""},{"location":"runtime/phases_8hpp/#define-parla_phases_hpp","title":"define PARLA_PHASES_HPP","text":"<pre><code>#define PARLA_PHASES_HPP \n</code></pre> <p>The documentation for this class was generated from the following file <code>src/c/backend/include/phases.hpp</code></p>"},{"location":"runtime/phases_8hpp_source/","title":"File phases.hpp","text":"<p>File List &gt; backend &gt; include &gt; phases.hpp</p> <p>Go to the documentation of this file. </p> <pre><code>#pragma once\n#ifndef PARLA_PHASES_HPP\n#define PARLA_PHASES_HPP\n\n#include \"atomic_wrapper.hpp\"\n#include \"containers.hpp\"\n#include \"device.hpp\"\n#include \"device_manager.hpp\"\n#include \"device_queues.hpp\"\n#include \"policy.hpp\"\n#include \"resources.hpp\"\n#include \"runtime.hpp\"\n\n#include &lt;memory&gt;\n#include &lt;string&gt;\n\nenum class MapperState { Failure = 0, Success = 1, MAX = 2 };\nenum class MemoryReserverState { Failure = 0, Success = 1, MAX = 2 };\nenum class RuntimeReserverState {\nFailure = 0,\nNoTask = 1,\nNoResource = 2,\nNoWorker = 3,\nSuccess = 4,\nMAX = 5\n};\nenum class LauncherState { Failure = 0, Success = 1, MAX = 2 };\n\ntemplate &lt;typename S&gt; class PhaseStatus {\nprotected:\nconst int size{static_cast&lt;int&gt;(S::MAX)};\nstd::string name{\"Status\"};\n\npublic:\nint status[static_cast&lt;int&gt;(S::MAX)];\n\nPhaseStatus() = default;\nPhaseStatus(std::string name) : name(name) {}\n\nvoid reset() {\nfor (int i = 0; i &lt; size; ++i) {\nthis-&gt;status[i] = 0;\n}\n}\n\ninline void set(S state, int value) {\nthis-&gt;status[static_cast&lt;int&gt;(state)] = value;\n}\ninline const int get(S state) const {\nreturn this-&gt;status[static_cast&lt;int&gt;(state)];\n}\ninline void increase(S state) { this-&gt;status[static_cast&lt;int&gt;(state)]++; }\ninline void decrease(S state) { this-&gt;status[static_cast&lt;int&gt;(state)]--; }\n\nvoid print() const {\nstd::cout &lt;&lt; this-&gt;name + \"(\";\nfor (int i = 0; i &lt; size; ++i) {\nstd::cout &lt;&lt; this-&gt;status[i];\n}\nstd::cout &lt;&lt; \")\\n\";\n}\n};\n\nclass MapperStatus : public PhaseStatus&lt;MapperState&gt; {};\nclass MemoryReserverStatus : public PhaseStatus&lt;MemoryReserverState&gt; {};\nclass RuntimeReserverStatus : public PhaseStatus&lt;RuntimeReserverState&gt; {};\nclass LauncherStatus : public PhaseStatus&lt;LauncherState&gt; {};\n\nclass SchedulerPhase {\npublic:\nSchedulerPhase() = default;\n\nSchedulerPhase(InnerScheduler *scheduler, DeviceManager *devices)\n: scheduler(scheduler), device_manager(devices) {}\n\nvirtual void enqueue(InnerTask *task) = 0;\n\nvirtual void enqueue(std::vector&lt;InnerTask *&gt; &amp;tasks) = 0;\n\nvirtual void run(SchedulerPhase *next_phase) = 0;\n\nvirtual size_t get_count() = 0;\n\nprotected:\ninline static const std::string name{\"Phase\"};\nstd::mutex mtx;\nInnerScheduler *scheduler;\nDeviceManager *device_manager;\nTaskStateList enqueue_buffer;\n};\n\nclass Mapper : virtual public SchedulerPhase {\npublic:\nMapper() = delete;\nMapper(InnerScheduler *scheduler, DeviceManager *devices,\nstd::shared_ptr&lt;MappingPolicy&gt; policy)\n: SchedulerPhase(scheduler, devices), dummy_dev_idx_{0}, policy_{policy} {\ndev_num_mapped_tasks_.resize(devices-&gt;get_num_devices());\n}\n\nvoid enqueue(InnerTask *task);\nvoid enqueue(std::vector&lt;InnerTask *&gt; &amp;tasks);\nvoid run(SchedulerPhase *next_phase);\nsize_t get_count();\n\nsize_t atomic_incr_num_mapped_tasks() {\nreturn total_num_mapped_tasks_.fetch_add(1, std::memory_order_relaxed);\n}\n\nsize_t atomic_incr_num_mapped_tasks_device(DevID_t dev_id) {\nreturn dev_num_mapped_tasks_[dev_id].fetch_add(1,\nstd::memory_order_relaxed);\n}\n\nsize_t atomic_decr_num_mapped_tasks() {\nreturn total_num_mapped_tasks_.fetch_sub(1, std::memory_order_relaxed);\n}\n\nsize_t atomic_decr_num_mapped_tasks_device(DevID_t dev_id) {\nreturn dev_num_mapped_tasks_[dev_id].fetch_sub(1,\nstd::memory_order_relaxed);\n}\n\nconst size_t atomic_load_total_num_mapped_tasks() const {\nreturn total_num_mapped_tasks_.load(std::memory_order_relaxed);\n}\n\nconst size_t atomic_load_dev_num_mapped_tasks_device(DevID_t dev_id) const {\nreturn dev_num_mapped_tasks_[dev_id].load(std::memory_order_relaxed);\n}\n\nprotected:\ninline static const std::string name{\"Mapper\"};\nMapperStatus status{name};\nTaskQueue mappable_tasks;\nstd::vector&lt;InnerTask *&gt; mapped_tasks_buffer;\nuint64_t dummy_dev_idx_;\n\nstd::shared_ptr&lt;MappingPolicy&gt; policy_;\nstd::atomic&lt;size_t&gt; total_num_mapped_tasks_{0};\nstd::vector&lt;CopyableAtomic&lt;size_t&gt;&gt; dev_num_mapped_tasks_;\n};\n\nclass MemoryReserver : virtual public SchedulerPhase {\npublic:\nMemoryReserver(InnerScheduler *scheduler, DeviceManager *devices)\n: SchedulerPhase(scheduler, devices) {\nthis-&gt;reservable_tasks =\nstd::make_shared&lt;PhaseManager&lt;ResourceCategory::Persistent&gt;&gt;(devices);\n}\n\nvoid enqueue(InnerTask *task);\nvoid enqueue(std::vector&lt;InnerTask *&gt; &amp;tasks);\nvoid run(SchedulerPhase *next_phase);\nsize_t get_count();\n\nprotected:\nstd::shared_ptr&lt;PhaseManager&lt;ResourceCategory::Persistent&gt;&gt; reservable_tasks;\ninline static const std::string name{\"Memory Reserver\"};\nMemoryReserverStatus status{name};\nstd::vector&lt;InnerTask *&gt; reserved_tasks_buffer;\n\nbool check_resources(InnerTask *task);\nvoid reserve_resources(InnerTask *task);\nvoid create_datamove_tasks(InnerTask *task);\n};\n\nclass RuntimeReserver : virtual public SchedulerPhase {\npublic:\nRuntimeReserver(InnerScheduler *scheduler, DeviceManager *devices)\n: SchedulerPhase(scheduler, devices) {\n// std::cout &lt;&lt; \"RuntimeReserver created\" &lt;&lt; std::endl;\n// FIXME: This leaks memory. Need to add deconstructor.\nthis-&gt;runnable_tasks =\nstd::make_shared&lt;PhaseManager&lt;ResourceCategory::NonPersistent&gt;&gt;(\ndevices);\nthis-&gt;movement_tasks =\nstd::make_shared&lt;PhaseManager&lt;ResourceCategory::Movement&gt;&gt;(devices);\n}\n\nvoid enqueue(InnerTask *task);\nvoid enqueue(std::vector&lt;InnerTask *&gt; &amp;tasks);\nvoid run(SchedulerPhase *next_phase);\nsize_t get_count();\nsize_t get_compute_count();\nsize_t get_movement_count();\n\nconst std::string &amp;get_name() const { return this-&gt;name; }\nconst RuntimeReserverStatus &amp;get_status() const { return this-&gt;status; }\nconst void print_status() const { this-&gt;status.print(); }\n\nprotected:\nstd::shared_ptr&lt;PhaseManager&lt;ResourceCategory::NonPersistent&gt;&gt; runnable_tasks;\nstd::shared_ptr&lt;PhaseManager&lt;ResourceCategory::Movement&gt;&gt; movement_tasks;\n\ninline static const std::string name{\"Runtime Reserver\"};\nRuntimeReserverStatus status{name};\nstd::vector&lt;InnerTask *&gt; launchable_tasks_buffer;\n\nbool check_resources(InnerTask *task);\nbool check_data_resources(InnerTask *task);\n\nvoid reserve_resources(InnerTask *task);\nvoid reserve_data_resources(InnerTask *task);\n};\n\nclass Launcher : virtual public SchedulerPhase {\npublic:\n/*Number of running tasks. A task is running if it has been assigned to a\n   * worker and is not complete*/\nstd::atomic&lt;size_t&gt; num_running_tasks{0};\n\nLauncher(InnerScheduler *scheduler, DeviceManager *devices)\n: SchedulerPhase(scheduler, devices) {}\n\n/*Add a task to the launcher. Currently this acquires the GIL and dispatches\n   * the work to a Python Worker for each task */\nvoid enqueue(InnerTask *task){};\nvoid enqueue(InnerTask *task, InnerWorker *worker);\nvoid enqueue(std::vector&lt;InnerTask *&gt; &amp;tasks){};\n\n/* A placeholder function in case work needs to be done at this stage. For\n   * example, dispatching a whole buffer of tasks*/\nvoid run();\nvoid run(SchedulerPhase *next_phase) { this-&gt;run(); };\n\n/* Number of running tasks. A task is running if it has been assigned to a\n   * worker and is not complete */\nsize_t get_count() { return this-&gt;num_running_tasks.load(); }\n\nprotected:\ninline static const std::string name{\"Launcher\"};\nLauncherStatus status{name};\n/*Buffer to store not yet launched tasks. Currently unused. Placeholder in\n   * case it becomes useful.*/\nTaskList task_buffer;\nWorkerList worker_buffer;\n};\n\n#endif // PARLA_PHASES_HPP\n</code></pre>"},{"location":"runtime/policy_8hpp/","title":"File policy.hpp","text":"<p>FileList &gt; backend &gt; include &gt; policy.hpp</p> <p>Go to the source code of this file.</p> <p>Interface for mapping policies. </p> <ul> <li><code>#include \"device.hpp\"</code></li> <li><code>#include \"parray_tracker.hpp\"</code></li> <li><code>#include \"runtime.hpp\"</code></li> <li><code>#include &lt;memory&gt;</code></li> </ul>"},{"location":"runtime/policy_8hpp/#classes","title":"Classes","text":"Type Name class LocalityLoadBalancingMappingPolicy class MappingPolicy"},{"location":"runtime/policy_8hpp/#public-types","title":"Public Types","text":"Type Name typedef double Score_t"},{"location":"runtime/policy_8hpp/#public-types-documentation","title":"Public Types Documentation","text":""},{"location":"runtime/policy_8hpp/#typedef-score_t","title":"typedef Score_t","text":"<pre><code>using Score_t =  double;\n</code></pre> <p>The documentation for this class was generated from the following file <code>src/c/backend/include/policy.hpp</code></p>"},{"location":"runtime/policy_8hpp_source/","title":"File policy.hpp","text":"<p>File List &gt; backend &gt; include &gt; policy.hpp</p> <p>Go to the documentation of this file. </p> <pre><code>#ifndef PARLA_POLICY_HPP\n#define PARLA_POLICY_HPP\n\n#include \"device.hpp\"\n#include \"parray_tracker.hpp\"\n#include \"runtime.hpp\"\n\n#include &lt;memory&gt;\n\nusing Score_t = double;\n\nclass Mapper;\n\nclass MappingPolicy {\npublic:\nMappingPolicy(DeviceManager *device_manager, PArrayTracker *parray_tracker)\n: device_manager_(device_manager), parray_tracker_(parray_tracker) {}\n\nvirtual bool calc_score_devplacement(\nInnerTask *task,\nconst std::shared_ptr&lt;DeviceRequirement&gt; &amp;dev_placement_req,\nconst Mapper &amp;mapper, Score_t *score,\nconst std::vector&lt;std::pair&lt;parray::InnerPArray *, AccessMode&gt;&gt;\n&amp;parray_list) = 0;\n\nvirtual bool calc_score_archplacement(\nInnerTask *task, ArchitectureRequirement *arch_placement_req,\nconst Mapper &amp;mapper, std::shared_ptr&lt;DeviceRequirement&gt; &amp;chosen_dev_req,\nScore_t *chosen_dev_score,\nconst std::vector&lt;std::pair&lt;parray::InnerPArray *, AccessMode&gt;&gt;\n&amp;parray_list,\nstd::vector&lt;bool&gt; *is_dev_assigned = nullptr) = 0;\n\nvirtual bool calc_score_mdevplacement(\nInnerTask *task, MultiDeviceRequirements *mdev_placement_req,\nconst Mapper &amp;mapper,\nstd::vector&lt;std::shared_ptr&lt;DeviceRequirement&gt;&gt; *member_device_reqs,\nScore_t *average_score,\nconst std::vector&lt;\nstd::vector&lt;std::pair&lt;parray::InnerPArray *, AccessMode&gt;&gt;&gt;\n&amp;parray_list) = 0;\n\nprotected:\nDeviceManager *device_manager_;\nPArrayTracker *parray_tracker_;\nint rrcount = 0;\n};\n\nclass LocalityLoadBalancingMappingPolicy : public MappingPolicy {\npublic:\nusing MappingPolicy::MappingPolicy;\n\nbool calc_score_devplacement(\nInnerTask *task,\nconst std::shared_ptr&lt;DeviceRequirement&gt; &amp;dev_placement_req,\nconst Mapper &amp;mapper, Score_t *score,\nconst std::vector&lt;std::pair&lt;parray::InnerPArray *, AccessMode&gt;&gt;\n&amp;parray_list) override;\n\nbool calc_score_archplacement(\nInnerTask *task, ArchitectureRequirement *arch_placement_req,\nconst Mapper &amp;mapper, std::shared_ptr&lt;DeviceRequirement&gt; &amp;chosen_dev_req,\nScore_t *chosen_dev_score,\nconst std::vector&lt;std::pair&lt;parray::InnerPArray *, AccessMode&gt;&gt;\n&amp;parray_list,\nstd::vector&lt;bool&gt; *is_dev_assigned = nullptr) override;\n\nbool calc_score_mdevplacement(\nInnerTask *task, MultiDeviceRequirements *mdev_placement_req,\nconst Mapper &amp;mapper,\nstd::vector&lt;std::shared_ptr&lt;DeviceRequirement&gt;&gt; *member_device_reqs,\nScore_t *average_score,\nconst std::vector&lt;\nstd::vector&lt;std::pair&lt;parray::InnerPArray *, AccessMode&gt;&gt;&gt;\n&amp;parray_list) override;\n};\n\n#endif\n</code></pre>"},{"location":"runtime/profiling_8hpp/","title":"File profiling.hpp","text":"<p>FileList &gt; backend &gt; include &gt; profiling.hpp</p> <p>Go to the source code of this file.</p> <p>Provides macros for NVTX profiling and BINLOG tracing. </p> <ul> <li><code>#include &lt;chrono&gt;</code></li> <li><code>#include &lt;fstream&gt;</code></li> <li><code>#include &lt;iostream&gt;</code></li> <li><code>#include &lt;thread&gt;</code></li> </ul>"},{"location":"runtime/profiling_8hpp/#public-functions","title":"Public Functions","text":"Type Name int initialize_log (std::string filename)  void log_scheduler_1 (const int type, std::string msg, T * class_ptr)  void log_scheduler_2 (const int type, std::string msg1, T * class_ptr1, std::string msg2, G * class_ptr2)  void log_scheduler_msg (const int type, std::string msg)  void log_task_1 (const int type, std::string msg, T * class_ptr)  void log_task_2 (const int type, std::string msg1, T * class_ptr1, std::string msg2, G * class_ptr2)  void log_task_msg (const int type, std::string msg)  void log_worker_1 (const int type, std::string msg, T * class_ptr)  void log_worker_2 (const int type, std::string msg1, T * class_ptr1, std::string msg2, G * class_ptr2)  void log_worker_msg (const int type, std::string msg)  int write_log (std::string filename)"},{"location":"runtime/profiling_8hpp/#macros","title":"Macros","text":"Type Name define LOG_ADAPT_DERIVED (args...)  define LOG_ADAPT_ENUM (args...)  define LOG_ADAPT_STRUCT (args...)  define LOG_DEBUG (args...)  define LOG_ERROR (args...)  define LOG_FATAL (args...)  define LOG_INFO (args...)  define LOG_TRACE (args...)  define LOG_WARN (args...)  define NVTX_COLOR (c1, c2, c3)  define NVTX_COLOR_BLACK  NVTX_COLOR(0, 0, 0) define NVTX_COLOR_BLUE  NVTX_COLOR(0, 0, 255) define NVTX_COLOR_CYAN  NVTX_COLOR(0, 255, 255) define NVTX_COLOR_GRAY  NVTX_COLOR(127, 127, 127) define NVTX_COLOR_GREEN  NVTX_COLOR(0, 255, 0) define NVTX_COLOR_LIGHT_GREEN  NVTX_COLOR(127, 255, 0) define NVTX_COLOR_MAGENTA  NVTX_COLOR(255, 0, 255) define NVTX_COLOR_ORANGE  NVTX_COLOR(255, 127, 0) define NVTX_COLOR_PURPLE  NVTX_COLOR(127, 0, 255) define NVTX_COLOR_RED  NVTX_COLOR(255, 0, 0) define NVTX_COLOR_TEAL  NVTX_COLOR(0, 168, 255) define NVTX_COLOR_WHITE  NVTX_COLOR(255, 255, 255) define NVTX_COLOR_YELLOW  NVTX_COLOR(255, 255, 0) define NVTX_RANGE (name, color)  define SCHEDULER  'Scheduler' define TASK  'Task' define WORKER  'Worker'"},{"location":"runtime/profiling_8hpp/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/profiling_8hpp/#function-initialize_log","title":"function initialize_log","text":"<pre><code>inline int initialize_log (\nstd::string filename\n) </code></pre>"},{"location":"runtime/profiling_8hpp/#function-log_scheduler_1","title":"function log_scheduler_1","text":"<pre><code>template&lt;typename T typename T&gt;\ninline void log_scheduler_1 (\nconst int type,\nstd::string msg,\nT * class_ptr\n) </code></pre>"},{"location":"runtime/profiling_8hpp/#function-log_scheduler_2","title":"function log_scheduler_2","text":"<pre><code>template&lt;typename T typename T, typename G typename G&gt;\ninline void log_scheduler_2 (\nconst int type,\nstd::string msg1,\nT * class_ptr1,\nstd::string msg2,\nG * class_ptr2\n) </code></pre>"},{"location":"runtime/profiling_8hpp/#function-log_scheduler_msg","title":"function log_scheduler_msg","text":"<pre><code>inline void log_scheduler_msg (\nconst int type,\nstd::string msg\n) </code></pre>"},{"location":"runtime/profiling_8hpp/#function-log_task_1","title":"function log_task_1","text":"<pre><code>template&lt;typename T typename T&gt;\ninline void log_task_1 (\nconst int type,\nstd::string msg,\nT * class_ptr\n) </code></pre>"},{"location":"runtime/profiling_8hpp/#function-log_task_2","title":"function log_task_2","text":"<pre><code>template&lt;typename T typename T, typename G typename G&gt;\ninline void log_task_2 (\nconst int type,\nstd::string msg1,\nT * class_ptr1,\nstd::string msg2,\nG * class_ptr2\n) </code></pre>"},{"location":"runtime/profiling_8hpp/#function-log_task_msg","title":"function log_task_msg","text":"<pre><code>inline void log_task_msg (\nconst int type,\nstd::string msg\n) </code></pre>"},{"location":"runtime/profiling_8hpp/#function-log_worker_1","title":"function log_worker_1","text":"<pre><code>template&lt;typename T typename T&gt;\ninline void log_worker_1 (\nconst int type,\nstd::string msg,\nT * class_ptr\n) </code></pre>"},{"location":"runtime/profiling_8hpp/#function-log_worker_2","title":"function log_worker_2","text":"<pre><code>template&lt;typename T typename T, typename G typename G&gt;\ninline void log_worker_2 (\nconst int type,\nstd::string msg1,\nT * class_ptr1,\nstd::string msg2,\nG * class_ptr2\n) </code></pre>"},{"location":"runtime/profiling_8hpp/#function-log_worker_msg","title":"function log_worker_msg","text":"<pre><code>inline void log_worker_msg (\nconst int type,\nstd::string msg\n) </code></pre>"},{"location":"runtime/profiling_8hpp/#function-write_log","title":"function write_log","text":"<pre><code>inline int write_log (\nstd::string filename\n) </code></pre>"},{"location":"runtime/profiling_8hpp/#macro-definition-documentation","title":"Macro Definition Documentation","text":""},{"location":"runtime/profiling_8hpp/#define-log_adapt_derived","title":"define LOG_ADAPT_DERIVED","text":"<pre><code>#define LOG_ADAPT_DERIVED (\nargs...\n) </code></pre>"},{"location":"runtime/profiling_8hpp/#define-log_adapt_enum","title":"define LOG_ADAPT_ENUM","text":"<pre><code>#define LOG_ADAPT_ENUM (\nargs...\n) </code></pre>"},{"location":"runtime/profiling_8hpp/#define-log_adapt_struct","title":"define LOG_ADAPT_STRUCT","text":"<pre><code>#define LOG_ADAPT_STRUCT (\nargs...\n) </code></pre>"},{"location":"runtime/profiling_8hpp/#define-log_debug","title":"define LOG_DEBUG","text":"<pre><code>#define LOG_DEBUG (\nargs...\n) </code></pre>"},{"location":"runtime/profiling_8hpp/#define-log_error","title":"define LOG_ERROR","text":"<pre><code>#define LOG_ERROR (\nargs...\n) </code></pre>"},{"location":"runtime/profiling_8hpp/#define-log_fatal","title":"define LOG_FATAL","text":"<pre><code>#define LOG_FATAL (\nargs...\n) </code></pre>"},{"location":"runtime/profiling_8hpp/#define-log_info","title":"define LOG_INFO","text":"<pre><code>#define LOG_INFO (\nargs...\n) </code></pre>"},{"location":"runtime/profiling_8hpp/#define-log_trace","title":"define LOG_TRACE","text":"<pre><code>#define LOG_TRACE (\nargs...\n) </code></pre>"},{"location":"runtime/profiling_8hpp/#define-log_warn","title":"define LOG_WARN","text":"<pre><code>#define LOG_WARN (\nargs...\n) </code></pre>"},{"location":"runtime/profiling_8hpp/#define-nvtx_color","title":"define NVTX_COLOR","text":"<pre><code>#define NVTX_COLOR (\nc1,\nc2,\nc3\n) </code></pre>"},{"location":"runtime/profiling_8hpp/#define-nvtx_color_black","title":"define NVTX_COLOR_BLACK","text":"<pre><code>#define NVTX_COLOR_BLACK NVTX_COLOR(0, 0, 0)\n</code></pre>"},{"location":"runtime/profiling_8hpp/#define-nvtx_color_blue","title":"define NVTX_COLOR_BLUE","text":"<pre><code>#define NVTX_COLOR_BLUE NVTX_COLOR(0, 0, 255)\n</code></pre>"},{"location":"runtime/profiling_8hpp/#define-nvtx_color_cyan","title":"define NVTX_COLOR_CYAN","text":"<pre><code>#define NVTX_COLOR_CYAN NVTX_COLOR(0, 255, 255)\n</code></pre>"},{"location":"runtime/profiling_8hpp/#define-nvtx_color_gray","title":"define NVTX_COLOR_GRAY","text":"<pre><code>#define NVTX_COLOR_GRAY NVTX_COLOR(127, 127, 127)\n</code></pre>"},{"location":"runtime/profiling_8hpp/#define-nvtx_color_green","title":"define NVTX_COLOR_GREEN","text":"<pre><code>#define NVTX_COLOR_GREEN NVTX_COLOR(0, 255, 0)\n</code></pre>"},{"location":"runtime/profiling_8hpp/#define-nvtx_color_light_green","title":"define NVTX_COLOR_LIGHT_GREEN","text":"<pre><code>#define NVTX_COLOR_LIGHT_GREEN NVTX_COLOR(127, 255, 0)\n</code></pre>"},{"location":"runtime/profiling_8hpp/#define-nvtx_color_magenta","title":"define NVTX_COLOR_MAGENTA","text":"<pre><code>#define NVTX_COLOR_MAGENTA NVTX_COLOR(255, 0, 255)\n</code></pre>"},{"location":"runtime/profiling_8hpp/#define-nvtx_color_orange","title":"define NVTX_COLOR_ORANGE","text":"<pre><code>#define NVTX_COLOR_ORANGE NVTX_COLOR(255, 127, 0)\n</code></pre>"},{"location":"runtime/profiling_8hpp/#define-nvtx_color_purple","title":"define NVTX_COLOR_PURPLE","text":"<pre><code>#define NVTX_COLOR_PURPLE NVTX_COLOR(127, 0, 255)\n</code></pre>"},{"location":"runtime/profiling_8hpp/#define-nvtx_color_red","title":"define NVTX_COLOR_RED","text":"<pre><code>#define NVTX_COLOR_RED NVTX_COLOR(255, 0, 0)\n</code></pre>"},{"location":"runtime/profiling_8hpp/#define-nvtx_color_teal","title":"define NVTX_COLOR_TEAL","text":"<pre><code>#define NVTX_COLOR_TEAL NVTX_COLOR(0, 168, 255)\n</code></pre>"},{"location":"runtime/profiling_8hpp/#define-nvtx_color_white","title":"define NVTX_COLOR_WHITE","text":"<pre><code>#define NVTX_COLOR_WHITE NVTX_COLOR(255, 255, 255)\n</code></pre>"},{"location":"runtime/profiling_8hpp/#define-nvtx_color_yellow","title":"define NVTX_COLOR_YELLOW","text":"<pre><code>#define NVTX_COLOR_YELLOW NVTX_COLOR(255, 255, 0)\n</code></pre>"},{"location":"runtime/profiling_8hpp/#define-nvtx_range","title":"define NVTX_RANGE","text":"<pre><code>#define NVTX_RANGE (\nname,\ncolor\n) </code></pre>"},{"location":"runtime/profiling_8hpp/#define-scheduler","title":"define SCHEDULER","text":"<pre><code>#define SCHEDULER 'Scheduler'\n</code></pre>"},{"location":"runtime/profiling_8hpp/#define-task","title":"define TASK","text":"<pre><code>#define TASK 'Task'\n</code></pre>"},{"location":"runtime/profiling_8hpp/#define-worker","title":"define WORKER","text":"<pre><code>#define WORKER 'Worker'\n</code></pre> <p>The documentation for this class was generated from the following file <code>src/c/backend/include/profiling.hpp</code></p>"},{"location":"runtime/profiling_8hpp_source/","title":"File profiling.hpp","text":"<p>File List &gt; backend &gt; include &gt; profiling.hpp</p> <p>Go to the documentation of this file. </p> <pre><code>// #pragma once\n#ifndef PARLA_PROFILING_HPP\n#define PARLA_PROFILING_HPP\n\n#include &lt;chrono&gt;\n#include &lt;fstream&gt;\n#include &lt;iostream&gt;\n#include &lt;thread&gt;\n\n#if defined(PARLA_ENABLE_NVTX)\n\n#include &lt;nvtx3/nvtx3.hpp&gt;\n\nstruct my_domain {\nstatic constexpr char const *name{\"Parla Runtime\"};\n};\n\nusing my_scoped_range = nvtx3::scoped_range_in&lt;my_domain&gt;;\nusing my_registered_string = nvtx3::registered_string_in&lt;my_domain&gt;;\n\n/*\n// Statically configure the message strings so they are not reiniailized on\n// every tracing call\n// This decreases the tracing overhead\nstruct add_dependent_msg{ static constexpr char const*\nmessage{\"add_dependency\"}; }; struct add_dependency_msg{ static constexpr char\nconst* message{\"add_dependent\"}; }; struct notify_dependents_msg{ static\nconstexpr char const* message{\"notify_dependents\"}; }; struct run_launcher_msg{\nstatic constexpr char const* message{\"run_launcher\"}; };\n*/\n\n#define NVTX_COLOR(c1, c2, c3)                                                 \\\n  nvtx3::rgb { c1, c2, c3 }\n#define NVTX_RANGE(name, color) my_scoped_range r(name, color);\n\n#else\n\n#define NVTX_COLOR(c1, c2, c3)\n\n#define NVTX_RANGE(name, color)\n\n#endif // PARLA_ENABLE_NVTX\n\n#define NVTX_COLOR_RED NVTX_COLOR(255, 0, 0)\n#define NVTX_COLOR_GREEN NVTX_COLOR(0, 255, 0)\n#define NVTX_COLOR_BLUE NVTX_COLOR(0, 0, 255)\n\n#define NVTX_COLOR_YELLOW NVTX_COLOR(255, 255, 0)\n#define NVTX_COLOR_MAGENTA NVTX_COLOR(255, 0, 255)\n#define NVTX_COLOR_CYAN NVTX_COLOR(0, 255, 255)\n#define NVTX_COLOR_LIGHT_GREEN NVTX_COLOR(127, 255, 0)\n\n#define NVTX_COLOR_ORANGE NVTX_COLOR(255, 127, 0)\n#define NVTX_COLOR_PURPLE NVTX_COLOR(127, 0, 255)\n#define NVTX_COLOR_TEAL NVTX_COLOR(0, 168, 255)\n\n#define NVTX_COLOR_WHITE NVTX_COLOR(255, 255, 255)\n#define NVTX_COLOR_BLACK NVTX_COLOR(0, 0, 0)\n\n#define NVTX_COLOR_GRAY NVTX_COLOR(127, 127, 127)\n\n#ifdef PARLA_ENABLE_LOGGING\n#include &lt;binlog/Session.hpp&gt;\n#include &lt;binlog/SessionWriter.hpp&gt;\n#include &lt;binlog/advanced_log_macros.hpp&gt;\n#include &lt;binlog/binlog.hpp&gt;\n\nnamespace binlog {\n\nextern int global_reset_count;\n\ninline Session &amp;parla_session() {\nstatic Session parla_session;\nstatic unsigned int reset_count;\n// if (reset_count != global_reset_count) {\n//   parla_session = Session();\n//   reset_count = binlog::global_reset_count;\n// }\nreturn parla_session;\n}\n\ninline SessionWriter &amp;parla_writer() {\nstatic thread_local SessionWriter s_writer(parla_session(), 1 &lt;&lt; 20, 0,\ndetail::this_thread_id_string());\n\nstatic thread_local unsigned int reset_count;\n\nif (reset_count != binlog::global_reset_count) {\n/*\n    std::cout &lt;&lt; \"Resetting binlog session writer\" &lt;&lt; std::endl;\n    s_writer = SessionWriter(parla_session(), 1 &lt;&lt; 20, 0,\n                             detail::this_thread_id_string());\n    reset_count = binlog::global_reset_count;\n    */\n}\nreturn s_writer;\n}\n\n} // namespace binlog\n\n#define LOG_TRACE(args...) BINLOG_TRACE_WC(binlog::parla_writer(), args)\n#define LOG_DEBUG(args...) BINLOG_DEBUG_WC(binlog::parla_writer(), args)\n#define LOG_INFO(args...) BINLOG_INFO_WC(binlog::parla_writer(), args)\n#define LOG_WARN(args...) BINLOG_WARN_WC(binlog::parla_writer(), args)\n#define LOG_ERROR(args...) BINLOG_ERROR_WC(binlog::parla_writer(), args)\n#define LOG_FATAL(args...) BINLOG_CRITICAL_WC(binlog::parla_writer(), args)\n\n#define LOG_ADAPT_STRUCT(args...) BINLOG_ADAPT_STRUCT(args)\n#define LOG_ADAPT_DERIVED(args...) BINLOG_ADAPT_DERIVED(args)\n#define LOG_ADAPT_ENUM(args...) BINLOG_ADAPT_ENUM(args)\n#define LOG_ADAPT_DERIVED(args...) BINLOG_ADAPT_DERIVED(args)\n\ninline int initialize_log(std::string filename) {\nstd::ofstream logfile(filename.c_str(),\nstd::ofstream::out | std::ofstream::binary);\nbinlog::global_reset_count++;\nbinlog::parla_session().reconsumeMetadata(logfile);\n\n// std::cout &lt;&lt; \"Metadata written to: \" &lt;&lt; filename\n//           &lt;&lt; binlog::detail::this_thread_id_string() &lt;&lt; std::endl;\nlogfile.close();\nreturn 0;\n}\n\ninline int write_log(std::string filename) {\nstd::ofstream logfile(filename.c_str(),\nstd::ofstream::app | std::ofstream::binary);\n\nbinlog::parla_session().consume(logfile);\nlogfile.close();\n\nif (!logfile) {\nstd::cerr &lt;&lt; \"Failed to write logfile!\\n\";\nreturn 1;\n}\n\nstd::cout &lt;&lt; \"Log file written to: \" &lt;&lt; filename &lt;&lt; std::endl;\nreturn 0;\n}\n\n#else\n#define LOG_TRACE(args...)\n#define LOG_DEBUG(args...)\n#define LOG_INFO(args...)\n#define LOG_WARN(args...)\n#define LOG_ERROR(args...)\n#define LOG_FATAL(args...)\n\n#define LOG_ADAPT_STRUCT(args...)\n#define LOG_ADAPT_DERIVED(args...)\n#define LOG_ADAPT_ENUM(args...)\n\ninline int initialize_log(std::string filename) { return 0; }\n\ninline int write_log(std::string filename) { return 0; }\n\n#endif\n\n#define WORKER 'Worker'\n#define SCHEDULER 'Scheduler'\n#define TASK 'Task'\n\ninline void log_task_msg(const int type, std::string msg) {\n// const char* _msg = msg.c_str();\nswitch (type) {\ncase 0:\nLOG_TRACE(TASK, \"{}\", msg);\nbreak;\ncase 1:\nLOG_DEBUG(TASK, \"{}\", msg);\nbreak;\ncase 2:\nLOG_INFO(TASK, \"{}\", msg);\nbreak;\ncase 3:\nLOG_WARN(TASK, \"{}\", msg);\nbreak;\ncase 4:\nLOG_ERROR(TASK, \"{}\", msg);\nbreak;\ncase 5:\nLOG_FATAL(TASK, \"{}\", msg);\nbreak;\n}\n}\n\ninline void log_worker_msg(const int type, std::string msg) {\n// const char* _msg = msg.c_str();\nswitch (type) {\ncase 0:\nLOG_TRACE(WORKER, \"{}\", msg);\nbreak;\ncase 1:\nLOG_DEBUG(WORKER, \"{}\", msg);\nbreak;\ncase 2:\nLOG_INFO(WORKER, \"{}\", msg);\nbreak;\ncase 3:\nLOG_WARN(WORKER, \"{}\", msg);\nbreak;\ncase 4:\nLOG_ERROR(WORKER, \"{}\", msg);\nbreak;\ncase 5:\nLOG_FATAL(WORKER, \"{}\", msg);\nbreak;\n}\n}\n\ninline void log_scheduler_msg(const int type, std::string msg) {\n// const char* _msg = msg.c_str();\nswitch (type) {\ncase 0:\nLOG_TRACE(SCHEDULER, \"{}\", msg);\nbreak;\ncase 1:\nLOG_DEBUG(SCHEDULER, \"{}\", msg);\nbreak;\ncase 2:\nLOG_INFO(SCHEDULER, \"{}\", msg);\nbreak;\ncase 3:\nLOG_WARN(SCHEDULER, \"{}\", msg);\nbreak;\ncase 4:\nLOG_ERROR(SCHEDULER, \"{}\", msg);\nbreak;\ncase 5:\nLOG_FATAL(SCHEDULER, \"{}\", msg);\nbreak;\n}\n}\n\ntemplate &lt;typename T&gt;\ninline void log_task_1(const int type, std::string msg, T *class_ptr) {\n// const char* _msg = msg.c_str();\nswitch (type) {\ncase 0:\nLOG_TRACE(TASK, \"{} : {}\", msg, class_ptr);\nbreak;\ncase 1:\nLOG_DEBUG(TASK, \"{} : {}\", msg, class_ptr);\nbreak;\ncase 2:\nLOG_INFO(TASK, \"{} : {}\", msg, class_ptr);\nbreak;\ncase 3:\nLOG_WARN(TASK, \"{} : {}\", msg, class_ptr);\nbreak;\ncase 4:\nLOG_ERROR(TASK, \"{} : {}\", msg, class_ptr);\nbreak;\ncase 5:\nLOG_FATAL(TASK, \"{} : {}\", msg, class_ptr);\nbreak;\n}\n}\n\ntemplate &lt;typename T&gt;\ninline void log_worker_1(const int type, std::string msg, T *class_ptr) {\n// const char* _msg = msg.c_str();\nswitch (type) {\ncase 0:\nLOG_TRACE(WORKER, \"{} : {}\", msg, class_ptr);\nbreak;\ncase 1:\nLOG_DEBUG(WORKER, \"{} : {}\", msg, class_ptr);\nbreak;\ncase 2:\nLOG_INFO(WORKER, \"{} : {}\", msg, class_ptr);\nbreak;\ncase 3:\nLOG_WARN(WORKER, \"{} : {}\", msg, class_ptr);\nbreak;\ncase 4:\nLOG_ERROR(WORKER, \"{} : {}\", msg, class_ptr);\nbreak;\ncase 5:\nLOG_FATAL(WORKER, \"{} : {}\", msg, class_ptr);\nbreak;\n}\n}\n\ntemplate &lt;typename T&gt;\ninline void log_scheduler_1(const int type, std::string msg, T *class_ptr) {\n// const char* _msg = msg.c_str();\nswitch (type) {\ncase 0:\nLOG_TRACE(SCHEDULER, \"{} : {}\", msg, class_ptr);\nbreak;\ncase 1:\nLOG_DEBUG(SCHEDULER, \"{} : {}\", msg, class_ptr);\nbreak;\ncase 2:\nLOG_INFO(SCHEDULER, \"{} : {}\", msg, class_ptr);\nbreak;\ncase 3:\nLOG_WARN(SCHEDULER, \"{} : {}\", msg, class_ptr);\nbreak;\ncase 4:\nLOG_ERROR(SCHEDULER, \"{} : {}\", msg, class_ptr);\nbreak;\ncase 5:\nLOG_FATAL(SCHEDULER, \"{} : {}\", msg, class_ptr);\nbreak;\n}\n}\n\ntemplate &lt;typename T, typename G&gt;\ninline void log_task_2(const int type, std::string msg1, T *class_ptr1,\nstd::string msg2, G *class_ptr2) {\n// const char* _msg = msg.c_str();\nswitch (type) {\ncase 0:\nLOG_TRACE(TASK, \"{} : {} {} {}\", msg1, class_ptr1, msg2, class_ptr2);\nbreak;\ncase 1:\nLOG_DEBUG(TASK, \"{} : {} {} {}\", msg1, class_ptr1, msg2, class_ptr2);\nbreak;\ncase 2:\nLOG_INFO(TASK, \"{} : {} {} {}\", msg1, class_ptr1, msg2, class_ptr2);\nbreak;\ncase 3:\nLOG_WARN(TASK, \"{} : {} {} {}\", msg1, class_ptr1, msg2, class_ptr2);\nbreak;\ncase 4:\nLOG_ERROR(TASK, \"{} : {} {} {}\", msg1, class_ptr1, msg2, class_ptr2);\nbreak;\ncase 5:\nLOG_FATAL(TASK, \"{} : {} {} {}\", msg1, class_ptr1, msg2, class_ptr2);\nbreak;\n}\n}\n\ntemplate &lt;typename T, typename G&gt;\ninline void log_worker_2(const int type, std::string msg1, T *class_ptr1,\nstd::string msg2, G *class_ptr2) {\n// const char* _msg = msg.c_str();\nswitch (type) {\ncase 0:\nLOG_TRACE(WORKER, \"{} : {} {} {}\", msg1, class_ptr1, msg2, class_ptr2);\nbreak;\ncase 1:\nLOG_DEBUG(WORKER, \"{} : {} {} {}\", msg1, class_ptr1, msg2, class_ptr2);\nbreak;\ncase 2:\nLOG_INFO(WORKER, \"{} : {} {} {}\", msg1, class_ptr1, msg2, class_ptr2);\nbreak;\ncase 3:\nLOG_WARN(WORKER, \"{} : {} {} {}\", msg1, class_ptr1, msg2, class_ptr2);\nbreak;\ncase 4:\nLOG_ERROR(WORKER, \"{} : {} {} {}\", msg1, class_ptr1, msg2, class_ptr2);\nbreak;\ncase 5:\nLOG_FATAL(WORKER, \"{} : {} {} {}\", msg1, class_ptr1, msg2, class_ptr2);\nbreak;\n}\n}\n\ntemplate &lt;typename T, typename G&gt;\ninline void log_scheduler_2(const int type, std::string msg1, T *class_ptr1,\nstd::string msg2, G *class_ptr2) {\n// const char* _msg = msg.c_str();\nswitch (type) {\ncase 0:\nLOG_TRACE(WORKER, \"{} : {} {} {}\", msg1, class_ptr1, msg2, class_ptr2);\nbreak;\ncase 1:\nLOG_DEBUG(WORKER, \"{} : {} {} {}\", msg1, class_ptr1, msg2, class_ptr2);\nbreak;\ncase 2:\nLOG_INFO(WORKER, \"{} : {} {} {}\", msg1, class_ptr1, msg2, class_ptr2);\nbreak;\ncase 3:\nLOG_WARN(WORKER, \"{} : {} {} {}\", msg1, class_ptr1, msg2, class_ptr2);\nbreak;\ncase 4:\nLOG_ERROR(WORKER, \"{} : {} {} {}\", msg1, class_ptr1, msg2, class_ptr2);\nbreak;\ncase 5:\nLOG_FATAL(WORKER, \"{} : {} {} {}\", msg1, class_ptr1, msg2, class_ptr2);\nbreak;\n}\n}\n\n#endif // PARLA_PROFILING_HPP\n</code></pre>"},{"location":"runtime/resource__requirements_8hpp/","title":"File resource_requirements.hpp","text":"<p>FileList &gt; backend &gt; include &gt; resource_requirements.hpp</p> <p>Go to the source code of this file.</p> <p>Provides task constraint classes to hold potential placement locations and architectures. </p> <ul> <li><code>#include \"device.hpp\"</code></li> <li><code>#include &lt;memory&gt;</code></li> </ul>"},{"location":"runtime/resource__requirements_8hpp/#classes","title":"Classes","text":"Type Name class ArchitectureRequirement class DeviceRequirement class MultiDeviceRequirements class PlacementRequirementBase Base classes. class PlacementRequirementCollections Resource contains device types (architectures), specific devices, their memory and virtual computation units. class SinglePlacementRequirementBase <p>The documentation for this class was generated from the following file <code>src/c/backend/include/resource_requirements.hpp</code></p>"},{"location":"runtime/resource__requirements_8hpp_source/","title":"File resource_requirements.hpp","text":"<p>File List &gt; backend &gt; include &gt; resource_requirements.hpp</p> <p>Go to the documentation of this file. </p> <pre><code>#ifndef PARLA_RESOURCE_REQUIREMENTS_HPP\n#define PARLA_RESOURCE_REQUIREMENTS_HPP\n\n#include \"device.hpp\"\n\n#include &lt;memory&gt;\n\n\nclass PlacementRequirementBase {\npublic:\nvirtual bool is_multidev_req() = 0;\nvirtual bool is_arch_req() = 0;\nvirtual bool is_dev_req() = 0;\n};\nclass SinglePlacementRequirementBase : public PlacementRequirementBase {};\n\nclass PlacementRequirementCollections {\npublic:\nvoid\nappend_placement_req_opt(std::shared_ptr&lt;PlacementRequirementBase&gt; dev_req);\nconst std::vector&lt;std::shared_ptr&lt;PlacementRequirementBase&gt;&gt; &amp;\nget_placement_req_opts_ref();\n\nprivate:\nstd::vector&lt;std::shared_ptr&lt;PlacementRequirementBase&gt;&gt; placement_reqs_;\n};\n\nclass MultiDeviceRequirements : public PlacementRequirementBase {\npublic:\nvoid\nappend_placement_req(std::shared_ptr&lt;SinglePlacementRequirementBase&gt; req);\nbool is_multidev_req() override { return true; }\nbool is_arch_req() override { return false; }\nbool is_dev_req() override { return false; }\n\nconst std::vector&lt;std::shared_ptr&lt;SinglePlacementRequirementBase&gt;&gt; &amp;\nget_placement_reqs_ref();\n\nprivate:\nstd::vector&lt;std::shared_ptr&lt;SinglePlacementRequirementBase&gt;&gt; placement_reqs_;\n};\n\nclass DeviceRequirement : public SinglePlacementRequirementBase {\npublic:\nDeviceRequirement(Device *dev, ResourcePool_t res_req)\n: dev_(dev), res_req_(res_req) {}\n\nbool is_multidev_req() override { return false; }\nbool is_arch_req() override { return false; }\nbool is_dev_req() override { return true; }\n\nDevice *device() { return dev_; }\n\nconst ResourcePool_t &amp;res_req() const { return res_req_; }\nResourcePool_t &amp;res_req() { return res_req_; }\n\nprivate:\nDevice *dev_;\nResourcePool_t res_req_;\n};\n\nclass ArchitectureRequirement : public SinglePlacementRequirementBase {\npublic:\nvoid append_placement_req_opt(std::shared_ptr&lt;DeviceRequirement&gt; req);\nconst std::vector&lt;std::shared_ptr&lt;DeviceRequirement&gt;&gt; &amp;\nGetDeviceRequirementOptions();\nbool is_multidev_req() override { return false; }\nbool is_arch_req() override { return true; }\nbool is_dev_req() override { return false; }\n\nprivate:\nstd::vector&lt;std::shared_ptr&lt;DeviceRequirement&gt;&gt; placement_reqs_;\n};\n\n#endif\n</code></pre>"},{"location":"runtime/resources_8hpp/","title":"File resources.hpp","text":"<p>FileList &gt; backend &gt; include &gt; resources.hpp</p> <p>Go to the source code of this file.</p> <p>Provides a resource pool for tracking resource usage. </p> <ul> <li><code>#include &lt;array&gt;</code></li> <li><code>#include &lt;atomic&gt;</code></li> <li><code>#include &lt;iostream&gt;</code></li> <li><code>#include &lt;string&gt;</code></li> <li><code>#include &lt;type_traits&gt;</code></li> <li><code>#include &lt;unordered_map&gt;</code></li> <li><code>#include &lt;vector&gt;</code></li> <li><code>#include &lt;string_view&gt;</code></li> </ul>"},{"location":"runtime/resources_8hpp/#namespaces","title":"Namespaces","text":"Type Name namespace string_view_literals"},{"location":"runtime/resources_8hpp/#classes","title":"Classes","text":"Type Name class ResourcePool A pool of resources, allows for comparisons and updates of current values."},{"location":"runtime/resources_8hpp/#public-types","title":"Public Types","text":"Type Name enum Resource enum ResourceCategory typedef int64_t Resource_t"},{"location":"runtime/resources_8hpp/#public-attributes","title":"Public Attributes","text":"Type Name constexpr std::array&lt; Resource, 1 &gt; movement_resources   = = {Resource::Copy} constexpr std::array&lt; Resource, 1 &gt; non_persistent_resources   = = { Resource::VCU} constexpr std::array&lt; Resource, 1 &gt; persistent_resources   = = { Resource::Memory} constexpr std::array resource_names   = = {\"memory\"sv, \"vcu\"sv, \"copy\"sv}"},{"location":"runtime/resources_8hpp/#public-types-documentation","title":"Public Types Documentation","text":""},{"location":"runtime/resources_8hpp/#enum-resource","title":"enum Resource","text":"<pre><code>enum Resource {\nMemory = 0,\nVCU = 1,\nCopy = 2,\nMAX = 3\n};\n</code></pre>"},{"location":"runtime/resources_8hpp/#enum-resourcecategory","title":"enum ResourceCategory","text":"<pre><code>enum ResourceCategory {\nAll = 0,\nPersistent = 1,\nNonPersistent = 2,\nMovement = 3,\nMAX = 4\n};\n</code></pre>"},{"location":"runtime/resources_8hpp/#typedef-resource_t","title":"typedef Resource_t","text":"<pre><code>using Resource_t =  int64_t;\n</code></pre>"},{"location":"runtime/resources_8hpp/#public-attributes-documentation","title":"Public Attributes Documentation","text":""},{"location":"runtime/resources_8hpp/#variable-movement_resources","title":"variable movement_resources","text":"<pre><code>constexpr std::array&lt;Resource, 1&gt; movement_resources;\n</code></pre>"},{"location":"runtime/resources_8hpp/#variable-non_persistent_resources","title":"variable non_persistent_resources","text":"<pre><code>constexpr std::array&lt;Resource, 1&gt; non_persistent_resources;\n</code></pre>"},{"location":"runtime/resources_8hpp/#variable-persistent_resources","title":"variable persistent_resources","text":"<pre><code>constexpr std::array&lt;Resource, 1&gt; persistent_resources;\n</code></pre>"},{"location":"runtime/resources_8hpp/#variable-resource_names","title":"variable resource_names","text":"<pre><code>constexpr std::array resource_names;\n</code></pre> <p>The documentation for this class was generated from the following file <code>src/c/backend/include/resources.hpp</code></p>"},{"location":"runtime/resources_8hpp_source/","title":"File resources.hpp","text":"<p>File List &gt; backend &gt; include &gt; resources.hpp</p> <p>Go to the documentation of this file. </p> <pre><code>#ifndef RESOURCES_HPP\n#define RESOURCES_HPP\n\n#include &lt;array&gt;\n#include &lt;atomic&gt;\n#include &lt;iostream&gt;\n#include &lt;string&gt;\n#include &lt;type_traits&gt;\n#include &lt;unordered_map&gt;\n#include &lt;vector&gt;\n\n#include &lt;string_view&gt;\nusing namespace std::literals::string_view_literals; // Enables sv suffix only\n\nusing Resource_t = int64_t;\n\n// FIXME: Limiting copies should be the property of a topology object not a\n// resource pool. It is shared between devices. Need to get the source at\n// runtime.\n\nenum class Resource { Memory = 0, VCU = 1, Copy = 2, MAX = 3 };\nenum class ResourceCategory {\nAll = 0,\nPersistent = 1,\nNonPersistent = 2,\nMovement = 3,\nMAX = 4\n};\n\n// TODO(wlr): ResourcePool should have template specializations on the device\n// type.\n//       E.g. each has a constexpr array of active_resources on the device.\n//       This will allow us to use different types of resources for different\n//       devices and compare them. For now assume only memory and vcu exist and\n//       are used for all devices.\n\n/*\nIn the current plan there two phases where there are per-device queues:\n\nMemoryReserver, where persistent resources that have a lifetime greater than the\ntask execution are reserved. The only one of these that we track is memory.\nAnother name for this could be \"prefetched resources\". RuntimeReserver, where\n'non-persistent' runtime resources that have a lifetime equal to the task\nexecution. The only one of these that we track is VCUs. The persistent /\nnon-persistent tags refere to these two phases which track and compare different\nresources.\n\nIn practice these should be set by the architecture type and not shared\nglobally. For now we assume all devices have the same resource sets in all\nphases.\n\n*/\ninline constexpr std::array resource_names = {\"memory\"sv, \"vcu\"sv, \"copy\"sv};\n// inline std::unordered_map&lt;std::string, Resource&gt; resource_map = {\n//     {resource_names[Resource::MEMORY], Resource::MEMORY},\n//     {resource_names[Resource::VCU], Resource::VCU}};\n\ninline constexpr std::array&lt;Resource, 1&gt; persistent_resources = {\nResource::Memory};\ninline constexpr std::array&lt;Resource, 1&gt; non_persistent_resources = {\nResource::VCU};\ninline constexpr std::array&lt;Resource, 1&gt; movement_resources = {Resource::Copy};\n\nclass ResourcePool {\n\nusing V = Resource_t;\n\npublic:\nResourcePool(){\n// std::cout &lt;&lt; \"Resource Initialized:\" &lt;&lt; std::endl;\n// for (int i = 0; i &lt; resource_names.size(); i++) {\n//  std::cout &lt;&lt; this-&gt;resources[i].load() &lt;&lt; std::endl;\n//}\n};\n\nResourcePool(V memory, V vcu, V copy) {\nthis-&gt;resources[static_cast&lt;int&gt;(Resource::Memory)].exchange(memory);\nthis-&gt;resources[static_cast&lt;int&gt;(Resource::VCU)].exchange(vcu);\nthis-&gt;resources[static_cast&lt;int&gt;(Resource::Copy)].exchange(copy);\n}\n\nResourcePool(std::vector&lt;Resource&gt; &amp;resource_list, std::vector&lt;V&gt; &amp;values) {\nfor (auto i = 0; i &lt; resource_list.size(); i++) {\nconst int idx = static_cast&lt;int&gt;(resource_list[i]);\nthis-&gt;resources[idx].exchange(values[i]);\n}\n}\n\nResourcePool(std::vector&lt;std::pair&lt;Resource, V&gt;&gt; &amp;resource_list) {\nfor (auto i = 0; i &lt; resource_list.size(); i++) {\nconst int idx = static_cast&lt;int&gt;(resource_list[i].first);\nthis-&gt;resources[idx].exchange(resource_list[i].second);\n}\n}\n\nResourcePool(const ResourcePool &amp;other) {\nfor (auto i = 0; i &lt; resource_names.size(); i++) {\nthis-&gt;resources[i].exchange(other.resources[i].load());\n}\n}\n\ninline const V set(Resource resource, V value) {\nconst int idx = static_cast&lt;int&gt;(resource);\nreturn this-&gt;resources[idx].exchange(static_cast&lt;V&gt;(value));\n};\n\ninline const V get(Resource resource) const {\nconst int idx = static_cast&lt;int&gt;(resource);\nreturn this-&gt;resources[idx].load();\n};\n\ntemplate &lt;ResourceCategory category&gt;\ninline const bool check_greater(const ResourcePool &amp;other) const {\nif constexpr (category == ResourceCategory::All) {\nfor (auto i = 0; i &lt; resource_names.size(); i++) {\nif (this-&gt;resources[i].load() &lt; other.resources[i].load()) {\nreturn false;\n}\n}\nreturn true;\n} else if constexpr (category == ResourceCategory::Persistent) {\nfor (auto i = 0; i &lt; persistent_resources.size(); i++) {\nconst int idx = static_cast&lt;int&gt;(persistent_resources[i]);\nif (this-&gt;resources[idx].load() &lt; other.resources[idx].load()) {\nreturn false;\n}\n}\nreturn true;\n} else if constexpr (category == ResourceCategory::NonPersistent) {\nfor (auto i = 0; i &lt; non_persistent_resources.size(); i++) {\nconst int idx = static_cast&lt;int&gt;(non_persistent_resources[i]);\nif (this-&gt;resources[idx].load() &lt; other.resources[idx].load()) {\nreturn false;\n}\n}\nreturn true;\n} else if constexpr (category == ResourceCategory::Movement) {\nfor (auto i = 0; i &lt; movement_resources.size(); i++) {\nconst int idx = static_cast&lt;int&gt;(movement_resources[i]);\nif (this-&gt;resources[idx].load() &lt; other.resources[idx].load()) {\nreturn false;\n}\n}\nreturn true;\n}\n};\n\ntemplate &lt;ResourceCategory category&gt;\ninline const bool check_lesser(const ResourcePool &amp;other) const {\nif constexpr (category == ResourceCategory::All) {\nfor (auto i = 0; i &gt; resource_names.size(); i++) {\nif (this-&gt;resources[i].load() &lt;= other.resources[i].load()) {\nreturn false;\n}\n}\nreturn true;\n} else if constexpr (category == ResourceCategory::Persistent) {\nfor (auto i = 0; i &gt; persistent_resources.size(); i++) {\nconst int idx = static_cast&lt;int&gt;(persistent_resources[i]);\nif (this-&gt;resources[idx].load() &lt;= other.resources[idx].load()) {\nreturn false;\n}\n}\nreturn true;\n} else if constexpr (category == ResourceCategory::NonPersistent) {\nfor (auto i = 0; i &gt; non_persistent_resources.size(); i++) {\nconst int idx = static_cast&lt;int&gt;(non_persistent_resources[i]);\nif (this-&gt;resources[idx].load() &lt;= other.resources[idx].load()) {\nreturn false;\n}\n}\nreturn true;\n} else if constexpr (category == ResourceCategory::Movement) {\nfor (auto i = 0; i &gt; movement_resources.size(); i++) {\nconst int idx = static_cast&lt;int&gt;(movement_resources[i]);\nif (this-&gt;resources[idx].load() &lt;= other.resources[idx].load()) {\nreturn false;\n}\n}\nreturn true;\n}\n};\n\ntemplate &lt;ResourceCategory category&gt;\ninline void increase(const ResourcePool &amp;other) {\nif constexpr (category == ResourceCategory::All) {\nfor (auto i = 0; i &lt; resource_names.size(); i++) {\nthis-&gt;resources[i].fetch_add(other.resources[i].load());\n}\n} else if constexpr (category == ResourceCategory::Persistent) {\nfor (auto i = 0; i &lt; persistent_resources.size(); i++) {\nconst int idx = static_cast&lt;int&gt;(persistent_resources[i]);\nthis-&gt;resources[idx].fetch_add(other.resources[idx].load());\n}\n} else if constexpr (category == ResourceCategory::NonPersistent) {\nfor (auto i = 0; i &lt; non_persistent_resources.size(); i++) {\nconst int idx = static_cast&lt;int&gt;(non_persistent_resources[i]);\nthis-&gt;resources[idx].fetch_add(other.resources[idx].load());\n}\n} else if constexpr (category == ResourceCategory::Movement) {\nfor (auto i = 0; i &lt; movement_resources.size(); i++) {\nconst int idx = static_cast&lt;int&gt;(movement_resources[i]);\nthis-&gt;resources[idx].fetch_add(other.resources[idx].load());\n}\n}\n};\n\ntemplate &lt;ResourceCategory category&gt;\ninline void decrease(const ResourcePool &amp;other) {\nif constexpr (category == ResourceCategory::All) {\nfor (auto i = 0; i &lt; resource_names.size(); i++) {\nthis-&gt;resources[i].fetch_sub(other.resources[i].load());\n}\n} else if constexpr (category == ResourceCategory::Persistent) {\nfor (auto i = 0; i &lt; persistent_resources.size(); i++) {\nconst int idx = static_cast&lt;int&gt;(persistent_resources[i]);\nthis-&gt;resources[idx].fetch_sub(other.resources[idx].load());\n}\n} else if constexpr (category == ResourceCategory::NonPersistent) {\nfor (auto i = 0; i &lt; non_persistent_resources.size(); i++) {\nconst int idx = static_cast&lt;int&gt;(non_persistent_resources[i]);\nthis-&gt;resources[idx].fetch_sub(other.resources[idx].load());\n}\n} else if constexpr (category == ResourceCategory::Movement) {\nfor (auto i = 0; i &lt; movement_resources.size(); i++) {\nconst int idx = static_cast&lt;int&gt;(movement_resources[i]);\nthis-&gt;resources[idx].fetch_sub(other.resources[idx].load());\n}\n}\n};\n\nprotected:\nstd::array&lt;std::atomic&lt;V&gt;, resource_names.size()&gt; resources = {0, 0, 0};\n};\n\n#endif // RESOURCES_HPP\n</code></pre>"},{"location":"runtime/runtime_8hpp/","title":"File runtime.hpp","text":"<p>FileList &gt; backend &gt; include &gt; runtime.hpp</p> <p>Go to the source code of this file.</p> <p>The core C++ runtime for Parla. Includes the main scheduler and task classes. </p> <ul> <li><code>#include \"resources.hpp\"</code></li> <li><code>#include &lt;assert.h&gt;</code></li> <li><code>#include &lt;atomic&gt;</code></li> <li><code>#include &lt;chrono&gt;</code></li> <li><code>#include &lt;condition_variable&gt;</code></li> <li><code>#include &lt;cstdint&gt;</code></li> <li><code>#include &lt;exception&gt;</code></li> <li><code>#include &lt;fstream&gt;</code></li> <li><code>#include &lt;string&gt;</code></li> <li><code>#include &lt;thread&gt;</code></li> <li><code>#include &lt;unordered_map&gt;</code></li> <li><code>#include &lt;utility&gt;</code></li> <li><code>#include \"containers.hpp\"</code></li> <li><code>#include \"device_manager.hpp\"</code></li> <li><code>#include \"gpu_utility.hpp\"</code></li> <li><code>#include \"parray.hpp\"</code></li> <li><code>#include \"parray_tracker.hpp\"</code></li> <li><code>#include \"profiling.hpp\"</code></li> <li><code>#include \"resource_requirements.hpp\"</code></li> </ul>"},{"location":"runtime/runtime_8hpp/#namespaces","title":"Namespaces","text":"Type Name namespace Scheduler namespace Task namespace chrono_literals"},{"location":"runtime/runtime_8hpp/#classes","title":"Classes","text":"Type Name class InnerDataTask class InnerScheduler The C++ \"Mirror\" of Parla's Python Scheduler This class is used to create a C++ representation of a Parla Scheduler All scheduling logic should be handled by these after creation until launched by the Python callback. class InnerTask The C++ \"Mirror\" of Parla's Python Tasks This class is used to create a C++ representation of a Parla Task All scheduling logic should be handled by these after creation until launched by the Python callback. class InnerTaskSpace class InnerWorker The C++ \"Mirror\" of Parla's Python Workers This class is used to create a C++ representation of a Parla Worker All scheduling logic should be handled by these after creation until launched by the Python callback. class Status class StatusFlags class TaskBarrier The C++ \"Mirror\" of Parla's Python TaskSets &amp; Spaces They are used as barriers for the calling thread for the completion of their members. class WorkerPool &lt;typename AllWorkers_t, typename ActiveWorkers_t&gt;"},{"location":"runtime/runtime_8hpp/#public-types","title":"Public Types","text":"Type Name enum AccessMode typedef ProtectedVector&lt; uintptr_t &gt; PointerList typedef ProtectedVector&lt; TaskBarrier * &gt; SpaceList typedef ProtectedVector&lt; InnerTask * &gt; TaskList typedef ProtectedQueue&lt; InnerTask * &gt; TaskQueue typedef std::pair&lt; InnerTask *, Task::StatusFlags &gt; TaskState typedef std::vector&lt; TaskState &gt; TaskStateList typedef ProtectedVector&lt; InnerWorker * &gt; WorkerList typedef WorkerPool&lt; WorkerQueue, WorkerQueue &gt; WorkerPool_t typedef ProtectedQueue&lt; InnerWorker * &gt; WorkerQueue typedef void(* launchfunc_t typedef void(* stopfunc_t"},{"location":"runtime/runtime_8hpp/#public-functions","title":"Public Functions","text":"Type Name void launch_stop_callback (stopfunc_t func, void * scheduler)  void launch_task_callback (launchfunc_t func, void * scheduler, void * task, void * worker)"},{"location":"runtime/runtime_8hpp/#macros","title":"Macros","text":"Type Name define PARLA_BACKEND_HPP"},{"location":"runtime/runtime_8hpp/#public-types-documentation","title":"Public Types Documentation","text":""},{"location":"runtime/runtime_8hpp/#enum-accessmode","title":"enum AccessMode","text":"<pre><code>enum AccessMode {\nIN = 0,\nOUT = 1,\nINOUT = 2\n};\n</code></pre>"},{"location":"runtime/runtime_8hpp/#typedef-pointerlist","title":"typedef PointerList","text":"<pre><code>using PointerList =  ProtectedVector&lt;uintptr_t&gt;;\n</code></pre>"},{"location":"runtime/runtime_8hpp/#typedef-spacelist","title":"typedef SpaceList","text":"<pre><code>using SpaceList =  ProtectedVector&lt;TaskBarrier *&gt;;\n</code></pre>"},{"location":"runtime/runtime_8hpp/#typedef-tasklist","title":"typedef TaskList","text":"<pre><code>using TaskList =  ProtectedVector&lt;InnerTask *&gt;;\n</code></pre>"},{"location":"runtime/runtime_8hpp/#typedef-taskqueue","title":"typedef TaskQueue","text":"<pre><code>using TaskQueue =  ProtectedQueue&lt;InnerTask *&gt;;\n</code></pre>"},{"location":"runtime/runtime_8hpp/#typedef-taskstate","title":"typedef TaskState","text":"<pre><code>using TaskState =  std::pair&lt;InnerTask *, Task::StatusFlags&gt;;\n</code></pre>"},{"location":"runtime/runtime_8hpp/#typedef-taskstatelist","title":"typedef TaskStateList","text":"<pre><code>using TaskStateList =  std::vector&lt;TaskState&gt;;\n</code></pre>"},{"location":"runtime/runtime_8hpp/#typedef-workerlist","title":"typedef WorkerList","text":"<pre><code>using WorkerList =  ProtectedVector&lt;InnerWorker *&gt;;\n</code></pre>"},{"location":"runtime/runtime_8hpp/#typedef-workerpool_t","title":"typedef WorkerPool_t","text":"<pre><code>typedef WorkerPool&lt;WorkerQueue, WorkerQueue&gt; WorkerPool_t;\n</code></pre>"},{"location":"runtime/runtime_8hpp/#typedef-workerqueue","title":"typedef WorkerQueue","text":"<pre><code>using WorkerQueue =  ProtectedQueue&lt;InnerWorker *&gt;;\n</code></pre>"},{"location":"runtime/runtime_8hpp/#typedef-launchfunc_t","title":"typedef launchfunc_t","text":"<pre><code>typedef void(* launchfunc_t) (void *scheduler, void *task, void *worker);\n</code></pre>"},{"location":"runtime/runtime_8hpp/#typedef-stopfunc_t","title":"typedef stopfunc_t","text":"<pre><code>typedef void(* stopfunc_t) (void *scheduler);\n</code></pre>"},{"location":"runtime/runtime_8hpp/#public-functions-documentation","title":"Public Functions Documentation","text":""},{"location":"runtime/runtime_8hpp/#function-launch_stop_callback","title":"function launch_stop_callback","text":"<pre><code>inline void launch_stop_callback (\nstopfunc_t func,\nvoid * scheduler\n) </code></pre>"},{"location":"runtime/runtime_8hpp/#function-launch_task_callback","title":"function launch_task_callback","text":"<pre><code>inline void launch_task_callback (\nlaunchfunc_t func,\nvoid * scheduler,\nvoid * task,\nvoid * worker\n) </code></pre>"},{"location":"runtime/runtime_8hpp/#macro-definition-documentation","title":"Macro Definition Documentation","text":""},{"location":"runtime/runtime_8hpp/#define-parla_backend_hpp","title":"define PARLA_BACKEND_HPP","text":"<pre><code>#define PARLA_BACKEND_HPP \n</code></pre> <p>The documentation for this class was generated from the following file <code>src/c/backend/include/runtime.hpp</code></p>"},{"location":"runtime/runtime_8hpp_source/","title":"File runtime.hpp","text":"<p>File List &gt; backend &gt; include &gt; runtime.hpp</p> <p>Go to the documentation of this file. </p> <pre><code>#pragma once\n#ifndef PARLA_BACKEND_HPP\n#define PARLA_BACKEND_HPP\n\n#include \"resources.hpp\"\n#include &lt;assert.h&gt;\n#include &lt;atomic&gt;\n#include &lt;chrono&gt;\n#include &lt;condition_variable&gt;\n#include &lt;cstdint&gt;\n#include &lt;exception&gt;\n#include &lt;fstream&gt;\n#include &lt;string&gt;\n#include &lt;thread&gt;\n#include &lt;unordered_map&gt;\n#include &lt;utility&gt;\n\nusing namespace std::chrono_literals;\n\n#include \"containers.hpp\"\n\n#include \"device_manager.hpp\"\n#include \"gpu_utility.hpp\"\n#include \"parray.hpp\"\n#include \"parray_tracker.hpp\"\n#include \"profiling.hpp\"\n#include \"resource_requirements.hpp\"\n\n// General Note. A LOT of these atomics could just be declared as volatile.\n\n// Forward Declarations of Inner Classes\nclass InnerTask;\nclass TaskBarrier;\nclass InnerWorker;\nclass InnerScheduler;\n\n// Type Aliases for common containers\n\nusing WorkerQueue = ProtectedQueue&lt;InnerWorker *&gt;;\nusing WorkerList = ProtectedVector&lt;InnerWorker *&gt;;\n\nusing TaskQueue = ProtectedQueue&lt;InnerTask *&gt;;\nusing TaskList = ProtectedVector&lt;InnerTask *&gt;;\n\nusing SpaceList = ProtectedVector&lt;TaskBarrier *&gt;;\n\nusing PointerList = ProtectedVector&lt;uintptr_t&gt;;\n\n/* Access mode to a PArray. */\nenum AccessMode {\n// Input of a task.\nIN = 0,\n// Output of a task.\nOUT = 1,\n// Input/output of a task.\nINOUT = 2\n};\n\n// Forward declaration of python callbacks\n\n/* Python function to assign a task to a worker */\ntypedef void (*launchfunc_t)(void *scheduler, void *task, void *worker);\n\n/* Python function to stop the scheduler */\ntypedef void (*stopfunc_t)(void *scheduler);\n\n// Callback Launchers\n\n/* C++ -&gt; Cython callback to launch a single task */\ninline void launch_task_callback(launchfunc_t func, void *scheduler, void *task,\nvoid *worker) {\nfunc(scheduler, task, worker);\n}\n\n/* C*+ -&gt; Cython callback to stop the main scheduler. Called at runtime exit. */\ninline void launch_stop_callback(stopfunc_t func, void *scheduler) {\nfunc(scheduler);\n}\n\nnamespace Task {\n\n/*State of the task. Shows which part of the runtime the task is in.*/\nenum State {\n// Initial State. Task has been created but not spawned\nCREATED = 0,\n// Task has been spawned\nSPAWNED = 1,\n// Task has been mapped\nMAPPED = 2,\n// Task has persistent resources reserved\nRESERVED = 3,\n// Task is ready to run\nREADY = 4,\n// Task is currently running and has runtime resources reserved\nRUNNING = 5,\n// Task body has completed but GPU kernels may be asynchronously running\nRUNAHEAD = 6,\n// Task has completed\nCOMPLETED = 7\n};\n\nenum SynchronizationType {\n// No synchronization\nNONE = 0,\n// BLocking synchronization\nBLOCKING = 1,\n// Non-blocking synchronization\nNON_BLOCKING = 2,\n// User defined synchronization\nUSER = 3\n};\n\nclass StatusFlags {\npublic:\nbool spawnable{false};\nbool mappable{false};\nbool reservable{false};\nbool compute_runnable{false};\nbool runnable{false};\n\nStatusFlags() = default;\n\nStatusFlags(bool spawnable, bool mappable, bool reservable,\nbool compute_runnable, bool runnable)\n: spawnable(spawnable), mappable(mappable), reservable(reservable),\ncompute_runnable(compute_runnable), runnable(runnable) {}\n\nbool any() {\nreturn spawnable || mappable || reservable || compute_runnable || runnable;\n}\n};\n\n/* Properties of the tasks dependencies */\nenum Status {\n// Initial State. Status of dependencies is unknown or not spawned\nINITIAL = 0,\n// All dependencies are spawned (this task can be safely spawned)\nSPAWNABLE = 1,\n// All dependencies are mapped (this task can be safely mapped)\nMAPPABLE = 2,\n// All dependencies have persistent resources reserved (this task can be\n// safely reserved)\nRESERVABLE = 3,\n// All compute dependencies have RUNAHEAD/COMPLETED status\nCOMPUTE_RUNNABLE = 4,\n// All (including data) dependencies have RUNAHEAD/COMPLETED status\nRUNNABLE = 5\n};\n\n} // namespace Task\n\n#ifdef PARLA_ENABLE_LOGGING\nBINLOG_ADAPT_STRUCT(Task::StatusFlags, spawnable, mappable, reservable,\ncompute_runnable, runnable)\nBINLOG_ADAPT_ENUM(Task::State, CREATED, SPAWNED, MAPPED, RESERVED, READY,\nRUNNING, RUNAHEAD, COMPLETED)\nBINLOG_ADAPT_ENUM(Task::Status, INITIAL, SPAWNABLE, MAPPABLE, RESERVABLE,\nCOMPUTE_RUNNABLE, RUNNABLE)\n#endif\n\nusing TaskState = std::pair&lt;InnerTask *, Task::StatusFlags&gt;;\nusing TaskStateList = std::vector&lt;TaskState&gt;;\n\nclass InnerTask {\n\n// TODO(hc): those member vars should be protected.\npublic:\n/* Unique ID of the task. Can be used as a dictionary key.*/\nlong long int id = 0;\n\n/*Name of the task. Useful for logging and printing.*/\nstd::string name = \"\";\n\n/*Instance count of the task (Number of continuations of this task)*/\nint instance = 0;\n\n/* State of the task (where is this task)*/\nstd::atomic&lt;Task::State&gt; state{Task::CREATED};\n\n/* Status of the task (state of its dependencies)*/\nstd::atomic&lt;Task::Status&gt; status{Task::INITIAL};\n\n/* Reference to the scheduler (used for synchronizing state on events) */\nInnerScheduler *scheduler = nullptr;\n\n/*Container for Events*/\nPointerList events;\n\n/*Synchronization Type */\nTask::SynchronizationType sync_type = Task::NON_BLOCKING;\n\n/*Container for Streams*/\nPointerList streams;\n\n/*Task monitor*/\nstd::mutex mtx;\n\n/* Priority of the task. Higher priority tasks are scheduled first. */\nstd::atomic&lt;int&gt; priority{0};\n\n/* The pointer to the Python Task which contains the class body */\nvoid *py_task = nullptr; // TODO: Refactor to PyObject type?\n\n/* Container of Task Dependencies (should be thread-safe)*/\nTaskList dependencies;\n\n/* Container of Task Dependents (should be thread-safe)*/\nTaskList dependents;\n\n/* Container of Task Spaces */\nSpaceList spaces;\n\n/*Local depdendency buffer*/\nstd::vector&lt;InnerTask *&gt; dependency_buffer = std::vector&lt;InnerTask *&gt;();\n\n/* Number of blocking (uncompleted) compute task dependencies */\nstd::atomic&lt;int&gt; num_blocking_compute_dependencies{1};\n\n/* Number of  blocking (uncompleted) task (compute+data) dependencies */\nstd::atomic&lt;int&gt; num_blocking_dependencies{1};\n\n/* Number of unspawned dependencies */\nstd::atomic&lt;int&gt; num_unspawned_dependencies{1};\n\n/* Number of unmapped dependencies */\nstd::atomic&lt;int&gt; num_unmapped_dependencies{1};\n\n/* Number of unreserved dependencies */\nstd::atomic&lt;int&gt; num_unreserved_dependencies{1};\n\n/*Number of unreserved instances (for multidevice) */\nstd::atomic&lt;int&gt; num_persistant_instances{1};\nbool removed_reserved{false};\n\n/* Number of waiting instances (for multidevice) */\nstd::atomic&lt;int&gt; num_runtime_instances{1};\nbool removed_runtime{false};\n\n/* Task Assigned Device Set*/\nstd::vector&lt;Device *&gt; assigned_devices;\n\n/*Resource Requirements for each assigned device*/\nstd::unordered_map&lt;int, ResourcePool_t&gt; device_constraints;\n\n/* Task is data movement task */\nstd::atomic&lt;bool&gt; is_data{false};\n\n/* Task has processed data into data tasks (if any exists). Defaults to true\n   * if none exist. */\nstd::atomic&lt;bool&gt; processed_data{true};\n\n/* A list of a pair of PArray instances and access modes to them.\n     The first dimension index is for a device id specified in @spawn.\n     The second index space is for PArrays. */\nstd::vector&lt;std::vector&lt;std::pair&lt;parray::InnerPArray *, AccessMode&gt;&gt;&gt;\nparray_list;\n\nInnerTask();\nInnerTask(long long int id, void *py_task);\nInnerTask(std::string name, long long int id, void *py_task);\n\n/* Set the scheduler */\nvoid set_scheduler(InnerScheduler *scheduler);\n\n/* Set the name of the task */\nvoid set_name(std::string name);\n\n/* Get the name of the task */\nconst std::string &amp;get_name() const { return this-&gt;name; };\n\n/* Set the id of the task */\nvoid set_id(long long int name);\n\n/* Set the python task */\nvoid set_py_task(void *py_task);\n\n/* Set the priority of the task */\nvoid set_priority(int priority);\n\n/* Add a dependency to the task buffer but don't process it*/\nvoid queue_dependency(InnerTask *task);\n\n/* Add a list of dependencies to the task. For external use.*/\nTask::StatusFlags process_dependencies();\n\n/* Clear the dependency list */\nvoid clear_dependencies();\n\n/* Add a dependency to the task and process it*/\nTask::State add_dependency(InnerTask *task);\n\n/* Add a list of dependencies to the task and process them. For external\n   * use.*/\nTask::StatusFlags add_dependencies(std::vector&lt;InnerTask *&gt; &amp;tasks,\nbool data_tasks = false);\n\n/* Add a dependent to the task */\nTask::State add_dependent_task(InnerTask *task);\nTask::State add_dependent_space(TaskBarrier *barrier);\n\n/* Add a list of dependents to the task */\n// void add_dependents(std::vector&lt;bool&gt; result, std::vector&lt;InnerTask*&gt;&amp;\n// tasks);\n\n/*\n   * Add a PArray to the task\n   *\n   * @param parray Pointer to a PArray that this task use\n   * @param access_mode Access mode TODO(hc): This type is int and\n   *                                          it is immediately casted to\n   *                                          an enum type. This function\n   *                                          is called by Python through\n   * Cython, but C++ enum and Python enum or int are not compatible. So, for\n   * conveniency, I just pass int between Python and C++.\n   */\nvoid add_parray(parray::InnerPArray *parray, int access_mode, int dev_id);\n\n/*\n   *  Notify dependents that dependencies have completed\n   *  This should be called by the worker when a task has completed\n   *  Returns a container of tasks that are now ready to run\n   *  TODO: Decide on a container to use for this\n   */\nvoid notify_dependents(TaskStateList &amp;tasks, Task::State new_state);\nvoid notify_dependents_completed();\n\n/* Wrapper for testing */\nbool notify_dependents_wrapper();\n\n/* Notify the task that one of its dependents has completed\n   *  Decrements the number of blocking dependencies.\n   *  Return true if 0 blocking dependencies remain.\n   *  Used by \"notify_dependents\"\n   */\nTask::StatusFlags notify(Task::State dependency_state, bool is_data = false);\n\n/* Reset state and increment all internal counters. Used by continuation */\nvoid reset() {\n// TODO(wlr): Should this be done with set_state and assert old==RUNNING?\nthis-&gt;state.store(Task::SPAWNED);\nthis-&gt;status.store(Task::INITIAL);\nthis-&gt;instance++;\nthis-&gt;num_blocking_compute_dependencies.store(1);\nthis-&gt;num_blocking_dependencies.store(1);\nthis-&gt;num_unspawned_dependencies.store(1);\nthis-&gt;num_unmapped_dependencies.store(1);\nthis-&gt;num_unreserved_dependencies.store(1);\nthis-&gt;assigned_devices.clear();\n// this-&gt;reset_events_streams();\n}\n\n/* Return whether the task is ready to run */\nbool blocked();\n\n/* Get a task name */\nstd::string get_name();\n\n/* Get number of dependencies */\nint get_num_dependencies();\n\n/* Get number of dependents */\nint get_num_dependents();\n\n/* Get number of blocking dependencies */\ninline int get_num_blocking_dependencies() const {\nreturn this-&gt;num_blocking_dependencies.load();\n};\n\ninline int get_num_unmapped_dependencies() const {\nreturn this-&gt;num_unmapped_dependencies.load();\n};\n\ntemplate &lt;ResourceCategory category&gt; inline void set_num_instances() {\nif constexpr (category == ResourceCategory::Persistent) {\nthis-&gt;num_persistant_instances.store(this-&gt;assigned_devices.size());\n} else {\nthis-&gt;num_runtime_instances.store(this-&gt;assigned_devices.size());\n}\n};\n\ntemplate &lt;ResourceCategory category&gt; inline int decrement_num_instances() {\nif constexpr (category == ResourceCategory::Persistent) {\nreturn this-&gt;num_persistant_instances.fetch_sub(1);\n} else {\nreturn this-&gt;num_runtime_instances.fetch_sub(1);\n}\n};\n\ntemplate &lt;ResourceCategory category&gt; inline int get_num_instances() {\nif constexpr (category == ResourceCategory::Persistent) {\nreturn this-&gt;num_persistant_instances.load();\n} else {\nreturn this-&gt;num_runtime_instances.load();\n}\n};\n\ntemplate &lt;ResourceCategory category&gt; inline bool get_removed() {\nif constexpr (category == ResourceCategory::Persistent) {\nreturn this-&gt;removed_reserved;\n} else {\nreturn this-&gt;removed_runtime;\n}\n}\n\ntemplate &lt;ResourceCategory category&gt; inline void set_removed(bool waiting) {\nif constexpr (category == ResourceCategory::Persistent) {\nthis-&gt;removed_reserved = waiting;\n} else {\nthis-&gt;removed_runtime = waiting;\n}\n}\n\n/* Get dependency list. Used for testing Python interface. */\nstd::vector&lt;void *&gt; get_dependencies();\n\n/* Get dependents list. Used for testing Python interface. */\nstd::vector&lt;void *&gt; get_dependents();\n\n/*Add event to task*/\nvoid add_event(uintptr_t event) { this-&gt;events.push_back(event); }\n\n/*Add stream to task */\nvoid add_stream(uintptr_t stream) { this-&gt;streams.push_back(stream); };\n\n/* Reset events and streams */\nvoid reset_events_streams() {\nthis-&gt;events.clear();\nthis-&gt;streams.clear();\n}\n\n/* Synchronize self */\nvoid synchronize_events() {\nsize_t num_events = this-&gt;events.size_unsafe();\nfor (size_t i = 0; i &lt; num_events; i++) {\nuintptr_t event_ptr = this-&gt;events.at_unsafe(i);\nevent_synchronize(event_ptr);\n}\n}\n\n/*handle_runahead_dependencies*/\nvoid handle_runahead_dependencies(int sync_type) {\nif (sync_type == Task::BLOCKING) {\nthis-&gt;synchronize_dependency_events();\n} else if (sync_type == Task::NON_BLOCKING) {\nthis-&gt;wait_dependency_events();\n}\n}\n\n/*Synchronize dependencies*/\nvoid synchronize_dependency_events() {\nsize_t num_dependencies = this-&gt;dependencies.size_unsafe();\nfor (size_t i = 0; i &lt; num_dependencies; i++) {\nInnerTask *dependency = this-&gt;dependencies.at_unsafe(i);\ndependency-&gt;synchronize_events();\n}\n}\n\n/*Wait dependencies*/\n// TODO(wlr): This locking is overkill. Some of these aren't even necessary.\n// Comment(wlr): Removing all locks. By the time this executes all\n// dependencies will have ran their task bodies (can assume no more\n// modifications)\nvoid wait_dependency_events() {\n\nstd::cout &lt;&lt; \"Setting wait triggers for dependencies of \"\n&lt;&lt; this-&gt;get_name() &lt;&lt; std::endl;\n\n// For each dependency, wait on all of its events on all of our streams\nsize_t num_dependencies = this-&gt;dependencies.size_unsafe();\nfor (size_t i = 0; i &lt; num_dependencies; i++) {\nInnerTask *dependency = this-&gt;dependencies.at_unsafe(i);\nauto &amp;dependency_events = dependency-&gt;events;\n\nstd::cout &lt;&lt; \"Waiting for event from dependency: \"\n&lt;&lt; dependency-&gt;get_name() &lt;&lt; std::endl;\nsize_t num_events = dependency_events.size_unsafe();\nfor (size_t j = 0; j &lt; num_events; j++) {\nuintptr_t event_ptr = dependency_events.at_unsafe(j);\n// Wait on the event on all of our streams\nsize_t num_streams = this-&gt;streams.size_unsafe();\nfor (size_t k = 0; k &lt; num_streams; k++) {\nuintptr_t stream_ptr = this-&gt;streams.at_unsafe(k);\nevent_wait(event_ptr, stream_ptr);\n}\n}\n}\n}\n\n/* Get python task */\nvoid *get_py_task();\n\n/* Get the python assigned devices */\nstd::vector&lt;Device *&gt; &amp;get_assigned_devices();\n\n/*Add to the assigned device list*/\nvoid add_assigned_device(Device *device);\n\n/*\n   * Copy a vector of device pointers\n   *\n   * @param others Source vector of device pointers to copy\n   */\nvoid copy_assigned_devices(const std::vector&lt;Device *&gt; &amp;others);\n\n/* Set the task status */\nint set_state(int state);\n\n/* Set the task state */\nTask::State set_state(Task::State state);\n\n/* Get the task state */\nTask::State get_state() const {\nconst Task::State state = this-&gt;state.load();\nreturn state;\n}\n\n/*Set the task status */\nTask::Status set_status(Task::Status status);\n\n/*Determine status from parts*/\n// TODO(wlr): this should be private\nTask::Status determine_status(bool spawnable, bool mappable, bool reservable,\nbool ready);\n\n/*Get the task status*/\nTask::Status get_status() const {\nconst Task::Status status = this-&gt;status.load();\nreturn status;\n}\n\n/* Set complete */\nvoid set_complete();\n\n/* Get complete */\nbool get_complete();\n\nvoid add_device_req(Device *dev_ptr, MemorySz_t mem_sz, VCU_t num_vcus);\nvoid begin_arch_req_addition();\nvoid end_arch_req_addition();\nvoid begin_multidev_req_addition();\nvoid end_multidev_req_addition();\n\nPlacementRequirementCollections &amp;get_placement_req_options() {\nreturn placement_req_options_;\n}\n\n/* Return True if an instance is a data movement task */\nbool is_data_task();\n\nprotected:\n/*\n   *  1 &lt;--&gt; 3 (MultiDevAdd, normally SingleDevAdd) &lt;--&gt; 2*2 (SingleArchAdd)\n   *  1 &lt;--&gt; 2 (SingleArchAdd)\n   */\nenum ReqAdditionState {\nSingleDevAdd = 1,\n/* SingleArchAdd == 2, */\nMultiDevAdd = 3\n};\nuint32_t req_addition_mode_;\nstd::shared_ptr&lt;ArchitectureRequirement&gt; tmp_arch_req_;\nstd::shared_ptr&lt;MultiDeviceRequirements&gt; tmp_multdev_reqs_;\n// TODO(hc): rename these..\nPlacementRequirementCollections placement_req_options_;\n};\n\nclass InnerDataTask : public InnerTask {\npublic:\nInnerDataTask() = delete;\n// TODO(hc): this id is not unique (In case of compute task,\n//           The Python runtime maintains the unique id and assigns it.\n//           but this data move task is created in C++ and we cannot\n//           immediately assign the unique id. We may need another function\n//           call from Python t C++ when we create Python data move task\n//           later. The current id for all the data move tasks is 0.\nInnerDataTask(std::string name, long long int id, parray::InnerPArray *parray,\nAccessMode access_mode, int dev_id)\n: parray_(parray), access_mode_(access_mode), dev_id_(dev_id),\nInnerTask(name, id, nullptr) {\nthis-&gt;is_data = true;\n// Data tasks are created after persistent resource reservation.\n// Therefore its start state is always RESERVED.\nthis-&gt;set_state(Task::RESERVED);\n}\n\nvoid *get_py_parray();\n\nAccessMode get_access_mode();\n\n// TODO(hc): will be removed\nint get_device_id() { return this-&gt;dev_id_; }\n\nprivate:\nparray::InnerPArray *parray_;\nAccessMode access_mode_;\nint dev_id_;\n};\n\n#ifdef PARLA_ENABLE_LOGGING\nLOG_ADAPT_STRUCT(InnerTask, name, instance, get_state, get_status)\nLOG_ADAPT_DERIVED(InnerDataTask, (InnerTask))\n#endif\n\nclass TaskBarrier {\n// TODO: As is, this is not resuable.\n\n// TODO: This assumes the Python holder of the TaskBarrier will not be deleted\n// before all of its tasks are completed. Add backlinks for cleanup?\n\npublic:\nstd::mutex mtx;\nstd::condition_variable cv;\nint64_t id;\n\nstd::atomic&lt;int&gt; num_incomplete_tasks{0};\n\nTaskBarrier() = default;\n\nTaskBarrier(int num_tasks) : num_incomplete_tasks(num_tasks) {}\n\nTask::State _add_task(InnerTask *task);\nvoid add_task(InnerTask *task);\nvoid add_tasks(std::vector&lt;InnerTask *&gt; &amp;tasks);\nvoid set_id(int64_t id) { this-&gt;id = id; }\n\nvoid wait() {\n// std::cout &lt;&lt; \"Barrier Wait\" &lt;&lt; std::endl;\nstd::unique_lock&lt;std::mutex&gt; lck(mtx);\ncv.wait(lck, [this] { return num_incomplete_tasks == 0; });\n}\n\nvoid notify() {\nstd::unique_lock&lt;std::mutex&gt; lck(mtx);\nint prev = this-&gt;num_incomplete_tasks.fetch_sub(1);\nif (prev == 1) {\ncv.notify_all();\n}\n}\n};\n\nclass InnerTaskSpace : public TaskBarrier {\n\npublic:\nInnerTaskSpace() = default;\n\nstd::unordered_map&lt;int64_t, InnerTask *&gt; task_map;\n\nvoid add_task(int64_t key, InnerTask *task) {\ntask_map.insert({key, task});\nTaskBarrier::add_task(task);\n}\n\nvoid add_tasks(std::vector&lt;int64_t&gt; &amp;keys, std::vector&lt;InnerTask *&gt; &amp;tasks) {\nfor (int i = 0; i &lt; keys.size(); i++) {\ntask_map.insert({keys[i], tasks[i]});\n}\nTaskBarrier::add_tasks(tasks);\n}\n\nvoid get_tasks(std::vector&lt;int64_t&gt; &amp;keys, std::vector&lt;InnerTask *&gt; &amp;tasks) {\nfor (int i = 0; i &lt; keys.size(); i++) {\ntasks.push_back(task_map[keys[i]]);\n}\n}\n\nvoid wait() { TaskBarrier::wait(); }\n\nvoid notify() { TaskBarrier::notify(); }\n};\n\nclass InnerWorker {\n\npublic:\n/* Pointer to Python Worker object */\nvoid *py_worker = nullptr;\n\n/* Pointer to the active task */\n// void* py_task = nullptr;\nInnerTask *task = nullptr;\n\nInnerScheduler *scheduler = nullptr;\n\nstd::mutex mtx;\nstd::condition_variable cv;\nbool ready = false;\nbool notified = false;\n\nint thread_idx = -1;\n\n/* Task Buffer (for enqueing new ready tasks at task cleanup ) */\nTaskStateList enqueue_buffer;\n\n// TODO: (improvement?) Custom Barrier and Event Handling\n\n// TODO: (improvement?) A buffer for multiple tasks assigned to a worker\n\nInnerWorker() = default;\nInnerWorker(void *worker) : py_worker(worker){};\n\n/* Set the Python Worker */\nvoid set_py_worker(void *worker) { this-&gt;py_worker = worker; };\n\n/*Set the scheduler*/\nvoid set_scheduler(InnerScheduler *scheduler) {\nthis-&gt;scheduler = scheduler;\n};\n\n/* Set the thread idx */\nvoid set_thread_idx(int idx) { this-&gt;thread_idx = idx; };\n\n/* Wait for a task to be assigned */\nvoid wait();\n\n/* Assign a task to the worker and notify worker that it is available*/\nvoid assign_task(InnerTask *task);\n\n/*\n   * Get a C++ task instance that this worker thread will execute.\n   * This function returns two outputs, a pointer to a task pointer and\n   * a pointer to a flag specifying if this task is data task or not.\n   * If that is the data task, the callee creates a Python data task instance\n   * and makes a connection between the Python and the C++ instances.\n   *\n   * @param task A pointer to a pointer to a task (output)\n   * @param is_data_task A pointer to a flag that sets True if the task is data\n   * task.\n   */\nvoid get_task(InnerTask **task, bool *is_data_task);\n\n/* Remove task */\nvoid remove_task();\n\nvoid stop();\n};\n\n#ifdef PARLA_ENABLE_LOGGING\nLOG_ADAPT_STRUCT(InnerWorker, thread_idx, notified)\n#endif\n\ntemplate &lt;typename AllWorkers_t, typename ActiveWorkers_t&gt; class WorkerPool {\n\npublic:\n/* Container of all workers */\nAllWorkers_t all_workers;\n\n/* Container of available workers */\nActiveWorkers_t active_workers;\n\n/* Number of workers */\nint max_workers;\n\n/*Mutex for blocking spawn/await*/\nstd::mutex mtx;\n\n/*Condition variable for blocking spawn/await*/\nstd::condition_variable cv;\n\n/* Number of notified but not running workers*/\nstd::atomic&lt;int&gt; notified_workers{0};\n\nWorkerPool() = default;\nWorkerPool(int nworkers) : max_workers(nworkers){};\n\n/* Add a worker to the active pool */\nvoid enqueue_worker(InnerWorker *worker);\n\n/* Remove a worker from the active pool */\nInnerWorker *dequeue_worker();\n\n/* Add a worker to the all pool */\nvoid add_worker(InnerWorker *worker);\n\n/* Get number of available workers */\nint get_num_available_workers();\n\n/* Get number of total workers */\nint get_num_workers();\n\n/* Set number of total workers */\nvoid set_num_workers(int nworkers);\n\n/*Increase number of notified workers*/\nint increase_num_notified_workers();\n\n/*Decrease number of notified workers*/\nint decrease_num_notified_workers();\n\n/*Get number of notified workers*/\ninline int get_num_notified_workers() {\nreturn this-&gt;notified_workers.load();\n}\n\n/*Blocking for spawn/await so that other threads can take the GIL*/\nvoid spawn_wait();\n\n/* Remove a worker from the all pool */\n// void remove_worker(InnerWorker* worker);\n};\n\ntypedef WorkerPool&lt;WorkerQueue, WorkerQueue&gt; WorkerPool_t;\n\n// Forward declaration of scheduler phases\n\nclass Mapper;\nclass MemoryReserver;\nclass RuntimeReserver;\nclass Launcher;\nclass MappingPolicy;\nclass LocalityLoadBalancingMappingPolicy;\n\nnamespace Scheduler {\n\nenum State {\nspawned,\nmapped,\nreserved,\nready,\nlaunch,\nrunning,\ncomplete,\nfailed\n};\n\nclass Status {\nprivate:\nconst static int size = 8;\n\npublic:\nint status[8] = {0, 0, 0, 0, 0, 0, 0, 0};\n\nvoid reset() {\nfor (int i = 0; i &lt; size; i++) {\nstatus[i] = 0;\n}\n}\n\nvoid set(int index, int value) { this-&gt;status[index] = value; }\n\nint get(int index) { return this-&gt;status[index]; }\n\nvoid update(State state) { this-&gt;status[state]++; }\n\nvoid print() {\nstd::cout &lt;&lt; \"Scheduler Status: (\" &lt;&lt; this-&gt;status[0] &lt;&lt; \", \"\n&lt;&lt; this-&gt;status[1] &lt;&lt; \", \" &lt;&lt; this-&gt;status[2] &lt;&lt; \", \"\n&lt;&lt; this-&gt;status[3] &lt;&lt; \", \" &lt;&lt; this-&gt;status[4] &lt;&lt; \", \"\n&lt;&lt; this-&gt;status[5] &lt;&lt; \", \" &lt;&lt; this-&gt;status[6] &lt;&lt; \", \"\n&lt;&lt; this-&gt;status[7] &lt;&lt; \")\" &lt;&lt; std::endl;\n}\n};\n\n} // namespace Scheduler\n\nclass InnerScheduler {\n\npublic:\n/* Sleep Between Loops */\nbool sleep_flag = false;\n\n/* Time to sleep between loops (microseconds) */\nint sleep_time = 20;\n\n/* Task Buffer */\nstd::vector&lt;InnerTask *&gt; task_buffer = std::vector&lt;InnerTask *&gt;(10);\n\n/* Container of Thread Workers */\nWorkerPool_t workers;\n\n/* Active task counter (thread-safe) */\nstd::atomic&lt;int&gt; num_active_tasks{1};\n\n/* Should Run, Stop Condition */\nstd::atomic&lt;bool&gt; should_run = true;\n\n/* Phase: maps tasks to devices */\nMapper *mapper;\n\n/* Phase reserves resources to limit/plan task execution*/\nMemoryReserver *memory_reserver;\nRuntimeReserver *runtime_reserver;\n\n/*Responsible for launching a task. Signals worker thread*/\nLauncher *launcher;\n\nInnerScheduler(DeviceManager *device_manager);\n~InnerScheduler();\n// InnerScheduler(int nworkers);\n\n/* Pointer to callback to stop the Python scheduler */\nstopfunc_t stop_callback;\n\n/* Pointer to Python scheduler */\nvoid *py_scheduler;\n\n/* Scheduler Status */\nScheduler::Status status;\n\n/* Set the number of workers */\nvoid set_num_workers(int nworkers);\n\n/* Set Python Scheduler */\nvoid set_py_scheduler(void *py_scheduler);\n\n/* Set Python \"stop\" callback */\nvoid set_stop_callback(stopfunc_t stop_callback);\n\n/* Run the scheduler thread. Active for the lifetime of the Parla program */\nvoid run();\n\n/*Stop the scheduler. Called at the end of the Parla program */\nvoid stop();\n\n/* Activate scheduler on current thread. Runs through scheduler phases. */\nScheduler::Status activate();\n\n/* Activate wrapper for Python layer (for use as scheduler callback) */\nvoid activate_wrapper();\n\n/*Spawn a Task (increment active, set state, possibly enqueue)*/\nvoid spawn_task(InnerTask *task);\n\n/* Enqueue task. */\nvoid enqueue_task(InnerTask *task, Task::StatusFlags flags);\n\n/* Enqueue more than one task */\nvoid enqueue_tasks(TaskStateList &amp;tasks);\n\n/* Add worker */\nvoid add_worker(InnerWorker *worker);\n\n/* Enqueue worker. */\nvoid enqueue_worker(InnerWorker *worker);\n\n/* Complete all task finalization. Notify Dependents / Release Resources /\n   * Worker Enqueue */\nvoid task_cleanup(InnerWorker *worker, InnerTask *task, int state);\n\nvoid task_cleanup_presync(InnerWorker *worker, InnerTask *task, int state);\nvoid task_cleanup_postsync(InnerWorker *worker, InnerTask *task, int state);\n\n/* Get number of active tasks. A task is active if it is spawned but not\n   * complete */\nint get_num_active_tasks();\n\n/* Increase number of active tasks */\nvoid increase_num_active_tasks();\n\n/* Decrease number of active tasks. If zero tasks are active, stop the\n   * scheduler */\nvoid decrease_num_active_tasks();\n\n/*Increase number of notified workers*/\nint increase_num_notified_workers();\n\n/*Decrease number of notified workers*/\nint decrease_num_notified_workers();\n\n/* Get number of running tasks. A task is running if is Python task has been\n   * assigned and the task is not complete*/\nint get_num_running_tasks();\n\n/* Get number of ready tasks. A task is ready if its dependencies has been\n   * dispatched to a hardware queue or are complete */\nint get_num_ready_tasks();\n\n/* Get number of noitified workers */\nint get_num_notified_workers() {\nreturn this-&gt;workers.get_num_notified_workers();\n}\n\n/* Get a PArray tracker */\nPArrayTracker *get_parray_tracker() { return &amp;(this-&gt;parray_tracker_); }\n\n/* Reserve a PArray in a device */\nvoid reserve_parray(parray::InnerPArray *parray, DevID_t global_dev_id) {\nDevice *device =\nthis-&gt;device_manager_-&gt;get_device_by_global_id(global_dev_id);\nthis-&gt;parray_tracker_.reserve_parray(*parray, device);\n}\n\n/* Release a PArray in a device */\nvoid release_parray(parray::InnerPArray *parray, DevID_t global_dev_id) {\nDevice *device =\nthis-&gt;device_manager_-&gt;get_device_by_global_id(global_dev_id);\nthis-&gt;parray_tracker_.release_parray(*parray, device);\n}\n\nbool get_parray_state(DevID_t global_dev_idx, uint64_t parray_parent_id) {\nreturn this-&gt;parray_tracker_.get_parray_state(global_dev_idx,\nparray_parent_id);\n}\n\n/* Spawn wait. Slow down the compute bound spawning thread so tasks on other\n   * threads can start*/\nvoid spawn_wait();\n\nDeviceManager *get_device_manager() { return this-&gt;device_manager_; }\n\nprotected:\nDeviceManager *device_manager_;\n\nPArrayTracker parray_tracker_;\n};\n\n#endif // PARLA_BACKEND_HPP\n</code></pre>"},{"location":"runtime/task_8cpp/","title":"File task.cpp","text":"<p>FileList &gt; backend &gt; task.cpp</p> <p>Go to the source code of this file.</p> <ul> <li><code>#include \"include/containers.hpp\"</code></li> <li><code>#include \"include/resources.hpp\"</code></li> <li><code>#include \"include/runtime.hpp\"</code></li> <li><code>#include &lt;string.h&gt;</code></li> </ul>"},{"location":"runtime/task_8cpp/#macros","title":"Macros","text":"Type Name define DEPENDENCY_BUFFER_SIZE  4"},{"location":"runtime/task_8cpp/#macro-definition-documentation","title":"Macro Definition Documentation","text":""},{"location":"runtime/task_8cpp/#define-dependency_buffer_size","title":"define DEPENDENCY_BUFFER_SIZE","text":"<pre><code>#define DEPENDENCY_BUFFER_SIZE 4\n</code></pre> <p>The documentation for this class was generated from the following file <code>src/c/backend/task.cpp</code></p>"},{"location":"runtime/task_8cpp_source/","title":"File task.cpp","text":"<p>File List &gt; backend &gt; task.cpp</p> <p>Go to the documentation of this file. </p> <pre><code>#include \"include/containers.hpp\"\n#include \"include/resources.hpp\"\n#include \"include/runtime.hpp\"\n#include &lt;string.h&gt;\n\n#define DEPENDENCY_BUFFER_SIZE 4\n\n// Task Implementation\n\n// TODO(hc) member initialization list is preferable as it can reduce\n//          instructions (e.g.,\n//          https://stackoverflow.com/questions/9903248/initializing-fields-in-constructor-initializer-list-vs-constructor-body)\nInnerTask::InnerTask()\n: req_addition_mode_(SingleDevAdd), tmp_arch_req_(nullptr),\ntmp_multdev_reqs_(nullptr) {\nthis-&gt;dependency_buffer.reserve(DEPENDENCY_BUFFER_SIZE);\nthis-&gt;id = 0;\nthis-&gt;py_task = nullptr;\n}\n\nInnerTask::InnerTask(long long int id, void *py_task)\n: req_addition_mode_(SingleDevAdd) {\nthis-&gt;dependency_buffer.reserve(DEPENDENCY_BUFFER_SIZE);\nthis-&gt;id = id;\nthis-&gt;py_task = py_task;\n}\n\nInnerTask::InnerTask(std::string name, long long int id, void *py_task)\n: req_addition_mode_(SingleDevAdd) {\nthis-&gt;dependency_buffer.reserve(DEPENDENCY_BUFFER_SIZE);\nthis-&gt;name = name;\nthis-&gt;id = id;\nthis-&gt;py_task = py_task;\n}\n\nvoid InnerTask::set_scheduler(InnerScheduler *scheduler) {\nthis-&gt;scheduler = scheduler;\nsize_t num_devices = this-&gt;scheduler-&gt;get_device_manager()-&gt;get_num_devices();\nthis-&gt;parray_list.resize(num_devices);\n}\n\nvoid InnerTask::set_name(std::string name) {\n// std::cout &lt;&lt; \"Setting name to \" &lt;&lt; name &lt;&lt; std::endl;\nthis-&gt;name = name;\n}\n\nvoid InnerTask::set_id(long long int id) { this-&gt;id = id; }\n\nvoid InnerTask::set_py_task(void *py_task) { this-&gt;py_task = py_task; }\n\nvoid InnerTask::set_priority(int priority) { this-&gt;priority = priority; }\n\nvoid InnerTask::queue_dependency(InnerTask *task) {\nthis-&gt;dependency_buffer.push_back(task);\n}\n\nTask::StatusFlags InnerTask::process_dependencies() {\nNVTX_RANGE(\"InnerTask::process_dependencies\", NVTX_COLOR_MAGENTA)\nTask::StatusFlags status = this-&gt;add_dependencies(this-&gt;dependency_buffer);\nthis-&gt;dependency_buffer.clear();\nthis-&gt;dependency_buffer.reserve(DEPENDENCY_BUFFER_SIZE);\nreturn status;\n}\n\nvoid InnerTask::clear_dependencies() {\nthis-&gt;dependency_buffer.clear();\nthis-&gt;dependencies.clear();\n// this-&gt;dependency_buffer.reserve(DEPENDENCY_BUFFER_SIZE);\n}\n\nTask::State InnerTask::add_dependency(InnerTask *task) {\n\n// Store all added dependencies for bookkeeping\n// I cannot think of a scenario when multiple writers would be adding\n// dependencies NOTE: Please make this thread safe if we have one\nthis-&gt;dependencies.push_back_unsafe(task);\n\n// If the task is already complete, we don't need to add it to the dependency\n\nbool dependency_complete = false;\n\nTask::State dependent_state = task-&gt;add_dependent_task(this);\n\nif (dependent_state &gt;= Task::RUNAHEAD) {\nthis-&gt;num_blocking_dependencies.fetch_sub(1);\nthis-&gt;num_unspawned_dependencies.fetch_sub(1);\nthis-&gt;num_unmapped_dependencies.fetch_sub(1);\nthis-&gt;num_unreserved_dependencies.fetch_sub(1);\n} else if (dependent_state &gt;= Task::RESERVED) {\nthis-&gt;num_unspawned_dependencies.fetch_sub(1);\nthis-&gt;num_unmapped_dependencies.fetch_sub(1);\nthis-&gt;num_unreserved_dependencies.fetch_sub(1);\n} else if (dependent_state &gt;= Task::MAPPED) {\nthis-&gt;num_unspawned_dependencies.fetch_sub(1);\nthis-&gt;num_unmapped_dependencies.fetch_sub(1);\n} else if (dependent_state &gt;= Task::SPAWNED) {\nthis-&gt;num_unspawned_dependencies.fetch_sub(1);\n}\n\nreturn dependent_state;\n}\n\nTask::Status InnerTask::determine_status(bool new_spawnable, bool new_mappable,\nbool new_reservable,\nbool new_runnable) {\nif (new_runnable and this-&gt;processed_data) {\nreturn Task::RUNNABLE;\n} else if (new_runnable and !this-&gt;processed_data) {\nreturn Task::COMPUTE_RUNNABLE;\n} else if (new_reservable) {\nreturn Task::RESERVABLE;\n} else if (new_mappable) {\nreturn Task::MAPPABLE;\n} else if (new_spawnable) {\nreturn Task::SPAWNABLE;\n} else {\nreturn Task::INITIAL;\n}\n}\n\nTask::StatusFlags InnerTask::add_dependencies(std::vector&lt;InnerTask *&gt; &amp;tasks,\nbool data_tasks) {\nLOG_INFO(TASK, \"Adding dependencies to {}. D={}\", this, tasks);\n\n// TODO: Change all of this to lock free.\n//       Handle phase events\n\nif (data_tasks == false) {\nthis-&gt;num_unspawned_dependencies.fetch_add(tasks.size());\nthis-&gt;num_unmapped_dependencies.fetch_add(tasks.size());\nthis-&gt;num_unreserved_dependencies.fetch_add(tasks.size());\nthis-&gt;num_blocking_compute_dependencies.fetch_add(tasks.size());\n}\n\n// CHECKME: Is this still correct on the subsequent call (should be\n// tasks.size()+1 to prevent finishing while adding)\nthis-&gt;num_blocking_dependencies.fetch_add(tasks.size());\n\nfor (size_t i = 0; i &lt; tasks.size(); i++) {\nthis-&gt;add_dependency(tasks[i]);\n}\n\n// Decrement overcount to free this region\nbool spawnable = this-&gt;num_unspawned_dependencies.fetch_sub(1) == 1;\nbool mappable = this-&gt;num_unmapped_dependencies.fetch_sub(1) == 1;\n\n// Other counters are 'freed' in each phase before entering the next phase\n\nTask::StatusFlags status = Task::StatusFlags();\nstatus.spawnable = spawnable;\nstatus.mappable = mappable;\n\n// Task::Status status =\n//     this-&gt;determine_status(spawnable, mappable, reservable, ready);\n\nLOG_INFO(TASK, \"Added dependencies to {}. Status = {}\", this, status);\n\nreturn status;\n\n// If true, this task is ready to launch. Launching must be handled\n// Otherwise launching will be handled by another task's notify_dependents\n}\n\n/*\n *    let n = number of dependencies\n *    want to decrement n such that n = n-1 when both threads have run\n *\n *    thread 1                       thread 2\n *    s1 = check complete\n *    s1  ? n-- : n++\n *                                   notify_dependents: noop  -&gt; s3\n *    add to dependents\n *                                   notify_dependents: n--   -&gt; s4\n *    s2 = check complete\n *    s1 &amp;&amp; s1 ? noop : n--\n *\n *    This handles all cases except when s1=0 &amp; s3=1\n *    Adding lock to ensure s1 == s3, reverts to what we had before:\n *\n *    thread 1                       thread 2\n *                                   notify_dependents_mutex(): noop\n *    mutex_lock()\n *    s1 = check complete\n *    add to dependents\n *    mutex_unlock()\n *    s1  ? n-- : noop\n *                                   notify_dependents_mutex(): n--\n *    s2 = check complete\n *\n *    I am sure there is a better implementation of this.\n */\n\nTask::State InnerTask::add_dependent_task(InnerTask *task) {\n\n// Store all dependents for bookkeeping\n// Dependents can be written to by multiple threads calling this function\n// Dependents is read when the task is in cleanup, which can overlap with this\n// function This write needs to be thread-safe\n\n// NOTE: This is not a lock free implementation. I don't know how to make it\n// lock free\n//       This lock and its match in notify_dependents ensures correctness,\n//       explained above. A tasks \"completeness\" cannot change while we are\n//       adding a dependent to the list This means notify dependents has not\n//       run yet.\nthis-&gt;dependents.lock();\n\nTask::State state = this-&gt;get_state();   // s1\nthis-&gt;dependents.push_back_unsafe(task); // s3\n\nthis-&gt;dependents.unlock();\n\nreturn state;\n}\n\nTask::State InnerTask::add_dependent_space(TaskBarrier *barrier) {\nthis-&gt;spaces.lock();\nTask::State state = this-&gt;get_state();\nthis-&gt;spaces.push_back_unsafe(barrier);\nthis-&gt;spaces.unlock();\n\nreturn state;\n}\n\nvoid InnerTask::add_parray(parray::InnerPArray *parray, int am, int dev_id) {\nAccessMode access_mode = static_cast&lt;AccessMode&gt;(am);\nif (access_mode != AccessMode::IN) {\nparray-&gt;get_parent_parray()-&gt;add_task(this);\n}\nthis-&gt;parray_list[dev_id].emplace_back(std::make_pair(parray, access_mode));\n}\n\nvoid InnerTask::notify_dependents_completed() {\nLOG_INFO(TASK, \"Notifying dependents of {}.\", this);\nNVTX_RANGE(\"InnerTask::notify_dependents\", NVTX_COLOR_MAGENTA)\n\nthis-&gt;dependents.lock();\nthis-&gt;spaces.lock();\n\nfor (size_t i = 0; i &lt; this-&gt;spaces.size_unsafe(); i++) {\nauto space = this-&gt;spaces.get_unsafe(i);\nspace-&gt;notify();\n}\n\nthis-&gt;set_state(Task::COMPLETED);\n\nthis-&gt;spaces.unlock();\nthis-&gt;dependents.unlock();\n\nLOG_INFO(TASK, \"Notified dependents of {}.\", this);\n}\n\nvoid InnerTask::notify_dependents(TaskStateList &amp;buffer,\nTask::State new_state) {\nLOG_INFO(TASK, \"Notifying dependents of {}: {}\", this, buffer);\nNVTX_RANGE(\"InnerTask::notify_dependents\", NVTX_COLOR_MAGENTA)\n\n// NOTE: I changed this to queue up ready tasks instead of enqueing them one\n// at a time\n//       This is possibly worse, but splits out scheduler dependency.\n//       May need to change back to call scheduler.enqueue(task) here instead\n\nthis-&gt;dependents.lock();\n// std::cout &lt;&lt; \"Notifying dependents of \" &lt;&lt; this-&gt;name &lt;&lt; \": \" &lt;&lt;\n// this-&gt;dependents.size_unsafe() &lt;&lt; std::endl;\n\nfor (size_t i = 0; i &lt; this-&gt;dependents.size_unsafe(); i++) {\n\nauto task = this-&gt;dependents.get_unsafe(i);\nTask::StatusFlags status = task-&gt;notify(new_state, this-&gt;is_data.load());\n\n// std::cout &lt;&lt; \"Dependent Task is notified: \" &lt;&lt; task-&gt;name &lt;&lt; std::endl;\nif (status.any()) {\n// std::cout &lt;&lt; \"Dependent Task Ready: \" &lt;&lt; task-&gt;name &lt;&lt; std::endl;\nbuffer.push_back(std::make_pair(task, status));\n}\n}\n\nthis-&gt;set_state(new_state);\n\nthis-&gt;dependents.unlock();\n\n// std::cout &lt;&lt; \"Notified dependents of \" &lt;&lt; this-&gt;name &lt;&lt; \". Ready tasks: \"\n// &lt;&lt; buffer.size() &lt;&lt; std::endl;\n\nLOG_INFO(TASK, \"Notified dependents of {}. Ready tasks: {}\", this, buffer);\n}\n\nbool InnerTask::notify_dependents_wrapper() {\nTaskStateList buffer = TaskStateList();\nthis-&gt;notify_dependents(buffer, Task::MAPPED);\nreturn buffer.size() &gt; 0;\n}\n\nTask::StatusFlags InnerTask::notify(Task::State dependency_state,\nbool is_data) {\n\nbool spawnable = false;\nbool mappable = false;\nbool reservable = false;\nbool compute_runnable = false;\nbool runnable = false;\n\nif (is_data) {\nif (dependency_state == Task::RUNAHEAD) {\n// A data task never notifies for the other stages\nrunnable = (this-&gt;num_blocking_dependencies.fetch_sub(1) == 1);\n}\n} else {\nif (dependency_state == Task::RUNAHEAD) {\ncompute_runnable =\n(this-&gt;num_blocking_compute_dependencies.fetch_sub(1) == 1);\nrunnable = (this-&gt;num_blocking_dependencies.fetch_sub(1) == 1);\n} else if (dependency_state &gt;= Task::RESERVED) {\nreservable = (this-&gt;num_unreserved_dependencies.fetch_sub(1) == 1);\n} else if (dependency_state &gt;= Task::MAPPED) {\nmappable = (this-&gt;num_unmapped_dependencies.fetch_sub(1) == 1);\n} else if (dependency_state &gt;= Task::SPAWNED) {\nspawnable = (this-&gt;num_unspawned_dependencies.fetch_sub(1) == 1);\n}\n}\n\nTask::StatusFlags status;\nstatus.spawnable = spawnable;\nstatus.mappable = mappable;\nstatus.reservable = reservable;\nstatus.compute_runnable = compute_runnable;\nstatus.runnable = runnable;\n\nreturn status;\n}\n\nbool InnerTask::blocked() { return this-&gt;num_blocking_dependencies.load() &gt; 0; }\n\nstd::string InnerTask::get_name() { return this-&gt;name; }\n\nint InnerTask::get_num_dependencies() {\nreturn this-&gt;dependencies.atomic_size();\n}\n\nint InnerTask::get_num_dependents() { return this-&gt;dependents.atomic_size(); }\n\nstd::vector&lt;void *&gt; InnerTask::get_dependencies() {\nstd::vector&lt;void *&gt; dependency_list;\nthis-&gt;dependencies.lock();\nfor (size_t i = 0; i &lt; this-&gt;dependencies.size_unsafe(); i++) {\ndependency_list.push_back(this-&gt;dependencies.get_unsafe(i));\n}\nthis-&gt;dependencies.unlock();\nreturn dependency_list;\n}\n\nstd::vector&lt;void *&gt; InnerTask::get_dependents() {\nstd::vector&lt;void *&gt; dependent_list;\nthis-&gt;dependents.lock();\nfor (size_t i = 0; i &lt; this-&gt;dependents.size_unsafe(); i++) {\ndependent_list.push_back(this-&gt;dependents.get_unsafe(i));\n}\nthis-&gt;dependents.unlock();\nreturn dependent_list;\n}\n\nvoid *InnerTask::get_py_task() { return this-&gt;py_task; }\n\nint InnerTask::set_state(int state) {\nTask::State new_state = static_cast&lt;Task::State&gt;(state);\nTask::State old_state = this-&gt;set_state(new_state);\nint old_state_id = static_cast&lt;int&gt;(new_state);\nreturn old_state_id;\n}\n\nstd::vector&lt;Device *&gt; &amp;InnerTask::get_assigned_devices() {\nreturn this-&gt;assigned_devices;\n}\n\nvoid InnerTask::copy_assigned_devices(const std::vector&lt;Device *&gt; &amp;others) {\nthis-&gt;assigned_devices = others;\n}\n\nvoid InnerTask::add_assigned_device(Device *device) {\nthis-&gt;assigned_devices.push_back(device);\n}\n\nTask::State InnerTask::set_state(Task::State state) {\nTask::State new_state = state;\nTask::State old_state;\n\ndo {\nold_state = this-&gt;state.load();\n} while (!this-&gt;state.compare_exchange_weak(old_state, new_state));\n\nreturn old_state;\n}\n\nTask::Status InnerTask::set_status(Task::Status status) {\nTask::Status new_status = status;\nTask::Status old_status;\n\ndo {\nold_status = this-&gt;status.load();\n} while (!this-&gt;status.compare_exchange_weak(old_status, new_status));\n\nreturn old_status;\n}\n\n/*TODO(wlr): Deprecate this before merge.Need to update pxd and tests*/\nvoid InnerTask::set_complete() { this-&gt;set_state(Task::COMPLETED); }\n\nbool InnerTask::get_complete() { return this-&gt;get_state(); }\n\n// TODO(hc): The current Parla exploits two types of resources,\n//           memory and vcus. Later, this can be extended with\n//           a map.\nvoid InnerTask::add_device_req(Device *dev_ptr, MemorySz_t mem_sz,\nVCU_t num_vcus) {\nResourcePool_t res_req;\nres_req.set(Resource::Memory, mem_sz);\nres_req.set(Resource::VCU, num_vcus);\n\nstd::shared_ptr&lt;DeviceRequirement&gt; dev_req =\nstd::make_shared&lt;DeviceRequirement&gt;(dev_ptr, res_req);\nif (req_addition_mode_ == SingleDevAdd) {\nplacement_req_options_.append_placement_req_opt(std::move(dev_req));\n} else if (req_addition_mode_ % 2 == 0) { /* Architecture requirement */\ntmp_arch_req_-&gt;append_placement_req_opt(std::move(dev_req));\n} else if (req_addition_mode_ == MultiDevAdd) {\ntmp_multdev_reqs_-&gt;append_placement_req(std::move(dev_req));\n}\n}\n\nvoid InnerTask::begin_arch_req_addition() {\n// Setting architecture resource requirement\n// could be called within multi-device requirement\n// setup.\n++req_addition_mode_;\nassert(tmp_arch_req_ == nullptr);\ntmp_arch_req_ = std::make_shared&lt;ArchitectureRequirement&gt;();\n}\n\nvoid InnerTask::end_arch_req_addition() {\nassert(req_addition_mode_ % 2 == 0);\nif (req_addition_mode_ == 4) {\ntmp_multdev_reqs_-&gt;append_placement_req(std::move(tmp_arch_req_));\n} else {\nplacement_req_options_.append_placement_req_opt(std::move(tmp_arch_req_));\n}\n--req_addition_mode_;\n}\n\nvoid InnerTask::begin_multidev_req_addition() {\nassert(req_addition_mode_ == SingleDevAdd);\nassert(tmp_multdev_reqs_ == nullptr);\ntmp_multdev_reqs_ = std::make_shared&lt;MultiDeviceRequirements&gt;();\nreq_addition_mode_ = MultiDevAdd;\n}\n\nvoid InnerTask::end_multidev_req_addition() {\nassert(tmp_multdev_reqs_ != nullptr);\nplacement_req_options_.append_placement_req_opt(std::move(tmp_multdev_reqs_));\nreq_addition_mode_ = SingleDevAdd;\n}\n\nbool InnerTask::is_data_task() {\nreturn this-&gt;is_data.load(std::memory_order_relaxed);\n}\n\nvoid *InnerDataTask::get_py_parray() { return this-&gt;parray_-&gt;get_py_parray(); }\n\nAccessMode InnerDataTask::get_access_mode() { return this-&gt;access_mode_; }\n\nTask::State TaskBarrier::_add_task(InnerTask *task) {\nTask::State dependent_state = task-&gt;add_dependent_space(this);\n\nif (dependent_state == Task::COMPLETED) {\nthis-&gt;num_incomplete_tasks.fetch_sub(1, std::memory_order_relaxed);\n}\n\nreturn dependent_state;\n}\n\nvoid TaskBarrier::add_task(InnerTask *task) {\n// don't use this\nthis-&gt;num_incomplete_tasks.fetch_add(1, std::memory_order_relaxed);\nthis-&gt;_add_task(task);\nthis-&gt;notify();\n}\n\nvoid TaskBarrier::add_tasks(std::vector&lt;InnerTask *&gt; &amp;tasks) {\n\nthis-&gt;num_incomplete_tasks.fetch_add(tasks.size() + 1,\nstd::memory_order_relaxed);\nfor (auto task : tasks) {\nthis-&gt;_add_task(task);\n}\n\n// std::cout &lt;&lt; \"TaskBarrier::add_tasks: \" &lt;&lt;\n// this-&gt;num_incomplete_tasks.load()\n//           &lt;&lt; std::endl;\n\nthis-&gt;notify();\n}\n</code></pre>"},{"location":"runtime/dir_5c0d64f70903e893b1efe571a4b8de29/","title":"Dir src/python","text":"<p>FileList &gt; python</p>"},{"location":"runtime/dir_5c0d64f70903e893b1efe571a4b8de29/#directories","title":"Directories","text":"Type Name dir parla <p>The documentation for this class was generated from the following file <code>src/python/</code></p>"},{"location":"runtime/dir_01e5e731d859fbc2adf047dfd2a722c8/","title":"Dir src/python/parla","text":"<p>FileList &gt; parla</p>"},{"location":"runtime/dir_01e5e731d859fbc2adf047dfd2a722c8/#directories","title":"Directories","text":"Type Name dir cython <p>The documentation for this class was generated from the following file <code>src/python/parla/</code></p>"},{"location":"runtime/dir_80c92dcdcf9b21b47c410d887087bfe7/","title":"Dir src/python/parla/cython","text":"<p>FileList &gt; cython</p>"},{"location":"runtime/dir_80c92dcdcf9b21b47c410d887087bfe7/#files","title":"Files","text":"Type Name file containers.pyx file core.pyx Contains the core intermediate cython wrapper classes for Task, Workers, and Scheduler. file cyparray.pyx file cyparray_state.pyx file device.pyx file device_manager.pyx Contains the cython wrapper and python layer DeviceManager and StreamPool classes. file scheduler.pyx Contains the core Python logic to manage workers and launch tasks. file tasks.pyx Contains the Task and TaskEnvironment classes, which are used to represent tasks and their execution environments. file variants.pyx Provides decorators for dispatching functions based on the active TaskEnvironment. <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/</code></p>"},{"location":"runtime/containers_8pyx/","title":"File containers.pyx","text":"<p>FileList &gt; cython &gt; containers.pyx</p> <p>Go to the source code of this file.</p>"},{"location":"runtime/containers_8pyx/#namespaces","title":"Namespaces","text":"Type Name namespace containers <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/containers.pyx</code></p>"},{"location":"runtime/containers_8pyx_source/","title":"File containers.pyx","text":"<p>File List &gt; cython &gt; containers.pyx</p> <p>Go to the documentation of this file. </p>"},{"location":"runtime/core_8pyx/","title":"File core.pyx","text":"<p>FileList &gt; cython &gt; core.pyx</p> <p>Go to the source code of this file.</p> <p>Contains the core intermediate cython wrapper classes for Task, Workers, and Scheduler. </p>"},{"location":"runtime/core_8pyx/#namespaces","title":"Namespaces","text":"Type Name namespace core"},{"location":"runtime/core_8pyx/#classes","title":"Classes","text":"Type Name class CyDataMovementTaskAttributes class CyTaskList class DataMovementTaskAttributes class PyInnerScheduler class PyInnerTask class PyInnerWorker class PyTaskBarrier class PyTaskSpace class Resources <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/core.pyx</code></p>"},{"location":"runtime/core_8pyx_source/","title":"File core.pyx","text":"<p>File List &gt; cython &gt; core.pyx</p> <p>Go to the documentation of this file. </p> <pre><code>\"\"\"!\n@file core.pyx\n@brief Contains the core intermediate cython wrapper classes for Task, Workers, and Scheduler.\n\"\"\"\n\nimport cython \n\nfrom parla.common.parray.core import PArray\nfrom parla.common.dataflow import Dataflow\nfrom parla.common.globals import AccessMode\n\nfrom parla.cython.device cimport Device\nfrom parla.cython.cyparray cimport CyPArray\nfrom parla.cython.device_manager cimport CyDeviceManager, DeviceManager\nimport threading\nfrom enum import IntEnum, auto\nfrom parla.common.globals import cupy\nfrom libc.stdint cimport uintptr_t\n\n#Resource Types\n#TODO: Python ENUM\n\n#Logging functions\n\nLOG_TRACE = 0\nLOG_DEBUG = 1\nLOG_INFO = 2\nLOG_WARN = 3\nLOG_ERROR = 4\nLOG_FATAL = 5\n\ncpdef py_write_log(filename):\n    fname = filename.encode('utf-8')\n    write_log(fname)\n\ncpdef py_init_log(filename):\n    fname = filename.encode('utf-8')\n    initialize_log(fname)\n\ncpdef _log_task(logging_level, category, message, PyInnerTask obj):\n    cdef InnerTask* _inner = &lt;InnerTask*&gt; obj.c_task\n    msg = message.encode('utf-8')\n\n    if category == \"Task\":\n        log_task_1[InnerTask](logging_level, msg, _inner)\n    if category == \"Worker\":\n        log_worker_1[InnerTask](logging_level, msg, _inner)\n    if category == \"Scheduler\":\n            log_scheduler_1[InnerTask](logging_level, msg, _inner)\n\ncpdef _log_worker(logging_level, category, message, PyInnerWorker obj):\n    cdef InnerWorker* _inner = &lt;InnerWorker*&gt; obj.inner_worker\n    msg = message.encode('utf-8')\n\n    if category == \"Task\":\n        log_task_1[InnerWorker](logging_level, msg, _inner)\n    elif category == \"Worker\":\n        log_worker_1[InnerWorker](logging_level, msg, _inner)\n    elif category == \"Scheduelr\":\n        log_scheduler_1[InnerWorker](logging_level, msg, _inner)\n\ncpdef _log_task_worker(logging_level, category, message1, PyInnerTask obj1, message2, PyInnerWorker obj2):\n    cdef InnerTask* _inner1 = &lt;InnerTask*&gt; obj1.c_task\n    cdef InnerWorker* _inner2 = &lt;InnerWorker*&gt; obj2.inner_worker\n    msg1 = message1.encode('utf-8')\n    msg2 = message2.encode('utf-8')\n\n    if  category == \"Task\":\n        log_task_2[InnerTask, InnerWorker](logging_level, msg1, _inner1, msg2, _inner2)\n    if category  == \"Worker\":\n        log_worker_2[InnerTask, InnerWorker](logging_level, msg1, _inner1, msg2, _inner2)\n    if category == \"Scheduler\":\n        log_scheduler_2[InnerTask, InnerWorker](logging_level, msg1, _inner1, msg2, _inner2)\n\ninner_type1  = cython.fused_type(PyInnerTask, PyInnerWorker)\ninner_type2 = cython.fused_type(PyInnerTask, PyInnerWorker)\n\ncpdef binlog_0(category, message, logging_level=LOG_INFO):\n    msg = message.encode('utf-8')\n    if  category == \"Task\":\n        log_task_msg(logging_level, msg)\n    if category  == \"Worker\":\n        log_worker_msg(logging_level, msg)\n    if category == \"Scheduler\":\n        log_scheduler_msg(logging_level, msg)\n\ncpdef binlog_1(category, message, inner_type1 obj, logging_level=LOG_INFO):\n\n    if inner_type1 is PyInnerTask:\n        _log_task(logging_level, category, message, obj)\n    elif inner_type1 is PyInnerWorker:\n        _log_worker(logging_level, category, message, obj)\n    else:\n        raise Exception(\"Unknown type in logger function\")\n\ncpdef binlog_2(category, message1, inner_type1 obj1, message2, inner_type2 obj2, logging_level=LOG_INFO):\n\n    if inner_type1 is PyInnerTask:\n        if inner_type2 is PyInnerWorker:\n            _log_task_worker(logging_level, category, message1, obj1, message2, obj2)\n        else:\n            raise Exception(\"Unknown type combination in logger function\")\n    else:\n        raise Exception(\"Unknown type combination in logger function\")\n\n#cpdef log_2(category, message1, inner_type1  obj1,  message2, inner_type2 obj2):\n\n\n\ncpdef cpu_bsleep_gil(unsigned int microseconds):\n\"\"\"Busy sleep for a given number of microseconds, but don't release the GIL\"\"\"\n    cpu_busy_sleep(microseconds)\n\ncpdef cpu_bsleep_nogil(unsigned int microseconds):\n\"\"\"Busy sleep for a given number of microseconds, but release the GIL\"\"\"\n    with nogil:\n        cpu_busy_sleep(microseconds)\n\ncpdef gpu_bsleep_gil(dev, t, stream):\n    cdef int c_dev = dev\n    cdef unsigned long c_t = t\n    cdef uintptr_t c_stream = stream.ptr\n    gpu_busy_sleep(c_dev, c_t, c_stream)\n\ncpdef gpu_bsleep_nogil(dev, t, stream):\n    cdef int c_dev = dev\n    cdef unsigned long c_t = t\n    cdef uintptr_t c_stream = stream.ptr\n    with nogil:\n        gpu_busy_sleep(c_dev, c_t, c_stream)\n\n# Define callbacks for C++ to call back into Python\n\ncdef void callback_launch(void* python_scheduler, void* python_task, void*\n        python_worker) nogil:\n    with gil:\n        #print(\"Inside callback to cython\", flush=True)\n        task = &lt;object&gt;python_task\n        scheduler = &lt;object&gt;python_scheduler\n        worker = &lt;object&gt;python_worker\n\n        scheduler.assign_task(task, worker)\n\n        #print(\"Done with callback\", flush=True)\n        #(&lt;object&gt;python_function)(&lt;object&gt;python_input)\n\ncdef void callback_stop(void* python_function) nogil:\n    with gil:\n        #print(\"Inside callback to cython (stop)\", flush=True)\n        scheduler = &lt;object&gt;python_function\n        scheduler.stop_callback()\n\n        #(&lt;object&gt;python_function)(&lt;object&gt;python_input)\n\n#Define the Cython Wrapper Classes\n\ncdef class PyInnerTask:\n    cdef InnerTask* c_task\n    cdef string name\n\n    def __cinit__(self):\n        cdef InnerTask* _c_task\n        _c_task = new InnerTask()\n        self.c_task = _c_task\n\n    def __init__(self, long long int idx, object python_task):\n        cdef InnerTask* _c_task\n        _c_task = self.c_task\n\n        binlog_1(\"Task\", \"Creating task\", self)\n\n        _c_task.set_id(idx)\n        _c_task.set_py_task(&lt;void *&gt; python_task)\n\n    cpdef set_py_task(self, python_task):\n        cdef InnerTask* _c_task = self.c_task\n        _c_task.set_py_task(&lt;void*&gt; python_task)\n\n    cpdef update_name(self, string name):\n        cdef InnerTask* _c_task = self.c_task\n        self.name = name\n        _c_task.set_name(name)\n\n    def __dealloc__(self):\n        binlog_0(\"Task\", \"Task {} is being deallocated\".format(self.name))\n        del self.c_task\n\n    cpdef add_priority(self, priority):\n        cdef InnerTask* _c_task = self.c_task\n        cdef int c_priority = priority\n        _c_task.set_priority(c_priority)\n\n    cpdef get_py_task(self):\n        cdef InnerTask* c_self = self.c_task\n        return &lt;object&gt; c_self.get_py_task()\n\n    cpdef set_scheduler(self, PyInnerScheduler scheduler):\n        cdef InnerTask* c_self = self.c_task\n        cdef InnerScheduler* c_scheduler = scheduler.inner_scheduler\n        c_self.set_scheduler(c_scheduler)\n\n    cpdef add_dependencies(self, dependency_list, process=False):\n        cdef InnerTask* c_self = self.c_task\n\n        cdef PyInnerTask dependency\n        cdef InnerTask* c_dependency\n\n        cdef bool status = False \n        cdef _StatusFlags status_flags\n\n        try: \n            for i in range(0, len(dependency_list)):\n                d = dependency_list[i]\n                dependency = d.inner_task\n                c_dependency = dependency.c_task\n                c_self.queue_dependency(c_dependency)\n        except TypeError:\n            for d in dependency_list:\n                dependency = d.inner_task\n                c_dependency = dependency.c_task\n                c_self.queue_dependency(c_dependency)\n\n        if process:\n            with nogil:\n                status_flags = c_self.process_dependencies()\n                status = status_flags.mappable\n\n        return status\n\n    cpdef clear_dependencies(self):\n        cdef InnerTask* c_self = self.c_task\n        c_self.clear_dependencies()\n\n    cpdef get_dependencies(self):\n        cdef InnerTask* c_self = self.c_task\n\n        cdef vector[void*] c_dependencies = c_self.get_dependencies()\n        cdef size_t num_deps = c_dependencies.size()\n\n        cdef PyInnerTask py_dependency\n        cdef InnerTask* c_dependency\n\n        dependencies = []\n        for i in range(num_deps):\n            c_dependency = &lt;InnerTask*&gt; c_dependencies[i]\n            py_dependency = &lt;PyInnerTask&gt; c_dependency.get_py_task()\n            dependencies.append(py_dependency)\n\n        return dependencies\n\n    cpdef get_dependents(self):\n        cdef InnerTask* c_self = self.c_task\n\n        cdef vector[void*] c_dependents = c_self.get_dependents()\n        cdef size_t num_deps = c_dependents.size()\n\n        cdef PyInnerTask py_dependent\n        cdef InnerTask* c_dependent\n\n        dependents = []\n        for i in range(num_deps):\n            c_dependent = &lt;InnerTask*&gt; c_dependents[i]\n            py_dependent = &lt;PyInnerTask&gt; c_dependent.get_py_task()\n            dependents.append(py_dependent)\n\n        return dependents\n\n    cpdef get_num_dependencies(self):\n        cdef InnerTask* c_self = self.c_task\n        return c_self.get_num_dependencies()\n\n    cpdef get_num_dependents(self):\n        cdef InnerTask* c_self = self.c_task\n        return c_self.get_num_dependents()\n\n    cpdef get_num_blocking_dependencies(self):\n        cdef InnerTask* c_self = self.c_task\n        return c_self.get_num_blocking_dependencies()\n\n    cpdef get_num_unmapped_dependencies(self):\n        cdef InnerTask* c_self = self.c_task\n        return c_self.get_num_unmapped_dependencies()\n\n    cpdef get_assigned_devices(self):\n        cdef InnerTask* c_self = self.c_task\n\n        cdef vector[Device*] c_devices = c_self.get_assigned_devices()\n        cdef size_t num_devices = c_devices.size()\n\n        cdef Device* c_device\n\n        devices = []\n        for i in range(num_devices):\n            c_device = &lt;Device*&gt; c_devices[i]\n            py_device = &lt;object&gt; c_device.get_py_device()\n            devices.append(py_device)\n\n        return devices\n\n    cpdef add_parray(self, CyPArray cy_parray, flag, int dev_id):\n        cdef InnerTask* c_self = self.c_task\n        c_self.add_parray(cy_parray.get_cpp_parray(), int(flag), dev_id)\n\n    cpdef notify_dependents_wrapper(self):\n        cdef InnerTask* c_self = self.c_task\n        cdef bool status = False\n        with nogil:\n            status = c_self.notify_dependents_wrapper()\n        return status\n\n    cpdef set_state(self, int state):\n        cdef InnerTask* c_self = self.c_task\n        return c_self.set_state(state)\n\n    cpdef set_complete(self):\n        cdef InnerTask* c_self = self.c_task\n        c_self.set_state(7)\n\n    cpdef add_device_req(self, CyDevice cy_device, long mem_sz, int num_vcus):\n        cdef InnerTask* c_self = self.c_task\n        cdef Device* cpp_device = cy_device.get_cpp_device()\n        c_self.add_device_req(cpp_device, mem_sz, num_vcus)\n\n    cpdef begin_arch_req_addition(self):\n        cdef InnerTask* c_self = self.c_task\n        c_self.begin_arch_req_addition()\n\n    cpdef end_arch_req_addition(self):\n        cdef InnerTask* c_self = self.c_task\n        c_self.end_arch_req_addition()\n\n    cpdef begin_multidev_req_addition(self):\n        cdef InnerTask* c_self = self.c_task\n        c_self.begin_multidev_req_addition()\n\n    cpdef end_multidev_req_addition(self):\n        cdef InnerTask* c_self = self.c_task\n        c_self.end_multidev_req_addition()\n\n    cpdef set_c_task(self, CyDataMovementTaskAttributes c_attrs):\n        self.c_task = c_attrs.get_c_task()\n\n    cpdef add_stream(self, py_stream):\n        cdef uintptr_t i_stream \n        cdef InnerTask* c_self = self.c_task\n\n        if isinstance(py_stream, cupy.cuda.Stream):\n            i_stream = &lt;uintptr_t&gt; py_stream.ptr\n            c_self.add_stream(i_stream)\n\n    cpdef add_event(self, py_event):\n        cdef uintptr_t i_event \n        cdef InnerTask* c_self = self.c_task\n\n        if isinstance(py_event, cupy.cuda.Event):\n            i_event = &lt;uintptr_t&gt; py_event.ptr\n            c_self.add_event(i_event)\n\n    cpdef reset_events_streams(self):\n        cdef InnerTask* c_self = self.c_task\n        c_self.reset_events_streams()\n\n    cpdef handle_runahead_dependencies(self, int sync_type):\n        cdef InnerTask* c_self = self.c_task\n        cdef int c_sync_type = sync_type\n        with nogil:\n            c_self.handle_runahead_dependencies(c_sync_type)\n\n    cpdef synchronize_events(self):\n        cdef InnerTask* c_self = self.c_task\n        with nogil:\n            c_self.synchronize_events()\n\ncdef class CyTaskList:\n    cdef vector[InnerTask*] c_task_list\n\n    def __cinit__(self):\n        cdef vector[InnerTask*] _task_list\n        self.c_task_listc_task_list = _task_list\n\n\ncdef class PyTaskBarrier:\n    cdef TaskBarrier* c_task_barrier\n\n    def __cinit__(self):\n        cdef TaskBarrier* _task_barrier\n        _task_barrier = new TaskBarrier()\n        self.c_task_barrierc_task_barrier = _task_barrier\n\n    def __init__(self, task_list=[]):\n\n        cdef TaskBarrier* c_self = self.c_task_barrierc_task_barrier\n\n        cdef CyTaskList cy_task_list\n\n        if isinstance(task_list, CyTaskList):\n            cy_task_list = task_list\n            c_self.add_tasks(cy_task_list.c_task_list)\n        else:\n            self.add_tasks(task_list)\n\n        self.c_task_barrierc_task_barrier.set_id(id(self))\n\n    def __dealloc__(self):\n        del self.c_task_barrierc_task_barrier\n\n    cpdef wait(self):\n        cdef TaskBarrier* c_self = self.c_task_barrierc_task_barrier\n        with nogil:\n            c_self.wait()\n\n    cpdef add_tasks(self, task_list):\n        cdef TaskBarrier* c_self = self.c_task_barrierc_task_barrier\n        cdef vector[InnerTask*] c_task_list\n        cdef PyInnerTask inner_task\n        cdef InnerTask* task\n\n        cdef CyTaskList cy_task_list\n\n        if isinstance(task_list, CyTaskList):\n            cy_task_list = task_list\n            c_task_list = cy_task_list.c_task_list\n        else:\n            for i in range(len(task_list)):\n                inner_task = task_list[i].inner_task \n                task = inner_task.c_task\n                c_task_list.push_back(task)\n\n        with nogil:\n            c_self.add_tasks(c_task_list)\n\ncdef class PyTaskSpace:\n    cdef InnerTaskSpace* c_task_space\n\n    def __cinit__(self):\n        cdef InnerTaskSpace* _task_space\n        _task_space = new InnerTaskSpace()\n        self.c_task_spacec_task_space = _task_space\n\n    def __init__(self):\n        self.c_task_spacec_task_space.set_id(id(self))\n\n    def __dealloc__(self):\n        del self.c_task_spacec_task_space\n\n\n    cpdef add_tasks(self, idx_list, task_list):\n        cdef InnerTaskSpace* c_self = self.c_task_spacec_task_space\n\n        cdef vector[int64_t] c_idx_list\n        cdef vector[InnerTask*] c_task_list\n\n        cdef PyInnerTask inner_task\n        cdef InnerTask* task\n\n        for i in range(len(idx_list)):\n            c_idx_list[i] = hash(idx_list[i])\n\n            inner_task = task_list[i].inner_task\n            task = inner_task.c_task\n            c_task_list[i] = task\n\n        c_self.add_tasks(c_idx_list, c_task_list)\n\n    cpdef get_tasks(self, idx_list, CyTaskList task_list):\n\n        cdef InnerTaskSpace* c_self = self.c_task_spacec_task_space\n\n        cdef vector[int64_t] c_idx_list\n        cdef vector[InnerTask*] c_task_list\n\n        cdef PyInnerTask inner_task\n        cdef InnerTask* task\n\n        for i in range(len(idx_list)):\n            c_idx_list[i] = hash(idx_list[i])\n\n        c_self.get_tasks(c_idx_list, task_list.c_task_list)\n\n    cpdef wait(self):\n        cdef InnerTaskSpace* c_self = self.c_task_spacec_task_space\n        with nogil:\n            c_self.wait()\n\n\n\n\n\n\n\n\n\n\n\n\n\ncdef class PyInnerWorker:\n    cdef InnerWorker* inner_worker\n\n    def __cinit__(self):\n        cdef InnerWorker* _inner_worker\n        _inner_worker = new InnerWorker()\n        self.inner_workerinner_worker = _inner_worker\n\n    def __init__(self, python_worker, PyInnerScheduler python_scheduler):\n        cdef InnerWorker* _inner_worker\n        _inner_worker = self.inner_workerinner_worker\n\n        _inner_worker.set_py_worker(&lt;void *&gt; python_worker)\n        _inner_worker.set_thread_idx(python_worker.index)\n\n        cdef InnerScheduler* c_scheduler\n        c_scheduler = python_scheduler.inner_scheduler\n        _inner_worker.set_scheduler(c_scheduler)\n\n\n    cpdef remove_task(self):\n        cdef InnerWorker* _inner_worker\n        _inner_worker = self.inner_workerinner_worker\n\n        _inner_worker.remove_task()\n\n    cpdef wait_for_task(self):\n        cdef InnerWorker* _inner_worker\n        _inner_worker = self.inner_workerinner_worker\n\n        with nogil:\n            _inner_worker.wait()\n\n    cpdef get_task(self):\n        cdef InnerWorker* _inner_worker\n        _inner_worker = self.inner_workerinner_worker\n\n        cdef InnerTask* c_task\n        cdef InnerDataTask* c_data_task\n        cdef bool is_data_task = False\n        cdef vector[Device*] c_devices \n        cdef size_t num_devices\n        cdef Device* c_device\n\n        if _inner_worker.ready:\n            _inner_worker.get_task(&amp;c_task, &amp;is_data_task)\n            if is_data_task == True:\n                # This case is that the current task that\n                # this worker thread gets is a data movement task.\n                py_assigned_devices = []\n                c_devices = c_task.get_assigned_devices()\n                name = c_task.get_name()\n                # Cast the base class instance to the inherited\n                # data movement task.\n                c_data_task = &lt;InnerDataTask *&gt; c_task\n                num_devices = c_devices.size()\n                # Construct a list of Python PArrays.\n                for i in range(num_devices):\n                    c_device = &lt;Device *&gt; c_devices[i]\n                    py_device = &lt;object&gt; c_device.get_py_device()\n                    py_assigned_devices.append(py_device)\n                py_parray = &lt;object&gt; c_data_task.get_py_parray()\n                access_mode = c_data_task.get_access_mode()\n                dev_id = c_data_task.get_device_id();\n\n                # Due to circular imports, the data movement task\n                # is not created, but necessary information/objects\n                # are created here.\n                cy_data_attrs = CyDataMovementTaskAttributes()\n                # A C++ pointer cannot be held in Python object.\n                # Therefore, exploit a Cython class.\n                cy_data_attrs.set_c_task(c_data_task)\n                py_task = DataMovementTaskAttributes(name, py_parray, \\\n                                  access_mode, py_assigned_devices, cy_data_attrs, \\\n                                  dev_id)\n            else:\n                py_task = &lt;object&gt; c_task.get_py_task()\n        else:\n            py_task = None\n        return py_task\n\n    cpdef stop(self):\n        cdef InnerWorker* _inner_worker\n        _inner_worker = self.inner_workerinner_worker\n\n        _inner_worker.stop()\n\n    def __dealloc__(self):\n        del self.inner_workerinner_worker\n\ncdef class PyInnerScheduler:\n    cdef InnerScheduler* inner_scheduler\n\n    def __cinit__(self, CyDeviceManager cy_device_manager, int num_workers, float vcus, object python_scheduler):\n        cdef InnerScheduler* _inner_scheduler\n        cdef DeviceManager* _cpp_device_manager = &lt;DeviceManager*&gt; cy_device_manager.get_cpp_device_manager()\n\n        _inner_scheduler = new InnerScheduler(_cpp_device_manager)\n        self.inner_schedulerinner_scheduler = _inner_scheduler\n\n    def __init__(self, CyDeviceManager cy_device_manager, int num_workers, float vcus, object python_scheduler):\n        cdef InnerScheduler* _inner_scheduler\n        _inner_scheduler = self.inner_schedulerinner_scheduler\n\n        _inner_scheduler.set_num_workers(num_workers)\n\n        _inner_scheduler.set_py_scheduler(&lt;void *&gt; python_scheduler)\n\n        cdef stopfunc_t py_stop = callback_stop\n        _inner_scheduler.set_stop_callback(py_stop)\n\n    cpdef get_status(self):\n        cdef InnerScheduler* c_self = self.inner_schedulerinner_scheduler\n        return c_self.should_run\n\n    def __dealloc__(self):\n        del self.inner_schedulerinner_scheduler\n\n    cpdef run(self):\n        cdef InnerScheduler* c_self = self.inner_schedulerinner_scheduler\n        with nogil:\n            c_self.run()\n\n    cpdef stop(self):\n        cdef InnerScheduler* c_self = self.inner_schedulerinner_scheduler\n        c_self.stop()\n\n    cpdef activate_wrapper(self):\n        cdef InnerScheduler* c_self = self.inner_schedulerinner_scheduler\n        c_self.activate_wrapper()\n\n    cpdef spawn_task(self, PyInnerTask task):\n        cdef InnerScheduler* c_self = self.inner_schedulerinner_scheduler\n        cdef InnerTask* c_task = task.c_task\n\n        c_self.spawn_task(c_task)\n\n    cpdef add_worker(self, PyInnerWorker worker):\n        cdef InnerScheduler* c_self = self.inner_schedulerinner_scheduler\n        cdef InnerWorker* c_worker = worker.inner_worker\n        c_self.add_worker(c_worker)\n\n    cpdef enqueue_worker(self, PyInnerWorker worker):\n        cdef InnerScheduler* c_self = self.inner_schedulerinner_scheduler\n        cdef InnerWorker* c_worker = worker.inner_worker\n        c_self.enqueue_worker(c_worker)\n\n    #TODO(wlr): Should we release the GIL here? Or is it better to keep it?\n    cpdef task_cleanup(self, PyInnerWorker worker, PyInnerTask task, int state):\n        cdef InnerScheduler* c_self = self.inner_schedulerinner_scheduler\n        cdef InnerWorker* c_worker = worker.inner_worker\n        cdef InnerTask* c_task = task.c_task\n        with nogil:\n            c_self.task_cleanup(c_worker, c_task, state)\n\n    cpdef task_cleanup_presync(self, PyInnerWorker worker, PyInnerTask task, int state):\n        cdef InnerScheduler* c_self = self.inner_schedulerinner_scheduler\n        cdef InnerWorker* c_worker = worker.inner_worker\n        cdef InnerTask* c_task = task.c_task\n        with nogil:\n            c_self.task_cleanup_presync(c_worker, c_task, state)\n\n    cpdef task_cleanup_postsync(self, PyInnerWorker worker, PyInnerTask task, int state):\n        cdef InnerScheduler* c_self = self.inner_schedulerinner_scheduler\n        cdef InnerWorker* c_worker = worker.inner_worker\n        cdef InnerTask* c_task = task.c_task\n        with nogil:\n            c_self.task_cleanup_postsync(c_worker, c_task, state)\n\n    cpdef get_num_active_tasks(self):\n        cdef InnerScheduler* c_self = self.inner_schedulerinner_scheduler\n        return c_self.get_num_active_tasks()\n\n    cpdef increase_num_active_tasks(self):\n        cdef InnerScheduler* c_self = self.inner_schedulerinner_scheduler\n        c_self.increase_num_active_tasks()\n\n    cpdef decrease_num_active_tasks(self):\n        cdef InnerScheduler* c_self = self.inner_schedulerinner_scheduler\n        c_self.decrease_num_active_tasks()\n\n    #cpdef get_num_active_workers(self):\n    #    cdef InnerScheduler* c_self = self.inner_scheduler\n    #    return c_self.get_num_active_workers()\n\n    cpdef get_num_ready_tasks(self):\n        cdef InnerScheduler* c_self = self.inner_schedulerinner_scheduler\n        return c_self.get_num_ready_tasks()\n\n    cpdef get_num_running_tasks(self):\n        cdef InnerScheduler* c_self = self.inner_schedulerinner_scheduler\n        return c_self.get_num_running_tasks()\n\n    cpdef get_num_notified_workers(self):\n        cdef InnerScheduler* c_self = self.inner_schedulerinner_scheduler\n        return c_self.get_num_notified_workers()\n\n    cpdef spawn_wait(self):\n        cdef InnerScheduler* c_self = self.inner_schedulerinner_scheduler\n        with nogil:\n            c_self.spawn_wait()\n\n    cpdef reserve_parray(self, CyPArray cy_parray, int global_dev_id):\n        cdef InnerScheduler* c_self = self.inner_schedulerinner_scheduler\n        c_self.reserve_parray(cy_parray.get_cpp_parray(), global_dev_id)\n\n    cpdef release_parray(self, CyPArray cy_parray, int global_dev_id):\n        cdef InnerScheduler* c_self = self.inner_schedulerinner_scheduler\n        c_self.release_parray(cy_parray.get_cpp_parray(), global_dev_id)\n\n    cpdef get_parray_state(\\\n        self, int global_dev_id, long long int parray_parent_id):\n        cdef InnerScheduler* c_self = self.inner_schedulerinner_scheduler\n        return c_self.get_parray_state(global_dev_id, parray_parent_id)\n\n\nclass Resources:\n\n    def __init__(self, vcus):\n        self.resourcesresources = vcus\n\n\ncdef class CyDataMovementTaskAttributes:\n\"\"\"\n    While creating a Python data movement task,\n    we need to connect the Python and the C++ instances.\n    However, we cannot pass the C++ instance (or its pointer)\n    through a normal Python class, but need to use a bridge\n    Cython class. This is for that.\n    \"\"\"\n    cdef InnerDataTask* c_data_task\n    cdef set_c_task(self, InnerDataTask* c_data_task):\n        self.c_data_taskc_data_task = c_data_task\n\n    cdef InnerTask* get_c_task(self):\n        return self.c_data_taskc_data_task\n\n\nclass DataMovementTaskAttributes:\n\"\"\"\n    Hold necessary information to create a data move task.\n    This is delcared to avoid circular imports that could happen\n    when we import tasks.pyx in here.\n    \"\"\"\n    def __init__(self, name, py_parray: PArray, access_mode, assigned_devices, \\\n                 c_attrs: CyDataMovementTaskAttributes, dev_id):\n        self.namename = name\n        self.parrayparray = py_parray\n        self.access_modeaccess_mode = access_mode\n        self.assigned_devicesassigned_devices = assigned_devices\n        self.c_attrsc_attrs = c_attrs\n        self.dev_iddev_id = dev_id\n</code></pre>"},{"location":"runtime/cyparray_8pyx/","title":"File cyparray.pyx","text":"<p>FileList &gt; cython &gt; cyparray.pyx</p> <p>Go to the source code of this file.</p>"},{"location":"runtime/cyparray_8pyx/#namespaces","title":"Namespaces","text":"Type Name namespace cyparray"},{"location":"runtime/cyparray_8pyx/#classes","title":"Classes","text":"Type Name class CyPArray <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/cyparray.pyx</code></p>"},{"location":"runtime/cyparray_8pyx_source/","title":"File cyparray.pyx","text":"<p>File List &gt; cython &gt; cyparray.pyx</p> <p>Go to the documentation of this file. </p> <pre><code># distutils: language=c++\n\nfrom .cyparray cimport InnerPArray\nfrom .cyparray_state cimport CyPArrayState\nfrom parla.common.parray.core import PArray\n\n# a Cython wrapper class around C++ PArray\ncdef class CyPArray:\n\n    def __init__(self, py_parray, uint64_t id, uint64_t parent_id, py_parent_parray, \\\n                 CyPArrayState parray_state, int num_devices):\n        pass\n\n    def __cinit__(self, py_parray, uint64_t id, uint64_t parent_id, py_parent_parray, \\\n                  CyPArrayState parray_state, int num_devices):\n        cdef InnerPArray* cpp_parent_parray = NULL\n        cdef CyPArray cy_parent_parray\n        if py_parent_parray is not None and py_parent_parray.ID != py_parray.ID:\n            cy_parent_parray = py_parent_parray.cy_parray\n            cpp_parent_parray = cy_parent_parray.get_cpp_parray()\n\n        self.cpp_parray = new InnerPArray(\\\n            &lt;void *&gt; py_parray, id, parent_id, cpp_parent_parray,\n            parray_state.get_cpp_parray_state(), num_devices)\n\n    def __dealloc__(self):\n        del self.cpp_parray\n\n    def set_size(self, new_size):\n        self.cpp_parray.set_size(new_size)\n\n    cdef InnerPArray* get_cpp_parray(self):\n        return self.cpp_parray\n\n    cpdef get_num_active_tasks(self, int global_dev_id):\n        return self.cpp_parray.get_num_active_tasks(global_dev_id)\n\n    cpdef get_parray_parentid(self):\n        return self.cpp_parray.get_parray_parentid()\n</code></pre>"},{"location":"runtime/cyparray__state_8pyx/","title":"File cyparray_state.pyx","text":"<p>FileList &gt; cython &gt; cyparray_state.pyx</p> <p>Go to the source code of this file.</p>"},{"location":"runtime/cyparray__state_8pyx/#namespaces","title":"Namespaces","text":"Type Name namespace cyparray_state"},{"location":"runtime/cyparray__state_8pyx/#classes","title":"Classes","text":"Type Name class CyPArrayState <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/cyparray_state.pyx</code></p>"},{"location":"runtime/cyparray__state_8pyx_source/","title":"File cyparray_state.pyx","text":"<p>File List &gt; cython &gt; cyparray_state.pyx</p> <p>Go to the documentation of this file. </p> <pre><code># distutils: language=c++\n\"\"\"!\n@file cyparray_state.pyx\n@brief Contains the core intermediate cython wrapper classes for PArray Coherence.\n\"\"\"\nfrom .cyparray_state cimport PArrayState\n\n# a Cython wrapper class around C++ PArrayState\ncdef class CyPArrayState:\n    def __cinit__(self):\n        self.cpp_parray_statecpp_parray_state = new PArrayState()\n\n    def __init__(self):\n        pass\n\n    def __dealloc__(self):\n        del self.cpp_parray_state\n\n    def set_exist_on_device(self, device_id, exist):\n        self.cpp_parray_state.set_exist_on_device(device_id, exist)\n\n    def set_valid_on_device(self, device_id, valid):\n        self.cpp_parray_state.set_valid_on_device(device_id, valid)\n\n    cdef PArrayState* get_cpp_parray_state(self):\n        return self.cpp_parray_state\n</code></pre>"},{"location":"runtime/device_8pyx/","title":"File device.pyx","text":"<p>FileList &gt; cython &gt; device.pyx</p> <p>Go to the source code of this file.</p>"},{"location":"runtime/device_8pyx/#namespaces","title":"Namespaces","text":"Type Name namespace device"},{"location":"runtime/device_8pyx/#classes","title":"Classes","text":"Type Name class CupyStream class CyCPUDevice class CyCUDADevice class CyDevice class DeviceResource class DeviceResourceRequirement class PyArchitecture class PyCPUArchitecture class PyCPUDevice class PyCUDAArchitecture class PyCUDADevice class PyDevice class Stream <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/device.pyx</code></p>"},{"location":"runtime/device_8pyx_source/","title":"File device.pyx","text":"<p>File List &gt; cython &gt; device.pyx</p> <p>Go to the documentation of this file. </p> <pre><code>\"\"\"!\n@file device.pyx\n@brief Contains the user-facing device and architectures classes.\n\"\"\"\n\nfrom parla.common.globals import _Locals as Locals\nfrom parla.common.globals import cupy, CUPY_ENABLED\nfrom parla.common.globals import DeviceType as PyDeviceType\nfrom parla.common.globals import VCU_BASELINE\n\nfrom abc import ABCMeta, abstractmethod\nfrom dataclasses import dataclass\nfrom typing import Union, List, Iterable, Dict, Tuple\nfrom collections import defaultdict\nimport os \nfrom enum import IntEnum\n\ncdef class CyDevice:\n\"\"\"\n    A bridge between pure Python and C++ device objects.\n    \"\"\"\n    cdef Device* get_cpp_device(self):\n        return self._cpp_device\n\n    def __dealloc__(self):\n        del self._cpp_device\n\n    cpdef int get_global_id(self):\n        return self._cpp_device.get_global_id()\n\n    cpdef long long int query_resource(self, int resource_type):\n        return self._cpp_device.query_resource(&lt;Resource&gt; resource_type)\n\n    cpdef long long int query_reserved_resource(self, int resource_type):\n        return self._cpp_device.query_reserved_resource(&lt;Resource&gt; resource_type)\n\n    cpdef long long int query_mapped_resource(self, int resource_type):\n        return self._cpp_device.query_mapped_resource(&lt;Resource&gt; resource_type)\n\n\ncdef class CyCUDADevice(CyDevice):\n\"\"\"\n    An inherited class from `CyDevice` for a device object specialized to CUDA.\n    \"\"\"\n    def __cinit__(self, int dev_id, long mem_sz, long num_vcus, py_device):\n        # C++ device object.\n        # This object is deallocated by the C++ device manager.\n        self._cpp_device_cpp_device = new CUDADevice(dev_id, mem_sz, num_vcus, \\\n                                          &lt;void *&gt; py_device)\n\n    def __init__(self, int dev_id, long mem_sz, long num_vcus, py_device):\n        pass\n\n\ncdef class CyCPUDevice(CyDevice):\n\"\"\"\n    An inherited class from `CyDevice` for a device object specialized to CPU.\n    \"\"\"\n    def __cinit__(self, int dev_id, long mem_sz, long num_vcus, py_device):\n        # C++ device object.\n        # This object is deallocated by the C++ device manager.\n        self._cpp_device = new CPUDevice(dev_id, mem_sz, num_vcus, \\\n                                         &lt;void *&gt; py_device)\n\n    def __init__(self, int dev_id, long mem_sz, long num_vcus, py_device):\n        pass\n\n\n\n\n\nclass DeviceResource:\n    def __init__(self, memory_sz = 0, num_vcus = 0):\n        # This class represents a device total resource size.\n        # This can also be used to specify resource requirements\n        # of a task for task mapping. \n        # 0 value implies that there is no constraint in a\n        # resource. In the same sense, 0 value in a requirement\n        # implies that it can be mapped to a device even though \n        # that device does not have enough resource.\n        # TODO(hc): better design? map still has a problem that\n        #           users should remember keys.\n        self.memory_sz = memory_sz\n        self.num_vcus = num_vcus\n\n    #Comment(wlr): Reverted this as more things print \"object(fields)\" than not in our repo\n    def __repr__(self):\n        return f\"DeviceResource(memory_sz={self.memory_sz}, num_vcus={self.num_vcus})\"\n\n\nclass PyDevice:\n\"\"\"\n    This class is to abstract a single device in Python and manages\n    a device context as a task runs in Python.\n    \"\"\"\n    def __init__(self, dev_type, dev_type_name, dev_id: int):\n        self._dev_type_dev_type = dev_type\n        self._device_name_device_name = dev_type_name + \":\" + str(dev_id)\n        self._device_device = self\n        self._device_id_device_id = dev_id\n\n        self._device_device = self \n        self._global_id_global_id = None \n\n    def __dealloc__(self):\n        del self._cy_device\n\n    def __enter__(self):\n        return self \n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        pass\n        #print(f\"Exited device, {self.get_name()}, context\", flush=True)\n\n    @property\n    def id(self):\n        return self._dev_id_dev_id \n\n    @id.setter\n    def id(self, new_id):\n        self._dev_id_dev_id = new_id\n\n    @property\n    def global_id(self):\n        return self._global_id_global_id\n\n    @global_id.setter\n    def global_id(self, new_id):\n        self._global_id_global_id = new_id\n\n    def __getitem__(self, param):\n        if isinstance(param, Dict):\n            memory_sz = None if \"memory\" not in param else int(param[\"memory\"])\n            num_vcus = None if \"vcus\" not in param else \\\n                int(VCU_BASELINE * param[\"vcus\"]) if param[\"vcus\"] &lt;= 1 else param[\"vcus\"]\n            return (self, DeviceResource(memory_sz, num_vcus))\n        raise TypeError(\"[PyDevice] Parameter should be a dictionary specifying resource\",\n              \" requirements.\")\n\n    def get_global_id(self):\n        return self._cy_device.get_global_id()\n\n    def get_name(self):\n        return self._device_name_device_name\n\n    def get_cy_device(self):\n        return self._cy_device\n\n    def query_resource(self, res_type):\n        return self._cy_device.query_resource(res_type)\n\n    def query_reserved_resource(self, res_type):\n        return self._cy_device.query_reserved_resource(res_type)\n\n    def query_mapped_resource(self, res_type):\n        return self._cy_device.query_mapped_resource(res_type)\n\n    @property\n    def device(self):\n\"\"\"\n        Returns the external library device object if it exists (e.g. cupy for GPU devices).\n        Otherwise, return the Parla device object (self).\n        \"\"\"\n        return self._device_device\n\n    @property\n    def architecture(self):\n\"\"\"\n        Returns the architecture (type) of the device.\n        \"\"\"\n        return self._dev_type_dev_type\n\n    def get_type(self):\n\"\"\"\n        Returns the architecture (type) of the device.\n        \"\"\"\n        return self._dev_type_dev_type\n\n    def __repr__(self):\n        return self._device_name_device_name\n\n    def __hash__(self):\n        #NOTE: DEVICE NAMES MUST BE UNIQUE INSIDE A SCHEDULER INSTANCE\n        return hash(self._device_name_device_name)\n\n    def __eq__(self, other):\n        if isinstance(other, int):\n            return self._dev_type_dev_type == other\n        elif isinstance(other, PyDevice):\n            return self._device_name_device_name == other._device_name\n        else:\n            return False\n\n    def __str__(self):\n        return repr(self)\n\n    @property\n    def device_id(self):\n        return self._device_id_device_id\n\n    @property\n    def id(self):\n        return self._device_id_device_id\n\n\n\"\"\"\nDevice instances in Python manage resource status.\nTODO(hc): the device configuration will be packed in a data class soon.\n\"\"\"\n\nclass PyCUDADevice(PyDevice):\n\"\"\"\n    An inherited class from `PyDevice` for a device object specialized to CUDA.\n    \"\"\"\n    def __init__(self, dev_id: int, mem_sz: long, num_vcus: long):\n        super().__init__(DeviceType.CUDA, \"CUDA\", dev_id)\n        #TODO(wlr): If we ever support VECs, we might need to move this device initialization\n        self._cy_device_cy_device = CyCUDADevice(dev_id, mem_sz, num_vcus, self)\n\n    @property\n    def device(self):\n        if CUPY_ENABLED:\n            self._device_device_device = cupy.cuda.Device(self.device_iddevice_id)\n        return self._device_device_device\n\n\nclass PyCPUDevice(PyDevice):\n\"\"\"\n    An inherited class from `PyDevice` for a device object specialized to CPU.\n    \"\"\"\n    def __init__(self, dev_id: int, mem_sz: long, num_vcus: long):\n        super().__init__(DeviceType.CPU, \"CPU\", dev_id)\n        self._cy_device_cy_device = CyCPUDevice(dev_id, mem_sz, num_vcus, self)\n\n\nclass PyArchitecture(metaclass=ABCMeta):\n\"\"\"\n    This class is to abstract a single architecture and is utilized for\n    two purposes.\n    First, an architecture class holds and provides device instances.\n    (through a device manager)\n    Second, users can specify the architecture at task spawn's placement\n    parameter.\n    \"\"\"\n\n    def __init__(self, name, id):\n\"\"\"\n        Create a new Architecture with a name and the ID which the runtime\n        will use to identify it.\n        \"\"\"\n        self._name_name = name\n        self._id_id = id\n        self._devices_devices = []\n\n    def __call__(self, index, *args, **kwds):\n\"\"\"\n        Create a device with this architecture.\n        The arguments can specify which physical device you are requesting,\n        but the runtime may override you.\n\n        &gt;&gt;&gt; gpu(0)\n        \"\"\"\n        try:\n            return self._devices_devices[index]\n        except IndexError:\n            # If a requested device does not exist,\n            # ignore that placement.\n            error_msg = f\"{self._name} does not have device({index}).\"\n            error_msg += f\" Please specify existing devices.\"\n            raise ValueError(error_msg)\n\n    def __getitem__(self, param):\n        if isinstance(param, Dict):\n            memory_sz = None if \"memory\" not in param else param[\"memory\"]\n            num_vcus = None if \"vcus\" not in param else \\\n                int(VCU_BASELINE * param[\"vcus\"]) if param[\"vcus\"] &lt;= 1 else param[\"vcus\"]\n            return (self, DeviceResource(memory_sz, num_vcus))\n        raise TypeError(\"[PyArchitecture] Parameter should be a dictionary specifying resource\",\n              \" requirements.\")\n\n    @property\n    def id(self):\n        return self._id_id\n\n    @property\n    def name(self):\n        return self._name_name\n\n    @property\n    def devices(self):\n\"\"\"\n        :return: all `devices&lt;Device&gt;` with this architecture in the system.\n        \"\"\"\n        return self._devices_devices\n\n    def __eq__(self, o: object) -&gt; bool:\n        if isinstance(o, int):\n            return self.ididid == o\n        elif isinstance(o, type(self)):\n            return ( (self.ididid == o.id) and (self._name_name == o.name) )\n        else:\n            return False\n\n    def __hash__(self):\n        return self._id_id\n\n    def __repr__(self):\n        return type(self).__name__\n\n    def __mul__(self, num_archs: int):\n        arch_ps = [self for i in range(0, num_archs)]\n        return tuple(arch_ps)\n\n    def __len__(self):\n        return len(self._devices_devices)\n\n\nclass PyCUDAArchitecture(PyArchitecture):\n    def __init__(self):\n        super().__init__(\"CUDAArch\", DeviceType.CUDA)\n\n    def add_device(self, device):\n        assert isinstance(device, PyDevice)\n        self._devices_devices.append(device)\n\n\nclass PyCPUArchitecture(PyArchitecture):\n    def __init__(self):\n        super().__init__(\"CPUArch\", DeviceType.CPU)\n\n    def add_device(self, device):\n        assert isinstance(device, PyCPUDevice)\n        self._devices_devices.append(device)\n\n\n# TODO(hc): use dataclass later.\nclass DeviceResourceRequirement:\n    def __init__(self, device: PyDevice, res_req: DeviceResource):\n        self.devicedevice = device\n        self.res_reqres_req = res_req\n\n    def __repr__(self):\n        return \"(\"+self.devicedevice.get_name()+\", memory:\"+str(self.res_reqres_req.memory_sz)+ \\\n               \", num_vcus:\"+str(self.res_reqres_req.num_vcus)+\")\" \n\nPlacementSource = Union[PyArchitecture, PyDevice, Tuple[PyArchitecture, DeviceResource], \\\n                        Tuple[PyDevice, DeviceResource]]\n\n\nclass Stream:\n    def __init__(self, device=None, stream=None, non_blocking=True):\n        self._device_device = device\n        self._device_id_device_id = device.device.id\n        self._stream_stream = stream\n\n    def __repr__(self):\n        return f\"Stream({self._device})\"\n\n    def __str__(self):\n        return self.__repr____repr__()\n\n    def __enter__(self):\n        #print(\"Entering Stream: \", self, flush=True)\n        pass\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        #print(\"Exiting Stream: \", self, flush=True)\n        pass\n\n    @property\n    def device(self):\n        return self._device\n\n    @property\n    def stream(self):\n        return self._stream\n\n    def synchronize(self):\n        pass\n\n    def create_event(self):\n        return None\n\n    def wait_event(self):\n        pass\n\nclass CupyStream(Stream):\n\n    def __init__(self, device=None, stream=None, non_blocking=True):\n\"\"\"\n        Initialize a Parla Stream object.\n        Assumes device and stream are cupy objects.\n        \"\"\" \n\n        if device is None and stream is not None:\n            raise ValueError(\"Device must be specified if stream is specified.\")\n\n        if device is None:\n            self._device_device_device = cupy.cuda.Device()\n            self._device_id_device_id_device_id = self._device_device_device.id\n        else:\n            self._device_device_device = device\n            self._device_id_device_id_device_id = device.device.id\n\n        with cupy.cuda.Device(self._device_id_device_id_device_id) as d:\n            if stream is None:\n                self._stream_stream_stream = cupy.cuda.Stream(non_blocking=non_blocking)\n            else:\n                self._stream_stream_stream = stream\n\n    def __repr__(self):\n        return f\"Stream({self._device}, {self._stream})\"\n\n    def __str__(self):\n        return self.__repr____repr____repr__()\n\n    def __enter__(self):\n        #print(\"Entering Stream: \", self, Locals.task, self._device_id, flush=True)\n\n        #Set the device to the stream's device.\n        self.active_deviceactive_device = cupy.cuda.Device(self._device_id_device_id_device_id)\n\n        self.active_deviceactive_device.__enter__()\n        #self._device.__enter__()\n\n\n        #Set the stream to the current stream.\n        self._stream_stream_stream.__enter__()\n\n        Locals.push_stream(self)\n\n        return self \n\n    def __exit__(self, exc_type, exc_value, traceback):\n\n        ret_stream = False\n        ret_device = False\n\n        #Restore the stream to the previous stream.\n        ret_stream = self._stream_stream_stream.__exit__(exc_type, exc_value, traceback)\n\n        #Restore the device to the previous device.\n        ret_device = self.active_deviceactive_device.__exit__(exc_type, exc_value, traceback)\n\n        Locals.pop_stream()\n        return ret_stream and ret_device\n\n    @property\n    def device(self):\n        return self._device_device_device\n\n    @property\n    def stream(self):\n        return self._stream_stream_stream\n\n    def synchronize(self):\n        #print(\"Synchronizing stream\", flush=True)\n        self._stream_stream_stream.synchronize()\n\n    def create_event(self):\n        active_device = cupy.cuda.Device(self._device_id_device_id_device_id)\n        with active_device:\n            new_event = cupy.cuda.Event(block=True, disable_timing=True, interprocess=False)\n        return new_event\n\n    def wait_event(self, event):\n        self._stream_stream_stream.wait_event(event)\n\n    #TODO(wlr): What is the performance impact of this?\n    def __getatrr__(self, name):\n        if hasattr(self, name):\n            return getattr(self, name)\n        return getattr(self._stream_stream_stream, name)\n</code></pre>"},{"location":"runtime/device__manager_8pyx/","title":"File device_manager.pyx","text":"<p>FileList &gt; cython &gt; device_manager.pyx</p> <p>Go to the source code of this file.</p> <p>Contains the cython wrapper and python layer DeviceManager and StreamPool classes.</p>"},{"location":"runtime/device__manager_8pyx/#namespaces","title":"Namespaces","text":"Type Name namespace device_manager"},{"location":"runtime/device__manager_8pyx/#classes","title":"Classes","text":"Type Name class CyDeviceManager class PrintableFrozenSet class PyDeviceManager class StreamPool <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/device_manager.pyx</code></p>"},{"location":"runtime/device__manager_8pyx_source/","title":"File device_manager.pyx","text":"<p>File List &gt; cython &gt; device_manager.pyx</p> <p>Go to the documentation of this file. </p> <pre><code>\"\"\"!\n@file device_manager.pyx\n@brief Contains the cython wrapper and python layer DeviceManager and StreamPool classes.\n\"\"\"\n\nfrom parla.cython import device\nfrom parla.cython.device cimport Device\nfrom parla.common.globals import DeviceType, cupy, VCU_BASELINE\n\nfrom typing import FrozenSet, Collection, Iterable, Set, Tuple, List\n\nimport os\nimport psutil\nimport yaml\n\nPyDevice = device.PyDevice\nPyCUDADevice = device.PyCUDADevice\nPyCPUDevice = device.PyCPUDevice\nPyArchitecture = device.PyArchitecture\nPyCUDAArchitecture = device.PyCUDAArchitecture\nPyCPUArchitecture = device.PyCPUArchitecture\nDeviceResource = device.DeviceResource\nDeviceResourceRequirement = device.DeviceResourceRequirement\nStream = device.Stream\nCupyStream = device.CupyStream\nCUPY_ENABLED = device.CUPY_ENABLED\n\n# Architecture declaration.\n# To use these in the placement of @spawn,\n# declare these as global variables.\ngpu = PyCUDAArchitecture()\ncpu = PyCPUArchitecture()\n\n\ncdef class CyDeviceManager:\n\"\"\"\n    A bridge between pure Python and C++ device managers.\n    \"\"\"\n    def __cinit__(self):\n        self.cpp_device_manager_cpp_device_manager_ = new DeviceManager()\n\n    def __init__(self):\n        pass\n\n    def __dealloc__(self):\n        del self.cpp_device_manager_\n\n    cpdef register_device(self, CyDevice cy_device):\n\"\"\" Register devices to the c++ runtime. \"\"\"\n        cdef Device* cpp_device = cy_device.get_cpp_device()\n        self.cpp_device_manager_.register_device(cpp_device)\n\n    cpdef print_registered_devices(self):\n        self.cpp_device_manager_.print_registered_devices()\n\n    cpdef globalid_to_parrayid(self, global_dev_id):\n        return self.cpp_device_manager_.globalid_to_parrayid(global_dev_id)\n\n    cpdef parrayid_to_globalid(self, parray_dev_id):\n        return self.cpp_device_manager_.parrayid_to_globalid(parray_dev_id)\n\n    cdef DeviceManager* get_cpp_device_manager(self):\n        return self.cpp_device_manager_\n\n\nclass PrintableFrozenSet(frozenset):\n\"\"\"\n    Add __repr__ to frozenset.\n    \"\"\"\n    def get_name(self):\n        # TODO(hc): better way?\n        name = \"[FrozenSet] \"\n        for elem in self:\n            name += str(elem) + \",\"\n        return name[:-1]\n\n    def __repr__(self):\n        return self.get_nameget_name()\n\nclass StreamPool:\n\n    def __init__(self, device_list, per_device=8):\n\n        if CUPY_ENABLED:\n            self.StreamClassStreamClass = CupyStream \n        else:\n            self.StreamClassStreamClass = Stream\n\n        self._device_list_device_list = device_list\n        self._per_device_per_device = per_device\n        self._pool_pool = {}\n\n        for device in self._device_list_device_list:\n            self._pool_pool[device] = []\n\n            with device.device as d:\n                for i in range(self._per_device_per_device):\n                    self._pool_pool[device].append(self.StreamClassStreamClass(device=device))\n\n    def get_stream(self, device):\n        if len(self._pool_pool[device]) == 0:\n            #Create a new stream if the pool is empty.\n            new_stream = self.StreamClassStreamClass(device=device)\n            return new_stream\n\n        return self._pool_pool[device].pop()\n\n    def return_stream(self, stream):\n        self._pool_pool[stream.device].append(stream)\n\n    def __summarize__(self):\n        summary  = \"\"\n        for device in self._device_list_device_list:\n            summary += f\"({device} : {len(self._pool[device])})\"\n\n        return summary\n\n    def __repr__(self):\n        return f\"StreamPool({self.__summarize__()})\"\n\n\n#TODO(wlr):  - Allow device manager to initialize non-contiguous gpu ids. \n#TODO(wlr):  - Provide a way to iterate over these real device ids\n\n\nclass PyDeviceManager:\n\"\"\"\n    A device manager manages device objects and provides their information.\n    The Parla runtime should access device information through a device manager.\n    A single device manager for each Python and C++ is created and held\n    by each schedulers.\n    \"\"\"\n\n    def __init__(self, dev_config = None):\n        self.cy_device_managercy_device_manager = CyDeviceManager()\n        # Stores architectures to a dict so that device manager doesn't have\n        # to have all arch types.\n        self.py_registered_archspy_registered_archs = {}\n        self.registered_devicesregistered_devices = []\n\n        if CUPY_ENABLED:\n            try:\n                self.num_real_gpusnum_real_gpus = cupy.cuda.runtime.getDeviceCount()\n            except cupy.cuda.runtime.CUDARuntimeError:\n                self.num_real_gpusnum_real_gpus = 0\n        else:\n            self.num_real_gpusnum_real_gpus = 0\n\n        # Initialize Devices\n        if dev_config == None or dev_config == \"\":\n            self.register_cpu_devicesregister_cpu_devices()\n            self.register_cupy_gpu_devicesregister_cupy_gpu_devices()\n        else:\n            self.parse_config_and_register_devicesparse_config_and_register_devices(dev_config)\n        #self.register_devices_to_cpp()\n\n        # Initialize Device Hardware Queues\n        self.stream_poolstream_pool = StreamPool(gpu.devices)\n\n    def __dealloc__(self):\n        for arch in self.py_registered_archspy_registered_archs:\n            for dev in arch.devices:\n                del dev\n\n    def register_cupy_gpu_devices(self):\n\"\"\"\n        This function adds cupy GPU devices.\n        \"\"\"\n        # TODO(hc): Later, it will extend a GPU architecture type, like ones\n        #           from AMD.\n        if cupy is not None:\n            try:\n                num_of_gpus = cupy.cuda.runtime.getDeviceCount()\n            except cupy.cuda.runtime.CUDARuntimeError:\n                num_of_gpus = 0\n        else:\n            num_of_gpus = 0\n\n        if num_of_gpus &gt; 0:\n            self.py_registered_archspy_registered_archs[gpu] = gpu\n\n            for dev_id in range(num_of_gpus):\n                gpu_dev = cupy.cuda.Device(dev_id)\n                mem_info = gpu_dev.mem_info # tuple of free and total memory\n                                            # in bytes.\n                mem_sz = long(mem_info[1])\n                py_cuda_device = PyCUDADevice(dev_id, mem_sz, VCU_BASELINE)\n\n                #Add device to the architecture\n                gpu.add_device(py_cuda_device)\n\n                #Add device to the device manager (list of devices)\n                self.registered_devicesregistered_devices.append(py_cuda_device)\n\n                #Register device to the C++ runtime\n                cy_device = py_cuda_device.get_cy_device()\n                self.cy_device_managercy_device_manager.register_device(cy_device)\n\n        #comment(wlr): Removing this path because it can lead to confusing runtime errors with envs.\n        #else:\n        #    # It is possible that the current system does not have CUDA devices.\n        #    # But users can still specify `gpu` to task placement.\n        #    # To handle this case, we add a CPU device as the CUDA architecture\n        #    # type (So, Parla assumes that the target system must be equipped\n        #    # with at least one CPU core).\n        #    self.register_cpu_devices(gpu)\n\n    def register_cpu_devices(self, register_to_cuda: bool = False):\n        #if register_to_cuda:\n        #    gpu.add_device(cpu(0))\n        #    self.registered_devices.append(cpu(0))\n        #    cy_device = cpu(0).get_cy_device()\n        #    self.cy_device_manager.register_device(cy_device)\n        #else:\n        # Get the number of usable CPUs from this process.\n        # This might not be equal to the number of CPUs in the system.\n\n        num_cores = os.getenv(\"PARLA_NUM_CORES\")\n        if num_cores:\n            num_cores = int(num_cores)\n        else:\n            num_cores = len(os.sched_getaffinity(0))\n        if num_cores == 0:\n            raise RuntimeError(\"No CPU cores available for Parla.\")\n\n\n        mem_sz = os.getenv(\"PARLA_CPU_MEM\")\n        if mem_sz:\n            mem_sz = int(mem_sz)\n        else:\n            mem_sz = long(psutil.virtual_memory().total)\n\n        py_cpu_device = PyCPUDevice(0, mem_sz, VCU_BASELINE)\n        self.py_registered_archspy_registered_archs[cpu] = cpu\n        cpu.add_device(py_cpu_device)\n        self.registered_devicesregistered_devices.append(py_cpu_device)\n        cy_device = py_cpu_device.get_cy_device()\n        self.cy_device_managercy_device_manager.register_device(cy_device)\n\n\n    def register_devices_to_cpp(self):\n\"\"\"\n        Register devices to the both Python/C++ runtime.\n        \"\"\"\n        current_idx = 0\n        for py_arch in self.py_registered_archspy_registered_archs:\n            for py_device in py_arch.devices:\n                cy_device = py_device.get_cy_device()\n                self.cy_device_managercy_device_manager.register_device(cy_device)\n                py_device.global_id = current_idx \n                current_idx += 1\n\n    def print_registered_devices(self):\n        print(\"Python devices:\", flush=True)\n        for dev in self.py_registered_archspy_registered_archs:\n            print(f\"\\t Registered device: {dev}\", flush=True)\n        self.cy_device_managercy_device_manager.print_registered_devices()\n\n    def get_cy_device_manager(self):\n        return self.cy_device_managercy_device_manager\n\n    def get_num_gpus(self):\n        return len(self.py_registered_archspy_registered_archs[gpu].devices)\n\n    def get_num_cpus(self):\n        return len(self.py_registered_archspy_registered_archs[cpu].devices)\n\n    def parse_config_and_register_devices(self, yaml_config):\n        with open(yaml_config, \"r\") as f:\n            parsed_configs = yaml.safe_load(f)\n            # Parse CPU device information.\n            cpu_num_cores = parsed_configs[\"CPU\"][\"num_cores\"]\n            if cpu_num_cores &gt; 0:\n                self.py_registered_archspy_registered_archs[cpu] = cpu\n                cpu_mem_sz = parsed_configs[\"CPU\"][\"mem_sz\"]\n                py_cpu_device = PyCPUDevice(0, cpu_mem_sz, VCU_BASELINE) \n                cpu.add_device(py_cpu_device)\n                self.registered_devicesregistered_devices.append(py_cpu_device)\n                cy_device = py_cpu_device.get_cy_device()\n                self.cy_device_managercy_device_manager.register_device(cy_device)\n\n            num_of_gpus = parsed_configs[\"GPU\"][\"num_devices\"]\n            if num_of_gpus &gt; 0:\n                self.py_registered_archspy_registered_archs[gpu] = gpu\n                gpu_mem_sizes = parsed_configs[\"GPU\"][\"mem_sz\"]\n                assert(num_of_gpus == len(gpu_mem_sizes)) \n\n                for dev_id in range(num_of_gpus):\n\n                    if self.num_real_gpusnum_real_gpus &gt; 0:\n                        py_cuda_device = PyCUDADevice(dev_id % self.num_real_gpusnum_real_gpus, \\\n                                                    gpu_mem_sizes[dev_id], \\\n                                                    VCU_BASELINE)\n\n                    else:\n                        py_cuda_device = PyCPUDevice(dev_id, gpu_mem_sizes[dev_id], VCU_BASELINE)\n\n                    gpu.add_device(py_cuda_device)\n                    self.registered_devicesregistered_devices.append(py_cuda_device)\n                    cy_device = py_cuda_device.get_cy_device()\n                    self.cy_device_managercy_device_manager.register_device(cy_device)\n\n    def get_all_devices(self):\n        return self.registered_devicesregistered_devices\n\n    def get_all_architectures(self):\n        return self.py_registered_archspy_registered_archs.values()\n\n    def is_multidevice_placement(self, placement_tuple):\n        if len(placement_tuple) == 2 and \\\n                isinstance(placement_tuple[1], DeviceResource):\n            return False\n        return True\n\n    def construct_single_device_requirements(self, dev, res_req):\n        return DeviceResourceRequirement(dev, res_req)\n\n    def construct_single_architecture_requirements(self, arch, res_req):\n        arch_reqs = []\n        for d in arch.devices:\n            arch_reqs.append(self.construct_single_device_requirementsconstruct_single_device_requirements(\n                  d, res_req))\n        return PrintableFrozenSet(arch_reqs)\n\n    def construct_resource_requirements(self, placement_component, vcus, memory):\n        if isinstance(placement_component, Tuple) and \\\n              not self.is_multidevice_placementis_multidevice_placement(placement_component):\n                # In this case, the placement component consists of\n                # Device or Architecture, with its resource requirement.\n                placement, req = placement_component\n                req.memory_sz = req.memory_sz if req.memory_sz is not None else  \\\n                    (0 if memory is None else memory)\n                req.num_vcus = req.num_vcus if req.num_vcus is not None else  \\\n                    (0 if vcus is not None else vcus)\n                # If a device specified by users does not exit \n                # and was not registered to the Parla runtime,\n                # use CPU instead.\n                if isinstance(placement, PyArchitecture):\n                    # Architecture placement means that the task mapper\n                    # could choose one of the devices in the specified\n                    # architecture.\n                    # For example, if `gpu` is specified, all gpu devices\n                    # become target candidate devices and one of them\n                    # might be chosen as the final placement for a task.\n                    # To distinguish architecture placement from others,\n                    # it is converted to a frozen set of the entire devices.\n                    return self.construct_single_architecture_requirementsconstruct_single_architecture_requirements(\n                        placement, req)\n                elif isinstance(placement, PyDevice):\n                    return self.construct_single_device_requirementsconstruct_single_device_requirements(\n                        placement, req)\n        elif isinstance(placement_component, PyArchitecture):\n            vcus = vcus if vcus is not None else 0\n            memory = memory if memory is not None else 0\n            res_req = DeviceResource(memory, vcus)\n            return self.construct_single_architecture_requirementsconstruct_single_architecture_requirements(\n                placement_component, res_req)\n        elif isinstance(placement_component, PyDevice):\n            vcus = vcus if vcus is not None else 0\n            memory = memory if memory is not None else 0\n            res_req = DeviceResource(memory, vcus)\n            return self.construct_single_device_requirementsconstruct_single_device_requirements(\n                placement_component, res_req)\n        else:\n            raise TypeError(\"Incorrect placement\")\n\n\n    def unpack_placements(self, placement_components, vcus, memory):\n\"\"\" Unpack a placement parameter and return a list of\n            a pair of devices and requirements in a proper hierarchy structure.\n            Placements (from @spawn) could be collections, for\n            multi-device placements, a pair of architecture and\n            resource requirement, or a pair of device and resource requirement.\n        \"\"\"\n        assert(isinstance(placement_components, List) or \\\n            isinstance(placement_components, Tuple))\n        # Multi-device resource requirement or\n        # a list of devices, architectures, or multi-device \n        # requirements.\n        unpacked_devices = []\n        for c in placement_components:\n            if isinstance(c, Tuple) and self.is_multidevice_placementis_multidevice_placement(c):\n                # Multi-device placement is specified\n                # through a nested tuple of the placement API.\n                # Which means that, each nested tuple in the\n                # placement specifies a single placement for\n                # a task. The placement API allows multiple tuples for\n                # multi-device placements (e.g., placement=[(), (), ..]),\n                # and the task mapper chooses one of those options\n                # as the target requirement based on device states.\n                # In this case, recursively call this function and\n                # construct a list of member devices and their resource\n                # requirements to distinguish them from other flat\n                # resource requirements.\n                unpacked_devices.append(self.unpack_placementsunpack_placements(c, vcus, memory))\n            else:\n                unpacked_devices.append(self.construct_resource_requirementsconstruct_resource_requirements(c, vcus, memory))\n        return unpacked_devices\n\n    def get_device_reqs_from_placement(self, placement, vcus, memory):\n\"\"\" Unpack placement and return device objects that are specified\n            (or implied) through the placement argument of @spawn.\n            If None is passed to the placement, all devices exiting\n            in the current system become candidates of the placement. \"\"\"\n        # Placement cannot be None since it is set to a list of the whole \n        # devices.\n        assert placement is not None\n        ps = placement if isinstance(placement, Iterable) else [placement]\n        return self.unpack_placementsunpack_placements(ps, vcus, memory)\n\n    def globalid_to_parrayid(self, global_dev_id):\n        return self.cy_device_managercy_device_manager.globalid_to_parrayid(global_dev_id)\n\n    def parrayid_to_globalid(self, parray_dev_id):\n        return self.cy_device_managercy_device_manager.parrayid_to_globalid(parray_dev_id)\n</code></pre>"},{"location":"runtime/scheduler_8pyx/","title":"File scheduler.pyx","text":"<p>FileList &gt; cython &gt; scheduler.pyx</p> <p>Go to the source code of this file.</p> <p>Contains the core Python logic to manage workers and launch tasks. </p>"},{"location":"runtime/scheduler_8pyx/#namespaces","title":"Namespaces","text":"Type Name namespace scheduler"},{"location":"runtime/scheduler_8pyx/#classes","title":"Classes","text":"Type Name class ControllableThread class Scheduler class SchedulerContext class SchedulerException class TaskBodyException class WorkerThread class WorkerThreadException class _SchedulerLocals <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/scheduler.pyx</code></p>"},{"location":"runtime/scheduler_8pyx_source/","title":"File scheduler.pyx","text":"<p>File List &gt; cython &gt; scheduler.pyx</p> <p>Go to the documentation of this file. </p> <pre><code>\"\"\"!\n@file scheduler.pyx\n@brief Contains the core Python logic to manage workers and launch tasks.\n\"\"\"\n\nfrom abc import abstractmethod, ABCMeta\nfrom typing import Collection, Optional, Union, List, Dict\nimport threading\nfrom collections import deque, namedtuple, defaultdict\nimport inspect \nimport os\nfrom parla.common.globals import DeviceType, cupy, CUPY_ENABLED\nfrom parla.common.globals import SynchronizationType as SyncType\n\nimport traceback\nimport sys\n\n#cimport tasks\nfrom parla.cython import tasks\n\ncimport core\nfrom parla.cython import core\nfrom parla.cython.cyparray import CyPArray\n\nfrom parla.common.globals import _Locals as Locals \nfrom parla.common.globals import USE_PYTHON_RUNAHEAD, _global_data_tasks, PREINIT_THREADS\nfrom parla.common.parray.core import PArray\n\nTask = tasks.Task\nComputeTask = tasks.ComputeTask\nDataMovementTask = tasks.DataMovementTask\nTaskSpace = tasks.TaskSpace\ncreate_env = tasks.create_env\n\nfrom parla.utility.tracer import NVTXTracer\n\nPyInnerScheduler = core.PyInnerScheduler\nPyInnerWorker = core.PyInnerWorker\nPyInnerTask = core.PyInnerTask\n\nnvtx = NVTXTracer\nnvtx.initialize()\n\nclass TaskBodyException(RuntimeError):\n    pass\n\nclass SchedulerException(RuntimeError):\n    pass\n\nclass WorkerThreadException(RuntimeError):\n    pass\n\n\nclass _SchedulerLocals(threading.local):\n    def __init__(self):\n        super(_SchedulerLocals, self).__init__()\n        self._scheduler_context_stack = []\n\n    @property\n    def scheduler_context(self):\n        if self._scheduler_context_stack:\n            return self._scheduler_context_stack[-1]\n        else:\n            raise Exception(\"No scheduler context\")\n\n_scheduler_locals = _SchedulerLocals()\n\ndef get_scheduler_context():\n    return _scheduler_locals.scheduler_context\n\ndef get_device_manager():\n    return get_scheduler_context().device_manager\n\ndef get_stream_pool():\n    return get_scheduler_context().device_manager.stream_pool\n\nclass SchedulerContext:\n\n    #TODO: Add enviornments back\n\n    @property\n    @abstractmethod\n    def scheduler(self) -&gt; \"Scheduler\":\n        raise NotImplementedError()\n\n    def __enter__(self):\n        #TODO: Deprecate _scheduler_locals \n        _scheduler_locals._scheduler_context_stack.append(self)\n        Locals.push_scheduler(self.schedulerscheduler)\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        _scheduler_locals._scheduler_context_stack.pop()\n        Locals.pop_scheduler()\n\nclass ControllableThread(threading.Thread):\n\n    def __init__(self):\n        super().__init__()\n        self._should_run_should_run = True\n\n    def stop(self):\n        #print(\"Stopping Thread:\", self, flush=True)\n        with self._monitor:\n            self._should_run_should_run = False\n            self._monitor.notify_all()\n\n    @abstractmethod\n    def run(self):\n        pass\n\n\nclass WorkerThread(ControllableThread, SchedulerContext):\n    def __init__(self, scheduler, index):\n        super().__init__()\n        self._scheduler = scheduler\n        self._monitor = threading.Condition(threading.Lock())\n\n        self.index = index\n\n        self.task = None\n        self.status = \"Initializing\"\n\n        self.inner_worker = PyInnerWorker(self, scheduler.inner_scheduler)\n\n        #Add the worker to the scheduler pool of all workers (not yet active)\n        scheduler.inner_scheduler.add_worker(self.inner_worker)\n\n    def start(self, initialize=True):\n        super(ControllableThread, self).start()\n\n        if PREINIT_THREADS:\n            self._initialize()\n\n    def _initialize(self):\n        device_manager = self.scheduler.device_manager\n\n        #comment(wlr): wow, it is non-trivial to get the set of active cuda devices in the scheduler.\n        #TODO(wlr): Fix this in device_manager (see todo there)\n\n        if CUPY_ENABLED:\n            gpu_arch = device_manager.py_registered_archs[DeviceType.CUDA]\n            ngpus = len(gpu_arch)\n\n            for index in range(ngpus):\n                # Trigger cuBLAS/etc. initialization for this GPU in this thread.\n                with cupy.cuda.Device(index % device_manager.num_real_gpus) as device:\n                    a = cupy.asarray([2.])\n                    cupy.cuda.get_current_stream().synchronize()\n                    with cupy.cuda.Stream(False, True) as stream:\n                        cupy.asnumpy(cupy.sqrt(a))\n                        device.cublas_handle\n                        device.cusolver_handle\n                        device.cusolver_sp_handle\n                        device.cusparse_handle\n                        stream.synchronize()\n                        device.synchronize()\n\n\n\n    @property\n    def scheduler(self):\n        return self._scheduler\n\n    def assign_task(self, task):\n        #print(\"Worker waiting to assign task\", flush=True)\n        with self._monitor:\n            if self.task:\n                raise Exception(\"Worker already has a task\")\n            self.task = task\n            #print(\"Worker assigned task. Waking thread...\", flush=True)\n            self._monitor.notify()\n\n    def remove_task(self):\n        with self._monitor:\n            if not self.task:\n                raise Exception(\"Worker does not have a task\")\n            self.task = None\n\n    def run(self):\n        try:\n            #A worker thread is a scheduler context\n            with self:\n                #TODO: Perform any thread initialization on enviornment components\n\n                #Add the worker to the scheduler pool of active &amp; availabe workers\n                self.scheduler.inner_scheduler.enqueue_worker(self.inner_worker)\n\n                with self.scheduler.start_monitor:\n                    #print(\"NOTIFYING\", flush=True)\n                    self.scheduler.start_monitor.notify_all()\n\n                while self._should_run:\n                    self.status = \"Waiting\"\n                    #print(\"WAITING\", flush=True)\n\n                    #with self._monitor:\n                    #    if not self.task:\n                    #        self._monitor.wait()\n                    nvtx.push_range(message=\"worker::wait\", domain=\"Python Runtime\", color=\"blue\")\n                    self.inner_worker.wait_for_task()\n\n                    self.task = self.inner_worker.get_task()\n                    if isinstance(self.task, core.DataMovementTaskAttributes):\n                        self.task_attrs = self.task\n                        self.task = DataMovementTask()\n                        self.task.instantiate(self.task_attrs, self.scheduler)\n                        #if USE_PYTHON_RUNAHEAD:\n                            #This is a back up for testing\n                            #Need to keep the python object alive\n                            #Currently this is never cleaned up\n                        #comment(wlr): Need this is all cases currently. FIXME: Add stream/event creation in C++ so python isn't the owner.\n                        _global_data_tasks[id(self.task)] = self.task\n\n                    nvtx.pop_range(domain=\"Python Runtime\")\n\n                    #print(\"THREAD AWAKE\", self.index, self.task, self._should_run, flush=True)\n\n                    self.status = \"Running\"\n\n                    if isinstance(self.task, Task):\n                        active_task = self.task \n\n                        parla_devices = active_task.get_assigned_devices()\n                        device_context = create_env(parla_devices)\n\n                        #Save device_context with task object\n                        #comment(wlr): This replaces the old enviornment (for continuation tasks)\n                        #print(\"Setting environment for task\", active_task, flush=True)\n                        active_task.environment = device_context\n\n\n                        #Writes all 'default' streams and event pointers to c++ task\n                        #This allows their synchronization without the GIL and faster iteration over them\n                        #(only saves initial runtime ones, TODO(wlr): save any user added events or streams after body returns)\n                        device_context.write_to_task(active_task)\n                        #print(\"Wrote enviornment to task\", active_task, flush=True)\n\n                        #handle event wait in python \n                        if USE_PYTHON_RUNAHEAD:\n                            active_task.py_handle_runahead_dependencies() \n                        else:\n                            #handle event wait in C++ (good if num_dependencies large)\n                            active_task.handle_runahead_dependencies()\n\n                        nvtx.push_range(message=\"worker::run\", domain=\"Python Runtime\", color=\"blue\")\n\n                        # print(\"Running Task\", active_task, flush=True)\n\n                        #Push the task to the thread local stack\n                        Locals.push_task(active_task)\n\n                        with device_context as env:\n\n                            core.binlog_2(\"Worker\", \"Running task: \", active_task.inner_task, \" on worker: \", self.inner_worker)\n                            #Run the task body (this may complete the task or return a continuation)\n                            #The body may return asynchronusly before kernels have completed, in which case the task will be marked as runahead\n                            active_task.run()\n\n                        #Pop the task from the thread local stack\n                        Locals.pop_task()\n\n                        #Log events on all 'task default' streams\n                        device_context.record_events()\n\n                        nvtx.pop_range(domain=\"Python Runtime\")\n                        #print(\"Finished Task\", self.index, active_task.taskid.full_name, flush=True)\n\n                        nvtx.push_range(message=\"worker::cleanup\", domain=\"Python Runtime\", color=\"blue\")\n\n                        final_state  = active_task.state\n\n                        #FIXME: This can be cleaned up and hidden from this function with a better interface...\n                        if active_task.runahead == SyncType.NONE:\n                            device_context.finalize()\n\n                        #TODO(wlr): Add better exception handling\n                        if isinstance(final_state, tasks.TaskException):\n                            raise TaskBodyException(active_task.state.exception)\n\n                        elif isinstance(final_state, tasks.TaskRunning):\n                            nvtx.push_range(message=\"worker::continuation\", domain=\"Python Runtime\", color=\"red\")\n                            #print(\"CONTINUATION: \", active_task.taskid.full_name, active_task.state.dependencies, flush=True)\n                            active_task.dependencies = active_task.state.dependencies\n                            active_task.func = active_task.state.func\n                            active_task.args = active_task.state.args\n\n                            active_task.inner_task.clear_dependencies()\n                            active_task.add_dependencies(active_task.dependencies, process=False)\n                            nvtx.pop_range(domain=\"Python Runtime\")\n\n                        elif  isinstance(final_state, tasks.TaskRunahead):\n                            core.binlog_2(\"Worker\", \"Runahead task: \", active_task.inner_task, \" on worker: \", self.inner_worker)\n\n                        #print(\"Cleaning up Task\", active_task, flush=True)\n\n                        if USE_PYTHON_RUNAHEAD:\n                            #Handle synchronization in Python (for debugging, works!)\n                            self.scheduler.inner_scheduler.task_cleanup_presync(self.inner_worker, active_task.inner_task, active_task.state.value)\n                            if active_task.runahead != SyncType.NONE:\n                                device_context.synchronize(events=True)\n                            self.scheduler.inner_scheduler.task_cleanup_postsync(self.inner_worker, active_task.inner_task, active_task.state.value)\n                        else:\n                            #Handle synchronization in C++\n                            self.scheduler.inner_scheduler.task_cleanup(self.inner_worker, active_task.inner_task, active_task.state.value)\n\n                        #print(\"Finished Cleaning up Task\", active_task, flush=True)\n\n                        if active_task.runahead != SyncType.NONE:\n                            device_context.return_streams()\n\n                        if isinstance(final_state, tasks.TaskRunahead):\n                            final_state = tasks.TaskCompleted(final_state.return_value)\n                            core.binlog_2(\"Worker\", \"Completed task: \", active_task.inner_task, \" on worker: \", self.inner_worker)\n\n                        # print(\"Finished Task\", active_task, flush=True)\n                        active_task.state = final_state\n\n                        nvtx.pop_range(domain=\"Python Runtime\")\n                    elif self._should_run:\n                        raise WorkerThreadException(\"%r Worker: Woke without a task\", self.index)\n                    else:\n                        #print(\"Worker Thread Stopping\", flush=True)\n                        break\n\n        except Exception as e:\n            tb = traceback.format_exc()\n            print(\"Exception in Worker Thread \", self, \": \", e, tb, flush=True)\n\n            self.scheduler.exception_stack.append(e)\n            self.scheduler.stop()\n\n            if isinstance(e, TaskBodyException):\n                raise WorkerThreadException(f\"Unhandled Exception in Task: {self.task.get_name()}\") from e\n            if isinstance(e, KeyboardInterrupt):\n                print(\"You pressed Ctrl+C! In a worker!\", flush=True)\n                raise e\n            else:\n                raise WorkerThreadException(\"Unhandled Exception on \"+str(self))\n\n    def stop(self):\n        super().stop()\n        self.inner_worker.stop()\n        #print(\"Stopped Thread\", self, flush=True)\n\nclass Scheduler(ControllableThread, SchedulerContext):\n\n    def __init__(self, device_manager, n_threads=6, period=0.001):\n        super().__init__()\n\n        self.start_monitorstart_monitor = threading.Condition(threading.Lock())\n\n        self._monitor_monitor = threading.Condition(threading.Lock())\n\n        self.exception_stackexception_stack = []\n\n        self.default_taskspacedefault_taskspace = TaskSpace(\"global\")\n\n        #TODO: Handle resources better\n        resources = 1.0\n\n        self.device_managerdevice_manager = device_manager\n        cy_device_manager = self.device_managerdevice_manager.get_cy_device_manager()\n        self.inner_schedulerinner_scheduler = PyInnerScheduler(cy_device_manager, n_threads, resources, self)\n\n        self.worker_threadsworker_threads = [WorkerThread(self, i) for i in range(n_threads)]\n\n        with self.start_monitorstart_monitor:\n            for thread in self.worker_threadsworker_threads:\n                thread.start()\n            #print(\"Scheduler: Waiting at least one thread to Spawn\", flush=True)\n            self.start_monitorstart_monitor.wait()\n\n        self.start()\n\n    @property\n    def scheduler(self):\n        return self\n\n    def get_device_reqs_from_placement(self, placement, vcus, memory):\n        return self.device_managerdevice_manager.get_device_reqs_from_placement(placement, vcus, memory)\n\n    def __enter__(self):\n        if self.inner_schedulerinner_scheduler.get_num_active_tasks() != 1:\n            raise SchedulerException(\"Schedulers can only have a single scope.\")\n        return super().__enter__()\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        #print(\"Scheduler: Exiting\", flush=True)\n        try:\n            super().__exit__(exc_type, exc_val, exc_tb)\n            self.inner_schedulerinner_scheduler.decrease_num_active_tasks()\n            #print(\"Waiting for scheduler to stop\", flush=True)\n\n            with self._monitor_monitor:\n                #print(\"Busy Waiting for scheduler to stop\", flush=True)\n                while self.inner_schedulerinner_scheduler.get_status():\n                    self._monitor_monitor.wait()\n\n                #print(\"Scheduler: Stopping from __exit__\", flush=True)\n                for t in self.worker_threadsworker_threads:\n                    t.join()\n        except Exception as e:\n            self.exception_stackexception_stack.append(e)\n\n            if len(self.exception_stackexception_stack) &gt; 0:\n                raise self.exception_stackexception_stack[0]\n        finally:\n            pass\n            #print(\"Runtime Stopped\", flush=True)\n\n    def run(self):\n        #print(\"Scheduler: Running\", flush=True)\n        self.inner_schedulerinner_scheduler.run()\n        #print(\"Scheduler: Stopped Loop\", flush=True)\n\n    def stop(self):\n        #print(\"Scheduler: Stopping (Called from Python)\", flush=True)\n        self.inner_schedulerinner_scheduler.stop()\n\n    def get_num_running_tasks(self):\n        return self.inner_schedulerinner_scheduler.get_num_running_tasks()\n\n    def stop_callback(self):\n        super().stop()\n\n        for w in self.worker_threadsworker_threads:\n            w.stop()\n\n        #print(\"Scheduler: Stopped\", flush=True)\n\n    def spawn_task(self, task):\n        #print(\"Scheduler: Spawning Task\", task, flush=True)\n        self.inner_schedulerinner_scheduler.spawn_task(task.inner_task)\n\n\n    def assign_task(self, task, worker):\n        task.state = tasks.TaskRunning(task.func, task.args, task.dependencies)\n        worker.assign_task(task)\n\n    def get_num_notified_workers(self):\n        return self.inner_schedulerinner_scheduler.get_num_notified_workers()\n\n    def spawn_wait(self):\n        self.inner_schedulerinner_scheduler.spawn_wait()\n\n    def reserve_parray(self, cy_parray: CyPArray, global_dev_id: int):\n\"\"\"\n        Reserve PArray instances that are created through\n        __init__() of the PArray class.\n        In the current Parla, crosspy calls this function\n        during initialization if its internal array type is PArray.\n\n        :param parray: Created Cython PArray instance\n        :param global_dev_id: global logical device id that\n                              the PArray will be placed\n        \"\"\"\n        self.inner_schedulerinner_scheduler.reserve_parray(cy_parray, global_dev_id)\n\n    def release_parray(self, cy_parray: CyPArray, global_dev_id: int):\n\"\"\"\n        Release PArray instances that are evicted.\n\n        :param parray: Cython PArray instance to be evicted\n        :param global_dev_id: global logical device id that\n                              the PArray will be evicted\n        \"\"\"\n        self.inner_schedulerinner_scheduler.release_parray(cy_parray, global_dev_id)\n\n    def get_parray_state(\\\n        self, global_dev_id: int, parray_parent_id):\n\"\"\"\n        Return True if a parent PArray of the passed PArray exists on a\n        device.\n\n        :param global_dev_id: global logical device id that \n                              this function interests \n        :param parray_parent_id: parent PArray ID\n        \"\"\"\n        return self.inner_schedulerinner_scheduler.get_parray_state( \\\n            global_dev_id, parray_parent_id)\n\n\ndef _task_callback(task, body):\n\"\"\"\n    A function which forwards to a python function in the appropriate device context.\n    \"\"\"\n    try:\n        body = body\n\n        if inspect.iscoroutinefunction(body):\n            body = body()\n\n        if inspect.iscoroutine(body):\n            try:\n                in_value_task = getattr(task, \"value_task\", None)\n                in_value = in_value_task and in_value_task.result\n\n                new_task_info = body.send(in_value)\n                task.value_task = None\n                if not isinstance(new_task_info, tasks.TaskAwaitTasks):\n                    raise TypeError(\n                        \"Parla coroutine tasks must yield a TaskAwaitTasks\")\n                dependencies = new_task_info.dependencies\n                value_task = new_task_info.value_task\n                if value_task:\n                    assert isinstance(value_task, Task)\n                    task.value_task = value_task\n                return tasks.TaskRunning(_task_callback, (body,), dependencies)\n            except StopIteration as e:\n                result = None\n                if e.args:\n                    (result,) = e.args\n                return tasks.TaskRunahead(result)\n        else:\n            result = body()\n            return tasks.TaskRunahead(result)\n    finally:\n        pass\n</code></pre>"},{"location":"runtime/tasks_8pyx/","title":"File tasks.pyx","text":"<p>FileList &gt; cython &gt; tasks.pyx</p> <p>Go to the source code of this file.</p> <p>Contains the Task and TaskEnvironment classes, which are used to represent tasks and their execution environments. </p>"},{"location":"runtime/tasks_8pyx/#namespaces","title":"Namespaces","text":"Type Name namespace tasks"},{"location":"runtime/tasks_8pyx/#classes","title":"Classes","text":"Type Name class AtomicTaskList class AtomicTaskSpace class BackendTaskList class BackendTaskSpace class CPUEnvironment class ComputeTask A compute task is a task that executes a user defined Python function on a device. class DataMovementTask A data movement task is a task that moves data between devices. class GPUEnvironment class Task Python Task interface. class TaskCollection class TaskCompleted This state specifies that a task has completed execution. class TaskCreated This state specifies that a task has been created but not yet spawned. class TaskEnvironment A TaskEnvironment is a collection of devices or other TaskEnvironments used to coordinate and synchronize kernels in theTask body. class TaskException This state specifies that a task has completed execution with an exception. class TaskList class TaskMapped This state specifies that a task has been mapped to a device set, but not yet resered its resources there. class TaskReady This state specifies that a task is \"ready\" to be launched. class TaskReserved This state specifies that a task has reserved its persistent resources (e.g. class TaskRunahead State: A task is executing in a stream but the body has completed. class TaskRunning This state specifies that a task is executing in a stream. class TaskSpace class TaskSpawned This state specifies that a task is ready to be mapped to a specific device set. class TaskState Abstract base class for Task State. class TerminalEnvironment An endpoint TaskEnvironment representing a single device. class _TaskLocals <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/tasks.pyx</code></p>"},{"location":"runtime/tasks_8pyx_source/","title":"File tasks.pyx","text":"<p>File List &gt; cython &gt; tasks.pyx</p> <p>Go to the documentation of this file. </p> <pre><code>\"\"\"!\n@file tasks.pyx\n@brief Contains the Task and TaskEnvironment classes, which are used to represent tasks and their execution environments.\n\"\"\"\n\nfrom collections import namedtuple, defaultdict\nimport functools \n\nfrom parla.utility.threads import Propagate\n\ncimport core\nfrom parla.cython import core\nfrom parla.cython import device\n\nfrom parla.common.globals import _Locals as Locals\nfrom parla.common.globals import get_stream_pool, get_scheduler\nfrom parla.common.globals import DeviceType as PyDeviceType\nfrom parla.common.globals import AccessMode, Storage\n\nfrom parla.common.parray.core import PArray\nfrom parla.common.globals import SynchronizationType as SyncType \n\nPyDevice = device.PyDevice\nPyCUDADevice = device.PyCUDADevice\nPyCPUDevice = device.PyCPUDevice\nPyArchitecture = device.PyArchitecture\nPyCUDAArchitecture = device.PyCUDAArchitecture\n\nDeviceType = PyDeviceType\n\nfrom abc import abstractmethod, ABCMeta\nfrom typing import Optional, List, Iterable, Union\nfrom typing import Awaitable, Collection, Iterable, FrozenSet\nfrom copy import copy\nimport threading\n\nimport traceback\nimport sys\n\nimport cython \ncimport cython\n\nfrom parla.cython import device, device_manager\n\nDeviceResourceRequirement = device.DeviceResourceRequirement \ncpu = device_manager.cpu\n\n\nclass TaskState(object, metaclass=ABCMeta):\n\"\"\"!\n    @brief Abstract base class for Task State.\n    \"\"\"\n\n    __slots__ = []\n\n    @property\n    @abstractmethod\n    def value(self) -&gt; int:\n        raise NotImplementedError()\n\n    @property\n    @abstractmethod\n    def is_terminal(self) -&gt; bool:\n        raise NotImplementedError()\n\n\nclass TaskCreated(TaskState):\n\"\"\"!\n    @brief This state specifies that a task has been created but not yet spawned.\n    \"\"\"\n\n    @property\n    def value(self):\n        return 0\n\n    @property\n    def is_terminal(self):\n        return False\n\n\nclass TaskSpawned(TaskState):\n\"\"\"!\n    @brief This state specifies that a task is ready to be mapped to a specific device set\n    \"\"\"\n    @property\n    def value(self):\n        return 1\n\n    @property\n    def is_terminal(self):\n        return False\n\n\nclass TaskMapped(TaskState):\n\"\"\"!\n    @brief This state specifies that a task has been mapped to a device set, but not yet resered its resources there\n    \"\"\"\n    @property\n    def value(self):\n        return 2\n\n    @property\n    def is_terminal(self):\n        return False\n\n\nclass TaskReserved(TaskState):\n\"\"\"!\n    @brief This state specifies that a task has reserved its persistent resources (e.g. memory) on its device set. Data movement tasks have been created\n    \"\"\"\n    @property\n    def value(self):\n        return 3\n\n    @property\n    def is_terminal(self):\n        return False\n\n\nclass TaskReady(TaskState):\n\"\"\"!\n    @brief This state specifies that a task is \"ready\" to be launched. Its dependencies have been dispatched to hardware queues (or have completed)\n    \"\"\"\n    @property\n    def value(self):\n        return 4\n\n    @property\n    def is_terminal(self):\n        return False\n\n\nclass TaskRunning(TaskState):\n\"\"\"!\n    @brief This state specifies that a task is executing in a stream.\n    \"\"\"\n\n    __slots__ = [\"func\", \"args\", \"dependencies\"]\n\n    @property\n    def value(self):\n        return 5\n\n    @property\n    def is_terminal(self):\n        return False\n\n    # The argument dependencies intentially has no type hint.\n    # Callers can pass None if they want to pass empty dependencies.\n    def __init__(self, func, args, dependencies: Optional[List]):\n        #print(\"TaskRunning init\", flush=True)\n        if dependencies is not None:\n            # d could be one of four types: Task, DataMovementTask, TaskID or other types.\n            #assert all(isinstance(d, (Task, TaskID)) for d in dependencies)\n            #self.dependencies = [\n            #    d for d in dependencies if isinstance(d, Task)]\n\n            #COMMENT(wlr): I think we shouldn't filter out the TaskID here. Otherwise, we cannot barrier on unspawned tasks\n            self.dependenciesdependencies = dependencies\n        else:\n            self.dependenciesdependencies = []\n\n        self.argsargs = args\n        self.funcfunc = func\n        #print(\"TaskRunning init done\", flush=True)\n\n    def clear_dependencies(self):\n        self.dependenciesdependencies = []\n\n    def __repr__(self):\n        if self.funcfunc:\n            # return \"TaskRunning({}, {}, {})\".format(self.func.__name__, self.args, self.dependencies)\n            return \"TaskRunning({})\".format(self.funcfunc.__name__)\n        else:\n            return \"Functionless task\"\n\n\nclass TaskRunahead(TaskState):\n\"\"\"!\n    @brief State: A task is executing in a stream but the body has completed.\n    \"\"\"\n    __slots__ = [\"return_value\"]\n\n    def __init__(self, ret):\n        self.return_valuereturn_value = ret\n\n    @property\n    def value(self):\n        return 6\n\n    @property\n    def is_terminal(self):\n        return False\n\n    def __repr__(self):\n        return \"TaskRunahead({})\".format(self.return_valuereturn_value)\n\nclass TaskCompleted(TaskState):\n\"\"\"!\n    @brief This state specifies that a task has completed execution.\n    \"\"\"\n\n    __slots__ = [\"return_value\"]\n\n    @property\n    def value(self):\n        return 7\n\n    def __init__(self, ret):\n        self.return_valuereturn_value = ret\n\n    @property\n    def is_terminal(self):\n        return True\n\n    def __repr__(self):\n        return \"TaskCompleted({})\".format(self.return_valuereturn_value)\n\n\nclass TaskException(TaskState):\n\"\"\"!\n    @brief This state specifies that a task has completed execution with an exception.\n    \"\"\"\n\n    __slots__ = [\"exception\", \"traceback\"]\n\n    @property\n    def value(self):\n        return 8\n\n    @property\n    def is_terminal(self):\n        return True\n\n    def __init__(self, exc=None, tb=None):\n        self.exceptionexception = exc\n        self.tracebacktraceback = tb\n\n    def __repr__(self):\n        return \"TaskException({})\".format(self.exceptionexception)\n\n\nTaskAwaitTasks = namedtuple(\"AwaitTasks\", [\"dependencies\", \"value_task\"])\n\n\n#TODO: Deprecate Task Locals\nclass _TaskLocals(threading.local):\n    def __init__(self):\n        super(_TaskLocals, self).__init__()\n        self.task_scopestask_scopes = []\n        self.spawn_countspawn_count = 0\n\n    @property\n    def ctx(self):\n        return getattr(self, \"_ctx\", None)\n\n    @ctx.setter\n    def ctx(self, v):\n        self._ctx_ctx = v\n\n    @property\n    def global_tasks(self):\n        return getattr(self, \"_global_tasks\", [])\n\n    @global_tasks.setter\n    def global_tasks(self, v):\n        self._global_tasks_global_tasks = v\n\n\ntask_locals = _TaskLocals()\n\nclass Task:\n\"\"\"!\n    @brief Python Task interface. This class is used to represent a task in the task graph.\n\n    A task is a unit of work that can be executed asynchronously. Tasks are created by calling the spawn decorator on a python code block.\n    Tasks are scheduled for execution as soon as they are created.\n\n    The task class is a wrapper around a C++ task object. The C++ task object is created when the task is spawned and is destroyed when all references to the task are gone.\n    The python interface stores the Python function task body and passes all metadata (mapping and precedence constraints) to the C++ runtime on creations.\n    \"\"\"\n\n    def __init__(self, taskspace=None, idx=None, state=TaskCreated(), scheduler=None, name=None):\n\"\"\"!\n        @brief Create a new task empty object. Task objects are always created empty on first reference and are populated by the runtime when they are spawned. \n        \"\"\"\n\n        self.idid = id(self)\n\n        #TODO(wlr): Should this be a stack for continuation tasks?\n        self._environment_environment = NoneTask constructor\n\n        self.taskspacetaskspace = taskspace\n        self.idxidx = idx\n\n        self.statestate = state\n        self.schedulerscheduler = scheduler\n\n        self.runaheadrunahead = SyncType.BLOCKING\n\n        if isinstance(self.taskspacetaskspace, TaskSpace):\n            self.namename = self.unpack_nameunpack_name()\n        elif name is None:\n            self.namename = \"UnnamedTask_\"+str(idx)\n        else:\n            #Allow user to specify a name (used for testing and debugging)\n            self.namename = name\n\n        self.inner_taskinner_task = core.PyInnerTask(self.idid, self)\n        self.update_nameupdate_name()\n        self._env_env = None\n\n    @property\n    def env(self):\n\"\"\"!\n        @brief The active TaskEnvironment of the task.\n        \"\"\"\n        return self._env_env\n\n    @env.setter\n    def env(self, v):\n        self._env_env = v\n\n    def unpack_name(self) -&gt; str:\n\"\"\"!\n        @brief Create the name of the task from the taskspace and index.\n        @return The name of the task.\n        \"\"\"\n\n        if self.taskspacetaskspace is not None:\n            space_name = self.taskspacetaskspace._name\n        else:\n            return self.namename\n\n        if isinstance(self.idxidx, Iterable):\n            task_name = \"_\".join(str(i) for i in (space_name, *self.idxidx))\n        else:\n            task_name = \"_\".join(str(i) for i in (space_name, self.idxidx))\n\n        return task_name\n\n    def update_name(self):\n\"\"\"!\n        @brief Update the name of the task from the taskspace and index.\n        \"\"\"\n        name = self.unpack_nameunpack_name()\n        self.namename = name\n\n        name = name.encode('utf-8')\n        self.inner_taskinner_task.update_name(name)\n\n    def get_name(self) -&gt; str:\n\"\"\"!\n        @brief Get the name of the task.\n        @return The name of the task.\n        \"\"\"\n        return self.namename\n\n    @property\n    def environment(self):\n\"\"\"!\n        @brief The active TaskEnvironment of the task.\n        \"\"\"\n        return self._environment_environment\n\n    @environment.setter\n    def environment(self, env):\n        self._environment_environment = env\n\n    def handle_runahead_dependencies(self):\n\"\"\"!\n        @brief Wait (or synchronize) on all events that the task depends on.\n\n        This handles the synchronization through the C++ interface.\n        \"\"\"\n\n        if self.runaheadrunahead == SyncType.NONE:\n            return\n\n        sync_type = self.runaheadrunahead\n\n        env = self.environmentenvironmentenvironment\n\n        if env.has(DeviceType.CPU):\n            sync_type = SyncType.BLOCKING\n\n        self.inner_taskinner_task.handle_runahead_dependencies(int(sync_type))\n\n\n    def py_handle_runahead_dependencies(self):\n\"\"\"!\n        @brief Wait (or synchronize) on all events that the task depends on.\n\n        This handles the synchronization through the Python interface.\n        \"\"\"\n        #print(\"Handling synchronization for task {}\".format(self.name), self.runahead, flush=True)\n        assert(self.environmentenvironmentenvironment is not None)\n\n        if self.runaheadrunahead == SyncType.NONE:\n            return\n        elif self.runaheadrunahead == SyncType.BLOCKING or isinstance(self.envenvenv, CPUEnvironment):\n            sync_events = self.environmentenvironmentenvironment.synchronize_events\n        elif self.runaheadrunahead == SyncType.NON_BLOCKING:\n            sync_events = self.environmentenvironmentenvironment.wait_events\n        else:\n            raise NotImplementedError(\"Unknown synchronization type: {}\".format(self.runaheadrunahead))\n\n        #print(\"Trying to get dependencies: \", self.name)\n\n        dependencies = self.get_dependenciesget_dependencies()\n\n        #print(\"Dependencies: {}\".format(dependencies), flush=True)\n\n        for task in dependencies:\n            assert(isinstance(task, Task))\n\n            task_env = task.environment\n            assert(task_env is not None)\n            if isinstance(task_env, CPUEnvironment):\n                continue\n\n            sync_events(task_env)\n\n    def instantiate(self, dependencies=None, list_of_dev_reqs=[], priority=None, dataflow=None, runahead=SyncType.BLOCKING):\n\"\"\"!\n        @brief Add metadata to a blank task object. Includes dependencies, device requirements, priority, and dataflow.\n        @param dependencies A list of tasks that this task depends on.\n        @param list_of_dev_reqs A list of device requirements/constraints for this task.\n        @param priority The priority of the task.\n        @param dataflow The collection of CrossPy objects and dependence direction (IN/OUT/INOUT).\n        @param runahead The runahead synchronization type of the task. Defaults to SyncType.BLOCKING.\n        \"\"\"\n\n        self.dependenciesdependencies = dependencies\n        self.prioritypriority = priority\n        self.runaheadrunahead = runahead\n\n        self.add_dependenciesadd_dependencies(dependencies)\n\n        # A base task class holds a dataflow since both task types,\n        # compute and data move, need it temporarily (e.g., compute tasks\n        # need dataflow to create data move tasks) or\n        # permanently (e.g., data move tasks need dataflow during its lifecycle).\n        # Each data move task only needs a single Parray at this moment,\n        # but moving multiple PArrays was also considered as the future work.\n        self.add_dataflowadd_dataflow(dataflow)\n\n    def _wait_for_dependency_events(self, enviornment):\n        pass\n\n    @property\n    def result(self):\n\"\"\"!\n        @brief The return value of the task body. This is only valid after the task has completed.\n\n        @return The return value of the task body or an exception if the task threw an exception. Returns None if the task has not completed.\n        \"\"\"\n\n        if isinstance(self.statestate, TaskCompleted):\n            return self.statestate.return_value\n        elif isinstance(self.statestate, TaskException):\n            return self.statestate.exception\n\n        return None\n\n    @abstractmethod\n    def _execute_task(self):\n        raise NotImplementedError()\n\n    @abstractmethod\n    def _finish(self, ctx):\n        raise NotImplementedError()\n\n    def run(self):\n\"\"\"!\n        @brief Run the task body.\n        \"\"\"\n\n        #assert self.assigned, \"Task was not assigned to a device before execution\"\n        #assert isinstance(self.req, EnvironmentRequirements), \"Task was not assigned to a enviornment before execution\"\n\n        task_state = None\n        try:\n            #assert(self._state, TaskRunning)\n\n            task_state = self._execute_task_execute_task()\n\n            task_state = task_state or TaskRunahead(None)\n\n        except Exception as e:\n            tb = traceback.format_exc()\n            task_state = TaskException(e, tb)\n\n            print(\"Exception in Task \", self, \": \", e, tb, flush=True)\n\n            if isinstance(e, KeyboardInterrupt):\n                print(\"You pressed Ctrl+C! In a Task!\", flush=True)\n                raise e\n            #print(\"Task {} failed with exception: {} \\n {}\".format(self.name, e, tb), flush=True)\n\n        finally:\n            assert(task_state is not None)\n            self.statestate = task_state\n\n    def __await__(self):\n        return (yield TaskAwaitTasks([self], self))\n\n    def add_dependencies(self, dependency_list, process=False):\n        return self.inner_taskinner_task.add_dependencies(dependency_list, process)\n\n    def get_num_dependencies(self):\n        return self.inner_taskinner_task.get_num_dependencies()\n\n    def get_num_dependents(self):\n        return self.inner_taskinner_task.get_num_dependents()\n\n    def get_num_blocking_dependencies(self):\n        return self.inner_taskinner_task.get_num_blocking_dependencies()\n\n    def get_num_unmapped_dependencies(self):\n        return self.inner_taskinner_task.get_num_unmapped_dependencies()\n\n    def get_dependencies(self):\n        dependency_list = self.inner_taskinner_task.get_dependencies()\n        return dependency_list\n\n    def get_dependents(self):\n        dependent_list = self.inner_taskinner_task.get_dependents()\n        return dependent_list\n\n    def get_assigned_devices(self):\n        return self.inner_taskinner_task.get_assigned_devices()\n\n    def add_dataflow(self, dataflow):\n        if dataflow is not None:\n            for in_parray_tpl in dataflow.input:\n                in_parray = in_parray_tpl[0]\n                in_parray_devid = in_parray_tpl[1]\n                cy_parray = in_parray.cy_parray\n                self.inner_taskinner_task.add_parray(cy_parray,\n                    AccessMode.IN, in_parray_devid)\n            for out_parray_tpl in dataflow.output:\n                out_parray = out_parray_tpl[0]\n                out_parray_devid = out_parray_tpl[1]\n                cy_parray = out_parray.cy_parray\n                self.inner_taskinner_task.add_parray(cy_parray,\n                    AccessMode.OUT, out_parray_devid)\n            for inout_parray_tpl in dataflow.inout:\n                inout_parray = inout_parray_tpl[0]\n                inout_parray_devid = inout_parray_tpl[1]\n                cy_parray = inout_parray.cy_parray\n                self.inner_taskinner_task.add_parray(cy_parray,\n                    AccessMode.INOUT, inout_parray_devid)\n\n    def notify_dependents_wrapper(self):\n\"\"\"!\n        @brief Mock dependents interface only used for testing. Notify dependents should be called internall by the scheduler\n        \"\"\"\n        status = self.inner_taskinner_task.notify_dependents_wrapper()\n        return status\n\n    def set_scheduler(self, scheduler):\n\"\"\"!\n        @brief Set the scheduler the task has been spawned by.\n        \"\"\"\n        self.schedulerscheduler = scheduler\n        self.inner_taskinner_task.set_scheduler(scheduler.inner_scheduler)\n\n    def set_state(self, state):\n\"\"\"!\n        @brief Set the state of the task (passed to the C++ runtime)\n        \"\"\"\n        self.inner_taskinner_task.set_state(state)\n\n    def get_state(self):\n\"\"\"!\n        @brief Get the state of the task (from the C++ runtime)\n        \"\"\"\n        return self.inner_taskinner_task.get_state()\n\n    def set_complete(self):\n        self.inner_taskinner_task.set_complete()\n\n    def set_device_reqs(self, device_reqs):\n\n\"\"\"!\n        @brief Set the device requirements of the task.\n        @param device_reqs A list of device requirements. Each device requirement can be a single device, a single architecture, or a tuple of devices and architectures.\n        \"\"\"\n\n        # device_reqs: a list of device requirements,\n        # a list of list of devices and frozensets\n        # a list of a single frozenset\n        for req in device_reqs:\n            if isinstance(req, DeviceResourceRequirement):\n                # Single device.\n                self.inner_taskinner_task.add_device_req(\n                    req.device.get_cy_device(),\n                    req.res_req.memory_sz, req.res_req.num_vcus)\n            elif isinstance(req, FrozenSet):\n                # Single architecture\n                self.inner_taskinner_task.begin_arch_req_addition()\n                for member in req:\n                    self.inner_taskinner_task.add_device_req(\n                        member.device.get_cy_device(),\n                        member.res_req.memory_sz, member.res_req.num_vcus)\n                self.inner_taskinner_task.end_arch_req_addition()\n            elif isinstance(req, List):\n                # Multi-optional requirements\n                self.inner_taskinner_task.begin_multidev_req_addition()\n                for member in req: \n                    self.set_device_reqsset_device_reqs([member])\n                self.inner_taskinner_task.end_multidev_req_addition()\n\n    def __repr__(self):\n        return f\"Task({self.name})\"\n\n    def __hash__(self):\n            return hash(self.namename)\n\n    def __await__(self):\n        return (yield TaskAwaitTasks([self], self))\n\n    def add_stream(self, stream):\n\"\"\"\n        @brief Record a python managed cupy stream to the task.\n        \"\"\"\n        self.inner_taskinner_task.add_stream(stream)\n\n    def add_event(self, event):\n\"\"\"\n        @brief Record a python managed cupy event to the task.\n        \"\"\"\n        self.inner_taskinner_task.add_event(event)\n\n\nclass ComputeTask(Task):\n\"\"\"!\n    @brief A compute task is a task that executes a user defined Python function on a device.\n    \"\"\"\n\n\n    def __init__(self, taskspace=None, idx=None, state=TaskCreated(), scheduler=None, name=None):\n        super().__init__(taskspace, idx, state, scheduler, name)\n\n    def instantiate(self, function, args, dependencies=None, dataflow=None, priority=0, runahead=SyncType.BLOCKING):\n\"\"\"!\n        @brief Instantiate the task with a function and arguments.\n        @param function The function to execute.\n        @param args The arguments to the function.\n        @param dependencies A list of tasks that this task depends on.\n        @param dataflow The dataflow object that describes the data dependencies of the task. (Crosspy and data direction (IN/OUT/INOUT))\n        @param priority The priority of the task.\n        @param runahead The type of synchronization the task uses for runahead scheduling.\n        \"\"\"\n\n        #Holds the original function\n        self.base_functionbase_function = function\n\n        #Holds the function that will be executed (and its continuation)\n        self.funcfunc = function\n\n        #Holds the arguments to the function\n        self.argsargs = args\n\n        #Holds the dataflow object (in/out parrays)\n        self.dataflowdataflow = dataflow\n\n        super().instantiate(dependencies=dependencies, priority=priority, dataflow=dataflow, runahead=runahead)\n\n    def _execute_task(self):\n\"\"\"!\n        @brief Run the task body with the saved arguments. If the body is a continuation, run the continuation.\n        \"\"\"\n        return self.funcfunc(self, *self.argsargs)\n\n    def cleanup(self):\n\"\"\"!\n        @brief Cleanup the task by removing the function, arguments, and references to its data objects.\n        \"\"\"\n        self.funcfunc = None\n        self.argsargs = None\n        self.dataflowdataflow = None\n\n    def _finish(self, context):\n        pass\n\n\nclass DataMovementTask(Task):\n\"\"\"!\n    @brief A data movement task is a task that moves data between devices. It is not user defined.\n    \"\"\"\n\n    def __init__(self, parray: PArray=None, access_mode=None, \\\n        assigned_devices: List[PyDevice]=None, taskspace=None, \\\n        idx=0, state=TaskCreated(), scheduler=None, name=None):\n        super().__init__(taskspace, idx, state, scheduler, name)\n        self.parray = parray\n        self.access_mode = access_mode\n        self.assigned_devices = assigned_devices\n\n    def instantiate(self, attrs: core.DataMovementTaskAttributes, scheduler, runahead=SyncType.BLOCKING):\n\"\"\"!\n        @brief Instantiate the data movement task with attributes from the C++ runtime.\n        @param attrs The attributes of the data movement task.\n        @param scheduler The scheduler that the task is created under.\n        @param runahead The type of synchronization the task uses for runahead scheduling.\n        \"\"\"\n        self.namenamename = attrs.name\n        self.parrayparray = attrs.parray\n        self.access_modeaccess_mode = attrs.access_mode\n        self.assigned_devicesassigned_devices = attrs.assigned_devices\n        self.schedulerschedulerscheduler = scheduler\n        self.inner_taskinner_task.set_c_task(attrs.c_attrs)\n        self.inner_taskinner_task.set_py_task(self)\n        self.dev_iddev_id = attrs.dev_id\n        self.runaheadrunaheadrunahead = runahead\n\n    def _execute_task(self):\n\"\"\"!\n        @brief Run the data movement task. Calls the PArray interface to move the data to the assigned devices.\n        Devices are given by the local relative device id within the TaskEnvironment.\n        \"\"\"\n        write_flag = True if self.access_modeaccess_mode != AccessMode.IN else False\n\n        #TODO: Get device manager from task environment instead of scheduler at creation time\n        device_manager = self.schedulerschedulerscheduler.device_manager\n\"\"\"\n        for device in self.assigned_devices:\n            global_device_id = device.get_global_id()\n            self.parray._auto_move(device_manager.get_parray_id(global_device_id),\n                                   write_flag)\n        \"\"\"\n#self.parray._auto_move(device_manager.get_parray_id(self.dev_id), write_flag)\n        target_dev = self.assigned_devicesassigned_devices[0]\n        global_id = target_dev.get_global_id()\n        parray_id = device_manager.globalid_to_parrayid(global_id)\n        # print(\"Attempt to Move: \", self.parray.name, \" to a device \", parray_id, flush=True)\n        self.parrayparray._auto_move(parray_id, write_flag)\n        #print(self, \"Move PArray \", self.parray.ID, \" to a device \", parray_id, flush=True)\n        #print(self, \"STATUS: \", self.parray.print_overview())\n        return TaskRunahead(0)\n\n\n\ndef create_device_env(device):\n\"\"\"!\n    @brief Create a terminal device environment from a PyDevice.\n    @param device The PyDevice to create the environment from.\n    \"\"\"\n    if isinstance(device, PyCPUDevice):\n        return CPUEnvironment(device), DeviceType.CPU\n    elif isinstance(device, PyCUDADevice):\n        return GPUEnvironment(device), DeviceType.CUDA\n\ndef create_env(sources):\n\"\"\"!\n    @brief Create the union  TaskEnvironment from a list of TaskEnvironments or PyDevices.\n    @param sources The list of PyDevices (or Environments) to create the new environment from.\n    \"\"\"\n\n    targets = []\n\n    for env in sources:\n        if isinstance(env, PyDevice):\n            device = env\n            new_env, dev_type = create_device_env(env)\n            targets.append(new_env)\n\n    if len(targets) == 1:\n        return targets[0]\n    else:\n        return TaskEnvironment(targets)\n\nclass TaskEnvironment:\n\n\"\"\"!\n    @brief A TaskEnvironment is a collection of devices or other TaskEnvironments used to coordinate and synchronize kernels in the Task body.\n    \"\"\"\n\n    def __init__(self, environment_list, blocking=False):\n\n        self._store_store = Storage()\n\n        self.device_dictdevice_dict = defaultdict(list)\n\n        self.env_listenv_list = []\n        self.stream_liststream_list = []\n        self.is_terminalis_terminal = False\n        self.blockingblocking = blocking\n        self._device_device = None\n\n        self.device_listdevice_list = []\n        self._global_device_ids_global_device_ids = set()\n        self.event_dictevent_dict = {}\n        self.event_dictevent_dict['default'] = None\n\n        for env in environment_list:\n            for dev in env.devices:\n                self.device_listdevice_list.append(dev)\n                self.device_dictdevice_dict[dev.architecture].append(dev)\n\n            self._global_device_ids_global_device_ids  = self._global_device_ids_global_device_ids.union(env.global_ids)\n            self.env_listenv_list.append(env)\n\n    @property\n    def global_ids(self):\n\"\"\"\n        Return the global Parla device ids of the devices in this environment.\n        \"\"\"\n        return self._global_device_ids_global_device_ids\n\n    @property\n    def gpu_ids(self):\n\"\"\"\n        Returns the CUDA_VISIBLE_DEVICES ids of the GPU devices in this environment.\n        \"\"\"\n        return [device_env.get_parla_device().id for device_env in self.device_dictdevice_dict[DeviceType.CUDA]]\n\n    @property\n    def gpu_id(self):\n\"\"\"\n        Returns the CUDA_VISIBLE_DEVICES id of the first GPU device in this environment.\n        \"\"\"\n        return self.device_dictdevice_dict[DeviceType.CUDA][0].get_parla_device().id\n\n    def __repr__(self):\n        return f\"TaskEnvironment({self.env_list})\"\n\n    def get_parla_device(self):\n\"\"\"\n        Returns the Parla device associated with this environment.\n        \"\"\"\n        return self._device_device\n\n    def get_library_device(self):\n\"\"\"\n        Returns the library device associated with this environment. (e.g. cupy.cuda.Device)\n        \"\"\"\n        return self._device_device.device\n\n    def has(self, device_type):\n\"\"\"\n        Returns True if this environment has a device of the given type.\n        \"\"\"\n        return device_type in self.device_dictdevice_dict\n\n    @property\n    def streams(self):\n        if self.is_terminalis_terminal:\n            return self.stream_liststream_list\n        else:\n            return [None]\n\n    @property\n    def stream(self):\n\"\"\"\n        Returns the Parla stream associated with this environment.\n        \"\"\"\n        return self.streamsstreams[0]\n\n    @property\n    def cupy_stream(self):\n\"\"\"\n        Returns the cupy stream associated with this environment.\n        \"\"\"\n        return self.streamstream.stream\n\n    def loop(self, envlist=None):\n        if envlist is None:\n            envlist = self.contextscontexts\n\n        for env in envlist:\n            env.__enter__()\n            yield env\n            env.__exit__(None, None, None)\n\n    def get_devices(self, arch):\n        return self.device_dictdevice_dict[arch]\n\n    def get_all_devices(self):\n        #return sum(self.device_dict.values(), [])\n        return self.device_listdevice_list\n\n    @property\n    def contexts(self):\n        return self.env_listenv_list\n\n    @property\n    def devices(self):\n        #TODO: Improve this\n        devices = self.get_all_devicesget_all_devices()\n        #print(f\"Devices: {devices}\")\n        return devices\n\n    @property\n    def device(self):\n        return self.devicesdevices[0]\n\n    def get_cupy_devices(self):\n        return [dev.device for dev in self.get_devicesget_devices(DeviceType.CUDA)]\n\n    def synchronize(self, events=False, tags=['default'], return_to_pool=True):\n        #print(f\"Synchronizing {self}..\", flush=True)\n\n        if self.is_terminalis_terminal:\n            if events:\n                for tag in tags:\n                    #print(\"SELF: \", self, f\"Synchronizing on event {tag}..\", flush=True)\n                    self.synchronize_event(tag=tag)\n            else:\n                for stream in self.stream_liststream_list:\n                    #print(\"SELF: \", self, f\"Synchronizong on stream {stream}\", flush=True)\n                    stream.synchronize()\n\n            if return_to_pool:\n                stream_pool = get_stream_pool()\n                for stream in self.stream_liststream_list:\n                    stream_pool.return_stream(stream)\n        else:\n            for env in self.env_listenv_list:\n                #print(\"Non terminal: Recursing\", flush=True)\n                env.synchronize(events=events, tags=tags)\n\n    def __enter__(self):\n        #print(\"Entering environment:\", self.env_list, flush=True)\n\n        if len(self.env_listenv_list) == 0:\n            raise RuntimeError(\"[TaskEnvironment] No environment or device is available.\")\n\n        Locals.push_context(self)\n\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        #print(\"Exiting environment\", self.env_list, flush=True)\n        ret = False\n\n        Locals.pop_context()\n\n        return ret \n\n    def __getitem__(self, index):\n\n        if isinstance(index, int):\n            return self.env_listenv_list[index]\n\n        return create_env(self.env_listenv_list[index])\n\n\n    def store(self, key, value):\n        self._store_store.store(key, value)\n\n    def retrieve(self, key):\n        return self._store_store.retrieve(key)\n\n    @property\n    def storage(self):\n        return self._store_store\n\n    def __len__(self):\n        return len(self.env_listenv_list)\n\n    def return_streams(self):\n        for env in self.env_listenv_list:\n            env.return_streams()\n\n        stream_pool = get_stream_pool()\n        for stream in self.stream_liststream_list:\n            stream_pool.return_stream(stream)\n\n    #TODO: MOVE THIS TO C++!!!!\n    def finalize(self):\n        stream_pool = get_stream_pool()\n\n        for env in self.env_listenv_list:\n            env.finalize()\n\n        for stream in self.stream_liststream_list:\n            stream.synchronize()\n            stream_pool.return_stream(stream)\n\n    def __contains__(self, obj):\n        #TODO(wlr): Add optional support for CuPy device \n        if isinstance(obj, PyDevice):\n            return obj in self.device_listdevice_list\n        elif isinstance(obj, TaskEnvironment):\n            return obj.global_ids.issubset(self.global_idsglobal_ids)\n        else:\n            raise TypeError(\"The comparison is not supported. (Supported Types: TaskEnvironment)\")\n\n    def parfor(self, envlist=None):\n\n        if envlist is None:\n            envlist = self.contextscontexts\n\n        def deco(func):\n            @functools.wraps(func)\n            def wrapper(*args, **kwargs):\n                res = [Exception('Parallel Launcher [%s] raised an exception!' % (\n                    func.__name__))]\n\n                def EnvHandler(env, idx):\n                    Locals.index = idx \n                    env.__enter__()\n                    try:\n                        res[0] = func(env, *args, **kwargs)\n                    except Exception as e:\n                        res[0] = e\n                    finally:\n                        env.__exit__(None, None, None)\n\n                thread_list = []\n                return_list = []\n                for idx, env in enumerate(envlist):\n                    thread_list.append(Propagate(target=EnvHandler, args=(env, idx)))\n                try:\n                    for t in thread_list:\n                        t.start()\n                    for t in thread_list:\n                        t.join()\n                        return_list.append(t.value)\n                except Exception as e:\n                    print('Unhandled exception in Propagate wrapper', flush=True)\n                    raise e\n\n                ret = res[0]\n                if isinstance(ret, BaseException):\n                    raise ret\n                return ret\n            return wrapper()\n        return deco\n\n    def __contains__(self, obj):\n        if isinstance(obj, PyDevice):\n            return obj.global_id in self._global_device_ids_global_device_ids\n        elif isinstance(obj, TaskEnvironment):\n            return obj.global_ids.issubset(self._global_device_ids_global_device_ids)\n        else:\n            raise TypeError(\"Invalid type for __contains__\")\n\n\n    def wait_events(self, env, tags=['default']):\n\"\"\"\n        Wait for tagged events in the given environment on all streams in this environment.\n        \"\"\"\n\n        #print(\"Waiting for events\", env, tags, flush=True)\n\n        if not isinstance(tags, list):\n            tags = [tags]\n\n        for device in env.devices:\n            for stream in device.streams:\n                for tag in tags:\n                    #print(\"++Waiting for event\", device, stream, tag, flush=True)\n                    device.wait_event(stream=stream, tag=tag)\n\n    def synchronize_events(self, env, tags=['default']):\n\"\"\"\n        Synchronize tagged events in the given environment on all streams in this environment.\n        \"\"\"\n\n        if not isinstance(tags, list):\n            tags = [tags]\n\n        for device in env.devices:\n            for stream in device.streams:\n                for tag in tags:\n                    #print(\"++Synchronizing event\", device, stream, tag, flush=True)\n                    device.synchronize_event(tag=tag)\n\n    def record_events(self, tags=['default']):\n\"\"\"\n        Record tagged events on all streams in this environment.\n        \"\"\"\n\n        if not isinstance(tags, list):\n            tags = [tags]\n\n        for device in self.devicesdevices:\n            for stream in device.streams:\n                for tag in tags:\n                    #print(\"--Recording event\", device, stream, tag, flush=True)\n                    device.record_event(stream=stream, tag=tag)\n\n    def create_events(self, tags=['default']):\n\"\"\"\n        Create tagged events on all devices in this environment.\n        \"\"\"\n\n        if not isinstance(tags, list):\n            tags = [tags]\n\n        for device in self.devicesdevices:\n            for tag in tags:\n                device.create_event(tag=tag)\n\n    def write_to_task(self, task):\n\n        for device in self.devicesdevices:\n            device.write_to_task(task)\n\n    def write_streams_to_task(self, task):\n\n        for device in self.devicesdevices:\n            device.write_streams_to_task(task)\n\n\nclass TerminalEnvironment(TaskEnvironment):\n\n\"\"\"!\n    @brief An endpoint TaskEnvironment representing a single device. These are where most actual computation will take place.\n\n    @details A TerminalEnviornment is an edpoint TaskEnvironment that is made of a single device (CPU or GPU). If they are a GPU they will set the current CuPy context accordingly.\n    \"\"\"\n\n    def  __init__(self,  device, blocking=False):\n        super(TerminalEnvironment, self).__init__([], blocking=blocking)\n        self.device_dictdevice_dict[device.architecture].append(self)\n        self.device_listdevice_list.append(self)\n        self._device_device_device = device\n        self._arch_type_arch_type = device.architecture\n        self.is_terminalis_terminalis_terminal = True\n\n        self._global_device_ids_global_device_ids_global_device_ids = {device.get_global_id()}\n\n    def __repr__(self):\n        return f\"TerminalEnvironment({self._device})\"\n\n    @property\n    def contexts(self):\n        return [self]\n\n    @property\n    def devices(self):\n        return [self]\n\n    @property\n    def device(self):\n        return self\n\n    @property\n    def architecture(self):\n        return self._arch_type_arch_type\n\n    def __eq__(self, other):\n        if isinstance(other, int) or isinstance(other, PyDevice):\n            return self._device_device_device == other\n        elif isinstance(other, TerminalEnvironment):\n            return self._device_device_device == other._device\n        else:\n            return False\n\n    def __hash__(self):\n        return hash(self._device_device_device)\n\n    def __call__(self):\n        return self._device_device_device\n\n    def __len__(self):\n        return 1\n\n    def __getitem__(self, index):\n        if index == 0:\n            return self\n        else:\n            raise IndexError(\"TerminalEnvironment only has one device.\")\n\n    def record_event(self, stream=None, tag='default'):\n\"\"\"!\n        @brief Record a CUDA event on the current stream. \n        \"\"\"\n\n        if stream is None:\n            stream = Locals.stream \n\n        if tag not in self.event_dictevent_dict:\n            raise RuntimeError(\"Event must be created before recording.\")\n\n        event = self.event_dictevent_dict[tag]\n        if event is not None:\n            #print(\"TEST RECORD: \", event, stream.stream)\n            event.record(stream.stream)\n\n    def synchronize_event(self, tag='default'):\n\"\"\"!\n        @brief Synchronize host thread to the tagged CUDA event (sleep or waiting). \n        \"\"\"\n\n        if tag not in self.event_dictevent_dict:\n            raise RuntimeError(\"Event must be created before synchronizing.\")\n\n        event = self.event_dictevent_dict[tag]\n\n        if event is not None:\n            #print(\"TEST EVENT SYNC: \", event, flush=True)\n            event.synchronize()\n\n    def wait_event(self, stream=None, tag='default'):\n\"\"\"!\n        @brief Submit a cross-stream wait on the tagged CUDA event to the current stream. All further work submitted on the current stream will wait until the tagged event is recorded.\n        \"\"\"\n        if tag not in self.event_dictevent_dict:\n            raise RuntimeError(\"Event must be created before waiting.\")\n\n        event = self.event_dictevent_dict[tag]\n\n        if event is not None:\n            #print(\"TEST WAIT EVENT: \", stream, event)\n            stream.wait_event(event)\n\n    def create_event(self, stream=None, tag='default'):\n\"\"\"!\n        @brief Create a CUDA event on the current stream.  It can be used for synchronization or cross-stream waiting. It is not recorded by default at creation.\n        \"\"\"\n        if stream is None:\n            stream = Locals.stream\n        self.event_dictevent_dict[tag] = stream.create_event()\n\n    def write_to_task(self, task):\n\"\"\"!\n        @brief Store stream and event pointers in C++ task\n        \"\"\"\n        for stream in self.streamsstreams:\n            task.add_stream(stream.stream)\n\n        #for event in self.event_dict.values():\n        #    task.add_event(event)\n        task.add_event(self.event_dictevent_dict['default'])\n\n    def write_streams_to_task(self, task):\n\"\"\"!\n        @brief Record stream pointers into C++ task\n        \"\"\"\n        for stream in self.streamsstreams:\n            task.add_stream(stream.stream)\n\n    def write_events_to_task(self, task):\n\"\"\"!\n        @brief Record event pointers in C++ task\n        \"\"\"\n        #for event in self.event_dict.values():\n                #    task.add_event(event)\n        task.add_event(self.event_dictevent_dict['default'])\n\n\n\n\n\nclass CPUEnvironment(TerminalEnvironment):\n\n    def __init__(self,  device, blocking=False):\n        super(CPUEnvironment, self).__init__(device, blocking=blocking)\n\n    def __repr__(self):\n        return f\"CPUEnvironment({self._device})\"\n\n    def __enter__(self):\n        #print(\"Entering CPU Environment: \", self, flush=True)\n        Locals.push_context(self)\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        #print(\"Exiting CPU Environment: \", self, flush=True)\n        Locals.pop_context()\n        return False\n\n    def __len__(self):\n            return 1\n\n    def __getitem__(self, index):\n        if index == 0:\n            return self\n\n    def finalize(self):\n        pass\n\n    def return_streams(self):\n        pass\n\nclass GPUEnvironment(TerminalEnvironment):\n\n    def __init__(self, device, blocking=False):\n        super(GPUEnvironment, self).__init__(device, blocking=blocking)\n\n        stream_pool = get_stream_pool()\n        stream = stream_pool.get_stream(device=device)\n        self.stream_list.append(stream)\n\n        self.event_dict['default'] = stream.create_event()\n\n\n    def __repr__(self):\n        return f\"GPUEnvironment({self._device})\"\n\n\n    def __enter__(self):\n        #print(\"Entering GPU Environment: \", self, flush=True)\n        Locals.push_context(self)\n        self.active_stream = self.stream_list[0]\n        ret_stream = self.active_stream.__enter__()\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        #print(\"Exiting GPU Environment: \", self, flush=True)\n        ret = False\n        self.active_stream.__exit__(exc_type, exc_val, exc_tb)\n        Locals.pop_context()\n        return ret \n\n    def finalize(self):\n        stream_pool = get_stream_pool()\n        for stream in self.stream_list:\n            stream.synchronize()\n            stream_pool.return_stream(stream)\n\n    def return_streams(self):\n        stream_pool = get_stream_pool()\n        for stream in self.stream_list:\n            stream_pool.return_stream(stream)\n\n\n\n\ncpdef flatten_tasks(tasks, list output=[]):\n\n    #Unpack any TaskCollections\n    if isinstance(tasks, TaskCollection):\n        tasks = tasks.tasks\n\n    if isinstance(tasks, list) or isinstance(tasks, tuple):\n        for i in range(0, len(tasks)):\n            task = tasks[i]\n            flatten_tasks(task, output)\n    elif isinstance(tasks, Task):\n        output.append(tasks)\n    elif isinstance(tasks, dict):\n        keys = tasks.keys()\n        for i in range(0, len(keys)):\n            task = tasks[keys[i]]\n            flatten_tasks(task, output)\n    elif isinstance(tasks, Iterable):\n        #NOTE: This is not threadsafe if iterated concurrently\n        for task in tasks:\n            flatten_tasks(task, output)\n    else:\n        raise TypeError(\"TaskCollections can only contain Tasks or Iterable Containers of Tasks\")\n\ncdef step(tuple prefix, v):\n    return prefix + (v,)\n\n@cython.boundscheck(False)\ncpdef cy_parse_index(tuple prefix, index, list index_list, int depth=0, shape=None, start=None):\n    #Proof of concept for boundable index parsing\n    #TODO: Performance improvements (avoid recursion, etc.)\n    shape_flag = (shape is not None)\n\n    cdef int max_dim = len(shape) if shape_flag else 0\n    cdef int dim = len(prefix)\n\n    if dim &gt;= max_dim:\n        shape = None\n\n    shape_flag = (shape is not None)\n    start_flag = (start is not None)\n\n    cdef int lower_boundary = start[dim] if start_flag else 0\n    cdef int upper_boundary = lower_boundary + shape[dim] if shape_flag else -1\n\n    cdef int istart = 0\n    cdef int istop = 0\n    cdef int istep = 1\n\n    #TODO(wlr): Iterable check should be more robust (try/catch)\n\n    if len(index) &gt; 0:\n        i, *remainder = index\n\n        if isinstance(i, TaskCollection):\n            i = i.tasks\n\n        if isinstance(i, slice):\n            istart = max(i.start, lower_boundary) if i.start is not None else lower_boundary\n            if upper_boundary &gt;= 0:\n                istop = min(i.stop, upper_boundary) if i.stop is not None else upper_boundary\n            else:\n                istop = i.stop if i.stop is not None else -1\n            istep = i.step or 1\n\n            for v in range(istart, istop, istep):\n                cy_parse_index(step(prefix, v), remainder, index_list, depth+1, shape, start)\n        elif isinstance(i, Iterable):\n            if isinstance(i, str):\n                cy_parse_index(step(prefix, i), remainder, index_list, depth+1, shape, start)\n            elif isinstance(i, tuple) or isinstance(i, list):\n                for k in range(0, len(i)):\n                    cy_parse_index(step(prefix, i[k]), remainder, index_list, depth+1, shape, start)\n            elif isinstance(i, dict):\n                keys = i.keys()\n                for k in range(0, len(keys)):\n                    cy_parse_index(step(prefix, i[keys[k]]), remainder, index_list, depth+1, shape, start)\n            else:\n                #NOTE: This is not threadsafe if the iterator is shared\n                for v in i:\n                    cy_parse_index(step(prefix, v), remainder, index_list, depth+1, shape, start)\n        elif isinstance(i, int) or isinstance(i, float):\n            if (lower_boundary &lt;= i) and ( (upper_boundary &lt; 0) or (i &lt; upper_boundary) ):\n                cy_parse_index(step(prefix, i), remainder, index_list, depth+1, shape, start)\n        else:\n            cy_parse_index(step(prefix, i), remainder, index_list, depth+1, shape, start)\n    else:\n        index_list.append(prefix)\n\ndef parse_index(prefix, index,  step,  stop):\n\"\"\"Traverse :param:`index`, update :param:`prefix` by applying :param:`step`, :param:`stop` at leaf calls.\n\n    :param prefix: the initial state\n    :param index: the index tuple containing subindexes\n    :param step: a function with 2 input arguments (current_state, subindex) which returns the next state, applied for each subindex.\n    :param stop: a function with 1 input argument (final_state), applied each time subindexes exhaust.\n    \"\"\"\n    if len(index) &gt; 0:\n        i, *rest = index\n\n        if isinstance(i, TaskCollection):\n            i = i.tasks \n\n        if isinstance(i, slice):\n            for v in range(i.start or 0, i.stop, i.step or 1):\n                parse_index(step(prefix, v), rest, step, stop)\n        elif isinstance(i, Iterable):\n            for v in i:\n                parse_index(step(prefix, v), rest, step, stop)\n        else:\n            parse_index(step(prefix, i), rest, step, stop)\n    else:\n        stop(prefix)\n\n\ncpdef get_or_create_tasks(taskspace, list index_list, create=True):\n    cdef list task_list = []\n    cdef list new_tasks = []\n    cdef list new_index = []\n\n    tasks = taskspace._tasks\n\n    for i in range(0, len(index_list)):\n        index = index_list[i]\n\n        if index in tasks:\n            task = tasks[index]\n            task_list.append(task)\n        elif create:\n            task = ComputeTask(taskspace=taskspace, idx=index)\n            tasks[index] = task\n            task_list.append(task)\n            new_tasks.append(task)\n            new_index.append(index)\n\n    return task_list, (new_tasks, new_index)\nclass TaskCollection:\n\n    def __init__(self, tasks, name=None, flatten=True):\n        self._name_name = name\n        if flatten:\n            self._tasks_tasks = []\n            flatten_tasks(tasks, self._tasks_tasks)\n        else:\n            self._tasks_tasks = tasks\n\n    @property\n    def tasks(self):\n        return self._tasks_tasks\n\n    def __await__(self):\n        return (yield TaskAwaitTasks(self.taskstasks, None))\n\n    def __len__(self):\n        return len(self.taskstasks)\n\n    def __iter__(self):\n        return iter(self.taskstasks)\n\n    def __contains__(self, task):\n        return task in self._tasks_tasks\n\n    def __repr__(self):\n        return \"TaskCollection: {}\".format(self.taskstasks)\n\n    def __str__(self):\n        return repr(self)\n\n    def __hash__(self):\n        return hash(id(self))\n\n    def __eq__(self, other):\n        return id(self._tasks_tasks) == id(self._tasks_tasks)\n\n    def __ne__(self, other):\n        return not self.__eq____eq__(other)\n\n    def __add__(self, other):\n        return TaskCollection(self._tasks_tasks + other._tasks)\n\n    def __iadd__(self, other):\n        self._tasks_tasks += other._tasks\n        return self\n\n\n\nclass TaskList(TaskCollection):\n\n    def __init__(self, tasks, name=None, flatten=True):\n\n        if isinstance(tasks, TaskList):\n            self._name_name_name = tasks._name\n            self._tasks_tasks_tasks = tasks.tasks\n        else:\n            super().__init__(tasks, name, flatten)\n\n    def __getitem__(self, index):\n        task_list = self.taskstasks[index]\n\n        if isinstance(task_list, list):\n            return TaskList(task_list, flatten=False)\n        else:\n            #Return a single task\n            return task_list\n\n    def __repr__(self):\n        return \"TaskList: {}\".format(self.taskstasks)\n\n    def __add__(self, other):\n        return TaskList(self._tasks_tasks_tasks + other._tasks)\n\n    def __iadd__(self, other):\n        self._tasks_tasks_tasks += other._tasks\n        return self\n\ncpdef wait(barrier):\n\n    if isinstance(barrier, core.CyTaskList):\n        barrier = BackendTaskList(barrier)\n\n    barrier.wait()\n\nclass AtomicTaskList(TaskList):\n\n    def __init__(self, tasks, name=None, flatten=True):\n        super().__init__(tasks, name, flatten)\n        self.inner_barrierinner_barrier = core.PyTaskBarrier(self.taskstasks)\n\n    def __repr__(self):\n        return \"AtomicTaskList: {}\".format(self.taskstasks)\n\n    def __add__(self, other):\n        return AtomicTaskList(self._tasks_tasks_tasks + other._tasks)\n\n    def __iadd__(self, other):\n        raise TypeError(\"Cannot modify an AtomicTaskList\")\n\n    def wait(self):\n        self.inner_barrierinner_barrier.wait()\n\nclass BackendTaskList(TaskList):\n\n    def __init__(self, tasks, name=None, flatten=True):\n        self.inner_barrierinner_barrier = core.PyTaskBarrier(tasks)\n        self._tasks_tasks_tasks_tasks = None\n        self._name_name_name_name = name \n\n    def __repr__(self):\n        return \"BackendTaskList: {}\"\n\n    def wait(self):\n        self.inner_barrierinner_barrier.wait()\n\n\n_task_space_globals = {}\n\nclass TaskSpace(TaskCollection):\n\n    def __init__(self, name=\"\", create=True, shape=None, start=None):\n        self._name_name_name = name\n        self._id_id = id(self)\n        self._tasks_tasks_tasks = {}\n        self._create_create = create\n\n        if shape is not None and not isinstance(shape, tuple):\n            shape = (shape,)\n        if start is not None and not isinstance(start, tuple):\n            start = (start,)\n\n        self.shapeshape = shape\n        self.startstart = start\n\n        global _task_space_globals\n        _task_space_globals[self._id_id] = self\n\n        self._view_view = None\n\n    def __getitem__(self, index):\n\n        create = self._create_create\n        tasks = self._tasks_tasks_tasks\n\n        if isinstance(index, int):\n            start_flag = (self.startstart is not None)\n            shape_flag = (self.shapeshape is not None)\n            lower_boundary = self.startstart[0] if start_flag else 0\n            upper_boundary = lower_boundary + self.shapeshape[0] if shape_flag else -1\n\n            idx = [(index,)] if (index &gt;= lower_boundary) and ((index &lt;= upper_boundary) or (upper_boundary  &lt; 0)) else []\n            task_list, _= get_or_create_tasks(self, idx, create=create)\n\n            if len(task_list) == 1:\n                return task_list[0]\n            return TaskList(task_list)\n\n        if isinstance(index, str):\n            task_list, _ = get_or_create_tasks(self, [(index,)], create=create)\n            if len(task_list) == 1:\n                return task_list[0]\n            return TaskList(task_list)\n\n\n        if not isinstance(index, tuple):\n            index = (index,)\n\n        index_list = []\n        cy_parse_index((), index, index_list, shape=self.shapeshape, start=self.startstart)\n        task_list, _ = get_or_create_tasks(self, index_list, create=self._create_create)\n\n        if len(task_list) == 1:\n            return task_list[0]\n        else:\n            return TaskList(task_list)\n\n    @property\n    def tasks(self):\n        return self._tasks_tasks_tasks.values()\n\n    @property\n    def name(self):\n        return self._name_name_name\n\n    @property\n    def view(self):\n        if self._view_view is None:\n            self._view_view = type(self)(name=self._name_name_name, create=False, shape=self.shapeshape, start=self.startstart)\n            self._view_view._tasks = self._tasks_tasks_tasks\n        return self._view_view\n\n    def __repr__(self):\n        return f\"TaskSpace({self._name}, ntasks={len(self)})\"\n\n    def __add__(self, other):\n        merged_dict = {**self._tasks_tasks_tasks, **other._tasks}\n        merged_name = f\"{self._name} + {other._name}\"\n        new_space = type(self)(name=merged_name, create=False, shape=self.shapeshape, start=self.startstart)\n        new_space._tasks = merged_dict\n        return new_space\n\n    def __iadd__(self, other):\n        self._tasks_tasks_tasks.update(other._tasks)\n        return self\n\n\nclass AtomicTaskSpace(TaskSpace):\n\n    def __init__(self, name=\"\", create=True, shape=None, start=None):\n        super().__init__(name, create, shape, start)\n        self.inner_spaceinner_space = core.PyTaskBarrier()\n\n    def __repr__(self):\n        return f\"AtomicTaskSpace({self._name}, ntasks={len(self)})\"\n\n\n    def __getitem__(self, index):\n\n        create = self._create_create\n        tasks = self._tasks_tasks_tasks\n\n        if isinstance(index, int):\n            start_flag = (self.startstart is not None)\n            shape_flag = (self.shapeshape is not None)\n            lower_boundary = self.startstart[0] if start_flag else 0\n            upper_boundary = lower_boundary + self.shapeshape[0] if shape_flag else -1\n\n            idx = [(index,)] if (index &gt;= lower_boundary) and ((index &lt;= upper_boundary) or (upper_boundary  &lt; 0)) else []\n            task_list, (new_tasks, new_idx) = get_or_create_tasks(self, idx, create=create)\n\n            #self.inner_space.add_tasks(new_idx, new_tasks)\n            self.inner_spaceinner_space.add_tasks(new_tasks)\n\n            if len(task_list) == 1:\n                return task_list[0]\n\n            return AtomicTaskList(task_list)\n\n        if isinstance(index, str):\n            task_list, (new_tasks, new_index) = get_or_create_tasks(self, [(index,)], create=create)\n            #self.inner_space.add_tasks(new_idx, new_tasks)\n            self.inner_spaceinner_space.add_tasks(new_tasks)\n\n            if len(task_list) == 1:\n                return task_list[0]\n\n            return AtomicTaskList(task_list)\n\n\n        if not isinstance(index, tuple):\n            index = (index,)\n\n        index_list = []\n        cy_parse_index((), index, index_list, shape=self.shapeshape, start=self.startstart)\n        task_list, (new_tasks, new_index) = get_or_create_tasks(self, index_list, create=self._create_create)\n        #self.inner_space.add_tasks(new_idx, new_tasks)\n        self.inner_spaceinner_space.add_tasks(new_tasks)\n\n        if len(task_list) == 1:\n            return task_list[0]\n\n        return AtomicTaskList(task_list)\n\n    def wait(self):\n        self.inner_spaceinner_space.wait()\n\n\n#TODO(wlr): This is incredibly experimental. \nclass BackendTaskSpace(TaskSpace):\n\n    def __init__(self, name=\"\", create=True, shape=None, start=None):\n        super().__init__(name, create, shape, start)\n        self.inner_spaceinner_space = core.PyTaskSpace()\n\n    def __repr__(self):\n        return f\"BackendTaskspace({self._name}, ntasks={len(self)})\"\n\n\n    def __getitem__(self, index):\n\n        create = self._create_create\n        tasks = self._tasks_tasks_tasks\n\n        if isinstance(index, int):\n            start_flag = (self.startstart is not None)\n            shape_flag = (self.shapeshape is not None)\n            lower_boundary = self.startstart[0] if start_flag else 0\n            upper_boundary = lower_boundary + self.shapeshape[0] if shape_flag else -1\n\n            index_list = [(index,)] if (index &gt;= lower_boundary) and ((index &lt;= upper_boundary) or (upper_boundary  &lt; 0)) else []\n            task_list, (new_tasks, new_idx) = get_or_create_tasks(self, index_list, create=create)\n\n            #self.inner_space.add_tasks(new_idx, new_tasks)\n            self.inner_spaceinner_space.add_tasks(new_tasks)\n\n            return_list = core.CyTaskList()\n            self.inner_spaceinner_space.get_tasks(index_list, return_list)\n            return return_list\n\n        if isinstance(index, str):\n            index_list = [(index,)]\n            task_list, (new_tasks, new_index) = get_or_create_tasks(self, index_list, create=create)\n            #self.inner_space.add_tasks(new_idx, new_tasks)\n            self.inner_spaceinner_space.add_tasks(new_tasks)\n\n            return_list = core.CyTaskList()\n            self.inner_spaceinner_space.get_tasks(index_list, return_list)\n            return return_list\n\n\n        if not isinstance(index, tuple):\n            index = (index,)\n\n        index_list = []\n        cy_parse_index((), index, index_list, shape=self.shapeshape, start=self.startstart)\n        task_list, (new_tasks, new_index) = get_or_create_tasks(self, index_list, create=self._create_create)\n        #self.inner_space.add_tasks(new_idx, new_tasks)\n        self.inner_spaceinner_space.add_tasks(new_tasks)\n\n        return_list = core.CyTaskList()\n        self.inner_spaceinner_space.get_tasks(index_list, return_list)\n        return return_list\n\n\n    def wait(self):\n        self.inner_spaceinner_space.wait()\n</code></pre>"},{"location":"runtime/variants_8pyx/","title":"File variants.pyx","text":"<p>FileList &gt; cython &gt; variants.pyx</p> <p>Go to the source code of this file.</p> <p>Provides decorators for dispatching functions based on the active TaskEnvironment. </p>"},{"location":"runtime/variants_8pyx/#namespaces","title":"Namespaces","text":"Type Name namespace variants"},{"location":"runtime/variants_8pyx/#classes","title":"Classes","text":"Type Name class VariantDefinitionError Error for an invalid function variant definition. class _VariantFunction Function wrapper that dispatches to different architecture targets. <p>The documentation for this class was generated from the following file <code>src/python/parla/cython/variants.pyx</code></p>"},{"location":"runtime/variants_8pyx_source/","title":"File variants.pyx","text":"<p>File List &gt; cython &gt; variants.pyx</p> <p>Go to the documentation of this file. </p> <pre><code>\"\"\"!\n@file variants.pyx\n@brief Provides decorators for dispatching functions based on the active TaskEnvironment.\n\"\"\"\n\nimport functools \nfrom parla.common.globals import _Locals as Locals \nfrom parla.cython.device import PyArchitecture\n\nclass VariantDefinitionError(ValueError):\n\"\"\"!\n    @brief Error for an invalid function variant definition.\n    \"\"\"\n    pass\n\nclass _VariantFunction(object):\n\"\"\"!\n    @brief Function wrapper that dispatches to different architecture targets\n\n\n    Specialization is only supported on the architecture level.\n    Specifying specifications for specific devices (e.g. gpu(0) )is not supported.\n    \"\"\"\n\n    def __init__(self, func):\n        self._default = func \n        self._variants = {}\n        functools.update_wrapper(self, func)\n\n    def variant(self, spec_list, override=False):\n\"\"\"!\n        @brief Decorator to declare a variant of this function for a specific architecture.\n\n        @param spec_list A list of architectures to specialize this function for. Can be a single architecture, or a list of architectures. Each architecture can be a tuple of architectures to specialize for a multidevice configuration.\n        @param override If true, allow overriding an existing variant for one of the given architectures.\n        \"\"\"\n\n        if not isinstance(spec_list, list):\n            spec_list = [spec_list]\n\n        if any(t in self._variants_variants for t in spec_list) and not override:\n            raise VariantDefinitionError(\"Variant already exists for one of the given specialization targets.\")\n\n        def variant(f):\n            for t in spec_list:\n                assert isinstance(t, PyArchitecture)\n                self._variants_variants[t.id] = f\n            return f\n\n        variant.__name__ = \"{}.variant\".format(self._default_default.__name__)\n        return variant\n\n    def get_variant(self, spec_key):\n\"\"\"!\n        @brief Get the variant for a given specialization key.\n        \"\"\"\n        return self._variants_variants.get(spec_key, self._default_default)\n\n    def __repr__(self):\n        return \"{f} specialized to {targets}&gt;\".format(f=repr(self._default_default)[:-1], targets=tuple(self._variants_variants.keys()))\n\n    def __call__(self, *args, **kwargs):\n\"\"\"!\n        @brief Call the function, dispatching to the appropriate variant.\n        \"\"\"\n        local_context = Locals.context \n        local_devices = local_context.get_all_devices()\n\n        if len(local_devices) == 0:\n            return self._default_default(*args, **kwargs)\n\n        # Construct a architecture specialization key from the local devices.\n        spec_key = tuple([d.architecture for d in local_devices])\n        # If a single architecture variant type, it needs a single id, not a tuple.\n        spec_key = spec_key[0] if len(spec_key) == 1 else spec_key\n\n        # Get the variant for the current specialization key.\n        variant_f = self.get_variantget_variant(spec_key)\n\n        # Call the variant.\n        return variant_f(*args, **kwargs)\n\n\ndef specialize(func):\n\"\"\"!\n    @brief Decorator to create a function with specialized variants for different architectures. The default implementation is the decorated function.\n\n    A decorator to declare that this function has specialized variants for specific architectures.\n    The decorated function is the default implemention, used when no specialized implementation is available.\n    The default can just be `raise NotImplementedError()` in cases where no default implementation is possible.\n    To provide a specialized variant use the `variant` member of the main function:\n    .. testsetup::\n        from parla.function_decorators import *\n    &gt;&gt;&gt; @specialized\n    ... def f():\n    ...     raise NotImplementedError()\n    &gt;&gt;&gt; @f.variant(architecture)\n    ... def f_gpu():\n    ...     ...\n    `architecture` above will often by something like `cpu` or `gpu`, but is extensible.\n    Multiple architectures can be specified as separate parameters to use the same implementation on multiple architectures: `@f.variant(CPU, FPGA)`.\n    Each architecture can only be used once on a given function.\n    Architecture specialized functions are called just like any other function, but the implementation which is called is selected based on where the code executes.\n    The compiler will make the choice when it is compiling for a specific target.\n    \"\"\"\n    return _VariantFunction(func)\n</code></pre>"},{"location":"runtime/namespaces/","title":"Namespace List","text":"<p>Here is a list of all namespaces with brief descriptions:</p> <ul> <li>namespace Scheduler </li> <li>namespace Task </li> <li>namespace chrono </li> <li>namespace parla </li> <li>namespace cython <ul> <li>namespace containers </li> <li>namespace core </li> <li>namespace cyparray </li> <li>namespace cyparray_state </li> <li>namespace device </li> <li>namespace device_manager </li> <li>namespace scheduler </li> <li>namespace tasks </li> <li>namespace variants </li> </ul> </li> <li>namespace parray </li> <li>namespace std </li> <li>namespace chrono_literals </li> <li>namespace string_view_literals </li> <li>namespace threading </li> </ul>"},{"location":"runtime/classes/","title":"Class Index","text":""},{"location":"runtime/classes/#a","title":"a","text":"<ul> <li>ArchitectureRequirement</li> <li>AtomicTaskList (parla::cython::tasks)</li> <li>AtomicTaskSpace (parla::cython::tasks)</li> </ul>"},{"location":"runtime/classes/#b","title":"b","text":"<ul> <li>BackendTaskList (parla::cython::tasks)</li> <li>BackendTaskSpace (parla::cython::tasks)</li> </ul>"},{"location":"runtime/classes/#c","title":"c","text":"<ul> <li>CPUDevice</li> <li>CUDADevice</li> <li>CopyableAtomic</li> <li>CyDataMovementTaskAttributes (parla::cython::core)</li> <li>CyTaskList (parla::cython::core)</li> <li>CyPArray (parla::cython::cyparray)</li> <li>CyPArrayState (parla::cython::cyparray_state)</li> <li>CupyStream (parla::cython::device)</li> <li>CyCPUDevice (parla::cython::device)</li> <li>CyCUDADevice (parla::cython::device)</li> <li>CyDevice (parla::cython::device)</li> <li>CyDeviceManager (parla::cython::device_manager)</li> <li>ControllableThread (parla::cython::scheduler)</li> <li>CPUEnvironment (parla::cython::tasks)</li> <li>ComputeTask (parla::cython::tasks)</li> </ul>"},{"location":"runtime/classes/#d","title":"d","text":"<ul> <li>Device</li> <li>DeviceManager</li> <li>DeviceQueue</li> <li>DeviceRequirement</li> <li>DataMovementTaskAttributes (parla::cython::core)</li> <li>DeviceResource (parla::cython::device)</li> <li>DeviceResourceRequirement (parla::cython::device)</li> <li>DataMovementTask (parla::cython::tasks)</li> </ul>"},{"location":"runtime/classes/#g","title":"g","text":"<ul> <li>GPUEnvironment (parla::cython::tasks)</li> </ul>"},{"location":"runtime/classes/#i","title":"i","text":"<ul> <li>InnerDataTask</li> <li>InnerScheduler</li> <li>InnerTask</li> <li>InnerTaskSpace</li> <li>InnerWorker</li> <li>InnerPArray (parray)</li> </ul>"},{"location":"runtime/classes/#l","title":"l","text":"<ul> <li>Launcher</li> <li>LauncherStatus</li> <li>LocalityLoadBalancingMappingPolicy</li> </ul>"},{"location":"runtime/classes/#m","title":"m","text":"<ul> <li>Mapper</li> <li>MapperStatus</li> <li>MappingPolicy</li> <li>MemoryReserver</li> <li>MemoryReserverStatus</li> <li>MultiDeviceRequirements</li> </ul>"},{"location":"runtime/classes/#p","title":"p","text":"<ul> <li>PArrayTracker</li> <li>PhaseManager</li> <li>PhaseStatus</li> <li>PlacementRequirementBase</li> <li>PlacementRequirementCollections</li> <li>ProtectedQueue</li> <li>ProtectedVector</li> <li>PyInnerScheduler (parla::cython::core)</li> <li>PyInnerTask (parla::cython::core)</li> <li>PyInnerWorker (parla::cython::core)</li> <li>PyTaskBarrier (parla::cython::core)</li> <li>PyTaskSpace (parla::cython::core)</li> <li>PyArchitecture (parla::cython::device)</li> <li>PyCPUArchitecture (parla::cython::device)</li> <li>PyCPUDevice (parla::cython::device)</li> <li>PyCUDAArchitecture (parla::cython::device)</li> <li>PyCUDADevice (parla::cython::device)</li> <li>PyDevice (parla::cython::device)</li> <li>PrintableFrozenSet (parla::cython::device_manager)</li> <li>PyDeviceManager (parla::cython::device_manager)</li> <li>PArrayState (parray)</li> </ul>"},{"location":"runtime/classes/#r","title":"r","text":"<ul> <li>ResourcePool</li> <li>RuntimeReserver</li> <li>RuntimeReserverStatus</li> <li>Resources (parla::cython::core)</li> </ul>"},{"location":"runtime/classes/#s","title":"s","text":"<ul> <li>Status (Scheduler)</li> <li>SchedulerPhase</li> <li>SinglePlacementRequirementBase</li> <li>StatusFlags (Task)</li> <li>Stream (parla::cython::device)</li> <li>StreamPool (parla::cython::device_manager)</li> <li>Scheduler (parla::cython::scheduler)</li> <li>SchedulerContext (parla::cython::scheduler)</li> <li>SchedulerException (parla::cython::scheduler)</li> </ul>"},{"location":"runtime/classes/#t","title":"t","text":"<ul> <li>TaskBarrier</li> <li>TaskBodyException (parla::cython::scheduler)</li> <li>Task (parla::cython::tasks)</li> <li>TaskCollection (parla::cython::tasks)</li> <li>TaskCompleted (parla::cython::tasks)</li> <li>TaskCreated (parla::cython::tasks)</li> <li>TaskEnvironment (parla::cython::tasks)</li> <li>TaskException (parla::cython::tasks)</li> <li>TaskList (parla::cython::tasks)</li> <li>TaskMapped (parla::cython::tasks)</li> <li>TaskReady (parla::cython::tasks)</li> <li>TaskReserved (parla::cython::tasks)</li> <li>TaskRunahead (parla::cython::tasks)</li> <li>TaskRunning (parla::cython::tasks)</li> <li>TaskSpace (parla::cython::tasks)</li> <li>TaskSpawned (parla::cython::tasks)</li> <li>TaskState (parla::cython::tasks)</li> <li>TerminalEnvironment (parla::cython::tasks)</li> </ul>"},{"location":"runtime/classes/#v","title":"v","text":"<ul> <li>VariantDefinitionError (parla::cython::variants)</li> </ul>"},{"location":"runtime/classes/#w","title":"w","text":"<ul> <li>WorkerPool</li> <li>WorkerThread (parla::cython::scheduler)</li> <li>WorkerThreadException (parla::cython::scheduler)</li> </ul> <p>## \\</p> <ul> <li>_SchedulerLocals (parla::cython::scheduler)</li> <li>_TaskLocals (parla::cython::tasks)</li> <li>_VariantFunction (parla::cython::variants)</li> </ul>"},{"location":"runtime/hierarchy/","title":"Class Hierarchy","text":"<p>This inheritance list is sorted roughly, but not completely, alphabetically:</p> <ul> <li>class PlacementRequirementBase Base classes. </li> <li>class MultiDeviceRequirements </li> <li>class SinglePlacementRequirementBase <ul> <li>class ArchitectureRequirement </li> <li>class DeviceRequirement </li> </ul> </li> <li>class Device Devices can be distinguished from other devices by a class type and its index. </li> <li>class CPUDevice </li> <li>class CUDADevice </li> <li>class DeviceManager <code>DeviceManager</code> registers/provides devices and their information on the current system to the Parla runtime.</li> <li>class DeviceQueue Per-device container for tasks that are waiting to be dequeued. </li> <li>class InnerTask The C++ \"Mirror\" of Parla's Python Tasks This class is used to create a C++ representation of a Parla Task All scheduling logic should be handled by these after creation until launched by the Python callback. </li> <li>class InnerDataTask </li> <li>class InnerScheduler The C++ \"Mirror\" of Parla's Python Scheduler This class is used to create a C++ representation of a Parla Scheduler All scheduling logic should be handled by these after creation until launched by the Python callback. </li> <li>class TaskBarrier The C++ \"Mirror\" of Parla's Python TaskSets &amp; Spaces They are used as barriers for the calling thread for the completion of their members. </li> <li>class InnerTaskSpace </li> <li>class InnerWorker The C++ \"Mirror\" of Parla's Python Workers This class is used to create a C++ representation of a Parla Worker All scheduling logic should be handled by these after creation until launched by the Python callback. </li> <li>class SchedulerPhase Abstract Interface for general scheduler runtime phase. </li> <li>class Launcher </li> <li>class Mapper Mapper phase of the scheduler.</li> <li>class MemoryReserver MemoryReserver phase of the scheduler.</li> <li>class RuntimeReserver RuntimeReserver phase of the scheduler.</li> <li>class PhaseStatus Records metrics that track phase execution (e.g. success, failure, etc.) </li> <li>class MappingPolicy </li> <li>class LocalityLoadBalancingMappingPolicy </li> <li>class PArrayTracker </li> <li>class PhaseManager Manages a group of DeviceQueues. </li> <li>class PlacementRequirementCollections Resource contains device types (architectures), specific devices, their memory and virtual computation units. </li> <li>class ProtectedQueue </li> <li>class ProtectedVector </li> <li>class ResourcePool A pool of resources, allows for comparisons and updates of current values. </li> <li>class Scheduler::Status </li> <li>class Task::StatusFlags </li> <li>class WorkerPool </li> <li>class parla::cython::core::CyDataMovementTaskAttributes </li> <li>class parla::cython::core::CyTaskList </li> <li>class parla::cython::core::DataMovementTaskAttributes </li> <li>class parla::cython::core::PyInnerScheduler </li> <li>class parla::cython::core::PyInnerTask </li> <li>class parla::cython::core::PyInnerWorker </li> <li>class parla::cython::core::PyTaskBarrier </li> <li>class parla::cython::core::PyTaskSpace </li> <li>class parla::cython::core::Resources </li> <li>class parla::cython::cyparray::CyPArray </li> <li>class parla::cython::cyparray_state::CyPArrayState </li> <li>class parla::cython::device::Stream </li> <li>class parla::cython::device::CupyStream </li> <li>class parla::cython::device::CyDevice </li> <li>class parla::cython::device::CyCPUDevice </li> <li>class parla::cython::device::CyCUDADevice </li> <li>class parla::cython::device::DeviceResource </li> <li>class parla::cython::device::DeviceResourceRequirement </li> <li>class parla::cython::device::PyDevice </li> <li>class parla::cython::device::PyCPUDevice </li> <li>class parla::cython::device::PyCUDADevice </li> <li>class parla::cython::device_manager::CyDeviceManager </li> <li>class parla::cython::device_manager::PyDeviceManager </li> <li>class parla::cython::device_manager::StreamPool </li> <li>class parla::cython::scheduler::SchedulerContext </li> <li>class parla::cython::scheduler::Scheduler </li> <li>class parla::cython::scheduler::WorkerThread </li> <li>class parla::cython::tasks::TaskCollection </li> <li>class parla::cython::tasks::TaskList <ul> <li>class parla::cython::tasks::AtomicTaskList </li> <li>class parla::cython::tasks::BackendTaskList </li> </ul> </li> <li>class parla::cython::tasks::TaskSpace <ul> <li>class parla::cython::tasks::AtomicTaskSpace </li> <li>class parla::cython::tasks::BackendTaskSpace </li> </ul> </li> <li>class parla::cython::tasks::TaskEnvironment A TaskEnvironment is a collection of devices or other TaskEnvironments used to coordinate and synchronize kernels in theTask body. </li> <li>class parla::cython::tasks::TerminalEnvironment An endpoint TaskEnvironment representing a single device. <ul> <li>class parla::cython::tasks::CPUEnvironment </li> <li>class parla::cython::tasks::GPUEnvironment </li> </ul> </li> <li>class parla::cython::tasks::Task Python Task interface. </li> <li>class parla::cython::tasks::ComputeTask A compute task is a task that executes a user defined Python function on a device. </li> <li>class parla::cython::tasks::DataMovementTask A data movement task is a task that moves data between devices. </li> <li>class parray::InnerPArray </li> <li>class parray::PArrayState </li> <li>class std::atomic&lt; T &gt; </li> <li>class CopyableAtomic A copyable atomic class inherited from std::atomic. </li> <li>class metaclass </li> <li>class parla::cython::device::PyArchitecture <ul> <li>class parla::cython::device::PyCPUArchitecture </li> <li>class parla::cython::device::PyCUDAArchitecture </li> </ul> </li> <li>class parla::cython::device::PyArchitecture <ul> <li>class parla::cython::device::PyCPUArchitecture </li> <li>class parla::cython::device::PyCUDAArchitecture </li> </ul> </li> <li>class parla::cython::device::PyArchitecture <ul> <li>class parla::cython::device::PyCPUArchitecture </li> <li>class parla::cython::device::PyCUDAArchitecture </li> </ul> </li> <li>class parla::cython::tasks::TaskState Abstract base class for Task State. <ul> <li>class parla::cython::tasks::TaskCompleted This state specifies that a task has completed execution. </li> <li>class parla::cython::tasks::TaskCreated This state specifies that a task has been created but not yet spawned. </li> <li>class parla::cython::tasks::TaskException This state specifies that a task has completed execution with an exception. </li> <li>class parla::cython::tasks::TaskMapped This state specifies that a task has been mapped to a device set, but not yet resered its resources there. </li> <li>class parla::cython::tasks::TaskReady This state specifies that a task is \"ready\" to be launched. </li> <li>class parla::cython::tasks::TaskReserved This state specifies that a task has reserved its persistent resources (e.g. </li> <li>class parla::cython::tasks::TaskRunahead State: A task is executing in a stream but the body has completed. </li> <li>class parla::cython::tasks::TaskRunning This state specifies that a task is executing in a stream. </li> <li>class parla::cython::tasks::TaskSpawned This state specifies that a task is ready to be mapped to a specific device set. </li> </ul> </li> <li>class parla::cython::tasks::TaskState Abstract base class for Task State. <ul> <li>class parla::cython::tasks::TaskCompleted This state specifies that a task has completed execution. </li> <li>class parla::cython::tasks::TaskCreated This state specifies that a task has been created but not yet spawned. </li> <li>class parla::cython::tasks::TaskException This state specifies that a task has completed execution with an exception. </li> <li>class parla::cython::tasks::TaskMapped This state specifies that a task has been mapped to a device set, but not yet resered its resources there. </li> <li>class parla::cython::tasks::TaskReady This state specifies that a task is \"ready\" to be launched. </li> <li>class parla::cython::tasks::TaskReserved This state specifies that a task has reserved its persistent resources (e.g. </li> <li>class parla::cython::tasks::TaskRunahead State: A task is executing in a stream but the body has completed. </li> <li>class parla::cython::tasks::TaskRunning This state specifies that a task is executing in a stream. </li> <li>class parla::cython::tasks::TaskSpawned This state specifies that a task is ready to be mapped to a specific device set. </li> </ul> </li> <li>class parla::cython::tasks::TaskState Abstract base class for Task State. <ul> <li>class parla::cython::tasks::TaskCompleted This state specifies that a task has completed execution. </li> <li>class parla::cython::tasks::TaskCreated This state specifies that a task has been created but not yet spawned. </li> <li>class parla::cython::tasks::TaskException This state specifies that a task has completed execution with an exception. </li> <li>class parla::cython::tasks::TaskMapped This state specifies that a task has been mapped to a device set, but not yet resered its resources there. </li> <li>class parla::cython::tasks::TaskReady This state specifies that a task is \"ready\" to be launched. </li> <li>class parla::cython::tasks::TaskReserved This state specifies that a task has reserved its persistent resources (e.g. </li> <li>class parla::cython::tasks::TaskRunahead State: A task is executing in a stream but the body has completed. </li> <li>class parla::cython::tasks::TaskRunning This state specifies that a task is executing in a stream. </li> <li>class parla::cython::tasks::TaskSpawned This state specifies that a task is ready to be mapped to a specific device set. </li> </ul> </li> <li>class parla::cython::tasks::TaskState Abstract base class for Task State. <ul> <li>class parla::cython::tasks::TaskCompleted This state specifies that a task has completed execution. </li> <li>class parla::cython::tasks::TaskCreated This state specifies that a task has been created but not yet spawned. </li> <li>class parla::cython::tasks::TaskException This state specifies that a task has completed execution with an exception. </li> <li>class parla::cython::tasks::TaskMapped This state specifies that a task has been mapped to a device set, but not yet resered its resources there. </li> <li>class parla::cython::tasks::TaskReady This state specifies that a task is \"ready\" to be launched. </li> <li>class parla::cython::tasks::TaskReserved This state specifies that a task has reserved its persistent resources (e.g. </li> <li>class parla::cython::tasks::TaskRunahead State: A task is executing in a stream but the body has completed. </li> <li>class parla::cython::tasks::TaskRunning This state specifies that a task is executing in a stream. </li> <li>class parla::cython::tasks::TaskSpawned This state specifies that a task is ready to be mapped to a specific device set. </li> </ul> </li> <li>class parla::cython::tasks::TaskState Abstract base class for Task State. <ul> <li>class parla::cython::tasks::TaskCompleted This state specifies that a task has completed execution. </li> <li>class parla::cython::tasks::TaskCreated This state specifies that a task has been created but not yet spawned. </li> <li>class parla::cython::tasks::TaskException This state specifies that a task has completed execution with an exception. </li> <li>class parla::cython::tasks::TaskMapped This state specifies that a task has been mapped to a device set, but not yet resered its resources there. </li> <li>class parla::cython::tasks::TaskReady This state specifies that a task is \"ready\" to be launched. </li> <li>class parla::cython::tasks::TaskReserved This state specifies that a task has reserved its persistent resources (e.g. </li> <li>class parla::cython::tasks::TaskRunahead State: A task is executing in a stream but the body has completed. </li> <li>class parla::cython::tasks::TaskRunning This state specifies that a task is executing in a stream. </li> <li>class parla::cython::tasks::TaskSpawned This state specifies that a task is ready to be mapped to a specific device set. </li> </ul> </li> <li>class parla::cython::tasks::TaskState Abstract base class for Task State. <ul> <li>class parla::cython::tasks::TaskCompleted This state specifies that a task has completed execution. </li> <li>class parla::cython::tasks::TaskCreated This state specifies that a task has been created but not yet spawned. </li> <li>class parla::cython::tasks::TaskException This state specifies that a task has completed execution with an exception. </li> <li>class parla::cython::tasks::TaskMapped This state specifies that a task has been mapped to a device set, but not yet resered its resources there. </li> <li>class parla::cython::tasks::TaskReady This state specifies that a task is \"ready\" to be launched. </li> <li>class parla::cython::tasks::TaskReserved This state specifies that a task has reserved its persistent resources (e.g. </li> <li>class parla::cython::tasks::TaskRunahead State: A task is executing in a stream but the body has completed. </li> <li>class parla::cython::tasks::TaskRunning This state specifies that a task is executing in a stream. </li> <li>class parla::cython::tasks::TaskSpawned This state specifies that a task is ready to be mapped to a specific device set. </li> </ul> </li> <li>class parla::cython::tasks::TaskState Abstract base class for Task State. <ul> <li>class parla::cython::tasks::TaskCompleted This state specifies that a task has completed execution. </li> <li>class parla::cython::tasks::TaskCreated This state specifies that a task has been created but not yet spawned. </li> <li>class parla::cython::tasks::TaskException This state specifies that a task has completed execution with an exception. </li> <li>class parla::cython::tasks::TaskMapped This state specifies that a task has been mapped to a device set, but not yet resered its resources there. </li> <li>class parla::cython::tasks::TaskReady This state specifies that a task is \"ready\" to be launched. </li> <li>class parla::cython::tasks::TaskReserved This state specifies that a task has reserved its persistent resources (e.g. </li> <li>class parla::cython::tasks::TaskRunahead State: A task is executing in a stream but the body has completed. </li> <li>class parla::cython::tasks::TaskRunning This state specifies that a task is executing in a stream. </li> <li>class parla::cython::tasks::TaskSpawned This state specifies that a task is ready to be mapped to a specific device set. </li> </ul> </li> <li>class parla::cython::tasks::TaskState Abstract base class for Task State. <ul> <li>class parla::cython::tasks::TaskCompleted This state specifies that a task has completed execution. </li> <li>class parla::cython::tasks::TaskCreated This state specifies that a task has been created but not yet spawned. </li> <li>class parla::cython::tasks::TaskException This state specifies that a task has completed execution with an exception. </li> <li>class parla::cython::tasks::TaskMapped This state specifies that a task has been mapped to a device set, but not yet resered its resources there. </li> <li>class parla::cython::tasks::TaskReady This state specifies that a task is \"ready\" to be launched. </li> <li>class parla::cython::tasks::TaskReserved This state specifies that a task has reserved its persistent resources (e.g. </li> <li>class parla::cython::tasks::TaskRunahead State: A task is executing in a stream but the body has completed. </li> <li>class parla::cython::tasks::TaskRunning This state specifies that a task is executing in a stream. </li> <li>class parla::cython::tasks::TaskSpawned This state specifies that a task is ready to be mapped to a specific device set. </li> </ul> </li> <li>class parla::cython::tasks::TaskState Abstract base class for Task State. <ul> <li>class parla::cython::tasks::TaskCompleted This state specifies that a task has completed execution. </li> <li>class parla::cython::tasks::TaskCreated This state specifies that a task has been created but not yet spawned. </li> <li>class parla::cython::tasks::TaskException This state specifies that a task has completed execution with an exception. </li> <li>class parla::cython::tasks::TaskMapped This state specifies that a task has been mapped to a device set, but not yet resered its resources there. </li> <li>class parla::cython::tasks::TaskReady This state specifies that a task is \"ready\" to be launched. </li> <li>class parla::cython::tasks::TaskReserved This state specifies that a task has reserved its persistent resources (e.g. </li> <li>class parla::cython::tasks::TaskRunahead State: A task is executing in a stream but the body has completed. </li> <li>class parla::cython::tasks::TaskRunning This state specifies that a task is executing in a stream. </li> <li>class parla::cython::tasks::TaskSpawned This state specifies that a task is ready to be mapped to a specific device set. </li> </ul> </li> <li>class parla::cython::tasks::TaskState Abstract base class for Task State. <ul> <li>class parla::cython::tasks::TaskCompleted This state specifies that a task has completed execution. </li> <li>class parla::cython::tasks::TaskCreated This state specifies that a task has been created but not yet spawned. </li> <li>class parla::cython::tasks::TaskException This state specifies that a task has completed execution with an exception. </li> <li>class parla::cython::tasks::TaskMapped This state specifies that a task has been mapped to a device set, but not yet resered its resources there. </li> <li>class parla::cython::tasks::TaskReady This state specifies that a task is \"ready\" to be launched. </li> <li>class parla::cython::tasks::TaskReserved This state specifies that a task has reserved its persistent resources (e.g. </li> <li>class parla::cython::tasks::TaskRunahead State: A task is executing in a stream but the body has completed. </li> <li>class parla::cython::tasks::TaskRunning This state specifies that a task is executing in a stream. </li> <li>class parla::cython::tasks::TaskSpawned This state specifies that a task is ready to be mapped to a specific device set. </li> </ul> </li> <li>class ABCMeta </li> <li>class parla::cython::device::PyArchitecture <ul> <li>class parla::cython::device::PyCPUArchitecture </li> <li>class parla::cython::device::PyCUDAArchitecture </li> </ul> </li> <li>class parla::cython::device::PyArchitecture <ul> <li>class parla::cython::device::PyCPUArchitecture </li> <li>class parla::cython::device::PyCUDAArchitecture </li> </ul> </li> <li>class parla::cython::device::PyArchitecture <ul> <li>class parla::cython::device::PyCPUArchitecture </li> <li>class parla::cython::device::PyCUDAArchitecture </li> </ul> </li> <li>class parla::cython::tasks::TaskState Abstract base class for Task State. <ul> <li>class parla::cython::tasks::TaskCompleted This state specifies that a task has completed execution. </li> <li>class parla::cython::tasks::TaskCreated This state specifies that a task has been created but not yet spawned. </li> <li>class parla::cython::tasks::TaskException This state specifies that a task has completed execution with an exception. </li> <li>class parla::cython::tasks::TaskMapped This state specifies that a task has been mapped to a device set, but not yet resered its resources there. </li> <li>class parla::cython::tasks::TaskReady This state specifies that a task is \"ready\" to be launched. </li> <li>class parla::cython::tasks::TaskReserved This state specifies that a task has reserved its persistent resources (e.g. </li> <li>class parla::cython::tasks::TaskRunahead State: A task is executing in a stream but the body has completed. </li> <li>class parla::cython::tasks::TaskRunning This state specifies that a task is executing in a stream. </li> <li>class parla::cython::tasks::TaskSpawned This state specifies that a task is ready to be mapped to a specific device set. </li> </ul> </li> <li>class parla::cython::tasks::TaskState Abstract base class for Task State. <ul> <li>class parla::cython::tasks::TaskCompleted This state specifies that a task has completed execution. </li> <li>class parla::cython::tasks::TaskCreated This state specifies that a task has been created but not yet spawned. </li> <li>class parla::cython::tasks::TaskException This state specifies that a task has completed execution with an exception. </li> <li>class parla::cython::tasks::TaskMapped This state specifies that a task has been mapped to a device set, but not yet resered its resources there. </li> <li>class parla::cython::tasks::TaskReady This state specifies that a task is \"ready\" to be launched. </li> <li>class parla::cython::tasks::TaskReserved This state specifies that a task has reserved its persistent resources (e.g. </li> <li>class parla::cython::tasks::TaskRunahead State: A task is executing in a stream but the body has completed. </li> <li>class parla::cython::tasks::TaskRunning This state specifies that a task is executing in a stream. </li> <li>class parla::cython::tasks::TaskSpawned This state specifies that a task is ready to be mapped to a specific device set. </li> </ul> </li> <li>class parla::cython::tasks::TaskState Abstract base class for Task State. <ul> <li>class parla::cython::tasks::TaskCompleted This state specifies that a task has completed execution. </li> <li>class parla::cython::tasks::TaskCreated This state specifies that a task has been created but not yet spawned. </li> <li>class parla::cython::tasks::TaskException This state specifies that a task has completed execution with an exception. </li> <li>class parla::cython::tasks::TaskMapped This state specifies that a task has been mapped to a device set, but not yet resered its resources there. </li> <li>class parla::cython::tasks::TaskReady This state specifies that a task is \"ready\" to be launched. </li> <li>class parla::cython::tasks::TaskReserved This state specifies that a task has reserved its persistent resources (e.g. </li> <li>class parla::cython::tasks::TaskRunahead State: A task is executing in a stream but the body has completed. </li> <li>class parla::cython::tasks::TaskRunning This state specifies that a task is executing in a stream. </li> <li>class parla::cython::tasks::TaskSpawned This state specifies that a task is ready to be mapped to a specific device set. </li> </ul> </li> <li>class parla::cython::tasks::TaskState Abstract base class for Task State. <ul> <li>class parla::cython::tasks::TaskCompleted This state specifies that a task has completed execution. </li> <li>class parla::cython::tasks::TaskCreated This state specifies that a task has been created but not yet spawned. </li> <li>class parla::cython::tasks::TaskException This state specifies that a task has completed execution with an exception. </li> <li>class parla::cython::tasks::TaskMapped This state specifies that a task has been mapped to a device set, but not yet resered its resources there. </li> <li>class parla::cython::tasks::TaskReady This state specifies that a task is \"ready\" to be launched. </li> <li>class parla::cython::tasks::TaskReserved This state specifies that a task has reserved its persistent resources (e.g. </li> <li>class parla::cython::tasks::TaskRunahead State: A task is executing in a stream but the body has completed. </li> <li>class parla::cython::tasks::TaskRunning This state specifies that a task is executing in a stream. </li> <li>class parla::cython::tasks::TaskSpawned This state specifies that a task is ready to be mapped to a specific device set. </li> </ul> </li> <li>class parla::cython::tasks::TaskState Abstract base class for Task State. <ul> <li>class parla::cython::tasks::TaskCompleted This state specifies that a task has completed execution. </li> <li>class parla::cython::tasks::TaskCreated This state specifies that a task has been created but not yet spawned. </li> <li>class parla::cython::tasks::TaskException This state specifies that a task has completed execution with an exception. </li> <li>class parla::cython::tasks::TaskMapped This state specifies that a task has been mapped to a device set, but not yet resered its resources there. </li> <li>class parla::cython::tasks::TaskReady This state specifies that a task is \"ready\" to be launched. </li> <li>class parla::cython::tasks::TaskReserved This state specifies that a task has reserved its persistent resources (e.g. </li> <li>class parla::cython::tasks::TaskRunahead State: A task is executing in a stream but the body has completed. </li> <li>class parla::cython::tasks::TaskRunning This state specifies that a task is executing in a stream. </li> <li>class parla::cython::tasks::TaskSpawned This state specifies that a task is ready to be mapped to a specific device set. </li> </ul> </li> <li>class parla::cython::tasks::TaskState Abstract base class for Task State. <ul> <li>class parla::cython::tasks::TaskCompleted This state specifies that a task has completed execution. </li> <li>class parla::cython::tasks::TaskCreated This state specifies that a task has been created but not yet spawned. </li> <li>class parla::cython::tasks::TaskException This state specifies that a task has completed execution with an exception. </li> <li>class parla::cython::tasks::TaskMapped This state specifies that a task has been mapped to a device set, but not yet resered its resources there. </li> <li>class parla::cython::tasks::TaskReady This state specifies that a task is \"ready\" to be launched. </li> <li>class parla::cython::tasks::TaskReserved This state specifies that a task has reserved its persistent resources (e.g. </li> <li>class parla::cython::tasks::TaskRunahead State: A task is executing in a stream but the body has completed. </li> <li>class parla::cython::tasks::TaskRunning This state specifies that a task is executing in a stream. </li> <li>class parla::cython::tasks::TaskSpawned This state specifies that a task is ready to be mapped to a specific device set. </li> </ul> </li> <li>class parla::cython::tasks::TaskState Abstract base class for Task State. <ul> <li>class parla::cython::tasks::TaskCompleted This state specifies that a task has completed execution. </li> <li>class parla::cython::tasks::TaskCreated This state specifies that a task has been created but not yet spawned. </li> <li>class parla::cython::tasks::TaskException This state specifies that a task has completed execution with an exception. </li> <li>class parla::cython::tasks::TaskMapped This state specifies that a task has been mapped to a device set, but not yet resered its resources there. </li> <li>class parla::cython::tasks::TaskReady This state specifies that a task is \"ready\" to be launched. </li> <li>class parla::cython::tasks::TaskReserved This state specifies that a task has reserved its persistent resources (e.g. </li> <li>class parla::cython::tasks::TaskRunahead State: A task is executing in a stream but the body has completed. </li> <li>class parla::cython::tasks::TaskRunning This state specifies that a task is executing in a stream. </li> <li>class parla::cython::tasks::TaskSpawned This state specifies that a task is ready to be mapped to a specific device set. </li> </ul> </li> <li>class parla::cython::tasks::TaskState Abstract base class for Task State. <ul> <li>class parla::cython::tasks::TaskCompleted This state specifies that a task has completed execution. </li> <li>class parla::cython::tasks::TaskCreated This state specifies that a task has been created but not yet spawned. </li> <li>class parla::cython::tasks::TaskException This state specifies that a task has completed execution with an exception. </li> <li>class parla::cython::tasks::TaskMapped This state specifies that a task has been mapped to a device set, but not yet resered its resources there. </li> <li>class parla::cython::tasks::TaskReady This state specifies that a task is \"ready\" to be launched. </li> <li>class parla::cython::tasks::TaskReserved This state specifies that a task has reserved its persistent resources (e.g. </li> <li>class parla::cython::tasks::TaskRunahead State: A task is executing in a stream but the body has completed. </li> <li>class parla::cython::tasks::TaskRunning This state specifies that a task is executing in a stream. </li> <li>class parla::cython::tasks::TaskSpawned This state specifies that a task is ready to be mapped to a specific device set. </li> </ul> </li> <li>class parla::cython::tasks::TaskState Abstract base class for Task State. <ul> <li>class parla::cython::tasks::TaskCompleted This state specifies that a task has completed execution. </li> <li>class parla::cython::tasks::TaskCreated This state specifies that a task has been created but not yet spawned. </li> <li>class parla::cython::tasks::TaskException This state specifies that a task has completed execution with an exception. </li> <li>class parla::cython::tasks::TaskMapped This state specifies that a task has been mapped to a device set, but not yet resered its resources there. </li> <li>class parla::cython::tasks::TaskReady This state specifies that a task is \"ready\" to be launched. </li> <li>class parla::cython::tasks::TaskReserved This state specifies that a task has reserved its persistent resources (e.g. </li> <li>class parla::cython::tasks::TaskRunahead State: A task is executing in a stream but the body has completed. </li> <li>class parla::cython::tasks::TaskRunning This state specifies that a task is executing in a stream. </li> <li>class parla::cython::tasks::TaskSpawned This state specifies that a task is ready to be mapped to a specific device set. </li> </ul> </li> <li>class parla::cython::tasks::TaskState Abstract base class for Task State. <ul> <li>class parla::cython::tasks::TaskCompleted This state specifies that a task has completed execution. </li> <li>class parla::cython::tasks::TaskCreated This state specifies that a task has been created but not yet spawned. </li> <li>class parla::cython::tasks::TaskException This state specifies that a task has completed execution with an exception. </li> <li>class parla::cython::tasks::TaskMapped This state specifies that a task has been mapped to a device set, but not yet resered its resources there. </li> <li>class parla::cython::tasks::TaskReady This state specifies that a task is \"ready\" to be launched. </li> <li>class parla::cython::tasks::TaskReserved This state specifies that a task has reserved its persistent resources (e.g. </li> <li>class parla::cython::tasks::TaskRunahead State: A task is executing in a stream but the body has completed. </li> <li>class parla::cython::tasks::TaskRunning This state specifies that a task is executing in a stream. </li> <li>class parla::cython::tasks::TaskSpawned This state specifies that a task is ready to be mapped to a specific device set. </li> </ul> </li> <li>class frozenset </li> <li>class parla::cython::device_manager::PrintableFrozenSet </li> <li>class threading.Thread </li> <li>class parla::cython::scheduler::ControllableThread <ul> <li>class parla::cython::scheduler::Scheduler </li> <li>class parla::cython::scheduler::WorkerThread </li> </ul> </li> <li>class parla::cython::scheduler::ControllableThread <ul> <li>class parla::cython::scheduler::Scheduler </li> <li>class parla::cython::scheduler::WorkerThread </li> </ul> </li> <li>class parla::cython::scheduler::ControllableThread <ul> <li>class parla::cython::scheduler::Scheduler </li> <li>class parla::cython::scheduler::WorkerThread </li> </ul> </li> <li>class RuntimeError </li> <li>class parla::cython::scheduler::SchedulerException </li> <li>class parla::cython::scheduler::TaskBodyException </li> <li>class parla::cython::scheduler::WorkerThreadException </li> <li>class threading.local </li> <li>class parla::cython::scheduler::_SchedulerLocals </li> <li>class parla::cython::tasks::_TaskLocals </li> <li>class object </li> <li>class parla::cython::tasks::TaskState Abstract base class for Task State. <ul> <li>class parla::cython::tasks::TaskCompleted This state specifies that a task has completed execution. </li> <li>class parla::cython::tasks::TaskCreated This state specifies that a task has been created but not yet spawned. </li> <li>class parla::cython::tasks::TaskException This state specifies that a task has completed execution with an exception. </li> <li>class parla::cython::tasks::TaskMapped This state specifies that a task has been mapped to a device set, but not yet resered its resources there. </li> <li>class parla::cython::tasks::TaskReady This state specifies that a task is \"ready\" to be launched. </li> <li>class parla::cython::tasks::TaskReserved This state specifies that a task has reserved its persistent resources (e.g. </li> <li>class parla::cython::tasks::TaskRunahead State: A task is executing in a stream but the body has completed. </li> <li>class parla::cython::tasks::TaskRunning This state specifies that a task is executing in a stream. </li> <li>class parla::cython::tasks::TaskSpawned This state specifies that a task is ready to be mapped to a specific device set. </li> </ul> </li> <li>class parla::cython::tasks::TaskState Abstract base class for Task State. <ul> <li>class parla::cython::tasks::TaskCompleted This state specifies that a task has completed execution. </li> <li>class parla::cython::tasks::TaskCreated This state specifies that a task has been created but not yet spawned. </li> <li>class parla::cython::tasks::TaskException This state specifies that a task has completed execution with an exception. </li> <li>class parla::cython::tasks::TaskMapped This state specifies that a task has been mapped to a device set, but not yet resered its resources there. </li> <li>class parla::cython::tasks::TaskReady This state specifies that a task is \"ready\" to be launched. </li> <li>class parla::cython::tasks::TaskReserved This state specifies that a task has reserved its persistent resources (e.g. </li> <li>class parla::cython::tasks::TaskRunahead State: A task is executing in a stream but the body has completed. </li> <li>class parla::cython::tasks::TaskRunning This state specifies that a task is executing in a stream. </li> <li>class parla::cython::tasks::TaskSpawned This state specifies that a task is ready to be mapped to a specific device set. </li> </ul> </li> <li>class parla::cython::tasks::TaskState Abstract base class for Task State. <ul> <li>class parla::cython::tasks::TaskCompleted This state specifies that a task has completed execution. </li> <li>class parla::cython::tasks::TaskCreated This state specifies that a task has been created but not yet spawned. </li> <li>class parla::cython::tasks::TaskException This state specifies that a task has completed execution with an exception. </li> <li>class parla::cython::tasks::TaskMapped This state specifies that a task has been mapped to a device set, but not yet resered its resources there. </li> <li>class parla::cython::tasks::TaskReady This state specifies that a task is \"ready\" to be launched. </li> <li>class parla::cython::tasks::TaskReserved This state specifies that a task has reserved its persistent resources (e.g. </li> <li>class parla::cython::tasks::TaskRunahead State: A task is executing in a stream but the body has completed. </li> <li>class parla::cython::tasks::TaskRunning This state specifies that a task is executing in a stream. </li> <li>class parla::cython::tasks::TaskSpawned This state specifies that a task is ready to be mapped to a specific device set. </li> </ul> </li> <li>class parla::cython::tasks::TaskState Abstract base class for Task State. <ul> <li>class parla::cython::tasks::TaskCompleted This state specifies that a task has completed execution. </li> <li>class parla::cython::tasks::TaskCreated This state specifies that a task has been created but not yet spawned. </li> <li>class parla::cython::tasks::TaskException This state specifies that a task has completed execution with an exception. </li> <li>class parla::cython::tasks::TaskMapped This state specifies that a task has been mapped to a device set, but not yet resered its resources there. </li> <li>class parla::cython::tasks::TaskReady This state specifies that a task is \"ready\" to be launched. </li> <li>class parla::cython::tasks::TaskReserved This state specifies that a task has reserved its persistent resources (e.g. </li> <li>class parla::cython::tasks::TaskRunahead State: A task is executing in a stream but the body has completed. </li> <li>class parla::cython::tasks::TaskRunning This state specifies that a task is executing in a stream. </li> <li>class parla::cython::tasks::TaskSpawned This state specifies that a task is ready to be mapped to a specific device set. </li> </ul> </li> <li>class parla::cython::tasks::TaskState Abstract base class for Task State. <ul> <li>class parla::cython::tasks::TaskCompleted This state specifies that a task has completed execution. </li> <li>class parla::cython::tasks::TaskCreated This state specifies that a task has been created but not yet spawned. </li> <li>class parla::cython::tasks::TaskException This state specifies that a task has completed execution with an exception. </li> <li>class parla::cython::tasks::TaskMapped This state specifies that a task has been mapped to a device set, but not yet resered its resources there. </li> <li>class parla::cython::tasks::TaskReady This state specifies that a task is \"ready\" to be launched. </li> <li>class parla::cython::tasks::TaskReserved This state specifies that a task has reserved its persistent resources (e.g. </li> <li>class parla::cython::tasks::TaskRunahead State: A task is executing in a stream but the body has completed. </li> <li>class parla::cython::tasks::TaskRunning This state specifies that a task is executing in a stream. </li> <li>class parla::cython::tasks::TaskSpawned This state specifies that a task is ready to be mapped to a specific device set. </li> </ul> </li> <li>class parla::cython::tasks::TaskState Abstract base class for Task State. <ul> <li>class parla::cython::tasks::TaskCompleted This state specifies that a task has completed execution. </li> <li>class parla::cython::tasks::TaskCreated This state specifies that a task has been created but not yet spawned. </li> <li>class parla::cython::tasks::TaskException This state specifies that a task has completed execution with an exception. </li> <li>class parla::cython::tasks::TaskMapped This state specifies that a task has been mapped to a device set, but not yet resered its resources there. </li> <li>class parla::cython::tasks::TaskReady This state specifies that a task is \"ready\" to be launched. </li> <li>class parla::cython::tasks::TaskReserved This state specifies that a task has reserved its persistent resources (e.g. </li> <li>class parla::cython::tasks::TaskRunahead State: A task is executing in a stream but the body has completed. </li> <li>class parla::cython::tasks::TaskRunning This state specifies that a task is executing in a stream. </li> <li>class parla::cython::tasks::TaskSpawned This state specifies that a task is ready to be mapped to a specific device set. </li> </ul> </li> <li>class parla::cython::tasks::TaskState Abstract base class for Task State. <ul> <li>class parla::cython::tasks::TaskCompleted This state specifies that a task has completed execution. </li> <li>class parla::cython::tasks::TaskCreated This state specifies that a task has been created but not yet spawned. </li> <li>class parla::cython::tasks::TaskException This state specifies that a task has completed execution with an exception. </li> <li>class parla::cython::tasks::TaskMapped This state specifies that a task has been mapped to a device set, but not yet resered its resources there. </li> <li>class parla::cython::tasks::TaskReady This state specifies that a task is \"ready\" to be launched. </li> <li>class parla::cython::tasks::TaskReserved This state specifies that a task has reserved its persistent resources (e.g. </li> <li>class parla::cython::tasks::TaskRunahead State: A task is executing in a stream but the body has completed. </li> <li>class parla::cython::tasks::TaskRunning This state specifies that a task is executing in a stream. </li> <li>class parla::cython::tasks::TaskSpawned This state specifies that a task is ready to be mapped to a specific device set. </li> </ul> </li> <li>class parla::cython::tasks::TaskState Abstract base class for Task State. <ul> <li>class parla::cython::tasks::TaskCompleted This state specifies that a task has completed execution. </li> <li>class parla::cython::tasks::TaskCreated This state specifies that a task has been created but not yet spawned. </li> <li>class parla::cython::tasks::TaskException This state specifies that a task has completed execution with an exception. </li> <li>class parla::cython::tasks::TaskMapped This state specifies that a task has been mapped to a device set, but not yet resered its resources there. </li> <li>class parla::cython::tasks::TaskReady This state specifies that a task is \"ready\" to be launched. </li> <li>class parla::cython::tasks::TaskReserved This state specifies that a task has reserved its persistent resources (e.g. </li> <li>class parla::cython::tasks::TaskRunahead State: A task is executing in a stream but the body has completed. </li> <li>class parla::cython::tasks::TaskRunning This state specifies that a task is executing in a stream. </li> <li>class parla::cython::tasks::TaskSpawned This state specifies that a task is ready to be mapped to a specific device set. </li> </ul> </li> <li>class parla::cython::tasks::TaskState Abstract base class for Task State. <ul> <li>class parla::cython::tasks::TaskCompleted This state specifies that a task has completed execution. </li> <li>class parla::cython::tasks::TaskCreated This state specifies that a task has been created but not yet spawned. </li> <li>class parla::cython::tasks::TaskException This state specifies that a task has completed execution with an exception. </li> <li>class parla::cython::tasks::TaskMapped This state specifies that a task has been mapped to a device set, but not yet resered its resources there. </li> <li>class parla::cython::tasks::TaskReady This state specifies that a task is \"ready\" to be launched. </li> <li>class parla::cython::tasks::TaskReserved This state specifies that a task has reserved its persistent resources (e.g. </li> <li>class parla::cython::tasks::TaskRunahead State: A task is executing in a stream but the body has completed. </li> <li>class parla::cython::tasks::TaskRunning This state specifies that a task is executing in a stream. </li> <li>class parla::cython::tasks::TaskSpawned This state specifies that a task is ready to be mapped to a specific device set. </li> </ul> </li> <li>class parla::cython::tasks::TaskState Abstract base class for Task State. <ul> <li>class parla::cython::tasks::TaskCompleted This state specifies that a task has completed execution. </li> <li>class parla::cython::tasks::TaskCreated This state specifies that a task has been created but not yet spawned. </li> <li>class parla::cython::tasks::TaskException This state specifies that a task has completed execution with an exception. </li> <li>class parla::cython::tasks::TaskMapped This state specifies that a task has been mapped to a device set, but not yet resered its resources there. </li> <li>class parla::cython::tasks::TaskReady This state specifies that a task is \"ready\" to be launched. </li> <li>class parla::cython::tasks::TaskReserved This state specifies that a task has reserved its persistent resources (e.g. </li> <li>class parla::cython::tasks::TaskRunahead State: A task is executing in a stream but the body has completed. </li> <li>class parla::cython::tasks::TaskRunning This state specifies that a task is executing in a stream. </li> <li>class parla::cython::tasks::TaskSpawned This state specifies that a task is ready to be mapped to a specific device set. </li> </ul> </li> <li>class parla::cython::variants::_VariantFunction Function wrapper that dispatches to different architecture targets. </li> <li>class ValueError </li> <li>class parla::cython::variants::VariantDefinitionError Error for an invalid function variant definition. </li> </ul>"},{"location":"runtime/modules/","title":"Modules","text":"<p>Here is a list of all modules:</p>"},{"location":"runtime/","title":"Parla Documentation","text":"<p>Welcome to the core C++ &amp; cython documentation for Parla. This is the landing page for the Doxygen-generated HTML documentation.</p>"},{"location":"runtime/#about","title":"About","text":"<p>Parla is a heterogenous parallel programming framework for Python. The backend is a C++ runtime to avoid contention with the Python Global Interpreter Lock.</p>"},{"location":"runtime/#links","title":"Links","text":"<ul> <li>GitHub Repository </li> </ul>"},{"location":"runtime/pages/","title":"Class List","text":"<p>Here are the classes, structs, unions and interfaces with brief descriptions:</p>"},{"location":"runtime/class_members/","title":"Class Members","text":""},{"location":"runtime/class_members/#a","title":"a","text":"<ul> <li>append_placement_req_opt (ArchitectureRequirement, PlacementRequirementCollections)</li> <li>all_devices_ (DeviceManager)</li> <li>arch_devices_ (DeviceManager)</li> <li>access_mode_ (InnerDataTask)</li> <li>activate (InnerScheduler)</li> <li>activate_wrapper (InnerScheduler)</li> <li>add_worker (InnerScheduler, WorkerPool)</li> <li>add_assigned_device (InnerTask)</li> <li>add_dependencies (InnerTask, parla::cython::tasks::Task)</li> <li>add_dependency (InnerTask)</li> <li>add_dependent_space (InnerTask)</li> <li>add_dependent_task (InnerTask)</li> <li>add_device_req (InnerTask)</li> <li>add_event (InnerTask, parla::cython::tasks::Task)</li> <li>add_parray (InnerTask)</li> <li>add_stream (InnerTask, parla::cython::tasks::Task)</li> <li>assigned_devices (InnerTask, parla::cython::core::DataMovementTaskAttributes, parla::cython::tasks::DataMovementTask)</li> <li>add_task (InnerTaskSpace, TaskBarrier, parray::InnerPArray)</li> <li>add_tasks (InnerTaskSpace, TaskBarrier)</li> <li>assign_task (InnerWorker, parla::cython::scheduler::Scheduler, parla::cython::scheduler::WorkerThread)</li> <li>atomic_decr_num_mapped_tasks (Mapper)</li> <li>atomic_decr_num_mapped_tasks_device (Mapper)</li> <li>atomic_incr_num_mapped_tasks (Mapper)</li> <li>atomic_incr_num_mapped_tasks_device (Mapper)</li> <li>atomic_load_dev_num_mapped_tasks_device (Mapper)</li> <li>atomic_load_total_num_mapped_tasks (Mapper)</li> <li>append_placement_req (MultiDeviceRequirements)</li> <li>at (ProtectedQueue, ProtectedVector)</li> <li>at_unsafe (ProtectedQueue, ProtectedVector)</li> <li>atomic_size (ProtectedQueue, ProtectedVector)</li> <li>any (Task::StatusFlags)</li> <li>active_workers (WorkerPool)</li> <li>all_workers (WorkerPool)</li> <li>access_mode (parla::cython::core::DataMovementTaskAttributes, parla::cython::core::PyInnerWorker, parla::cython::tasks::DataMovementTask)</li> <li>active_device (parla::cython::device::CupyStream)</li> <li>add_device (parla::cython::device::PyCPUArchitecture, parla::cython::device::PyCUDAArchitecture)</li> <li>architecture (parla::cython::device::PyDevice, parla::cython::tasks::TerminalEnvironment)</li> <li>args (parla::cython::tasks::ComputeTask, parla::cython::tasks::TaskRunning)</li> <li>active_stream (parla::cython::tasks::GPUEnvironment)</li> <li>add_dataflow (parla::cython::tasks::Task)</li> </ul>"},{"location":"runtime/class_members/#b","title":"b","text":"<ul> <li>begin_arch_req_addition (InnerTask)</li> <li>begin_multidev_req_addition (InnerTask)</li> <li>blocked (InnerTask)</li> <li>back (ProtectedQueue, ProtectedVector)</li> <li>back_and_pop (ProtectedQueue, ProtectedVector)</li> <li>back_and_pop_unsafe (ProtectedQueue, ProtectedVector)</li> <li>back_unsafe (ProtectedQueue, ProtectedVector)</li> <li>base_function (parla::cython::tasks::ComputeTask)</li> <li>blocking (parla::cython::tasks::TaskEnvironment)</li> </ul>"},{"location":"runtime/class_members/#c","title":"c","text":"<ul> <li>CPUDevice (CPUDevice)</li> <li>CUDADevice (CUDADevice)</li> <li>CopyableAtomic (CopyableAtomic)</li> <li>check_resource_availability (Device)</li> <li>clear_dependencies (InnerTask, parla::cython::tasks::TaskRunning)</li> <li>copy_assigned_devices (InnerTask)</li> <li>cv (InnerWorker, TaskBarrier, WorkerPool)</li> <li>calc_score_archplacement (LocalityLoadBalancingMappingPolicy, MappingPolicy)</li> <li>calc_score_devplacement (LocalityLoadBalancingMappingPolicy, MappingPolicy)</li> <li>calc_score_mdevplacement (LocalityLoadBalancingMappingPolicy, MappingPolicy)</li> <li>check_resources (MemoryReserver, RuntimeReserver)</li> <li>create_datamove_tasks (MemoryReserver)</li> <li>clear (ProtectedQueue, ProtectedVector)</li> <li>clear_unsafe (ProtectedQueue, ProtectedVector)</li> <li>check_greater (ResourcePool)</li> <li>check_lesser (ResourcePool)</li> <li>check_data_resources (RuntimeReserver)</li> <li>compute_runnable (Task::StatusFlags)</li> <li>c_data_task (parla::cython::core::CyDataMovementTaskAttributes, parla::cython::core::PyInnerWorker)</li> <li>c_task_list (parla::cython::core::CyTaskList, parla::cython::core::PyTaskBarrier)</li> <li>c_attrs (parla::cython::core::DataMovementTaskAttributes)</li> <li>c_self (parla::cython::core::PyInnerScheduler, parla::cython::core::PyTaskBarrier, parla::cython::core::PyTaskSpace)</li> <li>c_task (parla::cython::core::PyInnerScheduler)</li> <li>c_worker (parla::cython::core::PyInnerScheduler)</li> <li>c_device (parla::cython::core::PyInnerWorker)</li> <li>c_devices (parla::cython::core::PyInnerWorker)</li> <li>cy_data_attrs (parla::cython::core::PyInnerWorker)</li> <li>c_task_barrier (parla::cython::core::PyTaskBarrier)</li> <li>cy_task_list (parla::cython::core::PyTaskBarrier)</li> <li>c_task_space (parla::cython::core::PyTaskSpace)</li> <li>cpp_parray (parla::cython::cyparray::CyPArray)</li> <li>cpp_parray_state (parla::cython::cyparray_state::CyPArrayState)</li> <li>create_event (parla::cython::device::CupyStream, parla::cython::device::Stream, parla::cython::tasks::TerminalEnvironment)</li> <li>cpp_device (parla::cython::device_manager::CyDeviceManager)</li> <li>cpp_device_manager_ (parla::cython::device_manager::CyDeviceManager)</li> <li>construct_resource_requirements (parla::cython::device_manager::PyDeviceManager)</li> <li>construct_single_architecture_requirements (parla::cython::device_manager::PyDeviceManager)</li> <li>construct_single_device_requirements (parla::cython::device_manager::PyDeviceManager)</li> <li>cy_device_manager (parla::cython::device_manager::PyDeviceManager)</li> <li>cleanup (parla::cython::tasks::ComputeTask)</li> <li>contexts (parla::cython::tasks::TaskEnvironment, parla::cython::tasks::TerminalEnvironment)</li> <li>create_events (parla::cython::tasks::TaskEnvironment)</li> <li>cupy_stream (parla::cython::tasks::TaskEnvironment)</li> <li>ctx (parla::cython::tasks::_TaskLocals)</li> </ul>"},{"location":"runtime/class_members/#d","title":"d","text":"<ul> <li>Device (Device)</li> <li>dev_global_id_ (Device)</li> <li>dev_id_ (Device, InnerDataTask)</li> <li>dev_type_ (Device)</li> <li>DeviceManager (DeviceManager)</li> <li>DeviceQueue (DeviceQueue)</li> <li>device (DeviceQueue, DeviceRequirement, parla::cython::device::CupyStream, parla::cython::device::DeviceResourceRequirement, parla::cython::device::PyCUDADevice, parla::cython::device::PyDevice, parla::cython::device::Stream, parla::cython::tasks::TaskEnvironment, parla::cython::tasks::TerminalEnvironment)</li> <li>DeviceRequirement (DeviceRequirement)</li> <li>dev_ (DeviceRequirement)</li> <li>decrease_num_active_tasks (InnerScheduler)</li> <li>decrease_num_notified_workers (InnerScheduler, WorkerPool)</li> <li>device_manager_ (InnerScheduler, MappingPolicy, PArrayTracker)</li> <li>decrement_num_instances (InnerTask)</li> <li>dependencies (InnerTask, parla::cython::tasks::Task, parla::cython::tasks::TaskRunning)</li> <li>dependency_buffer (InnerTask)</li> <li>dependents (InnerTask)</li> <li>determine_status (InnerTask)</li> <li>device_constraints (InnerTask)</li> <li>dev_num_mapped_tasks_ (Mapper)</li> <li>dummy_dev_idx_ (Mapper)</li> <li>device_queues (PhaseManager)</li> <li>decrease (PhaseStatus, ResourcePool)</li> <li>device_manager (SchedulerPhase, parla::cython::scheduler::Scheduler)</li> <li>dequeue_worker (WorkerPool)</li> <li>dev_id (parla::cython::core::DataMovementTaskAttributes, parla::cython::core::PyInnerWorker, parla::cython::tasks::DataMovementTask)</li> <li>devices (parla::cython::device::PyArchitecture, parla::cython::tasks::TaskEnvironment, parla::cython::tasks::TerminalEnvironment)</li> <li>device_id (parla::cython::device::PyDevice)</li> <li>default_taskspace (parla::cython::scheduler::Scheduler)</li> <li>dataflow (parla::cython::tasks::ComputeTask)</li> <li>device_dict (parla::cython::tasks::TaskEnvironment)</li> <li>device_list (parla::cython::tasks::TaskEnvironment)</li> <li>decr_num_active_tasks (parray::InnerPArray)</li> </ul>"},{"location":"runtime/class_members/#e","title":"e","text":"<ul> <li>empty (DeviceQueue, ProtectedQueue, ProtectedVector)</li> <li>enqueue (DeviceQueue, Launcher, Mapper, MemoryReserver, PhaseManager, RuntimeReserver, SchedulerPhase)</li> <li>enqueue_task (InnerScheduler)</li> <li>enqueue_tasks (InnerScheduler)</li> <li>enqueue_worker (InnerScheduler, WorkerPool)</li> <li>end_arch_req_addition (InnerTask)</li> <li>end_multidev_req_addition (InnerTask)</li> <li>events (InnerTask)</li> <li>enqueue_buffer (InnerWorker, SchedulerPhase)</li> <li>empty_unsafe (ProtectedQueue, ProtectedVector)</li> <li>exception_stack (parla::cython::scheduler::Scheduler)</li> <li>env (parla::cython::tasks::Task)</li> <li>environment (parla::cython::tasks::Task)</li> <li>env_list (parla::cython::tasks::TaskEnvironment)</li> <li>event_dict (parla::cython::tasks::TaskEnvironment)</li> <li>exception (parla::cython::tasks::TaskException)</li> <li>exists_on_device (parray::InnerPArray, parray::PArrayState)</li> </ul>"},{"location":"runtime/class_members/#f","title":"f","text":"<ul> <li>front (DeviceQueue, PhaseManager, ProtectedQueue, ProtectedVector)</li> <li>front_and_pop (ProtectedQueue, ProtectedVector)</li> <li>front_and_pop_unsafe (ProtectedQueue, ProtectedVector)</li> <li>front_unsafe (ProtectedQueue, ProtectedVector)</li> <li>finalize (parla::cython::tasks::CPUEnvironment, parla::cython::tasks::GPUEnvironment, parla::cython::tasks::TaskEnvironment)</li> <li>func (parla::cython::tasks::ComputeTask, parla::cython::tasks::TaskRunning)</li> </ul>"},{"location":"runtime/class_members/#g","title":"g","text":"<ul> <li>GetDeviceRequirementOptions (ArchitectureRequirement)</li> <li>get_global_id (Device, parla::cython::device::PyDevice)</li> <li>get_id (Device)</li> <li>get_mapped_pool (Device)</li> <li>get_mapped_resource (Device)</li> <li>get_max_resource (Device)</li> <li>get_memory_size (Device)</li> <li>get_name (Device, InnerTask, RuntimeReserver, parla::cython::device::PyDevice, parla::cython::device_manager::PrintableFrozenSet, parla::cython::tasks::Task)</li> <li>get_num_vcus (Device)</li> <li>get_py_device (Device)</li> <li>get_reserved_pool (Device)</li> <li>get_reserved_resource (Device)</li> <li>get_resource_pool (Device)</li> <li>get_type (Device, parla::cython::device::PyDevice)</li> <li>get_device_by_global_id (DeviceManager)</li> <li>get_device_by_parray_id (DeviceManager)</li> <li>get_devices (DeviceManager, parla::cython::tasks::TaskEnvironment)</li> <li>get_num_devices (DeviceManager, PhaseManager)</li> <li>globalid_to_parrayid (DeviceManager, parla::cython::device_manager::PyDeviceManager)</li> <li>get_device (DeviceQueue)</li> <li>get_access_mode (InnerDataTask)</li> <li>get_device_id (InnerDataTask)</li> <li>get_py_parray (InnerDataTask, parray::InnerPArray)</li> <li>get_device_manager (InnerScheduler)</li> <li>get_num_active_tasks (InnerScheduler, parray::InnerPArray)</li> <li>get_num_notified_workers (InnerScheduler, WorkerPool, parla::cython::scheduler::Scheduler)</li> <li>get_num_ready_tasks (InnerScheduler)</li> <li>get_num_running_tasks (InnerScheduler, parla::cython::scheduler::Scheduler)</li> <li>get_parray_state (InnerScheduler, PArrayTracker, parla::cython::scheduler::Scheduler)</li> <li>get_parray_tracker (InnerScheduler)</li> <li>get_assigned_devices (InnerTask, parla::cython::tasks::Task)</li> <li>get_complete (InnerTask)</li> <li>get_dependencies (InnerTask, parla::cython::tasks::Task)</li> <li>get_dependents (InnerTask, parla::cython::tasks::Task)</li> <li>get_num_blocking_dependencies (InnerTask, parla::cython::tasks::Task)</li> <li>get_num_dependencies (InnerTask, parla::cython::tasks::Task)</li> <li>get_num_dependents (InnerTask, parla::cython::tasks::Task)</li> <li>get_num_instances (InnerTask)</li> <li>get_num_unmapped_dependencies (InnerTask, parla::cython::tasks::Task)</li> <li>get_placement_req_options (InnerTask)</li> <li>get_py_task (InnerTask)</li> <li>get_removed (InnerTask)</li> <li>get_state (InnerTask, parla::cython::tasks::Task)</li> <li>get_status (InnerTask, RuntimeReserver)</li> <li>get_tasks (InnerTaskSpace)</li> <li>get_task (InnerWorker)</li> <li>get_count (Launcher, Mapper, MemoryReserver, RuntimeReserver, SchedulerPhase)</li> <li>get_placement_reqs_ref (MultiDeviceRequirements)</li> <li>get_num_device_queues (PhaseManager)</li> <li>get (PhaseStatus, ProtectedVector, ResourcePool, Scheduler::Status)</li> <li>get_placement_req_opts_ref (PlacementRequirementCollections)</li> <li>get_unsafe (ProtectedVector)</li> <li>get_vector (ProtectedVector)</li> <li>get_vector_copy (ProtectedVector)</li> <li>get_vector_copy_unsafe (ProtectedVector)</li> <li>get_vector_unsafe (ProtectedVector)</li> <li>get_compute_count (RuntimeReserver)</li> <li>get_movement_count (RuntimeReserver)</li> <li>get_num_available_workers (WorkerPool)</li> <li>get_num_workers (WorkerPool)</li> <li>get_cy_device (parla::cython::device::PyDevice)</li> <li>global_id (parla::cython::device::PyDevice)</li> <li>get_all_architectures (parla::cython::device_manager::PyDeviceManager)</li> <li>get_all_devices (parla::cython::device_manager::PyDeviceManager, parla::cython::tasks::TaskEnvironment)</li> <li>get_cy_device_manager (parla::cython::device_manager::PyDeviceManager)</li> <li>get_device_reqs_from_placement (parla::cython::device_manager::PyDeviceManager, parla::cython::scheduler::Scheduler)</li> <li>get_num_cpus (parla::cython::device_manager::PyDeviceManager)</li> <li>get_num_gpus (parla::cython::device_manager::PyDeviceManager)</li> <li>get_stream (parla::cython::device_manager::StreamPool)</li> <li>get_cupy_devices (parla::cython::tasks::TaskEnvironment)</li> <li>get_library_device (parla::cython::tasks::TaskEnvironment)</li> <li>get_parla_device (parla::cython::tasks::TaskEnvironment)</li> <li>global_ids (parla::cython::tasks::TaskEnvironment)</li> <li>gpu_id (parla::cython::tasks::TaskEnvironment)</li> <li>gpu_ids (parla::cython::tasks::TaskEnvironment)</li> <li>global_tasks (parla::cython::tasks::_TaskLocals)</li> <li>get_variant (parla::cython::variants::_VariantFunction)</li> <li>get_parent_parray (parray::InnerPArray)</li> <li>get_parray_parentid (parray::InnerPArray)</li> <li>get_size (parray::InnerPArray)</li> <li>get_task_list_ref (parray::InnerPArray)</li> </ul>"},{"location":"runtime/class_members/#h","title":"h","text":"<ul> <li>handle_runahead_dependencies (InnerTask, parla::cython::tasks::Task)</li> <li>has (parla::cython::tasks::TaskEnvironment)</li> </ul>"},{"location":"runtime/class_members/#i","title":"i","text":"<ul> <li>is_arch_req (ArchitectureRequirement, DeviceRequirement, MultiDeviceRequirements, PlacementRequirementBase)</li> <li>is_dev_req (ArchitectureRequirement, DeviceRequirement, MultiDeviceRequirements, PlacementRequirementBase)</li> <li>is_multidev_req (ArchitectureRequirement, DeviceRequirement, MultiDeviceRequirements, PlacementRequirementBase)</li> <li>InnerDataTask (InnerDataTask)</li> <li>InnerScheduler (InnerScheduler)</li> <li>increase_num_active_tasks (InnerScheduler)</li> <li>increase_num_notified_workers (InnerScheduler, WorkerPool)</li> <li>InnerTask (InnerTask)</li> <li>id (InnerTask, TaskBarrier, parla::cython::device::PyArchitecture, parla::cython::device::PyDevice, parla::cython::tasks::Task, parray::InnerPArray)</li> <li>instance (InnerTask)</li> <li>is_data (InnerTask)</li> <li>is_data_task (InnerTask, parla::cython::core::PyInnerWorker)</li> <li>InnerTaskSpace (InnerTaskSpace)</li> <li>InnerWorker (InnerWorker)</li> <li>increase (PhaseStatus, ResourcePool)</li> <li>inner_scheduler (parla::cython::core::PyInnerScheduler, parla::cython::scheduler::Scheduler)</li> <li>inner_worker (parla::cython::core::PyInnerWorker, parla::cython::scheduler::WorkerThread)</li> <li>inner_task (parla::cython::core::PyTaskBarrier, parla::cython::core::PyTaskSpace, parla::cython::tasks::Task)</li> <li>is_multidevice_placement (parla::cython::device_manager::PyDeviceManager)</li> <li>index (parla::cython::scheduler::WorkerThread)</li> <li>inner_barrier (parla::cython::tasks::AtomicTaskList, parla::cython::tasks::BackendTaskList)</li> <li>inner_space (parla::cython::tasks::AtomicTaskSpace, parla::cython::tasks::BackendTaskSpace)</li> <li>instantiate (parla::cython::tasks::ComputeTask, parla::cython::tasks::DataMovementTask, parla::cython::tasks::Task)</li> <li>idx (parla::cython::tasks::Task)</li> <li>is_terminal (parla::cython::tasks::TaskCompleted, parla::cython::tasks::TaskCreated, parla::cython::tasks::TaskEnvironment, parla::cython::tasks::TaskException, parla::cython::tasks::TaskMapped, parla::cython::tasks::TaskReady, parla::cython::tasks::TaskReserved, parla::cython::tasks::TaskRunahead, parla::cython::tasks::TaskRunning, parla::cython::tasks::TaskSpawned, parla::cython::tasks::TaskState, parla::cython::tasks::TerminalEnvironment)</li> <li>InnerPArray (parray::InnerPArray)</li> <li>incr_num_active_tasks (parray::InnerPArray)</li> </ul>"},{"location":"runtime/class_members/#l","title":"l","text":"<ul> <li>last_dev_id_ (DeviceManager)</li> <li>launcher (InnerScheduler)</li> <li>Launcher (Launcher)</li> <li>last_device_idx (PhaseManager)</li> <li>length (ProtectedQueue, ProtectedVector)</li> <li>lock (ProtectedQueue, ProtectedVector)</li> <li>launchable_tasks_buffer (RuntimeReserver)</li> <li>loop (parla::cython::tasks::TaskEnvironment)</li> </ul>"},{"location":"runtime/class_members/#m","title":"m","text":"<ul> <li>mapped_res_ (Device)</li> <li>MDQueue_t (DeviceQueue)</li> <li>MixedQueue_t (DeviceQueue)</li> <li>mixed_queue (DeviceQueue)</li> <li>mapper (InnerScheduler)</li> <li>memory_reserver (InnerScheduler)</li> <li>mtx (InnerTask, InnerWorker, PArrayTracker, ProtectedQueue, ProtectedVector, SchedulerPhase, TaskBarrier, WorkerPool)</li> <li>MappingPolicy (LocalityLoadBalancingMappingPolicy, MappingPolicy)</li> <li>Mapper (Mapper)</li> <li>mappable_tasks (Mapper)</li> <li>mapped_tasks_buffer (Mapper)</li> <li>MemoryReserver (MemoryReserver)</li> <li>managed_parrays_ (PArrayTracker)</li> <li>movement_tasks (RuntimeReserver)</li> <li>mappable (Task::StatusFlags)</li> <li>max_workers (WorkerPool)</li> <li>memory_sz (parla::cython::device::DeviceResource)</li> </ul>"},{"location":"runtime/class_members/#n","title":"n","text":"<ul> <li>num_tasks (DeviceQueue, PhaseManager)</li> <li>num_active_tasks (InnerScheduler, parray::InnerPArray)</li> <li>name (InnerTask, Launcher, Mapper, MemoryReserver, PhaseStatus, ProtectedQueue, ProtectedVector, RuntimeReserver, SchedulerPhase, parla::cython::core::DataMovementTaskAttributes, parla::cython::core::PyInnerWorker, parla::cython::device::PyArchitecture, parla::cython::tasks::DataMovementTask, parla::cython::tasks::Task, parla::cython::tasks::TaskSpace)</li> <li>notify (InnerTask, InnerTaskSpace, TaskBarrier)</li> <li>notify_dependents (InnerTask)</li> <li>notify_dependents_completed (InnerTask)</li> <li>notify_dependents_wrapper (InnerTask, parla::cython::tasks::Task)</li> <li>num_blocking_compute_dependencies (InnerTask)</li> <li>num_blocking_dependencies (InnerTask)</li> <li>num_persistant_instances (InnerTask)</li> <li>num_runtime_instances (InnerTask)</li> <li>num_unmapped_dependencies (InnerTask)</li> <li>num_unreserved_dependencies (InnerTask)</li> <li>num_unspawned_dependencies (InnerTask)</li> <li>notified (InnerWorker)</li> <li>num_running_tasks (Launcher)</li> <li>ndevices (PhaseManager)</li> <li>num_incomplete_tasks (TaskBarrier)</li> <li>notified_workers (WorkerPool)</li> <li>num_devices (parla::cython::core::PyInnerWorker)</li> <li>num_vcus (parla::cython::device::DeviceResource)</li> <li>num_real_gpus (parla::cython::device_manager::PyDeviceManager)</li> </ul>"},{"location":"runtime/class_members/#o","title":"o","text":"<ul> <li>operator= (CopyableAtomic, ProtectedVector)</li> <li>operator[] (ProtectedQueue, ProtectedVector)</li> </ul>"},{"location":"runtime/class_members/#p","title":"p","text":"<ul> <li>placement_reqs_ (ArchitectureRequirement, MultiDeviceRequirements, PlacementRequirementCollections)</li> <li>py_dev_ (Device)</li> <li>parrayid_to_globalid (DeviceManager, parla::cython::device_manager::PyDeviceManager)</li> <li>print_registered_devices (DeviceManager, parla::cython::device_manager::PyDeviceManager)</li> <li>pop (DeviceQueue, PhaseManager)</li> <li>parray_ (InnerDataTask)</li> <li>parray_tracker_ (InnerScheduler, MappingPolicy)</li> <li>py_scheduler (InnerScheduler)</li> <li>parray_list (InnerTask)</li> <li>placement_req_options_ (InnerTask)</li> <li>priority (InnerTask, parla::cython::tasks::Task)</li> <li>process_dependencies (InnerTask)</li> <li>processed_data (InnerTask)</li> <li>py_task (InnerTask, parla::cython::core::PyInnerWorker)</li> <li>py_worker (InnerWorker)</li> <li>policy_ (Mapper)</li> <li>PArrayTracker (PArrayTracker)</li> <li>PhaseManager (PhaseManager)</li> <li>PhaseStatus (PhaseStatus)</li> <li>print (PhaseStatus, Scheduler::Status)</li> <li>ProtectedQueue (ProtectedQueue)</li> <li>pop_back (ProtectedQueue, ProtectedVector)</li> <li>pop_back_unsafe (ProtectedQueue, ProtectedVector)</li> <li>pop_front (ProtectedQueue)</li> <li>pop_front_unsafe (ProtectedQueue)</li> <li>push_back (ProtectedQueue, ProtectedVector)</li> <li>push_back_unsafe (ProtectedQueue, ProtectedVector)</li> <li>push_front (ProtectedQueue)</li> <li>push_front_unsafe (ProtectedQueue)</li> <li>ProtectedVector (ProtectedVector)</li> <li>print_status (RuntimeReserver)</li> <li>parray (parla::cython::core::DataMovementTaskAttributes, parla::cython::tasks::DataMovementTask)</li> <li>py_assigned_devices (parla::cython::core::PyInnerWorker)</li> <li>py_device (parla::cython::core::PyInnerWorker)</li> <li>py_parray (parla::cython::core::PyInnerWorker)</li> <li>parse_config_and_register_devices (parla::cython::device_manager::PyDeviceManager)</li> <li>py_registered_archs (parla::cython::device_manager::PyDeviceManager)</li> <li>py_handle_runahead_dependencies (parla::cython::tasks::Task)</li> <li>parfor (parla::cython::tasks::TaskEnvironment)</li> <li>parent_id (parray::InnerPArray)</li> <li>PArrayState (parray::PArrayState)</li> </ul>"},{"location":"runtime/class_members/#q","title":"q","text":"<ul> <li>query_mapped_resource (Device, parla::cython::device::PyDevice)</li> <li>query_reserved_resource (Device, parla::cython::device::PyDevice)</li> <li>query_resource (Device, parla::cython::device::PyDevice)</li> <li>queue_dependency (InnerTask)</li> <li>q (ProtectedQueue)</li> </ul>"},{"location":"runtime/class_members/#r","title":"r","text":"<ul> <li>res_ (Device)</li> <li>reserved_res_ (Device)</li> <li>resource_map_ (Device)</li> <li>register_device (DeviceManager)</li> <li>res_req (DeviceRequirement, parla::cython::device::DeviceResourceRequirement)</li> <li>res_req_ (DeviceRequirement)</li> <li>release_parray (InnerScheduler, PArrayTracker, parla::cython::scheduler::Scheduler)</li> <li>reserve_parray (InnerScheduler, PArrayTracker, parla::cython::scheduler::Scheduler)</li> <li>run (InnerScheduler, Launcher, Mapper, MemoryReserver, RuntimeReserver, SchedulerPhase, parla::cython::scheduler::ControllableThread, parla::cython::scheduler::Scheduler, parla::cython::scheduler::WorkerThread, parla::cython::tasks::Task)</li> <li>runtime_reserver (InnerScheduler)</li> <li>ReqAdditionState (InnerTask)</li> <li>removed_reserved (InnerTask)</li> <li>removed_runtime (InnerTask)</li> <li>req_addition_mode_ (InnerTask)</li> <li>reset (InnerTask, PhaseStatus, Scheduler::Status)</li> <li>reset_events_streams (InnerTask)</li> <li>ready (InnerWorker)</li> <li>remove_task (InnerWorker, parla::cython::scheduler::WorkerThread)</li> <li>rrcount (MappingPolicy)</li> <li>reservable_tasks (MemoryReserver)</li> <li>reserve_resources (MemoryReserver, RuntimeReserver)</li> <li>reserved_tasks_buffer (MemoryReserver)</li> <li>reserve (ProtectedVector)</li> <li>reserve_unsafe (ProtectedVector)</li> <li>resize (ProtectedVector)</li> <li>resize_unsafe (ProtectedVector)</li> <li>ResourcePool (ResourcePool)</li> <li>resources (ResourcePool, parla::cython::core::Resources)</li> <li>RuntimeReserver (RuntimeReserver)</li> <li>reserve_data_resources (RuntimeReserver)</li> <li>runnable_tasks (RuntimeReserver)</li> <li>reservable (Task::StatusFlags)</li> <li>runnable (Task::StatusFlags)</li> <li>register_cpu_devices (parla::cython::device_manager::PyDeviceManager)</li> <li>register_cupy_gpu_devices (parla::cython::device_manager::PyDeviceManager)</li> <li>register_devices_to_cpp (parla::cython::device_manager::PyDeviceManager)</li> <li>registered_devices (parla::cython::device_manager::PyDeviceManager)</li> <li>return_stream (parla::cython::device_manager::StreamPool)</li> <li>return_streams (parla::cython::tasks::CPUEnvironment, parla::cython::tasks::GPUEnvironment, parla::cython::tasks::TaskEnvironment)</li> <li>runahead (parla::cython::tasks::DataMovementTask, parla::cython::tasks::Task)</li> <li>result (parla::cython::tasks::Task)</li> <li>return_value (parla::cython::tasks::TaskCompleted, parla::cython::tasks::TaskRunahead)</li> <li>record_events (parla::cython::tasks::TaskEnvironment)</li> <li>retrieve (parla::cython::tasks::TaskEnvironment)</li> <li>record_event (parla::cython::tasks::TerminalEnvironment)</li> </ul>"},{"location":"runtime/class_members/#s","title":"s","text":"<ul> <li>set_global_id (Device)</li> <li>size (DeviceQueue, PhaseManager, PhaseStatus, ProtectedQueue, ProtectedVector, Scheduler::Status)</li> <li>set_num_workers (InnerScheduler, WorkerPool)</li> <li>set_py_scheduler (InnerScheduler)</li> <li>set_stop_callback (InnerScheduler)</li> <li>should_run (InnerScheduler)</li> <li>sleep_flag (InnerScheduler)</li> <li>sleep_time (InnerScheduler)</li> <li>spawn_task (InnerScheduler, parla::cython::scheduler::Scheduler)</li> <li>spawn_wait (InnerScheduler, WorkerPool, parla::cython::scheduler::Scheduler)</li> <li>status (InnerScheduler, InnerTask, Launcher, Mapper, MemoryReserver, PhaseStatus, RuntimeReserver, Scheduler::Status, parla::cython::scheduler::WorkerThread)</li> <li>stop (InnerScheduler, InnerWorker, parla::cython::scheduler::ControllableThread, parla::cython::scheduler::Scheduler, parla::cython::scheduler::WorkerThread)</li> <li>stop_callback (InnerScheduler, parla::cython::scheduler::Scheduler)</li> <li>scheduler (InnerTask, InnerWorker, SchedulerPhase, parla::cython::scheduler::Scheduler, parla::cython::scheduler::SchedulerContext, parla::cython::scheduler::WorkerThread, parla::cython::tasks::DataMovementTask, parla::cython::tasks::Task)</li> <li>set_complete (InnerTask, parla::cython::tasks::Task)</li> <li>set_id (InnerTask, TaskBarrier)</li> <li>set_name (InnerTask)</li> <li>set_num_instances (InnerTask)</li> <li>set_priority (InnerTask)</li> <li>set_py_task (InnerTask)</li> <li>set_removed (InnerTask)</li> <li>set_scheduler (InnerTask, InnerWorker, parla::cython::tasks::Task)</li> <li>set_state (InnerTask, parla::cython::tasks::Task)</li> <li>set_status (InnerTask)</li> <li>spaces (InnerTask)</li> <li>state (InnerTask, parla::cython::tasks::Task)</li> <li>streams (InnerTask, parla::cython::tasks::TaskEnvironment)</li> <li>sync_type (InnerTask)</li> <li>synchronize_dependency_events (InnerTask)</li> <li>synchronize_events (InnerTask, parla::cython::tasks::TaskEnvironment)</li> <li>set_py_worker (InnerWorker)</li> <li>set_thread_idx (InnerWorker)</li> <li>set (PhaseStatus, ProtectedVector, ResourcePool, Scheduler::Status)</li> <li>size_unsafe (ProtectedQueue, ProtectedVector)</li> <li>set_unsafe (ProtectedVector)</li> <li>SchedulerPhase (SchedulerPhase)</li> <li>StatusFlags (Task::StatusFlags)</li> <li>spawnable (Task::StatusFlags)</li> <li>set_size (parla::cython::cyparray::CyPArray, parray::InnerPArray)</li> <li>set_exist_on_device (parla::cython::cyparray_state::CyPArrayState, parray::PArrayState)</li> <li>set_valid_on_device (parla::cython::cyparray_state::CyPArrayState, parray::PArrayState)</li> <li>stream (parla::cython::device::CupyStream, parla::cython::device::Stream, parla::cython::tasks::TaskEnvironment)</li> <li>synchronize (parla::cython::device::CupyStream, parla::cython::device::Stream, parla::cython::tasks::TaskEnvironment)</li> <li>stream_pool (parla::cython::device_manager::PyDeviceManager)</li> <li>StreamClass (parla::cython::device_manager::StreamPool)</li> <li>start_monitor (parla::cython::scheduler::Scheduler)</li> <li>start (parla::cython::scheduler::WorkerThread, parla::cython::tasks::TaskSpace)</li> <li>scheduler_context (parla::cython::scheduler::_SchedulerLocals)</li> <li>set_device_reqs (parla::cython::tasks::Task)</li> <li>storage (parla::cython::tasks::TaskEnvironment)</li> <li>store (parla::cython::tasks::TaskEnvironment)</li> <li>stream_list (parla::cython::tasks::TaskEnvironment)</li> <li>shape (parla::cython::tasks::TaskSpace)</li> <li>synchronize_event (parla::cython::tasks::TerminalEnvironment)</li> <li>spawn_count (parla::cython::tasks::_TaskLocals)</li> </ul>"},{"location":"runtime/class_members/#t","title":"t","text":"<ul> <li>task_buffer (InnerScheduler, Launcher)</li> <li>task_cleanup (InnerScheduler)</li> <li>task_cleanup_postsync (InnerScheduler)</li> <li>task_cleanup_presync (InnerScheduler)</li> <li>tmp_arch_req_ (InnerTask)</li> <li>tmp_multdev_reqs_ (InnerTask)</li> <li>task_map (InnerTaskSpace)</li> <li>task (InnerWorker, parla::cython::core::PyTaskBarrier, parla::cython::core::PyTaskSpace, parla::cython::scheduler::WorkerThread)</li> <li>thread_idx (InnerWorker)</li> <li>total_num_mapped_tasks_ (Mapper)</li> <li>track_parray (PArrayTracker)</li> <li>TaskBarrier (TaskBarrier)</li> <li>task_attrs (parla::cython::scheduler::WorkerThread)</li> <li>taskspace (parla::cython::tasks::Task)</li> <li>tasks (parla::cython::tasks::TaskCollection, parla::cython::tasks::TaskSpace)</li> <li>traceback (parla::cython::tasks::TaskException)</li> <li>task_scopes (parla::cython::tasks::_TaskLocals)</li> </ul>"},{"location":"runtime/class_members/#u","title":"u","text":"<ul> <li>untrack_parray (PArrayTracker)</li> <li>unlock (ProtectedQueue, ProtectedVector)</li> <li>update (Scheduler::Status)</li> <li>unpack_placements (parla::cython::device_manager::PyDeviceManager)</li> <li>unpack_name (parla::cython::tasks::Task)</li> <li>update_name (parla::cython::tasks::Task)</li> </ul>"},{"location":"runtime/class_members/#v","title":"v","text":"<ul> <li>vec (ProtectedVector)</li> <li>V (ResourcePool)</li> <li>value (parla::cython::tasks::TaskCompleted, parla::cython::tasks::TaskCreated, parla::cython::tasks::TaskException, parla::cython::tasks::TaskMapped, parla::cython::tasks::TaskReady, parla::cython::tasks::TaskReserved, parla::cython::tasks::TaskRunahead, parla::cython::tasks::TaskRunning, parla::cython::tasks::TaskSpawned, parla::cython::tasks::TaskState)</li> <li>view (parla::cython::tasks::TaskSpace)</li> <li>variant (parla::cython::variants::_VariantFunction)</li> <li>valid_on_device (parray::InnerPArray, parray::PArrayState)</li> </ul>"},{"location":"runtime/class_members/#w","title":"w","text":"<ul> <li>waiting_queue (DeviceQueue)</li> <li>workers (InnerScheduler)</li> <li>wait_dependency_events (InnerTask)</li> <li>wait (InnerTaskSpace, InnerWorker, TaskBarrier, parla::cython::tasks::AtomicTaskList, parla::cython::tasks::AtomicTaskSpace, parla::cython::tasks::BackendTaskList, parla::cython::tasks::BackendTaskSpace)</li> <li>worker_buffer (Launcher)</li> <li>WorkerPool (WorkerPool)</li> <li>wait_event (parla::cython::device::CupyStream, parla::cython::device::Stream, parla::cython::tasks::TerminalEnvironment)</li> <li>worker_threads (parla::cython::scheduler::Scheduler)</li> <li>wait_events (parla::cython::tasks::TaskEnvironment)</li> <li>write_streams_to_task (parla::cython::tasks::TaskEnvironment, parla::cython::tasks::TerminalEnvironment)</li> <li>write_to_task (parla::cython::tasks::TaskEnvironment, parla::cython::tasks::TerminalEnvironment)</li> <li>write_events_to_task (parla::cython::tasks::TerminalEnvironment)</li> </ul>"},{"location":"runtime/class_members/#_1","title":"~","text":"<ul> <li>~InnerScheduler (InnerScheduler)</li> <li>~PhaseManager (PhaseManager)</li> </ul>"},{"location":"runtime/class_members/#_","title":"_","text":"<ul> <li>_add_task (TaskBarrier)</li> <li>__cinit__ (parla::cython::core::CyTaskList, parla::cython::core::PyInnerScheduler, parla::cython::core::PyInnerWorker, parla::cython::core::PyTaskBarrier, parla::cython::core::PyTaskSpace, parla::cython::cyparray::CyPArray, parla::cython::cyparray_state::CyPArrayState, parla::cython::device::CyCPUDevice, parla::cython::device::CyCUDADevice, parla::cython::device_manager::CyDeviceManager)</li> <li>__init__ (parla::cython::core::DataMovementTaskAttributes, parla::cython::core::PyInnerScheduler, parla::cython::core::PyInnerWorker, parla::cython::core::PyTaskBarrier, parla::cython::core::PyTaskSpace, parla::cython::core::Resources, parla::cython::cyparray::CyPArray, parla::cython::cyparray_state::CyPArrayState, parla::cython::device::CupyStream, parla::cython::device::CyCPUDevice, parla::cython::device::CyCUDADevice, parla::cython::device::DeviceResource, parla::cython::device::DeviceResourceRequirement, parla::cython::device::PyArchitecture, parla::cython::device::PyCPUArchitecture, parla::cython::device::PyCPUDevice, parla::cython::device::PyCUDAArchitecture, parla::cython::device::PyCUDADevice, parla::cython::device::PyDevice, parla::cython::device::Stream, parla::cython::device_manager::CyDeviceManager, parla::cython::device_manager::PyDeviceManager, parla::cython::device_manager::StreamPool, parla::cython::scheduler::ControllableThread, parla::cython::scheduler::Scheduler, parla::cython::scheduler::WorkerThread, parla::cython::scheduler::_SchedulerLocals, parla::cython::tasks::AtomicTaskList, parla::cython::tasks::AtomicTaskSpace, parla::cython::tasks::BackendTaskList, parla::cython::tasks::BackendTaskSpace, parla::cython::tasks::CPUEnvironment, parla::cython::tasks::ComputeTask, parla::cython::tasks::DataMovementTask, parla::cython::tasks::GPUEnvironment, parla::cython::tasks::Task, parla::cython::tasks::TaskCollection, parla::cython::tasks::TaskCompleted, parla::cython::tasks::TaskEnvironment, parla::cython::tasks::TaskException, parla::cython::tasks::TaskList, parla::cython::tasks::TaskRunahead, parla::cython::tasks::TaskRunning, parla::cython::tasks::TaskSpace, parla::cython::tasks::TerminalEnvironment, parla::cython::tasks::_TaskLocals, parla::cython::variants::_VariantFunction)</li> <li>__dealloc__ (parla::cython::core::PyInnerScheduler, parla::cython::core::PyInnerWorker, parla::cython::core::PyTaskBarrier, parla::cython::core::PyTaskSpace, parla::cython::cyparray::CyPArray, parla::cython::cyparray_state::CyPArrayState, parla::cython::device::CyDevice, parla::cython::device::PyDevice, parla::cython::device_manager::CyDeviceManager, parla::cython::device_manager::PyDeviceManager)</li> <li>_inner_worker (parla::cython::core::PyInnerWorker)</li> <li>__enter__ (parla::cython::device::CupyStream, parla::cython::device::PyDevice, parla::cython::device::Stream, parla::cython::scheduler::Scheduler, parla::cython::scheduler::SchedulerContext, parla::cython::tasks::CPUEnvironment, parla::cython::tasks::GPUEnvironment, parla::cython::tasks::TaskEnvironment)</li> <li>__exit__ (parla::cython::device::CupyStream, parla::cython::device::PyDevice, parla::cython::device::Stream, parla::cython::scheduler::Scheduler, parla::cython::scheduler::SchedulerContext, parla::cython::tasks::CPUEnvironment, parla::cython::tasks::GPUEnvironment, parla::cython::tasks::TaskEnvironment)</li> <li>__getatrr__ (parla::cython::device::CupyStream)</li> <li>__repr__ (parla::cython::device::CupyStream, parla::cython::device::DeviceResource, parla::cython::device::DeviceResourceRequirement, parla::cython::device::PyArchitecture, parla::cython::device::PyDevice, parla::cython::device::Stream, parla::cython::device_manager::PrintableFrozenSet, parla::cython::device_manager::StreamPool, parla::cython::tasks::AtomicTaskList, parla::cython::tasks::AtomicTaskSpace, parla::cython::tasks::BackendTaskList, parla::cython::tasks::BackendTaskSpace, parla::cython::tasks::CPUEnvironment, parla::cython::tasks::GPUEnvironment, parla::cython::tasks::Task, parla::cython::tasks::TaskCollection, parla::cython::tasks::TaskCompleted, parla::cython::tasks::TaskEnvironment, parla::cython::tasks::TaskException, parla::cython::tasks::TaskList, parla::cython::tasks::TaskRunahead, parla::cython::tasks::TaskRunning, parla::cython::tasks::TaskSpace, parla::cython::tasks::TerminalEnvironment, parla::cython::variants::_VariantFunction)</li> <li>__str__ (parla::cython::device::CupyStream, parla::cython::device::PyDevice, parla::cython::device::Stream, parla::cython::tasks::TaskCollection)</li> <li>_device (parla::cython::device::CupyStream, parla::cython::device::PyCUDADevice, parla::cython::device::PyDevice, parla::cython::device::Stream, parla::cython::tasks::TaskEnvironment, parla::cython::tasks::TerminalEnvironment)</li> <li>_device_id (parla::cython::device::CupyStream, parla::cython::device::PyDevice, parla::cython::device::Stream)</li> <li>_stream (parla::cython::device::CupyStream, parla::cython::device::Stream)</li> <li>_cpp_device (parla::cython::device::CyCPUDevice, parla::cython::device::CyCUDADevice)</li> <li>__call__ (parla::cython::device::PyArchitecture, parla::cython::tasks::TerminalEnvironment, parla::cython::variants::_VariantFunction)</li> <li>__eq__ (parla::cython::device::PyArchitecture, parla::cython::device::PyDevice, parla::cython::tasks::TaskCollection, parla::cython::tasks::TerminalEnvironment)</li> <li>__getitem__ (parla::cython::device::PyArchitecture, parla::cython::device::PyDevice, parla::cython::tasks::AtomicTaskSpace, parla::cython::tasks::BackendTaskSpace, parla::cython::tasks::CPUEnvironment, parla::cython::tasks::TaskEnvironment, parla::cython::tasks::TaskList, parla::cython::tasks::TaskSpace, parla::cython::tasks::TerminalEnvironment)</li> <li>__hash__ (parla::cython::device::PyArchitecture, parla::cython::device::PyDevice, parla::cython::tasks::Task, parla::cython::tasks::TaskCollection, parla::cython::tasks::TerminalEnvironment)</li> <li>__len__ (parla::cython::device::PyArchitecture, parla::cython::tasks::CPUEnvironment, parla::cython::tasks::TaskCollection, parla::cython::tasks::TaskEnvironment, parla::cython::tasks::TerminalEnvironment)</li> <li>__mul__ (parla::cython::device::PyArchitecture)</li> <li>_devices (parla::cython::device::PyArchitecture)</li> <li>_id (parla::cython::device::PyArchitecture, parla::cython::tasks::TaskSpace)</li> <li>_name (parla::cython::device::PyArchitecture, parla::cython::tasks::BackendTaskList, parla::cython::tasks::TaskCollection, parla::cython::tasks::TaskList, parla::cython::tasks::TaskSpace)</li> <li>_cy_device (parla::cython::device::PyCPUDevice, parla::cython::device::PyCUDADevice)</li> <li>_dev_id (parla::cython::device::PyDevice)</li> <li>_dev_type (parla::cython::device::PyDevice)</li> <li>_device_name (parla::cython::device::PyDevice)</li> <li>_global_id (parla::cython::device::PyDevice)</li> <li>__summarize__ (parla::cython::device_manager::StreamPool)</li> <li>_device_list (parla::cython::device_manager::StreamPool)</li> <li>_per_device (parla::cython::device_manager::StreamPool)</li> <li>_pool (parla::cython::device_manager::StreamPool)</li> <li>_should_run (parla::cython::scheduler::ControllableThread)</li> <li>_monitor (parla::cython::scheduler::Scheduler, parla::cython::scheduler::WorkerThread)</li> <li>_initialize (parla::cython::scheduler::WorkerThread)</li> <li>_scheduler (parla::cython::scheduler::WorkerThread)</li> <li>_scheduler_context_stack (parla::cython::scheduler::_SchedulerLocals)</li> <li>__add__ (parla::cython::tasks::AtomicTaskList, parla::cython::tasks::TaskCollection, parla::cython::tasks::TaskList, parla::cython::tasks::TaskSpace)</li> <li>__iadd__ (parla::cython::tasks::AtomicTaskList, parla::cython::tasks::TaskCollection, parla::cython::tasks::TaskList, parla::cython::tasks::TaskSpace)</li> <li>_tasks (parla::cython::tasks::BackendTaskList, parla::cython::tasks::TaskCollection, parla::cython::tasks::TaskList, parla::cython::tasks::TaskSpace)</li> <li>_execute_task (parla::cython::tasks::ComputeTask, parla::cython::tasks::DataMovementTask, parla::cython::tasks::Task)</li> <li>_finish (parla::cython::tasks::ComputeTask, parla::cython::tasks::Task)</li> <li>__await__ (parla::cython::tasks::Task, parla::cython::tasks::TaskCollection)</li> <li>_env (parla::cython::tasks::Task)</li> <li>_environment (parla::cython::tasks::Task)</li> <li>_wait_for_dependency_events (parla::cython::tasks::Task)</li> <li>__contains__ (parla::cython::tasks::TaskCollection, parla::cython::tasks::TaskEnvironment)</li> <li>__iter__ (parla::cython::tasks::TaskCollection)</li> <li>__ne__ (parla::cython::tasks::TaskCollection)</li> <li>__slots__ (parla::cython::tasks::TaskCompleted, parla::cython::tasks::TaskException, parla::cython::tasks::TaskRunahead, parla::cython::tasks::TaskRunning, parla::cython::tasks::TaskState)</li> <li>_global_device_ids (parla::cython::tasks::TaskEnvironment, parla::cython::tasks::TerminalEnvironment)</li> <li>_store (parla::cython::tasks::TaskEnvironment)</li> <li>_create (parla::cython::tasks::TaskSpace)</li> <li>_view (parla::cython::tasks::TaskSpace)</li> <li>_arch_type (parla::cython::tasks::TerminalEnvironment)</li> <li>_ctx (parla::cython::tasks::_TaskLocals)</li> <li>_global_tasks (parla::cython::tasks::_TaskLocals)</li> <li>_default (parla::cython::variants::_VariantFunction)</li> <li>_variants (parla::cython::variants::_VariantFunction)</li> <li>_num_devices (parray::InnerPArray)</li> <li>_parent_parray (parray::InnerPArray)</li> <li>_py_parray (parray::InnerPArray)</li> <li>_size (parray::InnerPArray)</li> <li>_state (parray::InnerPArray)</li> <li>_task_lists (parray::InnerPArray)</li> <li>_exist_on_device (parray::PArrayState)</li> <li>_valid_on_device (parray::PArrayState)</li> </ul>"},{"location":"runtime/class_member_functions/","title":"Class Member Functions","text":""},{"location":"runtime/class_member_functions/#a","title":"a","text":"<ul> <li>append_placement_req_opt (ArchitectureRequirement, PlacementRequirementCollections)</li> <li>activate (InnerScheduler)</li> <li>activate_wrapper (InnerScheduler)</li> <li>add_worker (InnerScheduler, WorkerPool)</li> <li>add_assigned_device (InnerTask)</li> <li>add_dependencies (InnerTask, parla::cython::tasks::Task)</li> <li>add_dependency (InnerTask)</li> <li>add_dependent_space (InnerTask)</li> <li>add_dependent_task (InnerTask)</li> <li>add_device_req (InnerTask)</li> <li>add_event (InnerTask, parla::cython::tasks::Task)</li> <li>add_parray (InnerTask)</li> <li>add_stream (InnerTask, parla::cython::tasks::Task)</li> <li>add_task (InnerTaskSpace, TaskBarrier, parray::InnerPArray)</li> <li>add_tasks (InnerTaskSpace, TaskBarrier)</li> <li>assign_task (InnerWorker, parla::cython::scheduler::Scheduler, parla::cython::scheduler::WorkerThread)</li> <li>atomic_decr_num_mapped_tasks (Mapper)</li> <li>atomic_decr_num_mapped_tasks_device (Mapper)</li> <li>atomic_incr_num_mapped_tasks (Mapper)</li> <li>atomic_incr_num_mapped_tasks_device (Mapper)</li> <li>atomic_load_dev_num_mapped_tasks_device (Mapper)</li> <li>atomic_load_total_num_mapped_tasks (Mapper)</li> <li>append_placement_req (MultiDeviceRequirements)</li> <li>at (ProtectedQueue, ProtectedVector)</li> <li>at_unsafe (ProtectedQueue, ProtectedVector)</li> <li>atomic_size (ProtectedQueue, ProtectedVector)</li> <li>any (Task::StatusFlags)</li> <li>add_device (parla::cython::device::PyCPUArchitecture, parla::cython::device::PyCUDAArchitecture)</li> <li>architecture (parla::cython::device::PyDevice, parla::cython::tasks::TerminalEnvironment)</li> <li>add_dataflow (parla::cython::tasks::Task)</li> </ul>"},{"location":"runtime/class_member_functions/#b","title":"b","text":"<ul> <li>begin_arch_req_addition (InnerTask)</li> <li>begin_multidev_req_addition (InnerTask)</li> <li>blocked (InnerTask)</li> <li>back (ProtectedQueue, ProtectedVector)</li> <li>back_and_pop (ProtectedQueue, ProtectedVector)</li> <li>back_and_pop_unsafe (ProtectedQueue, ProtectedVector)</li> <li>back_unsafe (ProtectedQueue, ProtectedVector)</li> </ul>"},{"location":"runtime/class_member_functions/#c","title":"c","text":"<ul> <li>CPUDevice (CPUDevice)</li> <li>CUDADevice (CUDADevice)</li> <li>CopyableAtomic (CopyableAtomic)</li> <li>check_resource_availability (Device)</li> <li>clear_dependencies (InnerTask, parla::cython::tasks::TaskRunning)</li> <li>copy_assigned_devices (InnerTask)</li> <li>calc_score_archplacement (LocalityLoadBalancingMappingPolicy, MappingPolicy)</li> <li>calc_score_devplacement (LocalityLoadBalancingMappingPolicy, MappingPolicy)</li> <li>calc_score_mdevplacement (LocalityLoadBalancingMappingPolicy, MappingPolicy)</li> <li>check_resources (MemoryReserver, RuntimeReserver)</li> <li>create_datamove_tasks (MemoryReserver)</li> <li>clear (ProtectedQueue, ProtectedVector)</li> <li>clear_unsafe (ProtectedQueue, ProtectedVector)</li> <li>check_greater (ResourcePool)</li> <li>check_lesser (ResourcePool)</li> <li>check_data_resources (RuntimeReserver)</li> <li>create_event (parla::cython::device::CupyStream, parla::cython::device::Stream, parla::cython::tasks::TerminalEnvironment)</li> <li>construct_resource_requirements (parla::cython::device_manager::PyDeviceManager)</li> <li>construct_single_architecture_requirements (parla::cython::device_manager::PyDeviceManager)</li> <li>construct_single_device_requirements (parla::cython::device_manager::PyDeviceManager)</li> <li>cleanup (parla::cython::tasks::ComputeTask)</li> <li>contexts (parla::cython::tasks::TaskEnvironment, parla::cython::tasks::TerminalEnvironment)</li> <li>create_events (parla::cython::tasks::TaskEnvironment)</li> <li>cupy_stream (parla::cython::tasks::TaskEnvironment)</li> <li>ctx (parla::cython::tasks::_TaskLocals)</li> </ul>"},{"location":"runtime/class_member_functions/#d","title":"d","text":"<ul> <li>Device (Device)</li> <li>DeviceManager (DeviceManager)</li> <li>DeviceQueue (DeviceQueue)</li> <li>DeviceRequirement (DeviceRequirement)</li> <li>device (DeviceRequirement, parla::cython::device::CupyStream, parla::cython::device::PyCUDADevice, parla::cython::device::PyDevice, parla::cython::device::Stream, parla::cython::tasks::TaskEnvironment, parla::cython::tasks::TerminalEnvironment)</li> <li>decrease_num_active_tasks (InnerScheduler)</li> <li>decrease_num_notified_workers (InnerScheduler, WorkerPool)</li> <li>decrement_num_instances (InnerTask)</li> <li>determine_status (InnerTask)</li> <li>decrease (PhaseStatus, ResourcePool)</li> <li>dequeue_worker (WorkerPool)</li> <li>devices (parla::cython::device::PyArchitecture, parla::cython::tasks::TaskEnvironment, parla::cython::tasks::TerminalEnvironment)</li> <li>device_id (parla::cython::device::PyDevice)</li> <li>decr_num_active_tasks (parray::InnerPArray)</li> </ul>"},{"location":"runtime/class_member_functions/#e","title":"e","text":"<ul> <li>empty (DeviceQueue, ProtectedQueue, ProtectedVector)</li> <li>enqueue (DeviceQueue, Launcher, Mapper, MemoryReserver, PhaseManager, RuntimeReserver, SchedulerPhase)</li> <li>enqueue_task (InnerScheduler)</li> <li>enqueue_tasks (InnerScheduler)</li> <li>enqueue_worker (InnerScheduler, WorkerPool)</li> <li>end_arch_req_addition (InnerTask)</li> <li>end_multidev_req_addition (InnerTask)</li> <li>empty_unsafe (ProtectedQueue, ProtectedVector)</li> <li>env (parla::cython::tasks::Task)</li> <li>environment (parla::cython::tasks::Task)</li> <li>exists_on_device (parray::InnerPArray, parray::PArrayState)</li> </ul>"},{"location":"runtime/class_member_functions/#f","title":"f","text":"<ul> <li>front (DeviceQueue, PhaseManager, ProtectedQueue, ProtectedVector)</li> <li>front_and_pop (ProtectedQueue, ProtectedVector)</li> <li>front_and_pop_unsafe (ProtectedQueue, ProtectedVector)</li> <li>front_unsafe (ProtectedQueue, ProtectedVector)</li> <li>finalize (parla::cython::tasks::CPUEnvironment, parla::cython::tasks::GPUEnvironment, parla::cython::tasks::TaskEnvironment)</li> </ul>"},{"location":"runtime/class_member_functions/#g","title":"g","text":"<ul> <li>GetDeviceRequirementOptions (ArchitectureRequirement)</li> <li>get_global_id (Device, parla::cython::device::PyDevice)</li> <li>get_id (Device)</li> <li>get_mapped_pool (Device)</li> <li>get_mapped_resource (Device)</li> <li>get_max_resource (Device)</li> <li>get_memory_size (Device)</li> <li>get_name (Device, InnerTask, RuntimeReserver, parla::cython::device::PyDevice, parla::cython::device_manager::PrintableFrozenSet, parla::cython::tasks::Task)</li> <li>get_num_vcus (Device)</li> <li>get_py_device (Device)</li> <li>get_reserved_pool (Device)</li> <li>get_reserved_resource (Device)</li> <li>get_resource_pool (Device)</li> <li>get_type (Device, parla::cython::device::PyDevice)</li> <li>get_device_by_global_id (DeviceManager)</li> <li>get_device_by_parray_id (DeviceManager)</li> <li>get_devices (DeviceManager, parla::cython::tasks::TaskEnvironment)</li> <li>get_num_devices (DeviceManager, PhaseManager)</li> <li>globalid_to_parrayid (DeviceManager, parla::cython::device_manager::PyDeviceManager)</li> <li>get_device (DeviceQueue)</li> <li>get_access_mode (InnerDataTask)</li> <li>get_device_id (InnerDataTask)</li> <li>get_py_parray (InnerDataTask, parray::InnerPArray)</li> <li>get_device_manager (InnerScheduler)</li> <li>get_num_active_tasks (InnerScheduler, parray::InnerPArray)</li> <li>get_num_notified_workers (InnerScheduler, WorkerPool, parla::cython::scheduler::Scheduler)</li> <li>get_num_ready_tasks (InnerScheduler)</li> <li>get_num_running_tasks (InnerScheduler, parla::cython::scheduler::Scheduler)</li> <li>get_parray_state (InnerScheduler, PArrayTracker, parla::cython::scheduler::Scheduler)</li> <li>get_parray_tracker (InnerScheduler)</li> <li>get_assigned_devices (InnerTask, parla::cython::tasks::Task)</li> <li>get_complete (InnerTask)</li> <li>get_dependencies (InnerTask, parla::cython::tasks::Task)</li> <li>get_dependents (InnerTask, parla::cython::tasks::Task)</li> <li>get_num_blocking_dependencies (InnerTask, parla::cython::tasks::Task)</li> <li>get_num_dependencies (InnerTask, parla::cython::tasks::Task)</li> <li>get_num_dependents (InnerTask, parla::cython::tasks::Task)</li> <li>get_num_instances (InnerTask)</li> <li>get_num_unmapped_dependencies (InnerTask, parla::cython::tasks::Task)</li> <li>get_placement_req_options (InnerTask)</li> <li>get_py_task (InnerTask)</li> <li>get_removed (InnerTask)</li> <li>get_state (InnerTask, parla::cython::tasks::Task)</li> <li>get_status (InnerTask, RuntimeReserver)</li> <li>get_tasks (InnerTaskSpace)</li> <li>get_task (InnerWorker)</li> <li>get_count (Launcher, Mapper, MemoryReserver, RuntimeReserver, SchedulerPhase)</li> <li>get_placement_reqs_ref (MultiDeviceRequirements)</li> <li>get_num_device_queues (PhaseManager)</li> <li>get (PhaseStatus, ProtectedVector, ResourcePool, Scheduler::Status)</li> <li>get_placement_req_opts_ref (PlacementRequirementCollections)</li> <li>get_unsafe (ProtectedVector)</li> <li>get_vector (ProtectedVector)</li> <li>get_vector_copy (ProtectedVector)</li> <li>get_vector_copy_unsafe (ProtectedVector)</li> <li>get_vector_unsafe (ProtectedVector)</li> <li>get_compute_count (RuntimeReserver)</li> <li>get_movement_count (RuntimeReserver)</li> <li>get_num_available_workers (WorkerPool)</li> <li>get_num_workers (WorkerPool)</li> <li>get_cy_device (parla::cython::device::PyDevice)</li> <li>global_id (parla::cython::device::PyDevice)</li> <li>get_all_architectures (parla::cython::device_manager::PyDeviceManager)</li> <li>get_all_devices (parla::cython::device_manager::PyDeviceManager, parla::cython::tasks::TaskEnvironment)</li> <li>get_cy_device_manager (parla::cython::device_manager::PyDeviceManager)</li> <li>get_device_reqs_from_placement (parla::cython::device_manager::PyDeviceManager, parla::cython::scheduler::Scheduler)</li> <li>get_num_cpus (parla::cython::device_manager::PyDeviceManager)</li> <li>get_num_gpus (parla::cython::device_manager::PyDeviceManager)</li> <li>get_stream (parla::cython::device_manager::StreamPool)</li> <li>get_cupy_devices (parla::cython::tasks::TaskEnvironment)</li> <li>get_library_device (parla::cython::tasks::TaskEnvironment)</li> <li>get_parla_device (parla::cython::tasks::TaskEnvironment)</li> <li>global_ids (parla::cython::tasks::TaskEnvironment)</li> <li>gpu_id (parla::cython::tasks::TaskEnvironment)</li> <li>gpu_ids (parla::cython::tasks::TaskEnvironment)</li> <li>global_tasks (parla::cython::tasks::_TaskLocals)</li> <li>get_variant (parla::cython::variants::_VariantFunction)</li> <li>get_parent_parray (parray::InnerPArray)</li> <li>get_parray_parentid (parray::InnerPArray)</li> <li>get_size (parray::InnerPArray)</li> <li>get_task_list_ref (parray::InnerPArray)</li> </ul>"},{"location":"runtime/class_member_functions/#h","title":"h","text":"<ul> <li>handle_runahead_dependencies (InnerTask, parla::cython::tasks::Task)</li> <li>has (parla::cython::tasks::TaskEnvironment)</li> </ul>"},{"location":"runtime/class_member_functions/#i","title":"i","text":"<ul> <li>is_arch_req (ArchitectureRequirement, DeviceRequirement, MultiDeviceRequirements, PlacementRequirementBase)</li> <li>is_dev_req (ArchitectureRequirement, DeviceRequirement, MultiDeviceRequirements, PlacementRequirementBase)</li> <li>is_multidev_req (ArchitectureRequirement, DeviceRequirement, MultiDeviceRequirements, PlacementRequirementBase)</li> <li>InnerDataTask (InnerDataTask)</li> <li>InnerScheduler (InnerScheduler)</li> <li>increase_num_active_tasks (InnerScheduler)</li> <li>increase_num_notified_workers (InnerScheduler, WorkerPool)</li> <li>InnerTask (InnerTask)</li> <li>is_data_task (InnerTask)</li> <li>InnerTaskSpace (InnerTaskSpace)</li> <li>InnerWorker (InnerWorker)</li> <li>increase (PhaseStatus, ResourcePool)</li> <li>id (parla::cython::device::PyArchitecture, parla::cython::device::PyDevice)</li> <li>is_multidevice_placement (parla::cython::device_manager::PyDeviceManager)</li> <li>instantiate (parla::cython::tasks::ComputeTask, parla::cython::tasks::DataMovementTask, parla::cython::tasks::Task)</li> <li>is_terminal (parla::cython::tasks::TaskCompleted, parla::cython::tasks::TaskCreated, parla::cython::tasks::TaskException, parla::cython::tasks::TaskMapped, parla::cython::tasks::TaskReady, parla::cython::tasks::TaskReserved, parla::cython::tasks::TaskRunahead, parla::cython::tasks::TaskRunning, parla::cython::tasks::TaskSpawned, parla::cython::tasks::TaskState)</li> <li>InnerPArray (parray::InnerPArray)</li> <li>incr_num_active_tasks (parray::InnerPArray)</li> </ul>"},{"location":"runtime/class_member_functions/#l","title":"l","text":"<ul> <li>Launcher (Launcher)</li> <li>lock (ProtectedQueue, ProtectedVector)</li> <li>loop (parla::cython::tasks::TaskEnvironment)</li> </ul>"},{"location":"runtime/class_member_functions/#m","title":"m","text":"<ul> <li>MappingPolicy (LocalityLoadBalancingMappingPolicy, MappingPolicy)</li> <li>Mapper (Mapper)</li> <li>MemoryReserver (MemoryReserver)</li> </ul>"},{"location":"runtime/class_member_functions/#n","title":"n","text":"<ul> <li>notify (InnerTask, InnerTaskSpace, TaskBarrier)</li> <li>notify_dependents (InnerTask)</li> <li>notify_dependents_completed (InnerTask)</li> <li>notify_dependents_wrapper (InnerTask, parla::cython::tasks::Task)</li> <li>name (parla::cython::device::PyArchitecture, parla::cython::tasks::TaskSpace)</li> </ul>"},{"location":"runtime/class_member_functions/#o","title":"o","text":"<ul> <li>operator= (CopyableAtomic, ProtectedVector)</li> <li>operator[] (ProtectedQueue, ProtectedVector)</li> </ul>"},{"location":"runtime/class_member_functions/#p","title":"p","text":"<ul> <li>parrayid_to_globalid (DeviceManager, parla::cython::device_manager::PyDeviceManager)</li> <li>print_registered_devices (DeviceManager, parla::cython::device_manager::PyDeviceManager)</li> <li>pop (DeviceQueue, PhaseManager)</li> <li>process_dependencies (InnerTask)</li> <li>PArrayTracker (PArrayTracker)</li> <li>PhaseManager (PhaseManager)</li> <li>PhaseStatus (PhaseStatus)</li> <li>print (PhaseStatus, Scheduler::Status)</li> <li>ProtectedQueue (ProtectedQueue)</li> <li>pop_back (ProtectedQueue, ProtectedVector)</li> <li>pop_back_unsafe (ProtectedQueue, ProtectedVector)</li> <li>pop_front (ProtectedQueue)</li> <li>pop_front_unsafe (ProtectedQueue)</li> <li>push_back (ProtectedQueue, ProtectedVector)</li> <li>push_back_unsafe (ProtectedQueue, ProtectedVector)</li> <li>push_front (ProtectedQueue)</li> <li>push_front_unsafe (ProtectedQueue)</li> <li>ProtectedVector (ProtectedVector)</li> <li>print_status (RuntimeReserver)</li> <li>parse_config_and_register_devices (parla::cython::device_manager::PyDeviceManager)</li> <li>py_handle_runahead_dependencies (parla::cython::tasks::Task)</li> <li>parfor (parla::cython::tasks::TaskEnvironment)</li> <li>PArrayState (parray::PArrayState)</li> </ul>"},{"location":"runtime/class_member_functions/#q","title":"q","text":"<ul> <li>query_mapped_resource (Device, parla::cython::device::PyDevice)</li> <li>query_reserved_resource (Device, parla::cython::device::PyDevice)</li> <li>query_resource (Device, parla::cython::device::PyDevice)</li> <li>queue_dependency (InnerTask)</li> </ul>"},{"location":"runtime/class_member_functions/#r","title":"r","text":"<ul> <li>register_device (DeviceManager)</li> <li>res_req (DeviceRequirement)</li> <li>release_parray (InnerScheduler, PArrayTracker, parla::cython::scheduler::Scheduler)</li> <li>reserve_parray (InnerScheduler, PArrayTracker, parla::cython::scheduler::Scheduler)</li> <li>run (InnerScheduler, Launcher, Mapper, MemoryReserver, RuntimeReserver, SchedulerPhase, parla::cython::scheduler::ControllableThread, parla::cython::scheduler::Scheduler, parla::cython::scheduler::WorkerThread, parla::cython::tasks::Task)</li> <li>reset (InnerTask, PhaseStatus, Scheduler::Status)</li> <li>reset_events_streams (InnerTask)</li> <li>remove_task (InnerWorker, parla::cython::scheduler::WorkerThread)</li> <li>reserve_resources (MemoryReserver, RuntimeReserver)</li> <li>reserve (ProtectedVector)</li> <li>reserve_unsafe (ProtectedVector)</li> <li>resize (ProtectedVector)</li> <li>resize_unsafe (ProtectedVector)</li> <li>ResourcePool (ResourcePool)</li> <li>RuntimeReserver (RuntimeReserver)</li> <li>reserve_data_resources (RuntimeReserver)</li> <li>register_cpu_devices (parla::cython::device_manager::PyDeviceManager)</li> <li>register_cupy_gpu_devices (parla::cython::device_manager::PyDeviceManager)</li> <li>register_devices_to_cpp (parla::cython::device_manager::PyDeviceManager)</li> <li>return_stream (parla::cython::device_manager::StreamPool)</li> <li>return_streams (parla::cython::tasks::CPUEnvironment, parla::cython::tasks::GPUEnvironment, parla::cython::tasks::TaskEnvironment)</li> <li>result (parla::cython::tasks::Task)</li> <li>record_events (parla::cython::tasks::TaskEnvironment)</li> <li>retrieve (parla::cython::tasks::TaskEnvironment)</li> <li>record_event (parla::cython::tasks::TerminalEnvironment)</li> </ul>"},{"location":"runtime/class_member_functions/#s","title":"s","text":"<ul> <li>set_global_id (Device)</li> <li>size (DeviceQueue, PhaseManager, ProtectedQueue, ProtectedVector)</li> <li>set_num_workers (InnerScheduler, WorkerPool)</li> <li>set_py_scheduler (InnerScheduler)</li> <li>set_stop_callback (InnerScheduler)</li> <li>spawn_task (InnerScheduler, parla::cython::scheduler::Scheduler)</li> <li>spawn_wait (InnerScheduler, WorkerPool, parla::cython::scheduler::Scheduler)</li> <li>stop (InnerScheduler, InnerWorker, parla::cython::scheduler::ControllableThread, parla::cython::scheduler::Scheduler, parla::cython::scheduler::WorkerThread)</li> <li>set_complete (InnerTask, parla::cython::tasks::Task)</li> <li>set_id (InnerTask, TaskBarrier)</li> <li>set_name (InnerTask)</li> <li>set_num_instances (InnerTask)</li> <li>set_priority (InnerTask)</li> <li>set_py_task (InnerTask)</li> <li>set_removed (InnerTask)</li> <li>set_scheduler (InnerTask, InnerWorker, parla::cython::tasks::Task)</li> <li>set_state (InnerTask, parla::cython::tasks::Task)</li> <li>set_status (InnerTask)</li> <li>synchronize_dependency_events (InnerTask)</li> <li>synchronize_events (InnerTask, parla::cython::tasks::TaskEnvironment)</li> <li>set_py_worker (InnerWorker)</li> <li>set_thread_idx (InnerWorker)</li> <li>set (PhaseStatus, ProtectedVector, ResourcePool, Scheduler::Status)</li> <li>size_unsafe (ProtectedQueue, ProtectedVector)</li> <li>set_unsafe (ProtectedVector)</li> <li>SchedulerPhase (SchedulerPhase)</li> <li>StatusFlags (Task::StatusFlags)</li> <li>set_size (parla::cython::cyparray::CyPArray, parray::InnerPArray)</li> <li>set_exist_on_device (parla::cython::cyparray_state::CyPArrayState, parray::PArrayState)</li> <li>set_valid_on_device (parla::cython::cyparray_state::CyPArrayState, parray::PArrayState)</li> <li>stream (parla::cython::device::CupyStream, parla::cython::device::Stream, parla::cython::tasks::TaskEnvironment)</li> <li>synchronize (parla::cython::device::CupyStream, parla::cython::device::Stream, parla::cython::tasks::TaskEnvironment)</li> <li>scheduler (parla::cython::scheduler::Scheduler, parla::cython::scheduler::SchedulerContext, parla::cython::scheduler::WorkerThread)</li> <li>stop_callback (parla::cython::scheduler::Scheduler)</li> <li>start (parla::cython::scheduler::WorkerThread)</li> <li>scheduler_context (parla::cython::scheduler::_SchedulerLocals)</li> <li>set_device_reqs (parla::cython::tasks::Task)</li> <li>storage (parla::cython::tasks::TaskEnvironment)</li> <li>store (parla::cython::tasks::TaskEnvironment)</li> <li>streams (parla::cython::tasks::TaskEnvironment)</li> <li>synchronize_event (parla::cython::tasks::TerminalEnvironment)</li> </ul>"},{"location":"runtime/class_member_functions/#t","title":"t","text":"<ul> <li>task_cleanup (InnerScheduler)</li> <li>task_cleanup_postsync (InnerScheduler)</li> <li>task_cleanup_presync (InnerScheduler)</li> <li>track_parray (PArrayTracker)</li> <li>TaskBarrier (TaskBarrier)</li> <li>tasks (parla::cython::tasks::TaskCollection, parla::cython::tasks::TaskSpace)</li> </ul>"},{"location":"runtime/class_member_functions/#u","title":"u","text":"<ul> <li>untrack_parray (PArrayTracker)</li> <li>unlock (ProtectedQueue, ProtectedVector)</li> <li>update (Scheduler::Status)</li> <li>unpack_placements (parla::cython::device_manager::PyDeviceManager)</li> <li>unpack_name (parla::cython::tasks::Task)</li> <li>update_name (parla::cython::tasks::Task)</li> </ul>"},{"location":"runtime/class_member_functions/#v","title":"v","text":"<ul> <li>value (parla::cython::tasks::TaskCompleted, parla::cython::tasks::TaskCreated, parla::cython::tasks::TaskException, parla::cython::tasks::TaskMapped, parla::cython::tasks::TaskReady, parla::cython::tasks::TaskReserved, parla::cython::tasks::TaskRunahead, parla::cython::tasks::TaskRunning, parla::cython::tasks::TaskSpawned, parla::cython::tasks::TaskState)</li> <li>view (parla::cython::tasks::TaskSpace)</li> <li>variant (parla::cython::variants::_VariantFunction)</li> <li>valid_on_device (parray::InnerPArray, parray::PArrayState)</li> </ul>"},{"location":"runtime/class_member_functions/#w","title":"w","text":"<ul> <li>wait_dependency_events (InnerTask)</li> <li>wait (InnerTaskSpace, InnerWorker, TaskBarrier, parla::cython::tasks::AtomicTaskList, parla::cython::tasks::AtomicTaskSpace, parla::cython::tasks::BackendTaskList, parla::cython::tasks::BackendTaskSpace)</li> <li>WorkerPool (WorkerPool)</li> <li>wait_event (parla::cython::device::CupyStream, parla::cython::device::Stream, parla::cython::tasks::TerminalEnvironment)</li> <li>wait_events (parla::cython::tasks::TaskEnvironment)</li> <li>write_streams_to_task (parla::cython::tasks::TaskEnvironment, parla::cython::tasks::TerminalEnvironment)</li> <li>write_to_task (parla::cython::tasks::TaskEnvironment, parla::cython::tasks::TerminalEnvironment)</li> <li>write_events_to_task (parla::cython::tasks::TerminalEnvironment)</li> </ul>"},{"location":"runtime/class_member_functions/#_1","title":"~","text":"<ul> <li>~InnerScheduler (InnerScheduler)</li> <li>~PhaseManager (PhaseManager)</li> </ul>"},{"location":"runtime/class_member_functions/#_","title":"_","text":"<ul> <li>_add_task (TaskBarrier)</li> <li>__cinit__ (parla::cython::core::CyTaskList, parla::cython::core::PyInnerScheduler, parla::cython::core::PyInnerWorker, parla::cython::core::PyTaskBarrier, parla::cython::core::PyTaskSpace, parla::cython::cyparray::CyPArray, parla::cython::cyparray_state::CyPArrayState, parla::cython::device::CyCPUDevice, parla::cython::device::CyCUDADevice, parla::cython::device_manager::CyDeviceManager)</li> <li>__init__ (parla::cython::core::DataMovementTaskAttributes, parla::cython::core::PyInnerScheduler, parla::cython::core::PyInnerWorker, parla::cython::core::PyTaskBarrier, parla::cython::core::PyTaskSpace, parla::cython::core::Resources, parla::cython::cyparray::CyPArray, parla::cython::cyparray_state::CyPArrayState, parla::cython::device::CupyStream, parla::cython::device::CyCPUDevice, parla::cython::device::CyCUDADevice, parla::cython::device::DeviceResource, parla::cython::device::DeviceResourceRequirement, parla::cython::device::PyArchitecture, parla::cython::device::PyCPUArchitecture, parla::cython::device::PyCPUDevice, parla::cython::device::PyCUDAArchitecture, parla::cython::device::PyCUDADevice, parla::cython::device::PyDevice, parla::cython::device::Stream, parla::cython::device_manager::CyDeviceManager, parla::cython::device_manager::PyDeviceManager, parla::cython::device_manager::StreamPool, parla::cython::scheduler::ControllableThread, parla::cython::scheduler::Scheduler, parla::cython::scheduler::WorkerThread, parla::cython::scheduler::_SchedulerLocals, parla::cython::tasks::AtomicTaskList, parla::cython::tasks::AtomicTaskSpace, parla::cython::tasks::BackendTaskList, parla::cython::tasks::BackendTaskSpace, parla::cython::tasks::CPUEnvironment, parla::cython::tasks::ComputeTask, parla::cython::tasks::DataMovementTask, parla::cython::tasks::GPUEnvironment, parla::cython::tasks::Task, parla::cython::tasks::TaskCollection, parla::cython::tasks::TaskCompleted, parla::cython::tasks::TaskEnvironment, parla::cython::tasks::TaskException, parla::cython::tasks::TaskList, parla::cython::tasks::TaskRunahead, parla::cython::tasks::TaskRunning, parla::cython::tasks::TaskSpace, parla::cython::tasks::TerminalEnvironment, parla::cython::tasks::_TaskLocals, parla::cython::variants::_VariantFunction)</li> <li>__dealloc__ (parla::cython::core::PyInnerScheduler, parla::cython::core::PyInnerWorker, parla::cython::core::PyTaskBarrier, parla::cython::core::PyTaskSpace, parla::cython::cyparray::CyPArray, parla::cython::cyparray_state::CyPArrayState, parla::cython::device::CyDevice, parla::cython::device::PyDevice, parla::cython::device_manager::CyDeviceManager, parla::cython::device_manager::PyDeviceManager)</li> <li>__enter__ (parla::cython::device::CupyStream, parla::cython::device::PyDevice, parla::cython::device::Stream, parla::cython::scheduler::Scheduler, parla::cython::scheduler::SchedulerContext, parla::cython::tasks::CPUEnvironment, parla::cython::tasks::GPUEnvironment, parla::cython::tasks::TaskEnvironment)</li> <li>__exit__ (parla::cython::device::CupyStream, parla::cython::device::PyDevice, parla::cython::device::Stream, parla::cython::scheduler::Scheduler, parla::cython::scheduler::SchedulerContext, parla::cython::tasks::CPUEnvironment, parla::cython::tasks::GPUEnvironment, parla::cython::tasks::TaskEnvironment)</li> <li>__getatrr__ (parla::cython::device::CupyStream)</li> <li>__repr__ (parla::cython::device::CupyStream, parla::cython::device::DeviceResource, parla::cython::device::DeviceResourceRequirement, parla::cython::device::PyArchitecture, parla::cython::device::PyDevice, parla::cython::device::Stream, parla::cython::device_manager::PrintableFrozenSet, parla::cython::device_manager::StreamPool, parla::cython::tasks::AtomicTaskList, parla::cython::tasks::AtomicTaskSpace, parla::cython::tasks::BackendTaskList, parla::cython::tasks::BackendTaskSpace, parla::cython::tasks::CPUEnvironment, parla::cython::tasks::GPUEnvironment, parla::cython::tasks::Task, parla::cython::tasks::TaskCollection, parla::cython::tasks::TaskCompleted, parla::cython::tasks::TaskEnvironment, parla::cython::tasks::TaskException, parla::cython::tasks::TaskList, parla::cython::tasks::TaskRunahead, parla::cython::tasks::TaskRunning, parla::cython::tasks::TaskSpace, parla::cython::tasks::TerminalEnvironment, parla::cython::variants::_VariantFunction)</li> <li>__str__ (parla::cython::device::CupyStream, parla::cython::device::PyDevice, parla::cython::device::Stream, parla::cython::tasks::TaskCollection)</li> <li>__call__ (parla::cython::device::PyArchitecture, parla::cython::tasks::TerminalEnvironment, parla::cython::variants::_VariantFunction)</li> <li>__eq__ (parla::cython::device::PyArchitecture, parla::cython::device::PyDevice, parla::cython::tasks::TaskCollection, parla::cython::tasks::TerminalEnvironment)</li> <li>__getitem__ (parla::cython::device::PyArchitecture, parla::cython::device::PyDevice, parla::cython::tasks::AtomicTaskSpace, parla::cython::tasks::BackendTaskSpace, parla::cython::tasks::CPUEnvironment, parla::cython::tasks::TaskEnvironment, parla::cython::tasks::TaskList, parla::cython::tasks::TaskSpace, parla::cython::tasks::TerminalEnvironment)</li> <li>__hash__ (parla::cython::device::PyArchitecture, parla::cython::device::PyDevice, parla::cython::tasks::Task, parla::cython::tasks::TaskCollection, parla::cython::tasks::TerminalEnvironment)</li> <li>__len__ (parla::cython::device::PyArchitecture, parla::cython::tasks::CPUEnvironment, parla::cython::tasks::TaskCollection, parla::cython::tasks::TaskEnvironment, parla::cython::tasks::TerminalEnvironment)</li> <li>__mul__ (parla::cython::device::PyArchitecture)</li> <li>__summarize__ (parla::cython::device_manager::StreamPool)</li> <li>_initialize (parla::cython::scheduler::WorkerThread)</li> <li>__add__ (parla::cython::tasks::AtomicTaskList, parla::cython::tasks::TaskCollection, parla::cython::tasks::TaskList, parla::cython::tasks::TaskSpace)</li> <li>__iadd__ (parla::cython::tasks::AtomicTaskList, parla::cython::tasks::TaskCollection, parla::cython::tasks::TaskList, parla::cython::tasks::TaskSpace)</li> <li>_execute_task (parla::cython::tasks::ComputeTask, parla::cython::tasks::DataMovementTask, parla::cython::tasks::Task)</li> <li>_finish (parla::cython::tasks::ComputeTask, parla::cython::tasks::Task)</li> <li>__await__ (parla::cython::tasks::Task, parla::cython::tasks::TaskCollection)</li> <li>_wait_for_dependency_events (parla::cython::tasks::Task)</li> <li>__contains__ (parla::cython::tasks::TaskCollection, parla::cython::tasks::TaskEnvironment)</li> <li>__iter__ (parla::cython::tasks::TaskCollection)</li> <li>__ne__ (parla::cython::tasks::TaskCollection)</li> </ul>"},{"location":"runtime/class_member_variables/","title":"Class Member Variables","text":""},{"location":"runtime/class_member_variables/#a","title":"a","text":"<ul> <li>all_devices_ (DeviceManager)</li> <li>arch_devices_ (DeviceManager)</li> <li>access_mode_ (InnerDataTask)</li> <li>assigned_devices (InnerTask, parla::cython::core::DataMovementTaskAttributes, parla::cython::tasks::DataMovementTask)</li> <li>active_workers (WorkerPool)</li> <li>all_workers (WorkerPool)</li> <li>access_mode (parla::cython::core::DataMovementTaskAttributes, parla::cython::core::PyInnerWorker, parla::cython::tasks::DataMovementTask)</li> <li>active_device (parla::cython::device::CupyStream)</li> <li>args (parla::cython::tasks::ComputeTask, parla::cython::tasks::TaskRunning)</li> <li>active_stream (parla::cython::tasks::GPUEnvironment)</li> </ul>"},{"location":"runtime/class_member_variables/#b","title":"b","text":"<ul> <li>base_function (parla::cython::tasks::ComputeTask)</li> <li>blocking (parla::cython::tasks::TaskEnvironment)</li> </ul>"},{"location":"runtime/class_member_variables/#c","title":"c","text":"<ul> <li>cv (InnerWorker, TaskBarrier, WorkerPool)</li> <li>compute_runnable (Task::StatusFlags)</li> <li>c_data_task (parla::cython::core::CyDataMovementTaskAttributes, parla::cython::core::PyInnerWorker)</li> <li>c_task_list (parla::cython::core::CyTaskList, parla::cython::core::PyTaskBarrier)</li> <li>c_attrs (parla::cython::core::DataMovementTaskAttributes)</li> <li>c_self (parla::cython::core::PyInnerScheduler, parla::cython::core::PyTaskBarrier, parla::cython::core::PyTaskSpace)</li> <li>c_task (parla::cython::core::PyInnerScheduler)</li> <li>c_worker (parla::cython::core::PyInnerScheduler)</li> <li>c_device (parla::cython::core::PyInnerWorker)</li> <li>c_devices (parla::cython::core::PyInnerWorker)</li> <li>cy_data_attrs (parla::cython::core::PyInnerWorker)</li> <li>c_task_barrier (parla::cython::core::PyTaskBarrier)</li> <li>cy_task_list (parla::cython::core::PyTaskBarrier)</li> <li>c_task_space (parla::cython::core::PyTaskSpace)</li> <li>cpp_parray (parla::cython::cyparray::CyPArray)</li> <li>cpp_parray_state (parla::cython::cyparray_state::CyPArrayState)</li> <li>cpp_device (parla::cython::device_manager::CyDeviceManager)</li> <li>cpp_device_manager_ (parla::cython::device_manager::CyDeviceManager)</li> <li>cy_device_manager (parla::cython::device_manager::PyDeviceManager)</li> </ul>"},{"location":"runtime/class_member_variables/#d","title":"d","text":"<ul> <li>dev_global_id_ (Device)</li> <li>dev_id_ (Device, InnerDataTask)</li> <li>dev_type_ (Device)</li> <li>device (DeviceQueue, parla::cython::device::DeviceResourceRequirement)</li> <li>dev_ (DeviceRequirement)</li> <li>device_manager_ (InnerScheduler, MappingPolicy, PArrayTracker)</li> <li>dependencies (InnerTask, parla::cython::tasks::Task, parla::cython::tasks::TaskRunning)</li> <li>dependency_buffer (InnerTask)</li> <li>dependents (InnerTask)</li> <li>device_constraints (InnerTask)</li> <li>dev_num_mapped_tasks_ (Mapper)</li> <li>dummy_dev_idx_ (Mapper)</li> <li>device_queues (PhaseManager)</li> <li>device_manager (SchedulerPhase, parla::cython::scheduler::Scheduler)</li> <li>dev_id (parla::cython::core::DataMovementTaskAttributes, parla::cython::core::PyInnerWorker, parla::cython::tasks::DataMovementTask)</li> <li>default_taskspace (parla::cython::scheduler::Scheduler)</li> <li>dataflow (parla::cython::tasks::ComputeTask)</li> <li>device_dict (parla::cython::tasks::TaskEnvironment)</li> <li>device_list (parla::cython::tasks::TaskEnvironment)</li> </ul>"},{"location":"runtime/class_member_variables/#e","title":"e","text":"<ul> <li>events (InnerTask)</li> <li>enqueue_buffer (InnerWorker, SchedulerPhase)</li> <li>exception_stack (parla::cython::scheduler::Scheduler)</li> <li>env_list (parla::cython::tasks::TaskEnvironment)</li> <li>event_dict (parla::cython::tasks::TaskEnvironment)</li> <li>exception (parla::cython::tasks::TaskException)</li> </ul>"},{"location":"runtime/class_member_variables/#f","title":"f","text":"<ul> <li>func (parla::cython::tasks::ComputeTask, parla::cython::tasks::TaskRunning)</li> </ul>"},{"location":"runtime/class_member_variables/#i","title":"i","text":"<ul> <li>id (InnerTask, TaskBarrier, parla::cython::device::PyArchitecture, parla::cython::tasks::Task, parray::InnerPArray)</li> <li>instance (InnerTask)</li> <li>is_data (InnerTask)</li> <li>inner_scheduler (parla::cython::core::PyInnerScheduler, parla::cython::scheduler::Scheduler)</li> <li>inner_worker (parla::cython::core::PyInnerWorker, parla::cython::scheduler::WorkerThread)</li> <li>is_data_task (parla::cython::core::PyInnerWorker)</li> <li>inner_task (parla::cython::core::PyTaskBarrier, parla::cython::core::PyTaskSpace, parla::cython::tasks::Task)</li> <li>index (parla::cython::scheduler::WorkerThread)</li> <li>inner_barrier (parla::cython::tasks::AtomicTaskList, parla::cython::tasks::BackendTaskList)</li> <li>inner_space (parla::cython::tasks::AtomicTaskSpace, parla::cython::tasks::BackendTaskSpace)</li> <li>idx (parla::cython::tasks::Task)</li> <li>is_terminal (parla::cython::tasks::TaskEnvironment, parla::cython::tasks::TerminalEnvironment)</li> </ul>"},{"location":"runtime/class_member_variables/#l","title":"l","text":"<ul> <li>last_dev_id_ (DeviceManager)</li> <li>launcher (InnerScheduler)</li> <li>last_device_idx (PhaseManager)</li> <li>length (ProtectedQueue, ProtectedVector)</li> <li>launchable_tasks_buffer (RuntimeReserver)</li> </ul>"},{"location":"runtime/class_member_variables/#m","title":"m","text":"<ul> <li>mapped_res_ (Device)</li> <li>mixed_queue (DeviceQueue)</li> <li>mapper (InnerScheduler)</li> <li>memory_reserver (InnerScheduler)</li> <li>mtx (InnerTask, InnerWorker, PArrayTracker, ProtectedQueue, ProtectedVector, SchedulerPhase, TaskBarrier, WorkerPool)</li> <li>mappable_tasks (Mapper)</li> <li>mapped_tasks_buffer (Mapper)</li> <li>managed_parrays_ (PArrayTracker)</li> <li>movement_tasks (RuntimeReserver)</li> <li>mappable (Task::StatusFlags)</li> <li>max_workers (WorkerPool)</li> <li>memory_sz (parla::cython::device::DeviceResource)</li> </ul>"},{"location":"runtime/class_member_variables/#n","title":"n","text":"<ul> <li>num_tasks (DeviceQueue, PhaseManager)</li> <li>num_active_tasks (InnerScheduler, parray::InnerPArray)</li> <li>name (InnerTask, Launcher, Mapper, MemoryReserver, PhaseStatus, ProtectedQueue, ProtectedVector, RuntimeReserver, SchedulerPhase, parla::cython::core::DataMovementTaskAttributes, parla::cython::core::PyInnerWorker, parla::cython::tasks::DataMovementTask, parla::cython::tasks::Task)</li> <li>num_blocking_compute_dependencies (InnerTask)</li> <li>num_blocking_dependencies (InnerTask)</li> <li>num_persistant_instances (InnerTask)</li> <li>num_runtime_instances (InnerTask)</li> <li>num_unmapped_dependencies (InnerTask)</li> <li>num_unreserved_dependencies (InnerTask)</li> <li>num_unspawned_dependencies (InnerTask)</li> <li>notified (InnerWorker)</li> <li>num_running_tasks (Launcher)</li> <li>ndevices (PhaseManager)</li> <li>num_incomplete_tasks (TaskBarrier)</li> <li>notified_workers (WorkerPool)</li> <li>num_devices (parla::cython::core::PyInnerWorker)</li> <li>num_vcus (parla::cython::device::DeviceResource)</li> <li>num_real_gpus (parla::cython::device_manager::PyDeviceManager)</li> </ul>"},{"location":"runtime/class_member_variables/#p","title":"p","text":"<ul> <li>placement_reqs_ (ArchitectureRequirement, MultiDeviceRequirements, PlacementRequirementCollections)</li> <li>py_dev_ (Device)</li> <li>parray_ (InnerDataTask)</li> <li>parray_tracker_ (InnerScheduler, MappingPolicy)</li> <li>py_scheduler (InnerScheduler)</li> <li>parray_list (InnerTask)</li> <li>placement_req_options_ (InnerTask)</li> <li>priority (InnerTask, parla::cython::tasks::Task)</li> <li>processed_data (InnerTask)</li> <li>py_task (InnerTask, parla::cython::core::PyInnerWorker)</li> <li>py_worker (InnerWorker)</li> <li>policy_ (Mapper)</li> <li>parray (parla::cython::core::DataMovementTaskAttributes, parla::cython::tasks::DataMovementTask)</li> <li>py_assigned_devices (parla::cython::core::PyInnerWorker)</li> <li>py_device (parla::cython::core::PyInnerWorker)</li> <li>py_parray (parla::cython::core::PyInnerWorker)</li> <li>py_registered_archs (parla::cython::device_manager::PyDeviceManager)</li> <li>parent_id (parray::InnerPArray)</li> </ul>"},{"location":"runtime/class_member_variables/#q","title":"q","text":"<ul> <li>q (ProtectedQueue)</li> </ul>"},{"location":"runtime/class_member_variables/#r","title":"r","text":"<ul> <li>res_ (Device)</li> <li>reserved_res_ (Device)</li> <li>resource_map_ (Device)</li> <li>res_req_ (DeviceRequirement)</li> <li>runtime_reserver (InnerScheduler)</li> <li>removed_reserved (InnerTask)</li> <li>removed_runtime (InnerTask)</li> <li>req_addition_mode_ (InnerTask)</li> <li>ready (InnerWorker)</li> <li>rrcount (MappingPolicy)</li> <li>reservable_tasks (MemoryReserver)</li> <li>reserved_tasks_buffer (MemoryReserver)</li> <li>resources (ResourcePool, parla::cython::core::Resources)</li> <li>runnable_tasks (RuntimeReserver)</li> <li>reservable (Task::StatusFlags)</li> <li>runnable (Task::StatusFlags)</li> <li>res_req (parla::cython::device::DeviceResourceRequirement)</li> <li>registered_devices (parla::cython::device_manager::PyDeviceManager)</li> <li>runahead (parla::cython::tasks::DataMovementTask, parla::cython::tasks::Task)</li> <li>return_value (parla::cython::tasks::TaskCompleted, parla::cython::tasks::TaskRunahead)</li> </ul>"},{"location":"runtime/class_member_variables/#s","title":"s","text":"<ul> <li>should_run (InnerScheduler)</li> <li>sleep_flag (InnerScheduler)</li> <li>sleep_time (InnerScheduler)</li> <li>status (InnerScheduler, InnerTask, Launcher, Mapper, MemoryReserver, PhaseStatus, RuntimeReserver, Scheduler::Status, parla::cython::scheduler::WorkerThread)</li> <li>stop_callback (InnerScheduler)</li> <li>scheduler (InnerTask, InnerWorker, SchedulerPhase, parla::cython::tasks::DataMovementTask, parla::cython::tasks::Task)</li> <li>spaces (InnerTask)</li> <li>state (InnerTask, parla::cython::tasks::Task)</li> <li>streams (InnerTask)</li> <li>sync_type (InnerTask)</li> <li>size (PhaseStatus, Scheduler::Status)</li> <li>spawnable (Task::StatusFlags)</li> <li>stream_pool (parla::cython::device_manager::PyDeviceManager)</li> <li>StreamClass (parla::cython::device_manager::StreamPool)</li> <li>start_monitor (parla::cython::scheduler::Scheduler)</li> <li>stream_list (parla::cython::tasks::TaskEnvironment)</li> <li>shape (parla::cython::tasks::TaskSpace)</li> <li>start (parla::cython::tasks::TaskSpace)</li> <li>spawn_count (parla::cython::tasks::_TaskLocals)</li> </ul>"},{"location":"runtime/class_member_variables/#t","title":"t","text":"<ul> <li>task_buffer (InnerScheduler, Launcher)</li> <li>tmp_arch_req_ (InnerTask)</li> <li>tmp_multdev_reqs_ (InnerTask)</li> <li>task_map (InnerTaskSpace)</li> <li>task (InnerWorker, parla::cython::core::PyTaskBarrier, parla::cython::core::PyTaskSpace, parla::cython::scheduler::WorkerThread)</li> <li>thread_idx (InnerWorker)</li> <li>total_num_mapped_tasks_ (Mapper)</li> <li>task_attrs (parla::cython::scheduler::WorkerThread)</li> <li>taskspace (parla::cython::tasks::Task)</li> <li>traceback (parla::cython::tasks::TaskException)</li> <li>task_scopes (parla::cython::tasks::_TaskLocals)</li> </ul>"},{"location":"runtime/class_member_variables/#v","title":"v","text":"<ul> <li>vec (ProtectedVector)</li> </ul>"},{"location":"runtime/class_member_variables/#w","title":"w","text":"<ul> <li>waiting_queue (DeviceQueue)</li> <li>workers (InnerScheduler)</li> <li>worker_buffer (Launcher)</li> <li>worker_threads (parla::cython::scheduler::Scheduler)</li> </ul>"},{"location":"runtime/class_member_variables/#_","title":"_","text":"<ul> <li>_inner_worker (parla::cython::core::PyInnerWorker)</li> <li>_device (parla::cython::device::CupyStream, parla::cython::device::PyCUDADevice, parla::cython::device::PyDevice, parla::cython::device::Stream, parla::cython::tasks::TaskEnvironment, parla::cython::tasks::TerminalEnvironment)</li> <li>_device_id (parla::cython::device::CupyStream, parla::cython::device::PyDevice, parla::cython::device::Stream)</li> <li>_stream (parla::cython::device::CupyStream, parla::cython::device::Stream)</li> <li>_cpp_device (parla::cython::device::CyCPUDevice, parla::cython::device::CyCUDADevice)</li> <li>_devices (parla::cython::device::PyArchitecture)</li> <li>_id (parla::cython::device::PyArchitecture, parla::cython::tasks::TaskSpace)</li> <li>_name (parla::cython::device::PyArchitecture, parla::cython::tasks::BackendTaskList, parla::cython::tasks::TaskCollection, parla::cython::tasks::TaskList, parla::cython::tasks::TaskSpace)</li> <li>_cy_device (parla::cython::device::PyCPUDevice, parla::cython::device::PyCUDADevice)</li> <li>_dev_id (parla::cython::device::PyDevice)</li> <li>_dev_type (parla::cython::device::PyDevice)</li> <li>_device_name (parla::cython::device::PyDevice)</li> <li>_global_id (parla::cython::device::PyDevice)</li> <li>_device_list (parla::cython::device_manager::StreamPool)</li> <li>_per_device (parla::cython::device_manager::StreamPool)</li> <li>_pool (parla::cython::device_manager::StreamPool)</li> <li>_should_run (parla::cython::scheduler::ControllableThread)</li> <li>_monitor (parla::cython::scheduler::Scheduler, parla::cython::scheduler::WorkerThread)</li> <li>_scheduler (parla::cython::scheduler::WorkerThread)</li> <li>_scheduler_context_stack (parla::cython::scheduler::_SchedulerLocals)</li> <li>_tasks (parla::cython::tasks::BackendTaskList, parla::cython::tasks::TaskCollection, parla::cython::tasks::TaskList, parla::cython::tasks::TaskSpace)</li> <li>_env (parla::cython::tasks::Task)</li> <li>_environment (parla::cython::tasks::Task)</li> <li>__slots__ (parla::cython::tasks::TaskCompleted, parla::cython::tasks::TaskException, parla::cython::tasks::TaskRunahead, parla::cython::tasks::TaskRunning, parla::cython::tasks::TaskState)</li> <li>_global_device_ids (parla::cython::tasks::TaskEnvironment, parla::cython::tasks::TerminalEnvironment)</li> <li>_store (parla::cython::tasks::TaskEnvironment)</li> <li>_create (parla::cython::tasks::TaskSpace)</li> <li>_view (parla::cython::tasks::TaskSpace)</li> <li>_arch_type (parla::cython::tasks::TerminalEnvironment)</li> <li>_ctx (parla::cython::tasks::_TaskLocals)</li> <li>_global_tasks (parla::cython::tasks::_TaskLocals)</li> <li>_default (parla::cython::variants::_VariantFunction)</li> <li>_variants (parla::cython::variants::_VariantFunction)</li> <li>_num_devices (parray::InnerPArray)</li> <li>_parent_parray (parray::InnerPArray)</li> <li>_py_parray (parray::InnerPArray)</li> <li>_size (parray::InnerPArray)</li> <li>_state (parray::InnerPArray)</li> <li>_task_lists (parray::InnerPArray)</li> <li>_exist_on_device (parray::PArrayState)</li> <li>_valid_on_device (parray::PArrayState)</li> </ul>"},{"location":"runtime/class_member_typedefs/","title":"Class Member Typedefs","text":""},{"location":"runtime/class_member_typedefs/#m","title":"m","text":"<ul> <li>MDQueue_t (DeviceQueue)</li> <li>MixedQueue_t (DeviceQueue)</li> </ul>"},{"location":"runtime/class_member_typedefs/#v","title":"v","text":"<ul> <li>V (ResourcePool)</li> </ul>"},{"location":"runtime/class_member_enums/","title":"Class Member Enums","text":""},{"location":"runtime/class_member_enums/#r","title":"r","text":"<ul> <li>ReqAdditionState (InnerTask)</li> </ul>"},{"location":"runtime/namespace_members/","title":"Namespace Members","text":""},{"location":"runtime/namespace_members/#b","title":"b","text":"<ul> <li>barrier (parla::cython::tasks)</li> </ul>"},{"location":"runtime/namespace_members/#c","title":"c","text":"<ul> <li>c_dependencies (parla::cython::core)</li> <li>c_dependency (parla::cython::core)</li> <li>c_dependent (parla::cython::core)</li> <li>c_dependents (parla::cython::core)</li> <li>c_dev (parla::cython::core)</li> <li>c_device (parla::cython::core)</li> <li>c_devices (parla::cython::core)</li> <li>c_priority (parla::cython::core)</li> <li>c_scheduler (parla::cython::core)</li> <li>c_self (parla::cython::core)</li> <li>c_stream (parla::cython::core)</li> <li>c_sync_type (parla::cython::core)</li> <li>c_t (parla::cython::core)</li> <li>c_task (parla::cython::core)</li> <li>category (parla::cython::core)</li> <li>cpp_device (parla::cython::core)</li> <li>CUPY_ENABLED (parla::cython::device_manager)</li> <li>CupyStream (parla::cython::device_manager)</li> <li>cpu (parla::cython::device_manager, parla::cython::tasks)</li> <li>ComputeTask (parla::cython::scheduler)</li> <li>create_env (parla::cython::scheduler, parla::cython::tasks)</li> <li>create (parla::cython::tasks)</li> <li>create_device_env (parla::cython::tasks)</li> </ul>"},{"location":"runtime/namespace_members/#d","title":"d","text":"<ul> <li>d (parla::cython::core)</li> <li>dependencies (parla::cython::core)</li> <li>dependency (parla::cython::core)</li> <li>dependency_list (parla::cython::core)</li> <li>dependents (parla::cython::core)</li> <li>devices (parla::cython::core)</li> <li>DeviceResource (parla::cython::device_manager)</li> <li>DeviceResourceRequirement (parla::cython::device_manager, parla::cython::tasks)</li> <li>DataMovementTask (parla::cython::scheduler)</li> <li>DeviceType (parla::cython::tasks)</li> <li>depth (parla::cython::tasks)</li> <li>dim (parla::cython::tasks)</li> </ul>"},{"location":"runtime/namespace_members/#f","title":"f","text":"<ul> <li>fname (parla::cython::core)</li> </ul>"},{"location":"runtime/namespace_members/#g","title":"g","text":"<ul> <li>gpu (parla::cython::device_manager)</li> <li>get_device_manager (parla::cython::scheduler)</li> <li>get_scheduler_context (parla::cython::scheduler)</li> <li>get_stream_pool (parla::cython::scheduler)</li> </ul>"},{"location":"runtime/namespace_members/#i","title":"i","text":"<ul> <li>i_event (parla::cython::core)</li> <li>i_stream (parla::cython::core)</li> <li>inner_type1 (parla::cython::core)</li> <li>inner_type2 (parla::cython::core)</li> <li>i (parla::cython::tasks)</li> <li>index (parla::cython::tasks)</li> <li>index_list (parla::cython::tasks)</li> <li>istart (parla::cython::tasks)</li> <li>istep (parla::cython::tasks)</li> <li>istop (parla::cython::tasks)</li> </ul>"},{"location":"runtime/namespace_members/#k","title":"k","text":"<ul> <li>keys (parla::cython::tasks)</li> </ul>"},{"location":"runtime/namespace_members/#l","title":"l","text":"<ul> <li>LOG_DEBUG (parla::cython::core)</li> <li>LOG_ERROR (parla::cython::core)</li> <li>LOG_FATAL (parla::cython::core)</li> <li>LOG_INFO (parla::cython::core)</li> <li>LOG_TRACE (parla::cython::core)</li> <li>LOG_WARN (parla::cython::core)</li> <li>logging_level (parla::cython::core)</li> <li>lower_boundary (parla::cython::tasks)</li> </ul>"},{"location":"runtime/namespace_members/#m","title":"m","text":"<ul> <li>message (parla::cython::core)</li> <li>msg (parla::cython::core)</li> <li>msg1 (parla::cython::core)</li> <li>msg2 (parla::cython::core)</li> <li>max_dim (parla::cython::tasks)</li> </ul>"},{"location":"runtime/namespace_members/#n","title":"n","text":"<ul> <li>name (parla::cython::core)</li> <li>num_deps (parla::cython::core)</li> <li>num_devices (parla::cython::core)</li> <li>nvtx (parla::cython::scheduler)</li> <li>None (parla::cython::tasks)</li> <li>new_index (parla::cython::tasks)</li> <li>new_tasks (parla::cython::tasks)</li> </ul>"},{"location":"runtime/namespace_members/#o","title":"o","text":"<ul> <li>obj (parla::cython::core)</li> <li>obj2 (parla::cython::core)</li> <li>output (parla::cython::tasks)</li> </ul>"},{"location":"runtime/namespace_members/#p","title":"p","text":"<ul> <li>process (parla::cython::core)</li> <li>py_dependency (parla::cython::core)</li> <li>py_dependent (parla::cython::core)</li> <li>py_device (parla::cython::core)</li> <li>PlacementSource (parla::cython::device)</li> <li>PyArchitecture (parla::cython::device_manager, parla::cython::tasks)</li> <li>PyCPUArchitecture (parla::cython::device_manager)</li> <li>PyCPUDevice (parla::cython::device_manager, parla::cython::tasks)</li> <li>PyCUDAArchitecture (parla::cython::device_manager, parla::cython::tasks)</li> <li>PyCUDADevice (parla::cython::device_manager, parla::cython::tasks)</li> <li>PyDevice (parla::cython::device_manager, parla::cython::tasks)</li> <li>PyInnerScheduler (parla::cython::scheduler)</li> <li>PyInnerTask (parla::cython::scheduler)</li> <li>PyInnerWorker (parla::cython::scheduler)</li> <li>parse_index (parla::cython::tasks)</li> </ul>"},{"location":"runtime/namespace_members/#r","title":"r","text":"<ul> <li>remainder (parla::cython::tasks)</li> </ul>"},{"location":"runtime/namespace_members/#s","title":"s","text":"<ul> <li>State (Scheduler, Task)</li> <li>Status (Task)</li> <li>SynchronizationType (Task)</li> <li>scheduler (parla::cython::core)</li> <li>self (parla::cython::core)</li> <li>status (parla::cython::core)</li> <li>status_flags (parla::cython::core)</li> <li>Stream (parla::cython::device_manager)</li> <li>shape (parla::cython::tasks)</li> <li>shape_flag (parla::cython::tasks)</li> <li>start (parla::cython::tasks)</li> <li>start_flag (parla::cython::tasks)</li> <li>specialize (parla::cython::variants)</li> </ul>"},{"location":"runtime/namespace_members/#t","title":"t","text":"<ul> <li>task (parla::cython::core, parla::cython::tasks)</li> <li>Task (parla::cython::scheduler)</li> <li>TaskSpace (parla::cython::scheduler)</li> <li>TaskAwaitTasks (parla::cython::tasks)</li> <li>task_list (parla::cython::tasks)</li> <li>task_locals (parla::cython::tasks)</li> <li>tasks (parla::cython::tasks)</li> </ul>"},{"location":"runtime/namespace_members/#u","title":"u","text":"<ul> <li>upper_boundary (parla::cython::tasks)</li> </ul>"},{"location":"runtime/namespace_members/#w","title":"w","text":"<ul> <li>worker (parla::cython::core)</li> </ul>"},{"location":"runtime/namespace_members/#_","title":"_","text":"<ul> <li>__cinit__ (parla::cython::core)</li> <li>__dealloc__ (parla::cython::core)</li> <li>__init__ (parla::cython::core)</li> <li>_c_task (parla::cython::core)</li> <li>_inner (parla::cython::core)</li> <li>_inner1 (parla::cython::core)</li> <li>_inner2 (parla::cython::core)</li> <li>_scheduler_locals (parla::cython::scheduler)</li> <li>_task_callback (parla::cython::scheduler)</li> <li>_task_space_globals (parla::cython::tasks)</li> </ul>"},{"location":"runtime/namespace_member_functions/","title":"Namespace Member Functions","text":""},{"location":"runtime/namespace_member_functions/#c","title":"c","text":"<ul> <li>create_device_env (parla::cython::tasks)</li> <li>create_env (parla::cython::tasks)</li> </ul>"},{"location":"runtime/namespace_member_functions/#g","title":"g","text":"<ul> <li>get_device_manager (parla::cython::scheduler)</li> <li>get_scheduler_context (parla::cython::scheduler)</li> <li>get_stream_pool (parla::cython::scheduler)</li> </ul>"},{"location":"runtime/namespace_member_functions/#p","title":"p","text":"<ul> <li>parse_index (parla::cython::tasks)</li> </ul>"},{"location":"runtime/namespace_member_functions/#s","title":"s","text":"<ul> <li>specialize (parla::cython::variants)</li> </ul>"},{"location":"runtime/namespace_member_functions/#_","title":"_","text":"<ul> <li>__cinit__ (parla::cython::core)</li> <li>__dealloc__ (parla::cython::core)</li> <li>__init__ (parla::cython::core)</li> <li>_task_callback (parla::cython::scheduler)</li> </ul>"},{"location":"runtime/namespace_member_variables/","title":"Namespace Member Variables","text":""},{"location":"runtime/namespace_member_variables/#b","title":"b","text":"<ul> <li>barrier (parla::cython::tasks)</li> </ul>"},{"location":"runtime/namespace_member_variables/#c","title":"c","text":"<ul> <li>c_dependencies (parla::cython::core)</li> <li>c_dependency (parla::cython::core)</li> <li>c_dependent (parla::cython::core)</li> <li>c_dependents (parla::cython::core)</li> <li>c_dev (parla::cython::core)</li> <li>c_device (parla::cython::core)</li> <li>c_devices (parla::cython::core)</li> <li>c_priority (parla::cython::core)</li> <li>c_scheduler (parla::cython::core)</li> <li>c_self (parla::cython::core)</li> <li>c_stream (parla::cython::core)</li> <li>c_sync_type (parla::cython::core)</li> <li>c_t (parla::cython::core)</li> <li>c_task (parla::cython::core)</li> <li>category (parla::cython::core)</li> <li>cpp_device (parla::cython::core)</li> <li>CUPY_ENABLED (parla::cython::device_manager)</li> <li>CupyStream (parla::cython::device_manager)</li> <li>cpu (parla::cython::device_manager, parla::cython::tasks)</li> <li>ComputeTask (parla::cython::scheduler)</li> <li>create_env (parla::cython::scheduler)</li> <li>create (parla::cython::tasks)</li> </ul>"},{"location":"runtime/namespace_member_variables/#d","title":"d","text":"<ul> <li>d (parla::cython::core)</li> <li>dependencies (parla::cython::core)</li> <li>dependency (parla::cython::core)</li> <li>dependency_list (parla::cython::core)</li> <li>dependents (parla::cython::core)</li> <li>devices (parla::cython::core)</li> <li>DeviceResource (parla::cython::device_manager)</li> <li>DeviceResourceRequirement (parla::cython::device_manager, parla::cython::tasks)</li> <li>DataMovementTask (parla::cython::scheduler)</li> <li>DeviceType (parla::cython::tasks)</li> <li>depth (parla::cython::tasks)</li> <li>dim (parla::cython::tasks)</li> </ul>"},{"location":"runtime/namespace_member_variables/#f","title":"f","text":"<ul> <li>fname (parla::cython::core)</li> </ul>"},{"location":"runtime/namespace_member_variables/#g","title":"g","text":"<ul> <li>gpu (parla::cython::device_manager)</li> </ul>"},{"location":"runtime/namespace_member_variables/#i","title":"i","text":"<ul> <li>i_event (parla::cython::core)</li> <li>i_stream (parla::cython::core)</li> <li>inner_type1 (parla::cython::core)</li> <li>inner_type2 (parla::cython::core)</li> <li>i (parla::cython::tasks)</li> <li>index (parla::cython::tasks)</li> <li>index_list (parla::cython::tasks)</li> <li>istart (parla::cython::tasks)</li> <li>istep (parla::cython::tasks)</li> <li>istop (parla::cython::tasks)</li> </ul>"},{"location":"runtime/namespace_member_variables/#k","title":"k","text":"<ul> <li>keys (parla::cython::tasks)</li> </ul>"},{"location":"runtime/namespace_member_variables/#l","title":"l","text":"<ul> <li>LOG_DEBUG (parla::cython::core)</li> <li>LOG_ERROR (parla::cython::core)</li> <li>LOG_FATAL (parla::cython::core)</li> <li>LOG_INFO (parla::cython::core)</li> <li>LOG_TRACE (parla::cython::core)</li> <li>LOG_WARN (parla::cython::core)</li> <li>logging_level (parla::cython::core)</li> <li>lower_boundary (parla::cython::tasks)</li> </ul>"},{"location":"runtime/namespace_member_variables/#m","title":"m","text":"<ul> <li>message (parla::cython::core)</li> <li>msg (parla::cython::core)</li> <li>msg1 (parla::cython::core)</li> <li>msg2 (parla::cython::core)</li> <li>max_dim (parla::cython::tasks)</li> </ul>"},{"location":"runtime/namespace_member_variables/#n","title":"n","text":"<ul> <li>name (parla::cython::core)</li> <li>num_deps (parla::cython::core)</li> <li>num_devices (parla::cython::core)</li> <li>nvtx (parla::cython::scheduler)</li> <li>None (parla::cython::tasks)</li> <li>new_index (parla::cython::tasks)</li> <li>new_tasks (parla::cython::tasks)</li> </ul>"},{"location":"runtime/namespace_member_variables/#o","title":"o","text":"<ul> <li>obj (parla::cython::core)</li> <li>obj2 (parla::cython::core)</li> <li>output (parla::cython::tasks)</li> </ul>"},{"location":"runtime/namespace_member_variables/#p","title":"p","text":"<ul> <li>process (parla::cython::core)</li> <li>py_dependency (parla::cython::core)</li> <li>py_dependent (parla::cython::core)</li> <li>py_device (parla::cython::core)</li> <li>PlacementSource (parla::cython::device)</li> <li>PyArchitecture (parla::cython::device_manager, parla::cython::tasks)</li> <li>PyCPUArchitecture (parla::cython::device_manager)</li> <li>PyCPUDevice (parla::cython::device_manager, parla::cython::tasks)</li> <li>PyCUDAArchitecture (parla::cython::device_manager, parla::cython::tasks)</li> <li>PyCUDADevice (parla::cython::device_manager, parla::cython::tasks)</li> <li>PyDevice (parla::cython::device_manager, parla::cython::tasks)</li> <li>PyInnerScheduler (parla::cython::scheduler)</li> <li>PyInnerTask (parla::cython::scheduler)</li> <li>PyInnerWorker (parla::cython::scheduler)</li> </ul>"},{"location":"runtime/namespace_member_variables/#r","title":"r","text":"<ul> <li>remainder (parla::cython::tasks)</li> </ul>"},{"location":"runtime/namespace_member_variables/#s","title":"s","text":"<ul> <li>scheduler (parla::cython::core)</li> <li>self (parla::cython::core)</li> <li>status (parla::cython::core)</li> <li>status_flags (parla::cython::core)</li> <li>Stream (parla::cython::device_manager)</li> <li>shape (parla::cython::tasks)</li> <li>shape_flag (parla::cython::tasks)</li> <li>start (parla::cython::tasks)</li> <li>start_flag (parla::cython::tasks)</li> </ul>"},{"location":"runtime/namespace_member_variables/#t","title":"t","text":"<ul> <li>task (parla::cython::core, parla::cython::tasks)</li> <li>Task (parla::cython::scheduler)</li> <li>TaskSpace (parla::cython::scheduler)</li> <li>TaskAwaitTasks (parla::cython::tasks)</li> <li>task_list (parla::cython::tasks)</li> <li>task_locals (parla::cython::tasks)</li> <li>tasks (parla::cython::tasks)</li> </ul>"},{"location":"runtime/namespace_member_variables/#u","title":"u","text":"<ul> <li>upper_boundary (parla::cython::tasks)</li> </ul>"},{"location":"runtime/namespace_member_variables/#w","title":"w","text":"<ul> <li>worker (parla::cython::core)</li> </ul>"},{"location":"runtime/namespace_member_variables/#_","title":"_","text":"<ul> <li>_c_task (parla::cython::core)</li> <li>_inner (parla::cython::core)</li> <li>_inner1 (parla::cython::core)</li> <li>_inner2 (parla::cython::core)</li> <li>_scheduler_locals (parla::cython::scheduler)</li> <li>_task_space_globals (parla::cython::tasks)</li> </ul>"},{"location":"runtime/namespace_member_typedefs/","title":"Namespace Member Typedefs","text":""},{"location":"runtime/namespace_member_enums/","title":"Namespace Member Enums","text":""},{"location":"runtime/namespace_member_enums/#s","title":"s","text":"<ul> <li>State (Scheduler, Task)</li> <li>Status (Task)</li> <li>SynchronizationType (Task)</li> </ul>"},{"location":"runtime/functions/","title":"Functions","text":""},{"location":"runtime/functions/#c","title":"c","text":"<ul> <li>cpu_busy_sleep (gpu_utility.hpp)</li> </ul>"},{"location":"runtime/functions/#e","title":"e","text":"<ul> <li>event_synchronize (utility.cpp, gpu_utility.hpp)</li> <li>event_wait (utility.cpp, gpu_utility.hpp)</li> </ul>"},{"location":"runtime/functions/#g","title":"g","text":"<ul> <li>gpu_busy_sleep (utility.cpp, gpu_utility.hpp)</li> </ul>"},{"location":"runtime/functions/#i","title":"i","text":"<ul> <li>initialize_log (profiling.hpp)</li> </ul>"},{"location":"runtime/functions/#l","title":"l","text":"<ul> <li>log_scheduler_1 (profiling.hpp)</li> <li>log_scheduler_2 (profiling.hpp)</li> <li>log_scheduler_msg (profiling.hpp)</li> <li>log_task_1 (profiling.hpp)</li> <li>log_task_2 (profiling.hpp)</li> <li>log_task_msg (profiling.hpp)</li> <li>log_worker_1 (profiling.hpp)</li> <li>log_worker_2 (profiling.hpp)</li> <li>log_worker_msg (profiling.hpp)</li> <li>launch_stop_callback (runtime.hpp)</li> <li>launch_task_callback (runtime.hpp)</li> </ul>"},{"location":"runtime/functions/#s","title":"s","text":"<ul> <li>stream_synchronize (utility.cpp, gpu_utility.hpp)</li> </ul>"},{"location":"runtime/functions/#w","title":"w","text":"<ul> <li>write_log (profiling.hpp)</li> </ul>"},{"location":"runtime/macros/","title":"Macros","text":""},{"location":"runtime/macros/#d","title":"d","text":"<ul> <li>DEPENDENCY_BUFFER_SIZE (task.cpp)</li> </ul>"},{"location":"runtime/macros/#l","title":"l","text":"<ul> <li>LOG_ADAPT_DERIVED (profiling.hpp)</li> <li>LOG_ADAPT_ENUM (profiling.hpp)</li> <li>LOG_ADAPT_STRUCT (profiling.hpp)</li> <li>LOG_DEBUG (profiling.hpp)</li> <li>LOG_ERROR (profiling.hpp)</li> <li>LOG_FATAL (profiling.hpp)</li> <li>LOG_INFO (profiling.hpp)</li> <li>LOG_TRACE (profiling.hpp)</li> <li>LOG_WARN (profiling.hpp)</li> </ul>"},{"location":"runtime/macros/#n","title":"n","text":"<ul> <li>NVTX_COLOR (profiling.hpp)</li> <li>NVTX_COLOR_BLACK (profiling.hpp)</li> <li>NVTX_COLOR_BLUE (profiling.hpp)</li> <li>NVTX_COLOR_CYAN (profiling.hpp)</li> <li>NVTX_COLOR_GRAY (profiling.hpp)</li> <li>NVTX_COLOR_GREEN (profiling.hpp)</li> <li>NVTX_COLOR_LIGHT_GREEN (profiling.hpp)</li> <li>NVTX_COLOR_MAGENTA (profiling.hpp)</li> <li>NVTX_COLOR_ORANGE (profiling.hpp)</li> <li>NVTX_COLOR_PURPLE (profiling.hpp)</li> <li>NVTX_COLOR_RED (profiling.hpp)</li> <li>NVTX_COLOR_TEAL (profiling.hpp)</li> <li>NVTX_COLOR_WHITE (profiling.hpp)</li> <li>NVTX_COLOR_YELLOW (profiling.hpp)</li> <li>NVTX_RANGE (profiling.hpp)</li> </ul>"},{"location":"runtime/macros/#p","title":"p","text":"<ul> <li>PARLA_CONTAINERS_HPP (containers.hpp)</li> <li>PARLA_DEVICE_HPP (device.hpp)</li> <li>PARLA_DEVICE_MANAGER_HPP (device_manager.hpp)</li> <li>PARLA_PHASES_HPP (phases.hpp)</li> <li>PARLA_BACKEND_HPP (runtime.hpp)</li> </ul>"},{"location":"runtime/macros/#s","title":"s","text":"<ul> <li>SCHEDULER (profiling.hpp)</li> </ul>"},{"location":"runtime/macros/#t","title":"t","text":"<ul> <li>TASK (profiling.hpp)</li> </ul>"},{"location":"runtime/macros/#w","title":"w","text":"<ul> <li>WORKER (profiling.hpp)</li> </ul>"},{"location":"runtime/variables/","title":"Variables","text":""},{"location":"runtime/variables/#a","title":"a","text":"<ul> <li>architecture_names (device.hpp)</li> <li>architecture_types (device.hpp)</li> <li>AccessMode (runtime.hpp)</li> </ul>"},{"location":"runtime/variables/#d","title":"d","text":"<ul> <li>DevID_t (device.hpp, device_manager.hpp)</li> <li>DeviceType (device.hpp)</li> </ul>"},{"location":"runtime/variables/#l","title":"l","text":"<ul> <li>LauncherState (phases.hpp)</li> <li>launchfunc_t (runtime.hpp)</li> </ul>"},{"location":"runtime/variables/#m","title":"m","text":"<ul> <li>MemorySz_t (device.hpp)</li> <li>MapperState (phases.hpp)</li> <li>MemoryReserverState (phases.hpp)</li> <li>movement_resources (resources.hpp)</li> </ul>"},{"location":"runtime/variables/#n","title":"n","text":"<ul> <li>NUM_DEVICE_TYPES (device.hpp)</li> <li>non_persistent_resources (resources.hpp)</li> </ul>"},{"location":"runtime/variables/#p","title":"p","text":"<ul> <li>persistent_resources (resources.hpp)</li> <li>PointerList (runtime.hpp)</li> </ul>"},{"location":"runtime/variables/#r","title":"r","text":"<ul> <li>ResourcePool_t (device.hpp)</li> <li>RuntimeReserverState (phases.hpp)</li> <li>Resource (resources.hpp)</li> <li>ResourceCategory (resources.hpp)</li> <li>Resource_t (resources.hpp)</li> <li>resource_names (resources.hpp)</li> </ul>"},{"location":"runtime/variables/#s","title":"s","text":"<ul> <li>Score_t (policy.hpp)</li> <li>SpaceList (runtime.hpp)</li> <li>stopfunc_t (runtime.hpp)</li> </ul>"},{"location":"runtime/variables/#t","title":"t","text":"<ul> <li>TaskList (parray.hpp, runtime.hpp)</li> <li>TaskQueue (runtime.hpp)</li> <li>TaskState (runtime.hpp)</li> <li>TaskStateList (runtime.hpp)</li> </ul>"},{"location":"runtime/variables/#v","title":"v","text":"<ul> <li>VCU_t (device.hpp)</li> </ul>"},{"location":"runtime/variables/#w","title":"w","text":"<ul> <li>WorkerList (runtime.hpp)</li> <li>WorkerPool_t (runtime.hpp)</li> <li>WorkerQueue (runtime.hpp)</li> </ul>"},{"location":"runtime/links/","title":"Links","text":"<ul> <li>Related Pages<ul> <li>Parla Documentation</li> </ul> </li> <li>Modules</li> <li>Class List<ul> <li>class ArchitectureRequirement</li> <li>class CPUDevice</li> <li>class CUDADevice</li> <li>class CopyableAtomic</li> <li>class Device</li> <li>class DeviceManager</li> <li>class DeviceQueue</li> <li>class DeviceRequirement</li> <li>class InnerDataTask</li> <li>class InnerScheduler</li> <li>class InnerTask</li> <li>class InnerTaskSpace</li> <li>class InnerWorker</li> <li>class Launcher</li> <li>class LauncherStatus</li> <li>class LocalityLoadBalancingMappingPolicy</li> <li>class Mapper</li> <li>class MapperStatus</li> <li>class MappingPolicy</li> <li>class MemoryReserver</li> <li>class MemoryReserverStatus</li> <li>class MultiDeviceRequirements</li> <li>class PArrayTracker</li> <li>class PhaseManager</li> <li>class PhaseStatus</li> <li>class PlacementRequirementBase</li> <li>class PlacementRequirementCollections</li> <li>class ProtectedQueue</li> <li>class ProtectedVector</li> <li>class ResourcePool</li> <li>class RuntimeReserver</li> <li>class RuntimeReserverStatus</li> <li>namespace Scheduler</li> <li>class Scheduler::Status</li> <li>class SchedulerPhase</li> <li>class SinglePlacementRequirementBase</li> <li>namespace Task</li> <li>class Task::StatusFlags</li> <li>class TaskBarrier</li> <li>class WorkerPool</li> <li>namespace chrono</li> <li>namespace parla</li> <li>namespace parla::cython<ul> <li>namespace parla::cython::containers</li> <li>namespace parla::cython::core</li> <li>class parla::cython::core::CyDataMovementTaskAttributes</li> <li>class parla::cython::core::CyTaskList</li> <li>class parla::cython::core::DataMovementTaskAttributes</li> <li>class parla::cython::core::PyInnerScheduler</li> <li>class parla::cython::core::PyInnerTask</li> <li>class parla::cython::core::PyInnerWorker</li> <li>class parla::cython::core::PyTaskBarrier</li> <li>class parla::cython::core::PyTaskSpace</li> <li>class parla::cython::core::Resources</li> <li>namespace parla::cython::cyparray</li> <li>class parla::cython::cyparray::CyPArray</li> <li>namespace parla::cython::cyparray_state</li> <li>class parla::cython::cyparray_state::CyPArrayState</li> <li>namespace parla::cython::device</li> <li>class parla::cython::device::CupyStream</li> <li>class parla::cython::device::CyCPUDevice</li> <li>class parla::cython::device::CyCUDADevice</li> <li>class parla::cython::device::CyDevice</li> <li>class parla::cython::device::DeviceResource</li> <li>class parla::cython::device::DeviceResourceRequirement</li> <li>class parla::cython::device::PyArchitecture</li> <li>class parla::cython::device::PyCPUArchitecture</li> <li>class parla::cython::device::PyCPUDevice</li> <li>class parla::cython::device::PyCUDAArchitecture</li> <li>class parla::cython::device::PyCUDADevice</li> <li>class parla::cython::device::PyDevice</li> <li>class parla::cython::device::Stream</li> <li>namespace parla::cython::device_manager</li> <li>class parla::cython::device_manager::CyDeviceManager</li> <li>class parla::cython::device_manager::PrintableFrozenSet</li> <li>class parla::cython::device_manager::PyDeviceManager</li> <li>class parla::cython::device_manager::StreamPool</li> <li>namespace parla::cython::scheduler</li> <li>class parla::cython::scheduler::ControllableThread</li> <li>class parla::cython::scheduler::Scheduler</li> <li>class parla::cython::scheduler::SchedulerContext</li> <li>class parla::cython::scheduler::SchedulerException</li> <li>class parla::cython::scheduler::TaskBodyException</li> <li>class parla::cython::scheduler::WorkerThread</li> <li>class parla::cython::scheduler::WorkerThreadException</li> <li>class parla::cython::scheduler::_SchedulerLocals</li> <li>namespace parla::cython::tasks</li> <li>class parla::cython::tasks::AtomicTaskList</li> <li>class parla::cython::tasks::AtomicTaskSpace</li> <li>class parla::cython::tasks::BackendTaskList</li> <li>class parla::cython::tasks::BackendTaskSpace</li> <li>class parla::cython::tasks::CPUEnvironment</li> <li>class parla::cython::tasks::ComputeTask</li> <li>class parla::cython::tasks::DataMovementTask</li> <li>class parla::cython::tasks::GPUEnvironment</li> <li>class parla::cython::tasks::Task</li> <li>class parla::cython::tasks::TaskCollection</li> <li>class parla::cython::tasks::TaskCompleted</li> <li>class parla::cython::tasks::TaskCreated</li> <li>class parla::cython::tasks::TaskEnvironment</li> <li>class parla::cython::tasks::TaskException</li> <li>class parla::cython::tasks::TaskList</li> <li>class parla::cython::tasks::TaskMapped</li> <li>class parla::cython::tasks::TaskReady</li> <li>class parla::cython::tasks::TaskReserved</li> <li>class parla::cython::tasks::TaskRunahead</li> <li>class parla::cython::tasks::TaskRunning</li> <li>class parla::cython::tasks::TaskSpace</li> <li>class parla::cython::tasks::TaskSpawned</li> <li>class parla::cython::tasks::TaskState</li> <li>class parla::cython::tasks::TerminalEnvironment</li> <li>class parla::cython::tasks::_TaskLocals</li> <li>namespace parla::cython::variants</li> <li>class parla::cython::variants::VariantDefinitionError</li> <li>class parla::cython::variants::_VariantFunction</li> </ul> </li> <li>namespace parray</li> <li>class parray::InnerPArray</li> <li>class parray::PArrayState</li> <li>namespace std</li> <li>namespace std::chrono_literals</li> <li>namespace std::literals::string_view_literals</li> <li>namespace threading</li> </ul> </li> <li>Namespace ListNamespace List</li> <li>Namespace Members</li> <li>Namespace Member Functions</li> <li>Namespace Member Variables</li> <li>Namespace Member Typedefs</li> <li>Namespace Member Enumerations</li> <li>Class Index</li> <li>Class Hierarchy</li> <li>Class Members</li> <li>Class Member Functions</li> <li>Class Member Variables</li> <li>Class Member Typedefs</li> <li>Class Member Enumerations</li> <li>Files<ul> <li>src</li> <li>src/c<ul> <li>src/c/backend</li> <li>device.cpp</li> <li>device.cpp source</li> <li>device_manager.cpp</li> <li>device_manager.cpp source</li> <li>parray.cpp</li> <li>parray.cpp source</li> <li>parray_state.cpp</li> <li>parray_state.cpp source</li> <li>parray_tracker.cpp</li> <li>parray_tracker.cpp source</li> <li>phases.cpp</li> <li>phases.cpp source</li> <li>policy.cpp</li> <li>policy.cpp source</li> <li>resource_requirements.cpp</li> <li>resource_requirements.cpp source</li> <li>resources.cpp</li> <li>resources.cpp source</li> <li>scheduler.cpp</li> <li>scheduler.cpp source</li> <li>src/c/backend/impl_none<ul> <li>utility.cpp</li> <li>utility.cpp source</li> </ul> </li> <li>src/c/backend/include<ul> <li>atomic_wrapper.hpp</li> <li>atomic_wrapper.hpp source</li> <li>containers.hpp</li> <li>containers.hpp source</li> <li>device.hpp</li> <li>device.hpp source</li> <li>device_manager.hpp</li> <li>device_manager.hpp source</li> <li>device_queues.hpp</li> <li>device_queues.hpp source</li> <li>gpu_utility.hpp</li> <li>gpu_utility.hpp source</li> <li>parray.hpp</li> <li>parray.hpp source</li> <li>parray_state.hpp</li> <li>parray_state.hpp source</li> <li>parray_tracker.hpp</li> <li>parray_tracker.hpp source</li> <li>phases.hpp</li> <li>phases.hpp source</li> <li>policy.hpp</li> <li>policy.hpp source</li> <li>profiling.hpp</li> <li>profiling.hpp source</li> <li>resource_requirements.hpp</li> <li>resource_requirements.hpp source</li> <li>resources.hpp</li> <li>resources.hpp source</li> <li>runtime.hpp</li> <li>runtime.hpp source</li> </ul> </li> <li>task.cpp</li> <li>task.cpp source</li> </ul> </li> <li>src/python<ul> <li>src/python/parla</li> <li>src/python/parla/cython<ul> <li>containers.pyx</li> <li>containers.pyx source</li> <li>core.pyx</li> <li>core.pyx source</li> <li>cyparray.pyx</li> <li>cyparray.pyx source</li> <li>cyparray_state.pyx</li> <li>cyparray_state.pyx source</li> <li>device.pyx</li> <li>device.pyx source</li> <li>device_manager.pyx</li> <li>device_manager.pyx source</li> <li>scheduler.pyx</li> <li>scheduler.pyx source</li> <li>tasks.pyx</li> <li>tasks.pyx source</li> <li>variants.pyx</li> <li>variants.pyx source</li> </ul> </li> </ul> </li> </ul> </li> <li>File Variables</li> <li>File Functions</li> <li>File Macros</li> </ul>"}]}